{"./":{"url":"./","title":"Welcome","keywords":"","body":"一个测试开发工程师的自我修养 Welcome 时间飞逝，转眼间已经工作五年多了。 还记得刚毕业第一年时，还维护了一个个人博客主页，定期记录一些学习笔记和心得体会，但随着工作越来越忙，近几年总结的文章已经越来越少了。 为了能够不断自己积累和成长，另外也希望我自己的一些经验可以与大家共享，现在又重新开启维护当前这个gitbook了。 希望能够坚持下去吧，欢迎大家与我随时互动~ 本书结构 在当前这个Gitbook中，我会以一篇篇笔记的形式来组成，大家可以根据需要来查询和阅读。 整体来看，本书会分为如下几大部分： 编程语言篇 数据库篇 中间件篇 操作系统与内核篇 AI篇 云原生篇 工具杂谈篇 测试杂谈篇 测试服务篇 另外需要说的是，由于目前每天的工作也比较繁忙，因此本书的更新其实不是安装章节来顺序编写和更新的。相反，我则会根据当天或近期接触的一些技术内容进行相关内容的编写，因此更新顺序可能会略显杂乱。 还有就是本身中不会对具体知识进行过于深入的分析与讲解，但是在相关章节中，都会有一些参考的链接和资源，如果希望能够更加深入的了解和学习某些主题的知识时，可以根据链接资源进行自行学习。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/beginning.html":{"url":"language/python/beginning.html","title":"python基础","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/daemon.html":{"url":"language/python/daemon.html","title":"Python多线程中daemon属性的作用","keywords":"","body":"Python多线程中daemon属性的作用 基本概念 在详细讲解Python多线程中deamon属性之前，我们首先需要了解一些基本概念。 什么是线程、什么是进程？ 进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。 线程（Thread）是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 每个进程至少包含一个线程，并最为程序的入口，这个线程我们称之为该进程的主线程，其他线程称之为工作线程。 什么是子线程？ 了解了\"进程\"和\"线程\"的基本概念后，下面我们需要了解另一个概念\"子线程\"。 如果线程A启动了另一个线程，即线程B。那么，线程A就是线程B的父线程，而线程B就是线程A的子线程。 daemon的作用 daemon又称为\"守护程序\"，对于daemon线程而言，也就是我们说的守护线程。 那么守护线程有什么作用呢？它又是在守护什么呢？ 简单来说，我们有时希望一个线程能够伴随主线程常驻执行，比如周期性进行一些相关任务检查等。这时，我们可能就会需要一个while True循环来实现这一功能。 但是这个线程最终还是给退出呢~ 退出的时机应该就是主线程退出的时间。 这时，我们就需要用到守护线程了。 总结来说，daemon线程适用于一些随父线程常驻的线程，本身线程无需自动退出。 只有当父线程退出后，会跟随父线程一起退出的场景。 示例说明 下面，我们来通过一些python示例代码来演示相关daemon属性相关的作用。 首先，我们来看一下Thread类的初始化函数： class Thread: \"\"\"A class that represents a thread of control. \"\"\" _initialized = False def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None): # ... if daemon is not None: self._daemonic = daemon else: self._daemonic = current_thread().daemon # ... 上面的代码中，仅仅保留了__init__函数中与daemon参数相关的部分。 可以看到，当daemon值为None的时候，实际上相关的与继承了父线程的daemon属性。 除了None之类，dameon参数接收的取值为True和False。 下面，我们来分别看下daemon取值为true或false时，本身线程的行为是什么样的。 daemon为False时 当daemon为False时，父线程在运行完毕后，会等待所有子线程退出才结束程序。 import threading import time def foo(): for i in range(3): print('i={},foo thread daemon is {}'.format(i,threading.current_thread().isDaemon())) time.sleep(1) t = threading.Thread(target=foo,daemon=False) t.start() print(\"Main thread daemon is {}\".format(threading.current_thread().isDaemon())) print(\"Main Thread Exit.\") \"\"\" 运行结果： i=0,foo thread daemon is False Main thread daemon is False Main Thread Exit. i=1,foo thread daemon is False i=2,foo thread daemon is False \"\"\" 根据运行结果的顺序可以得知，主程序在线程完线程对象后就立即启动了，然后子线程返回了结果中第一行内容，然后sleep 1秒模拟 IO，这时CPU发现子线程阻塞了，就立即切到主线程继续执行。 主线程先后打印第二行和第三行，此时主线程的代码已经执行到结尾。 然后，因为主线程为子线程设置了daemon=False属性，这时就又发生了线程切换到子线程，子线程先后执行完第四行和第五行，然后子线程就完全执行完毕。 主线程看到子线程退出以后，也立即退出，整个程序结束。 换句话说，如果此时的子线程是一个无限循环的话，该程序将会永远无法退出。 daemon为True时 import threading import time def foo(): for i in range(3): print('i={},foo thread daemon is {}'.format(i,threading.current_thread().isDaemon())) time.sleep(1) t = threading.Thread(target=foo,daemon=True) t.start() print(\"Main thread daemon is {}\".format(threading.current_thread().isDaemon())) print(\"Main Thread Exit.\") \"\"\" 运行结果 ： i=0,foo thread daemon is True Main thread daemon is False Main Thread Exit. \"\"\" 从运行结果来看，当子线程设置daemon属性为True时，即主线程不关心子线程运行状态，主线程退出，子线程也必须跟着退出。 所以运行结果中子线程只执行了一句语句，就轮到主线程，主线程执行完最后两句，就立即退出，整个程序结束。 嵌套子线程的daemon为False时的情况 下面，我们来看一种相对复杂的情况，主线程首先Fork出daemon为True的线程，然后该线程继续Fork出多个daemon为False的线程。 import threading import time def bar(): while True: # 无限循环的子子线程 print('【bar】 daemon is {}'.format(threading.current_thread().isDaemon())) time.sleep(1) def foo(): for i in range(3): #启动3个子线程 print('i={},【foo】 thread daemon is {}'.format(i,threading.current_thread().isDaemon())) t1 = threading.Thread(target=bar,daemon=False) t1.start() t = threading.Thread(target=foo,daemon=True) t.start() print(\"Main thread daemon is {}\".format(threading.current_thread().isDaemon())) time.sleep(2) print(\"Main Thread Exit.\") \"\"\" 运行结果： i=0,【foo】 thread daemon is True Main thread daemon is False 【bar】 daemon is False i=1,【foo】 thread daemon is True 【bar】 daemon is False i=2,【foo】 thread daemon is True 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False Main Thread Exit. 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False 【bar】 daemon is False .......无限循环.... \"\"\" 主线程本来是不等子线程执行完毕的，但子线程要等待子子线程执行完毕，子子线程又是无限循环。 所以最终主线程也拦不住子子线程一直疯狂的输出，这就好比爷爷管得了儿子，但管不了孙子呀。 总结 通过上面的讲解，相信你已经了解了什么是daemon线程，以及如何选择是否创建daemon线程。 希望上面的内容对你有一些帮助。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/re.html":{"url":"language/python/re.html","title":"Python正则表达式详解","keywords":"","body":"Python正则表达式详解 什么是正则表达式 正则表达式就是描述字符串排列的一套规则。 主要目的是用于字符串匹配。 Python中，使用re模块来使用正则表达式。 本文主要从以下几个方面进行介绍：原子、元字符、模式修正符、贪婪模式和懒惰模式、Python中re模块的使用来介绍。 原子 原子是正则表达式中最基本的组成单位，每个正则表达式中最少要包含一个原子。 常见的原子包含以下几类： 1.普通字符 2.非打印字符 3.通用字符 4.原子表 普通字符 import re pattern = \"shi\" string = \"http://www.missshi.cn\" result = re.search(pattern, string) print(result.span()) # (15, 18) 其中，\"shi\"就是一组普通字符，普通字符就是指的是没有特殊含义的字符串。 非打印字符 import re pattern = \"\\n\" string = \"\"\"http://www.missshi.cn nianshi \"\"\" result = re.search(pattern, string) print(result.span()) # (21, 22) 其中，\"\\n\"就是一个非打印字符，或者也叫做转义字符或不可见字符。 常用的非打印字符见下表： 符号 含义 \\n 换行符 \\t Tab制表符 通用字符 import re pattern = \"\\w\\wshi\\D\" string = \"www.missshi.cn\" result = re.search(pattern, string) print(result.span()) #(6, 12) 其中，\\w、\\D等字符就是通用字符，通用字符只是可以通过一个字符来匹配一类普通字符的字符。 常用的通用字符如下表： 符号 含义 . 匹配除换行符外的全部符号 \\w 匹配任意一个字母、数字或下划线 \\W 匹配任意一个除字母、数字或下划线以外的字符 \\d 匹配任意一个十进制数 \\D 匹配任意一个除十进制数以外的字符 \\s 匹配任意一个空白字符 \\S 匹配任意一个除空白字符以外的字符 原子表 import re pattern = \"[abcs]shi\" string = \"www.missshi.cn\" result = re.search(pattern, string) print(result.span()) # (7, 11) 其中，\"[abcs]\"表示的就是一个原子表。 原子表可以定义一组地位平等的原子，在匹配时，取任意一个原子进行匹配。 具体来说，原子表由[]表示，[]内的原子地位相同。 此外，[^]时，表示的是除了括号内里面的原子外其余均可以匹配。 元字符 元字符是指在正则表达式中具有一些特殊含义的字符。 常见元字符见如下列表： 符号 含义 ^ 匹配字符串开始位置 $ 匹配字符串结束为止 * 匹配0次、1次或多次前面的原子 ? 匹配0次或1次前面的原子 + 匹配1次或多次前面的原子 {n} 匹配前面的原子出现n次 {n,} 匹配前面的原子出现n次或以上 {n,m} 匹配前面的原子出现n次到m次 | 模式选择符（从多个模式中选择一个） () 模式单元符（将多个原子合并为一个原子块） 模式修正 模式修正符是指在不改变正则表达式的情况下，通过模式修正符改变正则表达式的含义，从而实现一些匹配结果的调整等功能。 import re pattern = \"Sshi\" string = \"www.missshi.cn\" result = re.search(pattern, string) print(result) # None import re pattern = \"Sshi\" string = \"www.missshi.cn\" result = re.search(pattern, string, re.I) print(result.span()) # (7, 11) 可以看到，其中第一部分并没有匹配到内容，但是在第二部分中确匹配到了对应的字符串。 这就是re.I模式修正的功能，其中re.I表示了忽略大小写的匹配。 一些常见的模式修正符的含义如下： 符号 含义 I 匹配字符串开始位置 M 匹配字符串结束为止 L 匹配0次、1次或多次前面的原子 U 匹配0次或1次前面的原子 S 匹配1次或多次前面的原子 贪婪模式与懒惰模式 贪婪模式是指匹配尽可能长的长度。设置方法：p.*y。 懒惰模式是指采用就近匹配原则，找到即终止。设置方法：p.*?y。 import re pattern = \"w.*s\" string = \"www.missshiw.cn\" result = re.search(pattern, string) print(result.span()) # (0, 9) import re pattern = \"w.*?s\" string = \"www.missshiw.cn\" result = re.search(pattern, string) print(result.span()) # (0, 7) re模块详解 Python中常用的正则表达式函数有：re.match()，re.search()，findall()，re.sub()等。 re.match() re.match是从源字符串的第一个字符开始匹配，相当于在正则表达式的开头自动添加^。 示例： import re pattern = \"shi\" string = \"www.missshi.cn\" result = re.match(pattern, string) print(result) # None import re pattern = \"w.*shi\" string = \"www.missshi.cn\" result = re.match(pattern, string) print(result.span()) # (0, 11) re.search() re.search是全局正则匹配，在之前的示例中都已经演示了。 findall方式 之前的匹配方法都仅仅查找到第一个匹配对象，而如果有多个匹配对象，无法全部找出。 全部匹配的方式如下: 使用re.compile()对正则表达式进行预编译。 用编译生成的对象的findall()方法找出所有符合模式的结果。 示例代码如下： import re pattern = \"shi\" patt = re.compile(pattern) result = patt.findall(\"nianshinianshinianshi\") print(result) # ['shi', 'shi', 'shi'] re.sub() 如果希望对正则表达式匹配到的部分进行替换，则需要利用到re.sub()函数。 函数原型：re.sub(pattern, rep, string, max) 参数说明： pattern: 要匹配的模式 rep: 要替换成的字符串 string: 被替换的原始字符串 max: 最大替换次数，默认全部替换 示例如下： import re pattern = \"shi\" result = re.sub(pattern, \"nan\", \"nianshinianshinianshi\", 2) print(result) # niannanniannannianshi By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/datetime.html":{"url":"language/python/datetime.html","title":"Python时间日期详解","keywords":"","body":"Python时间日期详解 在Python开发中，我们常常会用到各种时间日期相关的工具。我们将在本节中对时间、日期相关的常用操作进行一系列的总结。 其中，本文主要涉及的Python库包括：time、datetime等。 获取当前的时间戳 import time print(time.time()) 获取当前时间的字符串格式 import time print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())) 获取当前日期的字符串格式 import time print(time.strftime(\"%Y-%m-%d\", time.localtime())) 将字符串转化为时间戳 import time time_str = \"2019-5-10 23:40:00\" # 先转换为时间数组 timeArray = time.strptime(time_str, \"%Y-%m-%d %H:%M:%S\") # 转换为时间戳 timeStamp = int(time.mktime(timeArray)) 对时间日期做加减操作 import datetime current_datetime = datetime.datetime.now() tomorrow_datetime = current_datetime + datetime.timedelta(days=1, hours=0, minutes=0, seconds=0) datetime 转化为字符串格式 import datetime current_datetime = datetime.datetime.now() print(current_datetime.strftime(\"%Y-%m-%d %H:%S:%M\")) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/operate_file.html":{"url":"language/python/operate_file.html","title":"Python自动检测文件编码格式并打开文件","keywords":"","body":"Python自动检测文件编码格式并打开文件 在 Python 中，我们常常会遇到一个问题，就是读取文件内容时，提示我们编码格式不正确，无法正常解析。 那么，针对这种情况有没有通用的解决办法呢？当时是有的。 chardet 在 Python 中，有一个第三方库 chardet 专门用于文本内容的编码格式检测: chardet 。 其基本的使用示例如下: import chardet file_path = \"operate_file.md\" with open(file_path, \"rb\") as f: print(chardet.detect(f.read())) 其得到的输出格式如下: {'encoding': 'utf-8', 'confidence': 0.99, 'language': ''} 其中，encoding 就是我们需要的文件的编码格式，confidence 表示置信度。 因此，我们只需要处理一个文件时，首先先读取文件的二进制格式，然后用 chardet 检测文件的编码格式，在用得到的编码格式读写文件即可。 完成示例 一个完整的示例如下: import chardet file_path = \"operate_file.md\" # 计算编码格式 with open(file_path, \"rb\") as f: encoding = chardet.detect(f.read())[\"encoding\"] # 读文件 with open(file_path, \"r\", encoding=encoding) as f: content = f.read() # 写文件 with open(file_path, \"w\", encoding=encoding) as f: f.write(content) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/os_system.html":{"url":"language/python/os_system.html","title":"Python判断当前操作系统","keywords":"","body":"Python判断当前操作系统 前言 我们都知道，Python是一门跨平台的语言，Python解释器本身几乎可以在所有的操作系统中运行。 然而，对于不同的操作系统而言，为了完成相同的任务可能需要执行命令可能并不一致，因此，我们往往需要在Python代码中判断出当前执行的平台，然后针对当前平台的不同编写适合于对应平台的逻辑。 在Python语言中，有多个内置库都能查询操作系统版本信息，下面我们来一一说明，你可以跟进需求选择合适的方式。 sys模块 下面，我们先看用一个示例开始我们的说明： import sys print(sys.platform) 在上面的代码中，我们引入了Python自带的库sys，并读取了sys.platform属性。 那么，sys.platform属性具体能由哪些值呢？常见的值如下: System sys.platform的值 AIX aix Linux linux Windows win32 Windows/Cygwin cygwin macOS darwin Ps: 需要说明的是，sys.platform属性值是在Python安装时就已经生成的。 os模块 除了sys模块外，os模块也提供了与系统有关的版本信息。 同样用一个示例开始说明： import os print(os.uname()) 其中，os模块的uname方法会返回一个对象来说明当前操作系统的信息。其中该对象中包含如下字段： sysname: 操作系统名称，如Darwin，Linux等 nodename: 机器名称，同hostname release: 操作系统版本号，如19.3.0 version: 操作系统版本信息，如Darwin Kernel Version 19.3.0: Thu Jan 9 20:58:23 PS T 2020; root:xnu-6153.81.5~1/RELEASE_X86_64 machine: 硬件标识信息，如x86_64 Ps: uname方法返回的对象用索引查询对应信息，也可以用.操作符查询对应属性值，例如： import os version_info = os.uname() print(version_info.sysname) print(version_info[1]) platform模块 除了sys和os模块外，Python还提供了一个更加强大的库专门用于查询操作系统相关信息。 下面，我们来通过实例依次讲解相关的方法。 import platform print(platform.python_version()) # 查询Python版本，如3.8.5 print(platform.architecture()) # 查询可执行程序的结构，如('32bit', 'WindowsPE') print(platform.node()) # 查询机器名称 print(platform.platform()) # 获取操作系统名称及版本号，macOS-10.15.3-x86_64-i386-64bit print(platform.processor()) # 查询处理器信息，如i386 print(platform.system()) # 查询操作系统信息，如Darwin print(platform.release()) # 查询操作系统版本号，如19.3.0 print(platform.version()) # 查询操作系统版本信息 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/directory.html":{"url":"language/python/directory.html","title":"Python目录相关操作总结","keywords":"","body":"Python目录相关操作总结 前言 在 Python 程序中，我们常常会涉及到一些目录相关的操作，例如，在当前目录下创建一个文件等。 那么，怎么找出当前文件所在目录、当前程序运行目录等等呢？下面，我们来依次看一下。 当前文件所在目录 在 python 文件中，查询当前文件所在目录时，需要涉及到以下相关知识。 __file__ 内置变量 os.path.abspath() 函数 os.path.dirname() 函数 __file__ 内置变量可以用于查询当前文件的地址。 若显示执行Python，会得到绝对路径; 若按相对路径来直接执行脚本./pyws/path_demo.py，会得到相对路径。 os.path.abspath() 函数接收一个文件地址作为输入参数，返回文件的绝对路径。 os.path.dirname() 函数接收一个文件地址作为输入参数，返回文件所属的目录。 完整示例如下: import os current_dir = os.path.dirname(os.path.abspath(__file__)) print(current_dir) 当前程序运行目录 在 python 文件中，查询当前程序的运行目录相对简单，可以直接调用如下函数即可。 import os workdir = os.getcwd() print(workdir) Ps: 该函数会返回当前程序的工作目录。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/import.html":{"url":"language/python/import.html","title":"Python import详解","keywords":"","body":"Python import详解 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/python_version.html":{"url":"language/python/python_version.html","title":"Python程序中判断当前Python版本","keywords":"","body":"Python程序中判断当前Python版本 前言 随时 Python2 的不再维护，越来越多的项目逐渐在向 Python3 迁移。 然而，很多时间我们项目已经存在了各种依赖，因此 Python2 -> Python3 的迁移过程往往要经历一段时间， 而这一段时间内，我们需要保证我们的程序对 Python2 和 Python3 均能够兼容。 那么，针对部分 Python2 和 Python3 不兼容的 API 而言，我们如何做到程序兼容呢？ 一个简单的方法是在程序中获取当前 Python 的版本，并针对不同的版本编写不同的代码。 查询 Python 的版本 Python 程序中，查询 Python 的版本非常简单，查询示例如下： import sys python_version = sys.version_info print(python_version.major) # 2 print(python_version.minor) # 7 print(python_version.micro) # 18 程序适配 当我们能够查询到当前的 Python 版本后，则可以根据不同的 Python 版本进行适配，以命令执行为例: import sys python_version = sys.version_info if python_version.major == 2: import commands status, output = commands.getstatusoutput(\"pwd\") else: import subprocess status, output = subprocess.getstatusoutput(\"pwd\") 在上面的例子中，我们针对 Python2 和 Python3 支持的不同命令执行 API 进行了相关的适配。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/requests.html":{"url":"language/python/requests.html","title":"Python HTTP请求重试机制","keywords":"","body":"Python HTTP请求重试机制 概述 我们都知道，Python 中有一个非常强大的 HTTP 请求的第三方库，就是 requests 库。 requests 库可以帮助我们轻松的发送各种 HTTP 请求。 但是，我们都知道，HTTP 是一种网络协议，既然依赖网络，那就一定不会是永远稳定的。 因此，我们经常需要做的一个事情就是在发送请求时，可以增加容错机制，而最常用的容错机制就是 重试 了。 在本文中，我们将会讲解如何优雅的使用 requests 库进行请求重试。 HTTPAdapter 与 Retry 对于 requests 库而言，添加重启策略其实很简单，我们仅需要创建一个 HTTPAdapter 并传递 Session 生效即可。 一个 demo 示例如下： import requests from requests.adapters import HTTPAdapter from requests.packages.urllib3.util.retry import Retry retry_strategy = Retry( total=3, status_forcelist=[429, 500, 502, 503, 504], method_whitelist=[\"HEAD\", \"GET\", \"OPTIONS\"] ) adapter = HTTPAdapter(max_retries=retry_strategy) session = requests.Session() session.mount(\"https://\", adapter) session.mount(\"http://\", adapter) response = session.get(\"https://en.wikipedia.org/w/api.php\") 对于一个默认的 Retry 类而言，本身已经提供了相对合理的默认值，但是它其实是高度可配置的。 下面，我们来详细说明一下 Retry 类可以接收的配置参数。 total: 总计重试的次数，默认为10。 status_forcelist: 针对指定的 HTTP 响应码进行重试，默认为 [413, 429, 503]。 method_whitelist: 需要进行重试的 HTTP 请求类型，默认为除去 POST 之外的外部类型。 backoff_factor: 用于表示在请求失败后多长时间后进行重试，计算规则为 backoff_factor (2 * ({number of total retries} - 1)) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python/decorate.html":{"url":"language/python/decorate.html","title":"Python 装饰器实战","keywords":"","body":"Python 装饰器实战 概述 在 Python 中，装饰器可以说是被提及的最多的功能之一了。它是面向切面编程的利器。 那么在本文中，我们将会对 Python 的装饰器进行详细的讲解说明。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python-thirdparty/beginning.html":{"url":"language/python-thirdparty/beginning.html","title":"常用Python第三方库","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python-thirdparty/python-nmap.html":{"url":"language/python-thirdparty/python-nmap.html","title":"python-nmap进行端口扫描","keywords":"","body":"python-nmap进行端口扫描 python-nmap是一个Python第三方库，可以用于使用nmap进行端口扫描。 它可以轻松地操作nmap进行扫描，对于想要自动执行扫描任务和报告的系统管理员而言，它将是一个理想的工具，同时它还支持nmap脚本输出。 安装 python-nmap作为一个Python的第三方库可以用Python标准的包管理工具进行安装： pip3 install python-nmap 快速使用 import nmap # import nmap.py module nm = nmap.PortScanner() # 实例化 nmap.PortScanner 对象 nm.scan('127.0.0.1', '22-443') # 扫描 127.0.0.1 的 22 至 443 端口 nm.command_line() # 获取命令行指令 : nmap -oX - -p 22-443 127.0.0.1 nm.scaninfo() # 获取 nmap 扫描信息 {'tcp': {'services': '22-443', 'method': 'connect'}} nm.all_hosts() # 获取扫描到的所有机器 nm['127.0.0.1'].hostname() # get one hostname for host 127.0.0.1, usualy the user record nm['127.0.0.1'].hostnames() # get list of hostnames for host 127.0.0.1 as a list of dict # [{'name':'hostname1', 'type':'PTR'}, {'name':'hostname2', 'type':'user'}] nm['127.0.0.1'].hostname() # get hostname for host 127.0.0.1 nm['127.0.0.1'].state() # get state of host 127.0.0.1 (up|down|unknown|skipped) nm['127.0.0.1'].all_protocols() # get all scanned protocols ['tcp', 'udp'] in (ip|tcp|udp|sctp) nm['127.0.0.1']['tcp'].keys() # get all ports for tcp protocol nm['127.0.0.1'].all_tcp() # get all ports for tcp protocol (sorted version) nm['127.0.0.1'].all_udp() # get all ports for udp protocol (sorted version) nm['127.0.0.1'].all_ip() # get all ports for ip protocol (sorted version) nm['127.0.0.1'].all_sctp() # get all ports for sctp protocol (sorted version) nm['127.0.0.1'].has_tcp(22) # is there any information for port 22/tcp on host 127.0.0.1 nm['127.0.0.1']['tcp'][22] # get infos about port 22 in tcp on host 127.0.0.1 nm['127.0.0.1'].tcp(22) # get infos about port 22 in tcp on host 127.0.0.1 nm['127.0.0.1']['tcp'][22]['state'] # get state of port 22/tcp on host 127.0.0.1 (open 组合使用 import nmap # import nmap.py module nm = nmap.PortScanner() for host in nm.all_hosts(): print('----------------------------------------------------') print('Host : %s (%s)' % (host, nm[host].hostname())) print('State : %s' % nm[host].state()) for proto in nm[host].all_protocols(): print('----------') print('Protocol : %s' % proto) lport = nm[host][proto].keys() lport.sort() for port in lport: print('port : %s\\tstate : %s' % (port, nm[host][proto][port]['state'])) print('----------------------------------------------------') # print result as CSV print(nm.csv()) print('----------------------------------------------------') # If you want to do a pingsweep on network 192.168.1.0/24: nm.scan(hosts='192.168.1.0/24', arguments='-n -sP -PE -PA21,23,80,3389') hosts_list = [(x, nm[x]['status']['state']) for x in nm.all_hosts()] for host, status in hosts_list: print('{0}:{1}'.format(host, status)) print('----------------------------------------------------') # Asynchronous usage of PortScannerAsync nma = nmap.PortScannerAsync() def callback_result(host, scan_result): print('------------------') print(host, scan_result) nma.scan(hosts='192.168.1.0/30', arguments='-sP', callback=callback_result) while nma.still_scanning(): print(\"Waiting ...\") nma.wait(2) # you can do whatever you want but I choose to wait after the end of the scan By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python-thirdparty/apscheduler.html":{"url":"language/python-thirdparty/apscheduler.html","title":"APScheduler实现Python定时任务管理","keywords":"","body":"APScheduler实现Python定时任务管理 简介 Advanced Python Scheduler (APScheduler) 是一个 Python 库，可以管理 Python 的定时任务。 利用 APScheduler ，我们可以轻松的添加或移除相关的定时任务。 我们还可以把 Job 信息存储在数据库中，这样它就能维护其自身的信息和状态。 即使当服务发生了重启，它也能正常恢复相关需要执行的任务。 除此之外，APScheduler 可以用作跨平台、特定于应用程序的平台特定调度程序。 但是请注意，APScheduler 本身不是守护程序或服务，也不附带任何命令行工具。 APScheduler 默认支持三种内置的任务调度方式： Cron 式调度（具有可选的开始/结束时间） 基于间隔的执行（以均匀间隔运行job，具有可选的开始/结束时间） 一次性延迟执行（在设定的日期/时间运行一次job） 此外，APScheduler 的后端存储对接了各种各样的存储服务，例如内存、SQL、MongoDB、Redis、ZK 等。 快速上手 在使用之前，我们首先需要安装 apscheduler，安装方式非常简单: pip install apscheduler 一个最简单的示例代码如下: from datetime import datetime import os from apscheduler.schedulers.blocking import BlockingScheduler def tick(): print('Tick! The time is: %s' % datetime.now()) if __name__ == '__main__': scheduler = BlockingScheduler() scheduler.add_job(tick, 'interval', seconds=3) print('Press Ctrl+{0} to exit'.format('Break' if os.name == 'nt' else 'C')) try: scheduler.start() except (KeyboardInterrupt, SystemExit): pass 运行上述代码，你就可以看到效果了！ Press Ctrl+C to exit Tick! The time is: 2021-07-27 16:32:52.281270 Tick! The time is: 2021-07-27 16:32:55.282624 Tick! The time is: 2021-07-27 16:32:58.281650 Tick! The time is: 2021-07-27 16:33:01.281851 Tick! The time is: 2021-07-27 16:33:04.282868 Tick! The time is: 2021-07-27 16:33:07.281247 核心概念 了解了 apscheduler 最简单的使用方式之后，我们就来展开对 apscheduler 的学习。 首先，我们来了解一下 apscheduler 中的一些核心概念。 apscheduler 包含如下几个核心概念： triggers: 包含调度相关逻辑，每个Job都有自己的触发器，用于确定下一次运行job的时间，除了初识配置之外，触发器是无状态的。 job stores: 包含了已调度的Job信息。默认情况下，这些Job信息仅仅保存在内存中，但是我们可以通过配置将其持久化到数据库中。 executors: 负责执行对应的Job，它们负责将Job中指定的任务交给对应的线程池或进程池来完成对应的操作。Job完成后，executor 会通知 schedulers 相关任务已完成。 schedulers: 调度器用于负责上述相关实体信息的绑定操作。通过，整个程序中只有一个调度器在运行。用户只需要管理Job信息即可，调度器负责触发Job的执行等操作。 scheduler、job stores、executor 和 trigger 的选择 对 scheduler 的选择主要取决于 APScheduler 的使用场景和目的。 以下是选择 scheduler 的快速指南： BlockingScheduler: APScheduler 是一个独立的应用。 BackgroundScheduler: APScheduler是集成在其他应用中，且期望 APScheduler 可以后台执行。 AsyncIOScheduler: 使用了 asyncio 模块。 GeventScheduler: 使用了 gevent 的应用。 TornadoScheduler: Tornado 应用。 TwistedScheduler: Twisted 应用。 QtScheduler: QT 应用。 是不是足够简单呢？ Job 信息的存储方案可选的方案比较多，大致选择思路如下： 是否在意服务重启后数据丢失？如果不在意，直接用默认的内存存储即可。 如果在意，就需要持久化数据，持久化的方案可以根据业务需要选择，SQL 是一种比较推荐的存储方式。 关于 executor 的配置，通常使用默认的 ThreadPoolExecutor 即可。 如果要执行的是 CPU 密集型的任务，也可以切换为 ProcessPoolExecutor 来发挥多个 CPU 的多核处理能力。 在添加 job 时，需要为 job 设置对应的 trigger。 trigger 的设置完全依赖的业务的需求，根据业务需求设置即可。 配置 Scheduler APScheduler 提供了许多不同的方式来配置 Scheduler 。 您可以使用配置字典，也可以将选项作为关键字参数传入。 您还可以先实例化 Scheduler 程序，然后添加 job 并配置 Scheduler 。 通过这种方式，您可以在任何环境中获得最大的灵活性。 一个默认的 APSscheduler 程序的配置方式如下: from apscheduler.schedulers.background import BackgroundScheduler scheduler = BackgroundScheduler() 默认情况下，将会得到一个 BackgroundScheduler ，它的 Job 信息存储在内存中，名称是 default。 同时使用了 ThreadPool 的方式的 executor，最大的线程是为 10。 下面，我们来看一个定制后的 Scheduler 对象： from apscheduler.schedulers.blocking import BlockingScheduler from apscheduler.jobstores.mongodb import MongoDBJobStore from apscheduler.executors.pool import ThreadPoolExecutor jobstores = { 'default': MongoDBJobStore(client=get_mongodb()) # get_mongodb 返回一个 MongoClient() 对象 } executors = { 'default': ThreadPoolExecutor(20) } job_defaults = { 'coalesce': False, 'max_instances': 3 } scheduler = BlockingScheduler( jobstores=jobstores, executors=executors, job_defaults=job_defaults, timezone=\"Asia/Shanghai\" ) 可以看到，在上述的 Scheduler 配置中，我们实现了: 使用了 MongoDB 进行数据持久化 executor 的并发数设置为了 20 默认情况下为新job关闭合并 新job的默认最大实例限制为 3 时区设置为上海时间。 启动 Scheduler 启动 Scheduler 的方式非常简单: scheduler.start() 即可。 其中，对于 BlockingScheduler ，调用 start 函数后就会阻塞等待，而其他的类型的 Scheduler 将会后台执行。 添加 Job 向 Scheduler 中添加 Job 有两种方式： 调用 add_job() 函数 通过 scheduled_job 装饰器函数 其中，add_job() 函数是最常用的方式，该函数会返回一个 apscheduler.job.Job 对象，可以对它进行进一步的修改或删除。 您可以随时在调度程序上调度job。如果添加job时调度程序尚未运行，则job将被暂定调度，并且仅在调度程序启动时计算其第一次运行时间。 需要注意的是，如果您使用序列化job的执行程序或job存储，它将对您的job增加一些要求： 目标可调用对象必须可全局访问。 可调用对象的任何参数都必须是可序列化的。 在内置job存储中，只有 MemoryJobStore 不序列化job。 在内置执行器中，只有 ProcessPoolExecutor 会序列化job。 Ps: 如果您在应用程序初始化期间在持久job存储中安排job，则必须为job定义显式 ID 并使用 replace_existing=True， 否则每次应用程序重新启动时您都会获得job的新副本！ 示例如下: scheduler.add_job( func1, trigger=\"cron\", hour=\"14\", id=\"func1\", replace_existing=True ) 限制同一个 Job 最大的并发实例执行数 默认情况下，每个job只允许同时运行一个实例。 这意味着，如果job即将运行，但前一次运行尚未完成，则将最新运行任务会当做 misfired 。 通过在添加job时使用 max_instances 关键字参数，可以设置调度程序允许并发运行的特定job的最大实例数。 任务合并 有时，调度程序可能无法在计划运行时执行计划作业。 最常见的一个场景就是当我们希望执行该任务时，当前程序处于退出的状态等。 发生这种情况时，该作业被视为 misfired 。 然后调度程序将根据作业的 misfire_grace_time 选项检查每个错过的执行时间，以查看是否仍应触发执行。 在这种情况下，这可能导致作业连续执行多次。 如果您的特定用例不希望这种行为，则可以使用合并将所有这些错过的执行合并为一个。 换句话说，如果为作业启用了合并并且调度程序看到该作业的一个或多个排队执行，它只会触发它一次。 调度实践管理 我们可以将事件侦听器附加到调度程序。 调度程序事件在某些情况下被触发，并且可能在其中包含有关该特定事件详细信息的附加信息。 通过为 add_listener() 提供适当的掩码参数，或者将不同的常量组合在一起，可以只侦听特定类型的事件。 可调用侦听器使用一个参数调用，即事件对象。 示例代码如下: from apscheduler.events import EVENT_JOB_EXECUTED, EVENT_JOB_ERROR def my_listener(event): if event.exception: print('The job crashed :(') else: print('The job worked :)') scheduler.add_listener(my_listener, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python-thirdparty/ijson.html":{"url":"language/python-thirdparty/ijson.html","title":"使用ijson解析超大JSON文件","keywords":"","body":"使用ijson解析超大JSON文件 在使用Python解析一个超大的JSON文件时，如果JSON文件过大，直接将其内容全部加载至内存中进行JSON解析往往会因为内存不足而失败。 而ijson是具有标准Python迭代器接口的迭代JSON解析器，非常适用于解析超大的JSON文件。 安装 ijson作为一个Python的第三方库可以用Python标准的包管理工具进行安装： pip3 install ijson QuickStart 我们将以如下json字符串为例来演示ijson相关的功能使用。 { \"earth\": { \"europe\": [ {\"name\": \"Paris\", \"type\": \"city\", \"info\": { ... }}, {\"name\": \"Thames\", \"type\": \"river\", \"info\": { ... }}, // ... ], \"america\": [ {\"name\": \"Texas\", \"type\": \"state\", \"info\": { ... }}, // ... ] } } ijson最常用的方法是将数据流转为一个可迭代对象： import ijson f = urlopen('http://.../') objects = ijson.items(f, 'earth.europe.item') cities = (o for o in objects if o['type'] == 'city') for city in cities: do_something_with(city) 上述的例子是直接从一个url中读取数据进行解析的方式，如果想要从文件中解析JSON数字，使用方式如下： import ijson with open(mark_file, \"r\") as f: objects = ijson.items(f, 'earth.europe.item') cities = (o for o in objects if o['type'] == 'city') for city in cities: do_something_with(city) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python-thirdparty/websockets.html":{"url":"language/python-thirdparty/websockets.html","title":"Python实战websocket协议","keywords":"","body":"Python实战websocket协议 websocket概述 WebSocket是一种在单个TCP连接上进行全双工通信的协议。WebSocket通信协议于2011年被IETF定为标准RFC 6455，并由RFC7936补充规范。WebSocket API也被W3C定为标准。 WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。 Python第三方库websocket websocket是一个Python实现的基于websocket协议的操作lib库。 通过websocket库可以实现websocket的客户端与服务端。 安装方式如下： pip3 install websocket Python Websocket服务端 下面，我们来参考一个基于Python的Websocket服务端实例Demo: 将下列内容保存为server.py： # -*- coding: UTF-8 -*- \"\"\" # www.missshi.cn \"\"\" import time import asyncio import websockets async def hello(websocket, path): \"\"\" # 定义异步函数 :param websocket: :param path: :return: \"\"\" print(\"requests url: %s\" % path) name = await websocket.recv() print(\"receive message: %s\" % name) greeting = \"Hello %s!\" % name await websocket.send(greeting) while True: await websocket.send(\"what happened\") print(\"send message: %s\" % greeting) time.sleep(1) # 启动服务 start_server = websockets.serve(hello, \"localhost\", 8765) asyncio.get_event_loop().run_until_complete(start_server) asyncio.get_event_loop().run_forever() Python Websocket客户端 将下列内容保存为client.py： # -*- coding: UTF-8 -*- \"\"\" # www.missshi.cn \"\"\" import asyncio import websockets async def hello(): \"\"\" # 发送ws消息 :return: \"\"\" uri = \"ws://localhost:8765/123\" async with websockets.connect(uri) as websocket: name = \"missshi!\" await websocket.send(name) print(\"send message: %s\" % name) while True: greeting = await websocket.recv() print(\"receive message: %s\" % greeting) asyncio.get_event_loop().run_until_complete(hello()) demo运行 下面，我们第一步首先要启动服务端： python3 ./server.py 然后，打开另外一个终端，启动客户端： python3 ./client.py By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python-thirdparty/flask_sockets.html":{"url":"language/python-thirdparty/flask_sockets.html","title":"Flask websocket协议实战","keywords":"","body":"Flask websocket协议实战 在Python实战websocket协议中，我们已经了解了如果使用Python实践基本的websocket协议。 而对于更加常用的场景，我们以Flask框架为例，来演示如何实现更加复杂的应用。 flask_sockets介绍 flask_sockets是一个基于Python3的，用于扩展Flask框架以支持websocket协议的Python第三方库。 安装方式如下： pip3 install flask_sockets 基于Flask实现的websocket接口 保存如下内容至flask_ws_server.py文件： # -*- coding: UTF-8 -*- \"\"\" # www.missshi.cn \"\"\" from flask import Flask from flask_sockets import Sockets import datetime import time app = Flask(__name__) sockets = Sockets(app) @sockets.route('/echo') def echo_socket(ws): \"\"\" # WebSocket接口实现 :param ws: :return: \"\"\" while not ws.closed: now = datetime.datetime.now().isoformat() + 'Z' ws.send(now) #发送数据 time.sleep(1) @app.route('/') def hello(): \"\"\" # HTTP接口 :return: \"\"\" return 'Hello World!' if __name__ == \"__main__\": from gevent import pywsgi from geventwebsocket.handler import WebSocketHandler server = pywsgi.WSGIServer(('', 5000), app, handler_class=WebSocketHandler) print('server start') server.serve_forever() 前端Demo访问websocket接口 为了能够更加直观的体验websocket接口的功能，我们需要一个前端页面来进行可视化显示。 保存如下内容为index.html文件： Title var ws = new WebSocket(\"ws://127.0.0.1:5000/echo\"); ws.onmessage = function (event) { content = document.createTextNode(event.data); $(\"#time\").html(content); }; 使用浏览器打开index.html文件即可看到如下内容： 可以看到，浏览器中的时间每隔1s会进行一次变化。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/python-thirdparty/scikit-image-1.html":{"url":"language/python-thirdparty/scikit-image-1.html","title":"scikit-image快速入门","keywords":"","body":"scikit-image快速入门 scikit-image初识 scikit-image是一个基于 numpy 数组的Python的图像处理包。 这个包的引用方法是： import skimage skimage中大多数的函数都隶属于它的子模块中，例如： from skimage import data camera = data.camera() skimage中的子模块列表及其函数列表可以参考API文档。 在scikit-image中，所有的图像都是使用numpy进行表示，例如可以用一个二维数组来表示一个灰度二维图像： type(camera) # camera.shape # (512, 512) 其中，skimage.data 子模块中提供了一组函数用于获取各种示例图像，便于我们基于这些示例图像快速入门scikit-image的功能。 coins = data.coins() from skimage import filters threshold_value = filters.threshold_otsu(coins) threshold_value # 107 当然，我们也可以直接将图片文件读取成为numpy中的Array，只需要使用skimage.io.imread即可。 import os filename = os.path.join(skimage.data_dir, 'moon.png') from skimage import io moon = io.imread(filename) 此外，我们还可以使用natsort来对图片进行排序并加载多张图片： import os from natsort import natsorted, ns from skimage import io list_files = os.listdir('.') print(list_files) # ['01.png', '010.png', '0101.png', '0190.png', '02.png'] list_files = natsorted(list_files) print(list_files) # ['01.png', '02.png', '010.png', '0101.png', '0190.png'] image_list = [] for filename in list_files: image_list.append(io.imread(filename)) scikit-image快速入门 scikit-image中图像是通过NumPy中的ndarray的数据结构来表示的。 因此，我们可以利用Numpy中很多的标准方法直接对数据进行处理： from skimage import data camera = data.camera() type(camera) # 例如，计算图片的形状与像素点数： camera.shape # (512, 512) camera.size # 262144 还有计算图片的亮度的统计信息： camera.min(), camera.max() # (0, 255) camera.mean() # 118.31400299072266 Numpy检索 Numpy的索引可以用于数据查询和数据修改，例如： # 查询camera中第10行、第20列的元素 camera[10, 20] # 153 # 修改camera中第3行、第10列的元素为0 camera[3, 10] = 0 PS：在Numpy的索引中，第一个维度camera.shape[0]对应的是行数、第二个维度camera.shape[1]对应的是列数。 另外，原点camera[0, 0]位于整个图像的左上角。 这种表示方法与矩阵和线性代数中的表示方法一致，但是与笛卡尔坐标不一致。 除了逐个像素处理外，我们还可以直接使用Numpy来直接查询和修改整组像素的值。 一、切片 # 设置前十行为黑色（0） camera[:10] = 0 二、掩码 mask = camera 修改图像颜色 坐标变化 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/django/beginning.html":{"url":"language/django/beginning.html","title":"熟练掌握Django","keywords":"","body":"熟练掌握Django Django 是一个高级的 Python 网络框架，可以快速开发安全和可维护的网站。由经验丰富的开发者构建，Django负责处理网站开发中麻烦的部分，因此你可以专注于编写应用程序，而无需重新开发。 它是免费和开源的，有活跃繁荣的社区，丰富的文档，以及很多免费和付费的解决方案。 优点 完备性: Django遵循“功能完备”的理念，提供开发人员可能想要“开箱即用”的几乎所有功能。 通用性: Django 可以（并已经）用于构建几乎任何类型的网站—从内容管理系统和维基，到社交网络和新闻网站。它可以与任何客户端框架一起工作，并且可以提供几乎任何格式（包括 HTML，Rss源，JSON，XML等）的内容。 安全性: Django 提供了多种完善的安全保护机制可以直接使用。 可扩展: Django 使用基于组件的 “无共享” 架构 (架构的每一部分独立于其他架构，因此可以根据需要进行替换或更改)。 可维护: Django 代码编写是遵照设计原则和模式，鼓励创建可维护和可重复使用的代码。特别是它使用了不要重复自己（DRY）原则，所以没有不必要的重复，减少了代码的数量。 灵活性: Django 是用Python编写的，它在许多平台上运行。这意味着你不受任务特定的服务器平台的限制，并且可以在许多种类的Linux，Windows和Mac OsX 上运行应用程序。 Django架构 开发环境准备 Anaconda PyCharm By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/django/quickstart.html":{"url":"language/django/quickstart.html","title":"Django快速上手","keywords":"","body":"Django快速上手 了解了Django的基本特点，并完成了相关开发环境准备后，接下来，我们将会从一个最简单的示例开始进行Django的学习。 创建第一个项目 Step1: 创建一个会议室管理项目，项目名称为meetingroom. django-admin startproject meetingroom cd meetingroom Step2: 启动项目 python manage.py runserver 0.0.0.0:8080 Step3: 开发浏览器，访问 http://127.0.0.1:8080。 正常情况下，你会看到如下内容： 初识后台管理系统 Django的一大优势是其自带了一个强大的后台管理系统，及时不写一行前端代码，也能够有一个配套的Web页面进行相关的管理操作。 下面，我们就来了解一下Django的后台管理系统吧。 打开浏览器，访问 http://127.0.0.1:8080/admin ，你将会看到如下登录框： 但是，我们好像还没有创建任何用户呢！ 下面，我们就先来创建一个用户。 创建用户之前，我们首先需要初始化Django内置表的数据库。 Ps: 由于Django默认使用了sqlite数据库，因此，再前期的实验环节，我们就不在额外搭建数据库了，而是使用默认的sqlite数据库。 初始化内置表的数据库的命令如下： python3 manage.py migrate # Operations to perform: # Apply all migrations: admin, auth, contenttypes, sessions # Running migrations: # Applying contenttypes.0001_initial... OK # Applying auth.0001_initial... OK # Applying admin.0001_initial... OK # Applying admin.0002_logentry_remove_auto_add... OK # Applying admin.0003_logentry_add_action_flag_choices... OK # Applying contenttypes.0002_remove_content_type_name... OK # Applying auth.0002_alter_permission_name_max_length... OK # Applying auth.0003_alter_user_email_max_length... OK # Applying auth.0004_alter_user_username_opts... OK # Applying auth.0005_alter_user_last_login_null... OK # Applying auth.0006_require_contenttypes_0002... OK # Applying auth.0007_alter_validators_add_error_messages... OK # Applying auth.0008_alter_user_username_max_length... OK # Applying auth.0009_alter_user_last_name_max_length... OK # Applying auth.0010_alter_group_name_max_length... OK # Applying auth.0011_update_proxy_permissions... OK # Applying auth.0012_alter_user_first_name_max_length... OK # Applying sessions.0001_initial... OK 可以看到，我们创建了admin, auth, contenttypes, sessions等相关的数据库表。 下面，我们就可以使用命令行来添加用户了： python3 ./manage.py createsuperuser # Username: missshi # Email address: wangzhe0912@tju.edu.cn # Password: # Password (again): # Superuser created successfully. 可以看到，输出createsuperuser子命令后，会提供交互式命令行接收用户名、邮箱、密码等相关参数。 全部信息输入完成后，我们想要创建的用户也就创建完成了，下面我们可以用刚才创建的用户登录看看。 登录成功后，正常情况下你将会看到如下页面： 可以看到，在这个页面中，我们可以看到Groups和Users两种对象，这些都是Django框架内置的功能。 此时，如果你点击Users进入到User列表页面的话，还能够看到你刚才创建的用户。 甚至，你已经可以在这个页面中进行用户、用户组的创建和管理了。是不是非常赞呢？ 编写一个应用 下面，我们需要编写一个职位管理系统的应用，这个应用需要实现的功能为管理员能够发布职位。 数据建模 在应用开发前，我们首先需要对核心数据对象进行建模，即针对核心对象，设置它有哪些字段等。 对于我们的职位管理系统的应用而言，最核心的对象就是职位了。 一条职位记录应该包括如下字段： 职位名称 类别 工作地点 职位职责 职位要求 发布人 发布日期 修改日期 创建应用 当我们对数据建模完成后，我们就需要创建应用了。 创建应用同样用到的是manage.py脚本： python manage.py startapp jobs 执行该命令后，我们可以看到会自动在当前目录中创建一个jobs的子目录。 可以看到，每个创建的app目录下都会自动生成如下文件： admin.py apps.py models.py tests.py views.py migrations目录 Ps: 需要注意的是，我们每创建一个应用后，需要修改整个项目的settings.py文件，并在其中的INSTALLED_APPS中增加对应app的名称，如jobs。 定义models文件 下面，我们需要修改jobs目录下的models.py文件，将我们针对职位建立的模型转化为代码写入models.py文件中。 from django.db import models from django.contrib.auth.models import User JobTypes = [ (0,\"技术类\"), (1,\"产品类\"), (2,\"运营类\"), (3,\"设计类\"), (4,\"市场营销类\") ] Cities = [ (0,\"北京\"), (1,\"上海\"), (2,\"深圳\"), (3,\"杭州\"), (4,\"广州\") ] class Job(models.Model): \"\"\" # 职位建模 \"\"\" job_id = models.CharField(blank=False, primary_key=True, unique=True, max_length=255, verbose_name=\"职位ID\") job_type = models.SmallIntegerField(blank=False, choices=JobTypes, verbose_name=\"职位类别\") job_name = models.CharField(max_length=250, blank=False, verbose_name=\"职位名称\") job_city = models.SmallIntegerField(choices=Cities, blank=False, verbose_name=\"工作地点\") job_responsibility = models.TextField(max_length=1024, verbose_name=\"职位职责\") job_requirement = models.TextField(max_length=1024, blank=False, verbose_name=\"职位要求\") creator = models.ForeignKey(User, verbose_name=\"创建人\", null=True, on_delete=models.SET_NULL) created_date = models.DateTimeField(verbose_name=\"创建日期\", auto_now_add=True) modified_date = models.DateTimeField(verbose_name=\"修改日期\", auto_now=True) 其中，models中定义了多种数据格式，如SmallInteger、Char、Text、DateTime等，另外ForeignKey表示外键引用，主要用户表与表的关联，例如此处creator就对应着系统内部的用户。 上述做用到的参数的作用如下： blank表示是否允许为空。 choices表示对于枚举类型而言可以选的值，接收一个数组参数，每个数组元素又是有(value, alias)的元组组成的。 verbose_name表示其别名，可以在admin管理后台中可见。 max_length表示字符串最大的长度。 on_delete参数主要用户外键引用，表示当引用的对象被删除后，相关的记录应该如何处理，SET_NULL表示关联数据被删除后，设置该字段为null。另外，当on_delete为SET_NULL时，需要设置该字段允许为空，即null=True auto_now_add表示首次添加记录时设置为当前时间。 auto_now表示每次记录更新时，设置为当前时间。 primary_key表示主动设置主键，如果没有主动设置主键，默认则会创建一个_id字段作为主键。 unique表示该字段是否有唯一性限制。 将Model注册当管理后台 上面的步骤中，我们创建了Job对应的Model相关的定义，但是为了能让我们的管理后台可以支持model的增、删、改、查等操作，我们需要将model注册到管理后台。 我们需要修改jobs目录下的admin.py文件: from django.contrib import admin from jobs.models import Job admin.site.register(Job) 同步数据库结构 上面，我们虽然已经定义了models对象，并注册到了管理后台，此时你访问管理后台应该也已经可以看到Jobs菜单了。 但是点击查询Jobs信息时，一定会看到一些报错，这是为什么呢？ 答案是我们虽然定义了数据对象，但是并没有在数据库中创建对应的表，导致Django在按照数据结构进行读写数据库时一定会引发报错。 下面，我们来看一下如何同步数据库，我们还是用到了manage.py脚本。 Step1: 生成同步脚本 python3 ./manage.py makemigrations 执行该命令后，可以看到，我们会在Job对应的migrations目录下生成一个0001_initial.py脚本，这个就是创建数据库的工具。 Step2: 执行同步脚本，同步数据库 python3 ./manage.py migrate 执行该命令后，相当于执行了刚才生成的0001_initial.py脚本，真实的在数据库中创建了对应的job表。 体验一下吧 下面，我们再次打开admin后台页面，我们就已经可以直接用后台管理页面进行Job相关的管理了。 管理后台体验优化 在上面的内容中，我们已经能够实现可以通过后台管理页面进行职位的增、删、改、查操作了，但是整体来说，用户体验并不好， 接下来，我们将会了解如何一步步的优化管理后台，从而使得整个后台的管理页面一步步优化。 默认值设置 在刚才新增Job时，其中有一些字段我们希望能够显示一些默认值，例如创建日期我们期望能够默认显示当前时间等。 默认值的设置非常简单，我们只需要在Model字段的定义中增加default属性即可，例如。 import datetime created_date = models.DateTimeField(verbose_name=\"创建日期\", default=datetime.now) 职位列表页中显示指定字段 创建对应的Job后，此时访问Job列表页，你看到的记录目前仅仅是Job object，这种显示方式非常不友好，我们希望能够在列表页中显示出Job的一些核心属性。 这些，我们需要在admin.py中进行定制，即创建JobAdmin类并赋值list_display属性对应的字段名称。 class JobAdmin(admin.ModelAdmin): list_display = ('job_name', 'job_type', 'job_city', 'creator', 'created_date', 'modified_date') # admin.site.register(Job) admin.site.register(Job, JobAdmin) # 注册时需要将JobAdmin一起进行注册 此时，再次访问列表详情页面时，我们应该就已经可以看到字段的信息了。 表单中隐藏默写字段 在新增Job时，有些字段我们希望直接设置为默认值，并不需要在表单中显示，例如创建人字段。 针对这种场景，我们同样需要在admin.py中进行定制，这次需要用到的是exclude属性: class JobAdmin(admin.ModelAdmin): exclude = ('creator','created_date','modified_date') 此时，再次进入新增、编辑等页面时，我们将会无法看到这些字段信息，也无法修改这些字段内容。 那么，就有一个问题，这些字段应该如何进行赋值呢？default属性设置默认值是一种方式，下面，我们来介绍另外一种方式: default属性设置默认值仅限于默认值固定的场景，但是对于默认值可能会发现变化的场景，此时，我们需要用到Admin类的save_model方法。 例如，我们希望creator字段值为当前登录用户时： class JobAdmin(admin.ModelAdmin): def save_model(self, request, obj, form, change): if obj.creator is None: obj.creator = request.user super().save_model(request, obj, form, change) 在上面的方法中，我们接收了request,obj,form,change四个参数。 其中，request表示当前请求的对象，obj表示当前记录对象。 我们将当前请求用户设置为当前job记录的creator属性值，然后再次调用save_model父类方法即可实现动态默认值的功能。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/django/settings.html":{"url":"language/django/settings.html","title":"Django配置文件详解","keywords":"","body":"Django配置文件详解 在本文中，我们主要来讲解Django的配置文件。 Django 的配置文件包含 Django 应用的所有配置项。 本文档介绍配置是如何生效的，以及哪些设置项是可配置的。 配置文件位置 在我们创建一个django项目时，会在django项目目录下创建一个与项目同名的文件夹，并在该文件夹下有一个settings.py文件。 这个settings.py就是我们项目的默认配置文件。 配置文件字段说明 DEBUG 默认为False。表示是否开启调试模式，布尔值。 Ps: 永远不要在 DEBUG 开启的情况下将网站部署到生产中。 调试模式的主要功能之一是显示详细的错误页面。如果你的应用程序在 DEBUG 为 True 时引发了异常，Django 会显示一个详细的回溯，包括很多关于你的环境的元数据，比如所有当前定义的 Django 配置（来自 settings.py）。 ALLOWED_HOSTS 声明当前 Django 网站可以服务的主机 / 域名的字符串列表。 这个列表中的值可以是完全限定的名称（例如 'www.example.com），在这种情况下，它们将与请求的 Host 头完全匹配（不区分大小写，不包括端口）。 以.开头的值可以用作子域通配符，例如: '.example.com' 将匹配 example.com、www.example.com 和 example.com 的任何其他子域。 '*' 的值将匹配任何东西，在这种情况下，你要负责提供你自己的 Host 头的验证。 Ps： 当 DEBUG为True 和 ALLOWED_HOSTS 为空时，主机将根据 ['.localhost', '127.0.0.1', '[::1]'] 进行验证。 当 DEBUG为False时，ALLOWED_HOSTS不允许为空。 INSTALLED_APPS 一个字符串的列表，表示在这个 Django 项目中所有被启用的应用。 默认的应用包括： INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', ] Ps: 需要注意的是，所有自己创建的应用都需要添加至 INSTALLED_APPS 中，应用才能生效。 MIDDLEWARE MIDDLEWARE表示需要用到的中间件列表，默认为： MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] TEMPLATES 一个包含所有 Django 模板引擎的配置的列表。列表中的每一项都是一个字典，包含了各个引擎的选项。 默认为： TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] DATABASES 一个包含所有数据库配置的字典，用于 Django。它是一个嵌套的字典，其内容是将一个数据库别名映射到一个包含单个数据库选项的字典中。 DATABASES默认的配置为： DATABASES = { 'default': { 'ENGINE': 'django.db.backends.sqlite3', 'NAME': BASE_DIR / 'db.sqlite3', } } 它表示使用项目目录下的db.sqlite3文件作为sqlite数据库进行数据存储。 当连接到其他数据库后端时，如 MariaDB、MySQL、Oracle 或 PostgreSQL，将需要额外的连接参数。 例如，一个PostgreSQL的配置如下： DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'NAME': 'mydatabase', 'USER': 'mydatabaseuser', 'PASSWORD': 'mypassword', 'HOST': '127.0.0.1', 'PORT': '5432', } } LANGUAGE_CODE 表示当前项目的语言，默认为en-us，表示美国英语。 如果想改为中文，可以设置为zh-hans。 Ps: USE_I18N 必须是激活状态，该配置才会有效果。 TIME_ZONE 表示当前项目的时区，默认为UTC时间。 为了能使得项目时间本土化，我们可以把TIME_ZONE的值设置为Asia/Shanghai。 指定配置文件 上文提到过，与项目同名的文件夹下的settings.py文件是Django项目默认的配置文件。 但有时我们希望指定某个其他文件为配置文件时，可以通过DJANGO_SETTINGS_MODULE环境变量进行设置。 DJANGO_SETTINGS_MODULE 的值是一个符合 Python 语法的路径，例如 mysite.settings。 Ps：要注意配置模块应位于 Python 的 import 搜索路径 中。 在项目代码内使用settings 在具体的Django应用中, 通过引入 django.conf.settings 使用配置, 例: from django.conf import settings if settings.DEBUG: # Do something pass By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/django/frontend.html":{"url":"language/django/frontend.html","title":"Django自定义页面编写","keywords":"","body":"Django自定义页面编写 在QuickStart中，我们已经利用Django Admin几乎零成本的实现了Django的后台管理页面。 但是，在真实的业务场景中，我们并不能让所有的用户都登录到后台管理页面进行操作，例如对于候选人而言，如果想要投递简历，那么登录到后台管理页面并不是一个推荐的方式。 因此，接下来，我们需要了解在Django中如何实现自定义页面的编写。 前端概述 对于一个Django项目而言，其自定义页面的编写大致可以分为两种方式: 前后端分离 与 Template页面渲染。 前后端分离方式是指前后端完全解耦，前端使用纯前端框架进行开发，例如React, VUE以及javascript等技术技术编写，后端通过接口提供前端页面需要的数据，前后端通过HTTP / websocket等通信协议进行交互。 Template页面渲染是一种相对古老的方法，它本质上一种前后端耦合的方式，即在后台项目中定义前端页面的html模板，并在后端项目中动作替换模板中项目的内容，从而生成Web页面可预览的html文件。 相比较而言: 对于纯后台开发人员而言，Template页面渲染的开发方式相对简单，不需要过多的了解JS以及前端框架等各种技术，就可以快速实现相关的功能。 但是，由于Template页面渲染是通过html页面渲染的方式进行页面编写，无法利用JS强大的生态圈，导致页面效果通常会较差。同时由于前后端全部耦合，对于开发而言也不容易拆分和合作开发。 因此，目前前后端分离方式已经基本成为了所有项目开发的标准方式，Template页面渲染正在逐步被淘汰。 但由于前后端分离方式对前端技术有一定要求，我并不会在本文中展开，而是仍然简单了解一些Template页面渲染的开发方式，让你能够实现一些基本页面的编写。 Ps: 在后续文章中，我们会讲解对于前后端分离方式的项目，Django应该如何提供后端接口，同时，也会在专门的系列文章中，分享如何快速进行前端开发。 Django自定义模板概述 我们先来了解一下Django自定义模板的基本原理： Django模板中包含了输出html页面中的静态部分的内容。 模块里面的动态内容会在运行的过程中被动态的替换。 在views中指定每个URL使用哪个模板来进行数据渲染，并传入用户替换动态内容的数据。 Django的自定义模板的一大特性是支持继承，具体来说： Django中允许定义一个骨架模板，在骨架模板中可以包含站点的公共元素，例如头部导航、菜单栏、尾部链接等。 同时，骨架模板中还可以定义Block块，这些Block块可以在继承的页面中实现覆盖。 每个页面都可以选择继承自其他页面。 自定义职位列表页面编写 下面，我们将会继续QuickStart中的职位管理系统的开发，分别编写适用于匿名用户浏览的职位列表和职位详情页面。 我们先来看职位列表页面的开发。 第一步: 在jobs目录下创建一个templates目录。 mkdir jobs/templates 第二步：定义一个匿名访问的基础页面base.html，并在基础页面中定义页头： Ps: 在上述base页面中，我们定义了页面的标题和一个block块，此外，对于每个block块都需要一个endblock来表示结束。 第三步：下面，我们就可以正式开始编写我们的职位列表页面的内容了: joblist.html。 下面，我们来了解一下上述代码的含义: extends 'base.html' 表示当前文件继承自base.html文件。 下面的所有内容都是对 block content 块进行的重写。 在Django的template渲染中大括号百分号内部可以包含python表达式，Template渲染时会自动解析。 第四步：view层中添加url对应页面。 在上面的内容中，我们已经定义了职位详情列表页面的样式和内容了，接下来，我们需要定义如何能访问到职位详情页面。 如果你还记得在本系列文章的开头中我们分享的Django架构图，那你应该就会知道Django中的入口应该是view层。 因此，我们需要在view层中添加url并映射到我们刚才编写的页面。 修改jobs/views.py文件如下： from django.template import loader from django.http import HttpResponse from jobs.models import Job from jobs.models import Cities, JobTypes def joblist(request): job_list = Job.objects.order_by('job_type') template = loader.get_template(\"joblist.html\") context = {'job_list': job_list} for job in job_list: job.city_name = Cities[job.job_city][1] job.type_name = JobTypes[job.job_type][1] return HttpResponse(template.render(context)) 第五步：url注册 view视图编写完成后，还有重要的一步，将上述定义的view视图注册到url中。 创建jobs/urls.py文件，编写内容如下： from django.conf.urls import url from jobs import views urlpatterns = [ # 职位列表 url(r\"^joblist/\", views.joblist, name=\"joblist\"), ] 除了在应用中注册url外，我们还需要在整个项目中的urls中添加当前应用的urls注册信息，具体来说，修改项目目录下的urls.py文件： from django.conf.urls import url, include urlpatterns = [ # 注册jobs应用 url(r\"^*\", include(\"jobs.urls\")), ] 到此为止，职位列表页面的定制开发就已经基本完成了。 自定义匿名用户可以查看的职位详情 接下来，我们需要做的是职位详情页面的定制开发。 第一步：创建job.html详情页模板： 模板渲染原理基本与之前的职位列表页面相同，此处不再赘述。 第二步：编写职位详情的views视图逻辑： from django.http import Http404 from django.shortcuts import render from jobs.models import Job from jobs.models import Cities def detail(request, job_id): # view函数直接接收了job_id参数 try: job = Job.objects.get(pk=job_id) job.city_name = Cities[job.job_city][1] logger.info('job retrieved from db :%s' % job_id) except Job.DoesNotExist: raise Http404(\"Job does not exist\") return render(request, 'job.html', {'job': job}) 第三步：url注册： from django.urls import path from jobs import views urlpatterns = [ path('job//', views.detail, name='detail'), # url中接收参数 ] 到此为止，职位详情页面就已经也开发完成了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/django/admin.html":{"url":"language/django/admin.html","title":"DjangoAdmin高级用法","keywords":"","body":"DjangoAdmin高级用法 在本节的内容中，我们将会继续以职位管理系统为例，来逐步讲解一些DjangoAdmin的高级功能。 数据分页展示 首先，我们需要在已有的项目中创建一个interview的应用。 python3 manage.py startapp interview 接下来，我们定义models.py文件如下： from django.db import models from django.contrib.auth.models import User from jobs.models import DEGREE_TYPE # 第一轮面试结果 FIRST_INTERVIEW_RESULT_TYPE = ((u'建议复试', u'建议复试'), (u'待定', u'待定'), (u'放弃', u'放弃')) # 复试面试建议 INTERVIEW_RESULT_TYPE = ((u'建议录用', u'建议录用'), (u'待定', u'待定'), (u'放弃', u'放弃')) # HR终面结论 HR_SCORE_TYPE = (('S', 'S'), ('A', 'A'), ('B', 'B'), ('C', 'C')) class Candidate(models.Model): # 基础信息 userid = models.IntegerField(unique=True, blank=True, null=True, verbose_name=u'应聘者ID') username = models.CharField(max_length=135, verbose_name=u'姓名') city = models.CharField(max_length=135, verbose_name=u'城市') phone = models.CharField(max_length=135, verbose_name=u'手机号码') email = models.EmailField(max_length=135, blank=True, verbose_name=u'邮箱') apply_position = models.CharField(max_length=135, blank=True, verbose_name=u'应聘职位') born_address = models.CharField(max_length=135, blank=True, verbose_name=u'生源地') gender = models.CharField(max_length=135, blank=True, verbose_name=u'性别') candidate_remark = models.CharField(max_length=135, blank=True, verbose_name=u'候选人信息备注') # 学校与学历信息 bachelor_school = models.CharField(max_length=135, blank=True, verbose_name=u'本科学校') master_school = models.CharField(max_length=135, blank=True, verbose_name=u'研究生学校') doctor_school = models.CharField(max_length=135, blank=True, verbose_name=u'博士生学校') major = models.CharField(max_length=135, blank=True, verbose_name=u'专业') degree = models.CharField(max_length=135, choices=DEGREE_TYPE, blank=True, verbose_name=u'学历') # 综合能力测评成绩，笔试测评成绩 test_score_of_general_ability = models.DecimalField(decimal_places=1, null=True, max_digits=3, blank=True, verbose_name=u'综合能力测评成绩') paper_score = models.DecimalField(decimal_places=1, null=True, max_digits=3, blank=True, verbose_name=u'笔试成绩') # 第一轮面试记录 first_score = models.DecimalField(decimal_places=1, null=True, max_digits=2, blank=True, verbose_name=u'初试分', help_text=u'1-5分，极优秀: >=4.5，优秀: 4-4.4，良好: 3.5-3.9，一般: 3-3.4，较差: =4.5，优秀: 4-4.4，良好: 3.5-3.9，一般: 3-3.4，较差: 可以看到，这个Candidate对象中包括了大量的属性字段。 同时，我们在Candidate类内，又定义了一个Meta类，其中包含db_table、verbose_name和verbose_name_plural三个属性。 这些其实也都是Django框架内定义的一些特殊变量，分别表示对应的数据库表的名称，数据库表在Web页面上显示的名称，数据库表的复数形式。 __str__是Python3的类中的一个特殊含义的函数，它表示将对象转换成str类型时，得到的string字符串的值。 下面，我们定义admin.py文件如下： from django.contrib import admin from interview.models import Candidate # 候选人管理类 class CandidateAdmin(admin.ModelAdmin): exclude = ('creator', 'created_date', 'modified_date') list_display = ( 'username', 'city', 'bachelor_school','get_resume', 'first_score', 'first_result', 'first_interviewer_user', 'second_score', 'second_result', 'second_interviewer_user', 'hr_score', 'hr_result', 'hr_interviewer_user',) admin.site.register(Candidate, CandidateAdmin) 同时，我们还需要在全局settings.py的INSTALL_APPS中增加interview这个应用。 接下来，我们需要初始化数据库： python3 ./manage.py makemigrations python3 ./manage.py migrate 此时，再次进入admin管理页面，可以点击\"应聘者\" +号来添加一个用户。 在添加应聘者页面中，你应该会看到有一个巨大无比的表单，这个表单看起来就非常的令人头痛，我们需要对这个表单进行分组和优化管理来使得大家在使用过程中没有那么痛苦。 我们需要扩展admin.py文件，在CandidateAdmin类中增加fieldsets属性，示例如下： from django.contrib import admin class CandidateAdmin(admin.ModelAdmin): fieldsets = ( (None, {\"fields\": (\"userid\", \"username\", \"email\")}), (\"第一轮面试\", {\"fields\": (\"first_score\", \"first_advantage\")}), (\"第二轮面试\", {\"fields\": (\"second_score\", \"second_advantage\")}), (\"第三轮面试\", {\"fields\": (\"hr_score\", \"hr_advantage\")}), ) 其中，fieldsets是表示字段分组的方式，本身是一个元组，元组中的每一个元素表示一个字段块。 每个fieldset又是由一个元组组成，元组的第一个元素表示分组名称，第二个元素是一个字典信息，包含一个fields字段，里面是属于当前块的字段。 此时，我们已经将所有字段都进行了分组显示，但是查看表单，我们会发现像用户名这种输入内容很短的字段，也需要占用一行，导致整体页面过长，这种显示方法并不合适。 因此，我们需要再次进行优化，将多个字段合并至同一行。 例如，我们希望将username和email合并成为一行： from django.contrib import admin class CandidateAdmin(admin.ModelAdmin): fieldsets = ( (None, {\"fields\": (\"userid\", (\"username\", \"email\"))}), (\"第一轮面试\", {\"fields\": (\"first_score\", \"first_advantage\")}), (\"第二轮面试\", {\"fields\": (\"second_score\", \"second_advantage\")}), (\"第三轮面试\", {\"fields\": (\"hr_score\", \"hr_advantage\")}), ) Ps: 我们只需要将\"username\", \"email\"再次用一个元组进行包围即可。 扩展命令行支持批量导入数据 虽然我们对管理页面进行了各种优化，但是仍然存在着大量的输入字段，因此从Web页面逐个添加用户仍然有着较大的成本。 因此，我们需要能够支持通过excel进行大量的数据导入，接下来，我们需要扩展admin工具来支持批量的excel数据导入。 在Django框架中，有一个management commands的机制，它可以扩展命令行功能来满足个性化的需求。 首先，我们首先需要创建management/commands目录，并在该目录下创建import_candidates.py文件： import csv from django.core.management import BaseCommand # 命令行扩展的基类 from interview.models import Candidate class Command(BaseCommand): help = '从一个CSV文件的内容中读取候选人列表，导入到数据库中' # 帮助信息 def add_arguments(self, parser): # 接收一个--path的参数 parser.add_argument('--path', type=str) def handle(self, *args, **kwargs): # handle函数编写具体的处理逻辑 path = kwargs['path'] with open(path, 'rt', encoding=\"gbk\") as f: reader = csv.reader(f, dialect='excel', delimiter=';') for row in reader: candidate = Candidate.objects.create( username=row[0], city=row[1], phone=row[2], bachelor_school=row[3], major=row[4], degree=row[5], test_score_of_general_ability=row[6], paper_score=row[7] ) print(candidate) 此时，我们只需要执行如下命令即可实现批量上传数据： python manage.py import_candidates --path /path/to/your/file.csv 列表支持筛选和查询 当我们导入大量的候选人后，我们会发现从候选人列表中查询指定特征的候选人变的非常难，因此，我们需要对候选人列表支持搜索、过滤和排序。 这些功能都可以借助Django的Admin的相关配置来快速实现，下面我们来看看应该怎么做把！ 依旧是修改admin.py文件中的CandidateAdmin类，增加如下属性： class CandidateAdmin(admin.ModelAdmin): # 右侧筛选条件 list_filter = ('city','first_result','second_result','hr_result','first_interviewer_user','second_interviewer_user','hr_interviewer_user') # 支持通用查询字段 search_fields = ('username', 'phone', 'email', 'bachelor_school') ### 列表页默认排序字段 ordering = ('hr_result','second_result','first_result') 可以看到，我们可以： list_filter增加筛选条件 search_fields增加可搜索条件 ordering添加字段默认排序规则 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/django/rest.html":{"url":"language/django/rest.html","title":"DjangoRestFramework快速入门","keywords":"","body":"DjangoRestFramework快速入门 概述 在我们之前的讲解中，我们曾经提到过目前大部分的项目是前后端分离的，即后端提供标准的接口，前端通过调用接口获取数据并进行渲染。 同时，随时目前微服务架构的不断流行，一个项目中可能会包含很多个功能模块，多个功能模块之间大部分也都是通过接口进行相互调用的。 而之前我们一直学习的View层其实更注重于Template渲染等相关的功能。 为了能够更加方便的实现标准化的HTTP接口，Django提供了一套专门的框架Django REST Framework用于快速提供REST风格的HTTP接口供外部访问。 Django REST Framework概述 Django REST Framework提供了一套丰富的框架，可以让我们轻松的： 提供标准的开放API 配置合适的权限控制 安装 Step1: 安装Django REST Framework相关的依赖库 pip3 install djangorestframework pip3 install markdown pip3 install django-filter Step2: 在项目的settings.py的INSTALLED_APPS中增加rest_framework。 Step3: 添加REST接口页面的登录、退出视图注册到项目的urls.py中: urlpatterns = [ ... path(r'^api-auth/', include(\"rest_framework.urls\")), ] Step4: 在项目的settings.py文件中增加REST_FRAMEWORK相关配置： REST_FRAMEWORK = { # Use Django's standard `django.contrib.auth` permissions, # or allow read-only access for unauthenticated users. 'DEFAULT_PERMISSION_CLASSES': [ 'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly' ] } 上述配置表示rest framework的默认接口权限为标准的auth鉴权且针对未授权用户开放只读权限。 到此为止，我们的Django REST Framework就已经开发完成了。 Django REST Framework快速上手 下面，我们来通过一个实例演示如何通过Django REST Framework来提供对应的接口。 其实，使用过程非常简单，我们只需要将对应的model注册到url中即可，省去了View的阶段。 具体来说，修改项目的urls.py文件，增加如下内容： from rest_framework import routers, serializers, viewsets # Serializers define the API representation. class UserSerializer(serializers.HyperlinkedModelSerializer): class Meta: model = User # 对应哪个模型 fields = ['url', 'username', 'email', 'is_staff'] # 返回哪些字段 # ViewSets define the view behavior. class UserViewSet(viewsets.ModelViewSet): queryset = User.objects.all() serializer_class = UserSerializer class JobSerializer(serializers.HyperlinkedModelSerializer): class Meta: model = Job fields = '__all__' class JobViewSet(viewsets.ModelViewSet): \"\"\" API endpoint that allows groups to be viewed or edited. \"\"\" queryset = Job.objects.all() serializer_class = JobSerializer router = routers.DefaultRouter() router.register(r'users', UserViewSet) router.register(r'jobs', JobViewSet) urlpatterns = [ ... path('api/', include(router.urls)), ] 可以看到，我们在上述代码中，分别创建了User和Job的Serializer和ViewSet，并将其注册到路由。 此时，直接访问http://127.0.0.1:8080/api/ 地址，你就已经可以看到REST Framework相关的API页面并进行操作了。 Django REST Framework接口扩展 有时，我们需要在接口请求中增加某些字段的逻辑校验，或者是我们的一个表中包含了一些外键，这时，我们需要对Serializer进行扩展满足业务需求： class TaskSerializer(serializers.HyperlinkedModelSerializer): \"\"\" # Serializer类 \"\"\" class Meta: \"\"\" # 元数据 \"\"\" model = Task fields = ( \"name\", \"status\", \"device_id\", \"action\", \"url\" ) def validate(self, attrs): \"\"\" # 数据验证 \"\"\" if \"device_id\" not in self.context[\"request\"].data: raise Exception(\"device_id is required\") device_id = self.context[\"request\"].data[\"device_id\"] try: Device.objects.get(pk=device_id) except ObjectDoesNotExist: raise Exception(\"device_id %s not exists\" % device_id) attrs[\"device_id\"] = self.context[\"request\"].data[\"device_id\"] return attrs def create(self, validated_data): \"\"\" # 处理内置逻辑 \"\"\" device = Device.objects.get(pk=validated_data[\"device_id\"]) return Task.objects.create(device=device, **validated_data) 以上述代码为例，我们在Serializer类中增加了validate和create两个函数。 这两个函数都是Django REST Framework中有特殊函数的含义名称。 先来看validate： validate函数是指可以在接口被真正处理前，对传入的参数进行校验和补充。 validate函数接收一个self和attrs属性，我们可以通过self.context[\"request\"].data来读取HTTP原始请求数据进行参数校验，同时可以通过给attr属性赋值使得其可以在create函数中直接使用。 再看来create函数： create函数会在validate函数调用返回后再次进行调用，本质上是用于重写数据库写入逻辑，例如对于外键这种场景，我们就需要重写数据库写入逻辑。 其中，create函数同样接收两个参数，分别是self和validated_data，而validated_data其实就是在validate函数中返回的attrs属性值。 另外需要说明的时，在fields属性中，如果设置为__all__时，我们默认是无法查看到外键关联的字段的，此时，有两种方法可以解决该问题： 方法一: fields属性中，补充model_name_id从而显示对应外键的主键值。 方法二: 在Meta类下，新增depth属性，并设置为大于等于1的数，此时，会将外键关联的数据进行嵌套查询并完整显示出来。其中，depth表示嵌套搜索的层数。 Django REST Framework自定义接口 可以看到，在上面的例子中，我们会非常少的代码就实现了将模型映射到接口中，并对外提供。 但你应该会发现，上面的例子中仅仅是将模型映射到接口并直接对外暴露，这会导致我们无法加入自定义的业务逻辑。 例如，有时我们一个业务操作可能会涉及到多张表的增、删、改、查操作等，这时应该怎么处理呢？ Django REST Framework其实也提供了一种自定义接口逻辑的方法，我们以下面的例子进行说明： from django.urls import path from rest_framework.decorators import api_view from rest_framework.decorators import permission_classes from rest_framework.response import Response from rest_framework.permissions import IsAuthenticated @api_view([\"GET\", \"POST\"]) @permission_classes([IsAuthenticated]) def get_self_task(request): \"\"\" # 获取当前的设备的Task任务 \"\"\" if request.method == \"GET\": host_ip = request.GET[\"host_ip\"] else: host_ip = request.data[\"host_ip\"] return Response({\"code\": 200, \"host_ip\": host_ip}) urlpatterns = [ path('api/get_self_task', get_self_task) ] 可以看到，在上面的例子中，我们定义了一个get_self_task函数，这个函数可以接收GET和POST请求。 对于GET请求，从url中获取host_ip信息，对于POST请求，从body中获取host_ip信息，并将相关结果进行返回。 其中，@permission_classes([IsAuthenticated])是必不可少的，因为我们之前的settings.py 中设置的相关权限的配置，因此需要在所有自定义的api_view函数中都需要增加该装饰器。 参考资源 Django REST Framework官方 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/django/celery.html":{"url":"language/django/celery.html","title":"DjangoCelery快速入门","keywords":"","body":"Django Celery快速入门 什么是Celery Celery是一个分布式任务的框架，具备如下特点： 简单：几行代码就可以创建一个简单的Celery任务。 高可用：任务可以自动重试。 快速：可以在一分钟内执行上百万个任务。 灵活：每一部分都可以轻松进行扩展。 Celery使用场景 Celery非常适合用于去做需要异步执行的任务，例如： 发送电子邮件，发送IM消息通知 爬取网页，数据分析 图片和视频处理 生成报告等 Celery架构 Celery架构如下图所示： 首先，任务的来源可以是WebServer下发，也是可以是定时任务器下发。 接下来，下发的任务首先会存放到一个Broker的队列中等待处理。 然后Worker会从Broker消息队列中读取消息并处理。 最后将处理后得到的结果再次写入一个数据库进行存储。 Celery环境搭建 下面，我们来看如何搭建Celery的环境。 第一步：安装Celery第三方库 pip3 install celery 第二步：安装Celery依赖库 pip3 install \"celery[librabbitmq,redis,auth,msgpack]\" 第三步：做为Broker示例，我们需要安装一个Redis，此处，我们用docker了部署一个Redis实例 docker run -d -p 6379:6379 redis 到此为止，Celery的基本环境我们就已经准备完成了，下面我们可以用一个Celery的demo来验证我们的环境是否OK。 Celery Demo 创建tasks.py文件如下: from celery import Celery app = Celery('tasks', broker='redis://127.0.0.1', backend='redis://127.0.0.1') @app.task def add(x, y): return x + y 启动celery worker: celery -A tasks worker --loglevel=info 接下来，我们创建一个运行任务的脚本run_task.py: from tasks import add result = add.delay(4, 4) print('Is Task ready: %s' % result.ready()) run_result = result.get(timeout=1) print(\"task result: %s\" % run_result) 运行脚本，观察输出如下： python3 ./run_task.py # Is Task ready: False # task result: 8 可以看到，该任务的确是异步执行的，首先执行后，任务的状态并未完成，然后等待任务执行完成后，获取到了计算的结果。 Celery任务的监控 因为任务异步化对于我们项目的运维和问题定位无疑是增加了一定的成本，为了能够让我们的系统更加容易监控和观察，Celery提供了一套监控方案：Flower。 下面，我们来体验一下Flower。 Step1: 安装flower pip3 install flower==0.9.7 Step2: 启动flower celery -A tasks flower --broker=redis://localhost:6379/0 访问localhost:5555可以看到如下页面: 在该页面中，我们可以查询Celery相关的节点，任务等一系列详细信息。 Django集成Celery 在上面的例子中，我们主要在讲解Celery自身的功能和用法，接下来，我们将会结合Django来讲解如何在Django中使用Celery。 第一步: 在Django主应用的目录下，创建一个celery.py文件： from __future__ import absolute_import, unicode_literals import os from celery import Celery os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'project_name.settings') app = Celery('project_name') # Using a string here means the worker doesn't have to serialize # the configuration object to child processes. # - namespace='CELERY' means all celery-related configuration keys # should have a `CELERY_` prefix. app.config_from_object('django.conf:settings', namespace='CELERY') # Load task modules from all registered Django app configs. app.autodiscover_tasks() # 自动收集各个应用下的tasks.py文件 @app.task(bind=True) def debug_task(self): print('Request: {0!r}'.format(self.request)) 第二步: 在Django主应用目录下修改__init__.py文件如下： from __future__ import absolute_import, unicode_literals # This will make sure the app is always imported when # Django starts so that shared_task will use this app. from .celery import app as celery_app __all__ = ('celery_app',) 它的作用是在项目启动的时候初始化Celery APP对象。 第三步: 修改settings.py文件，增加Celery的相关配置。 CELERY_BROKER_URL = 'redis://redis:6379/0' CELERY_RESULT_BACKEND = 'redis://redis:6379/1' CELERY_ACCEPT_CONTENT = ['application/json'] CELERY_RESULT_SERIALIZER = 'json' CELERY_TASK_SERIALIZER = 'json' CELERY_TIMEZONE = 'Asia/Shanghai' CELERYD_MAX_TASKS_PER_CHILD = 10 CELERYD_LOG_FILE = os.path.join(BASE_DIR, \"logs\", \"celery_work.log\") CELERYBEAT_LOG_FILE = os.path.join(BASE_DIR, \"logs\", \"celery_beat.log\") 第四步：在对应的APP目录下，创建tasks.py文件： from __future__ import absolute_import, unicode_literals from celery import shared_task from .dingtalk import send @shared_task def send_dingtalk_message(message): send(message) 此时，只需要在将之前调用send的方法改成send_dingtalk_message.delay的方式调用，即可实现异步任务执行的逻辑。 第五步: 启动相关服务 启动Celery celery --app ${project_name} worker -l info 启动Django python3 ./manage.py runserver 0.0.0.0:8000 启动flower监控 celery -A ${project_name} flower Django支持定时任务 上面的内容中，我们使用Django + Celery结合实现了异步任务的执行，接下来，我们将会利用Celery + Django实现定时任务。 准备工作 Step1: 安装第三方依赖 pip3 install django-celery-beat Step2: 在项目配置的INSTALL_APPS中添加django_celery_beat。 Step3: 同步数据库表结构。 python3 ./manage.py migrate Step4: 启动Beat进程 celery -A ${project_name} beat --scheduler django_celery_beat.schedulers:DatabaseScheduler 管理定时任务的方法 在django-celery-beat中，有如下几种管理定时任务的方式： 在Admin后台添加管理定时任务。 系统启动时自动注册定时任务。 直接设置应用的beat_scheduler。 运行时添加定时任务。 django-celery-beat管理后台管理定时任务 打开django-celery-beat管理后台，你会看到Periodic Task的项目下存在Intervals 、 Crontabs 、 Periodic task。 其中： Intervals 定义了定时任务的间隔时间。 Crontabs 支持通过 Linux Crontabs 的格式来定义任务的运行时机的。 Periodic task 中定义了具体有哪些定时任务。 最终，我们可以通过在Admin管理后台创建 Periodic task 来实现定时任务的管理。 系统启动时自动注册定时任务 除了Admin管理后台外，我们还可以在系统启动时启动注册定时任务，注册的方式如下，修改project_name/celery.py文件，增加如下内容： from celery.schedules import crontab @app.task def test(arg): print(arg) @app.on_after_configure.connect def setup_periodic_tasks(sender, **kwargs): # Calls test('hello') every 10 seconds. sender.add_periodic_task(10.0, test.s('hello'), name='hello every 10') # Calls test('world') every 30 seconds sender.add_periodic_task(30.0, test.s('world'), expires=10) # Executes every Monday morning at 7:30 a.m. sender.add_periodic_task( crontab(hour=7, minute=30, day_of_week=1), test.s('Happy Mondays!'), ) 直接设置应用的beat_scheduler app.conf.beat_schedule = { 'add-every-10-seconds': { 'task': 'app_name.tasks.function_name', 'schedule': 10.0, 'args': (16, 4, ) }, } 直接对Celery对象设置 conf.beat_schedule 即可。 运行时添加定时任务 from django_celery_beat.models import PeriodicTask, IntervalSchedule # 创建定时策略 scheduler, created = IntervalSchedule.object.get_or_create(every=10, period=IntervalSchedule.SECONDS) # 创建任务 task = PeriodicTask.objects.create( interval=scheduler, name=\"say welcome\", task='project_name.celery.function', args=json.dumps(data) ) 参考资源 Celery官方文档 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/beginning.html":{"url":"language/shell/beginning.html","title":"Shell快速入门","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/variable.html":{"url":"language/shell/variable.html","title":"Shell 变量详解","keywords":"","body":"shell 变量详解 定义变量 在 shell 中定义一个变量的示例如下： your_name=\"wangzhe0912\" 注意： 变量名和等号之间不能有空格。 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线（_）。 不能使用bash里的关键字。 除了显示的给变量赋值，在 shell 中还可以通过语句给变量赋值，如： for file in `ls /etc` // 或 for file in $(ls /etc) 以上语句将 /etc 下目录的文件名循环出来。 使用变量 使用一个定义过的变量，只要在变量名前面加美元符号即可，如： your_name=\"qinjx\" echo $your_name echo ${your_name} 其中，变量名外面的花括号是可选的，加不加都行（推荐加上）。 加花括号是为了帮助解释器识别变量的边界，比如下面这种情况： for skill in Ada Coffe Action Java; do echo \"I am good at ${skill}Script\" done 对于已定义的变量，可以被重新定义，如: your_name=\"tom\" echo $your_name your_name=\"alibaba\" echo $your_name 只读变量 有时，我们希望某个变量是只读的，即不能被修改。 此时，可以使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。 示例如下： myUrl=\"https://www.google.com\" readonly myUrl myUrl=\"https://www.runoob.com\" 运行脚本，结果如下： /bin/sh: NAME: This variable is read only. 删除变量 使用 unset 命令可以删除变量。语法： unset variable_name Ps: 变量被删除后不能再次使用。unset 命令不能删除只读变量。 变量类型 在运行shell时，会同时存在三种变量：局部变量、全局变量、环境变量。 局部变量 Shell 也支持自定义函数，但是 Shell 函数和 C++、Java、C# 等其他编程语言函数的一个不同点就是： 在 Shell 函数中定义的变量默认就是全局变量，它和在函数外部定义变量拥有一样的效果。请看下面的代码： #!/bin/bash #定义函数 function func(){ a=99 } #调用函数 func #输出函数内部的变量 echo $a 上述命令输出结果为 99 。 也就是说，虽然 a 是在 func 函数内部定义的，但是在函数外部也可以得到它的值，证明它的作用域是全局的，而不是仅仅局限于函数内部。 要想变量的作用域仅限于函数内部，可以在定义时加上local命令，此时该变量就成了局部变量。 #!/bin/bash #定义函数 function func(){ local a=99 } #调用函数 func #输出函数内部的变量 echo $a 此时，输出结果为空，表明变量 a 在函数外部无效，是一个局部变量。 全局变量 上面已经提到了，shell 中默认定义的变量就是一个全局变量，那么这个全局变量生效的范围是什么样的呢？ 所谓全局变量，就是指变量在当前的整个Shell进程中都有效。每个Shell进程都有自己的作用域，彼此之间互不影响。 这里面有一个很重要的概念，当前的整个Shell进程。 那么，怎么来理解什么是一个shell进程呢？ 一. 不同的 shell 终端窗口对应着不同的 shell 进程，这个比较好理解，我们此处不多解释。 二. 在一个 Shell 进程中可以使用 source 命令执行多个 Shell 脚本文件，此时全局变量在这些脚本文件中都有效。 例如，现在有两个 Shell 脚本文件，分别是 a.sh 和 b.sh。a.sh 的代码如下： #!/bin/bash echo $a b=200 b.sh 的代码如下： #!/bin/bash echo $b 打开一个 Shell 窗口，输入以下命令： a=99 source ./a.sh # 99 source ./b.sh # 200 这三条命令都是在一个进程中执行的，从输出结果可以发现，在 Shell 窗口中以命令行的形式定义的变量 a，在 a.sh 中有效；在 a.sh 中定义的变量 b， 在 b.sh 中也有效，变量 b 的作用范围已经超越了 a.sh。 三. 在一个 shell 进程中，sh 执行其他 shell 脚本时，会创建出不同的 shell 进行，导致全局变量无法在新的 shell 脚本中生效。 同样还是以上述 a.sh 和 b.sh 的代码为例，打开一个 shell 窗口，输入如下命令： a=99 sh ./a.sh # sh ./b.sh # 我们把 source 修改为 sh 后，可以看到行为已经发生了具体的变化，这正式因为 sh 命令执行时会新建一个 shell 进程，导致全局变量无法传递。 环境变量 那么，如果我们想要让一个变量可以在 fork 出的 shell 进程中同样生效时，应该怎么处理呢？这就要用到我们接下来介绍的环境变量了。 如果使用 export 命令将全局变量导出，那么它就在所有的子进程中也有效了，这称为“环境变量”。 环境变量被创建时所处的 Shell 进程称为父进程，如果在父进程中再创建一个新的进程来执行 Shell 命令，那么这个新的进程被称作 Shell 子进程。 当 Shell 子进程产生时，它会继承父进程的环境变量为自己所用，所以说环境变量可从父进程传给子进程。不难理解，环境变量还可以传递给孙进程。 注意，两个没有父子关系的 Shell 进程是不能传递环境变量的，并且环境变量只能向下传递而不能向上传递，即“传子不传父”。 修改 a.sh 文件如下： #!/bin/bash echo $a export b=200 打开一个 shell 窗口，输入如下命令： export a=99 sh ./a.sh # 99 sh ./b.sh # 200 此时，可以发现此时虽然是用 sh fork 出来了子进程，但是我们设置的相关变量依旧是有效的。 Ps: 通过 export 导出的环境变量只对当前 Shell 进程以及所有的子进程有效，如果最顶层的父进程被关闭了， 那么环境变量也就随之消失了，其它的进程也就无法使用了，所以说环境变量也是临时的。 shell 字符串 字符串是 shell 编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），字符串可以用单引号，也可以用双引号，也可以不用引号。 单引号 str='this is a string' 单引号字符串的限制： 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的； 单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。 双引号 your_name='runoob' str=\"Hello, I know you are \\\"$your_name\\\"! \\n\" echo -e $str 输出结果为： Hello, I know you are \"runoob\"! 双引号的优点： 双引号里可以有变量。 双引号里可以出现转义字符。 拼接字符串 your_name=\"runoob\" # 使用双引号拼接 greeting=\"hello, \"$your_name\" !\" greeting_1=\"hello, ${your_name} !\" echo $greeting $greeting_1 # 使用单引号拼接 greeting_2='hello, '$your_name' !' greeting_3='hello, ${your_name} !' echo $greeting_2 $greeting_3 输出结果为： hello, runoob ! hello, runoob ! hello, runoob ! hello, ${your_name} ! 获取字符串的长度 string=\"abcd\" echo ${#string} #输出 4 即在变量名前增加 # 号，并使用 ${} 包围时相关于计算该字符串的长度。 截断子字符串 以下示例从字符串第 2 个字符开始截取 4 个字符： string=\"runoob is a great site\" echo ${string:1:4} # 输出 unoo Ps: 字符串的索引规则与 Python 的语言一致，索引都是从0开始。 查找子字符串 查找字符 i 或 o 的位置(哪个字母先出现就计算哪个)： string=\"runoob is a great site\" echo `expr index \"$string\" io` # 输出 4 Ps: 上述脚本中使用了 ``` 进行了命令执行。 shell 数组 bash支持一维数组（不支持多维数组），并且没有限定数组的大小。 类似于 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 定义数组 在 Shell 中，用括号来表示数组，数组元素用\"空格\"符号分割开。定义数组的一般形式为： 数组名=(值1 值2 ... 值n) 例如: array_name=(value0 value1 value2 value3) 或者: array_name=( value0 value1 value2 value3 ) 还可以单独定义数组的各个分量: array_name[0]=value0 array_name[1]=value1 array_name[n]=valuen Ps: 可以不使用连续的下标，而且下标的范围没有限制。 读取数组 读取数组元素值的一般格式是： ${数组名[下标]} 例如: valuen=${array_name[n]} 使用 @ 符号可以获取数组中的所有元素，例如： echo ${array_name[@]} 获取数组的长度 获取数组长度的方法与获取字符串长度的方法相同，例如： # 取得数组元素的个数 length=${#array_name[@]} # 或者 length=${#array_name[*]} # 取得数组单个元素的长度 lengthn=${#array_name[n]} shell 注释 以 # 开头的行就是注释，会被解释器忽略。 通过每一行加一个 # 号设置多行注释，像这样： #-------------------------------------------- # 这是一个注释 #-------------------------------------------- ##### 用户配置区 开始 ##### # # # 这里可以添加脚本描述信息 # # ##### 用户配置区 结束 ##### 上面针对的是单行注释，如果想要进行多行注释，方式如下： : 其中，EOF 也可以替换为其他符号，例如: : 系统环境变量 在 Linux 中，有一些系统内置且具备一些特殊含义的环境变量，例如： $USER: 当前用户 $UID: 当前用户ID $PATH: 默认命令搜索路径，该目录下包含的二进制命令和脚本可以直接运行，无须输入完整路径。 $PS1: 当前终端提示样式 预定义变量 预定义变量是指 Linux Shell 中一些内置的有特殊含义的变量，例如: $?: 返回上一条命令的返回码 $$: 返回当前进程PID $0: 返回当前的进程/脚本名称 $#: 返回传入参数的数量 $@/$*: 返回全部传入的参数 ${number}: 用于参数接收，表示接收第 number 个传入的参数。 ${number-default}: 用于参数接收，表示接收第 number 个传入的参数，如果没有传入参数，则将default值作为默认值。 环境变量配置文件 我们已经知道，环境变量在 Shell 中非常重要了，那么怎么设置默认的环境变量呢？ 在 Linux 系统中，与环境变量相关的配置文件包括如下： /etc/profile /etc/profile.d/ /etc/bashrc ~/.bash_profile ~/.bashrc 那么为什么需要这么多的配置文件来设置环境变量呢？各个不同的文件有什么区别呢？ 首先，适用范围不同： 对于 /etc/ 目录下的配置文件而言，生效的范围是所有登录用户。 对于 ~ 目录下的配置文件当前，生效的范围是当前用户。 其次，加载时机不同： 对于 profile 类配置文件而言: 对于 no login shell 而言，是不会生效的。如 su root 对于 bashrc 类配置文件而言: 无论是 login shell 还是 no login shell，都会生效。如 su - root By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/function.html":{"url":"language/shell/function.html","title":"Shell 函数详解","keywords":"","body":"Shell 函数详解 在本节中，我们将会详细讲解 Shell 中函数的使用。 函数基本格式 linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。 shell中函数的定义格式如下： [ function ] function_name() { action; [return int;] } 说明： 在函数定义前，可以加 function 关键词，也可以省略。 函数参数返回，可以加 return 进行显示指定返回值，如果不显示使用 return 语句，则将会以最后一条命令的返回码作为返回值返回。 示例程序如下： demoFun(){ echo \"这是我的第一个 shell 函数!\" } echo \"-----函数开始执行-----\" demoFun echo \"-----函数执行完毕-----\" Ps: 需要注意的是函数调用的过程中，不能在函数名后追加 () 。 注意：所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分，直至shell解释器首次发现它时，才可以使用。调用函数仅使用其函数名即可。 带有 return 的函数 下面，我们来针对一个带有返回值的函数进行演示。 funWithReturn(){ echo \"这个函数会对输入的两个数字进行相加运算...\" echo \"输入第一个数字: \" read aNum echo \"输入第二个数字: \" read anotherNum echo \"两个数字分别为 $aNum 和 $anotherNum !\" return $(($aNum+$anotherNum)) } funWithReturn echo \"输入的两个数字之和为 $? !\" 其中，通过 $? 可以读取上一条函数执行得到的返回值。 函数传参 下面，我们来看一下如果和参数调用的过程中进行参数传递。 在Shell中，调用函数时可以向其传递参数。 与其他语言的函数调用不一样，对于 shell 而言，在函数体内部，通过 $n 的形式来获取参数的值，例如，$1 表示第一个参数，$2 表示第二个参数。 一个示例如下： funWithParam(){ echo \"第一个参数为 $1 !\" echo \"第二个参数为 $2 !\" echo \"第十个参数为 $10 !\" echo \"第十个参数为 ${10} !\" echo \"第十一个参数为 ${11} !\" echo \"参数总数有 $# 个!\" echo \"作为一个字符串输出所有参数 $* !\" } funWithParam 1 2 3 4 5 6 7 8 9 34 73 其中，主要注意的是： $10 不能获取第十个参数，获取第十个参数需要 ${10}，即当 n>=10 时，需要使用 ${n} 来获取参数。 $# 可以获取传递到脚本或函数的参数个数。 $* 或 $# 以一个字符串显示所有向脚本传递的参数。 函数的输入参数处理 针对多个参数传入而言，shell 中有多种推荐的处理方式。 方式一: for 循环处理 for para in $* do echo \"receive param： ${para}\" done 方式二: while 循环处理 while [ $# -gt 0 ]; do echo \"receive param： ${1}\" shift done 其中，shift 表示去除传入的第一个参数。 系统内置函数 在 Linux 系统中，在 /etc/init.d/functions 文件中已经定义了一系列的内置常用函数，我们可以直接使用。 例如: source /etc/init.d/functions echo_success echo_failure echo_passed By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/operators.html":{"url":"language/shell/operators.html","title":"Shell 基本运算符","keywords":"","body":"Shell 基本运算符 概述 Shell 和其他编程语言一样，支持多种运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符 原生 bash 其实不支持简单的数学运算，但是可以通过其他命令来实现， 例如 expr, let, 双圆括号，其中 expr 最常用。 expr 是一款表达式计算工具，使用它能完成表达式的求值操作。 例如，两个数相加(注意使用的是反引号 ` 而不是单引号 ')： #!/bin/bash val=`expr 2 + 2` echo \"两数之和为 : $val\" 执行脚本，输出结果如下所示： 两数之和为 : 4 有两点需要注意一下： 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。 完整的表达式要被 包含，注意这个字符不是常用的单引号，在 Esc 键下边。 算术运算符 下表列出了常用的算术运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 示例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a \\* $b 结果为 200。 / 除法 expr $b / $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 = 赋值 a=$b 将把变量 b 的值赋给 a。 == 相等。用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。 Ps: 条件表达式要放在方括号之间，并且要有空格，例如: [$a==$b] 是错误的，必须写成 [ $a == $b ]。 代码示例如下： a=10 b=20 val=`expr $a + $b` echo \"a + b : $val\" val=`expr $a - $b` echo \"a - b : $val\" val=`expr $a \\* $b` echo \"a * b : $val\" val=`expr $b / $a` echo \"b / a : $val\" val=`expr $b % $a` echo \"b % a : $val\" if [ $a == $b ] then echo \"a 等于 b\" fi if [ $a != $b ] then echo \"a 不等于 b\" fi 执行脚本，输出结果如下所示： a + b : 30 a - b : -10 a * b : 200 b / a : 2 b % a : 0 a 不等于 b 注意： 乘号(*)前边必须加反斜杠()才能实现乘法运算； if...then...fi 是条件语句，后续还会详细讲解。 在 MAC 中 shell 的 expr 语法是：$((表达式))，此处表达式中的 \"*\" 不需要转义符号 \"\\\" 。 关系运算符 关系运算符只支持数字，不支持字符串，除非字符串的值是数字。 下表列出了常用的关系运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 示例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 代码示例如下： a=10 b=20 if [ $a -eq $b ] then echo \"$a -eq $b : a 等于 b\" else echo \"$a -eq $b: a 不等于 b\" fi if [ $a -ne $b ] then echo \"$a -ne $b: a 不等于 b\" else echo \"$a -ne $b : a 等于 b\" fi if [ $a -gt $b ] then echo \"$a -gt $b: a 大于 b\" else echo \"$a -gt $b: a 不大于 b\" fi if [ $a -lt $b ] then echo \"$a -lt $b: a 小于 b\" else echo \"$a -lt $b: a 不小于 b\" fi if [ $a -ge $b ] then echo \"$a -ge $b: a 大于或等于 b\" else echo \"$a -ge $b: a 小于 b\" fi if [ $a -le $b ] then echo \"$a -le $b: a 小于或等于 b\" else echo \"$a -le $b: a 大于 b\" fi 执行脚本，输出结果如下所示： 10 -eq 20: a 不等于 b 10 -ne 20: a 不等于 b 10 -gt 20: a 不大于 b 10 -lt 20: a 小于 b 10 -ge 20: a 小于 b 10 -le 20: a 小于或等于 b 布尔运算符 下表列出了常用的布尔运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 示例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 布尔运算符实例如下： a=10 b=20 if [ $a != $b ] then echo \"$a != $b : a 不等于 b\" else echo \"$a == $b: a 等于 b\" fi if [ $a -lt 100 -a $b -gt 15 ] then echo \"$a 小于 100 且 $b 大于 15 : 返回 true\" else echo \"$a 小于 100 且 $b 大于 15 : 返回 false\" fi if [ $a -lt 100 -o $b -gt 100 ] then echo \"$a 小于 100 或 $b 大于 100 : 返回 true\" else echo \"$a 小于 100 或 $b 大于 100 : 返回 false\" fi if [ $a -lt 5 -o $b -gt 100 ] then echo \"$a 小于 5 或 $b 大于 100 : 返回 true\" else echo \"$a 小于 5 或 $b 大于 100 : 返回 false\" fi 执行脚本，输出结果如下所示： 10 != 20 : a 不等于 b 10 小于 100 且 20 大于 15 : 返回 true 10 小于 100 或 20 大于 100 : 返回 true 10 小于 5 或 20 大于 100 : 返回 false 逻辑运算符 以下介绍 Shell 的逻辑运算符，假定变量 a 为 10，变量 b 为 20: 运算符 说明 示例 && 逻辑与 [[ $a -lt 100 && $b -gt 100 ]] 返回 false || 逻辑或 [[ $a -lt 100 || $b -gt 100 ]] 返回 true 示例代码如下: a=10 b=20 if [[ $a -lt 100 && $b -gt 100 ]] then echo \"返回 true\" else echo \"返回 false\" fi if [[ $a -lt 100 || $b -gt 100 ]] then echo \"返回 true\" else echo \"返回 false\" fi 执行脚本，输出结果如下所示： 返回 false 返回 true 字符串运算符 下表列出了常用的字符串运算符，假定变量 a 为 \"abc\"，变量 b 为 \"efg\": 运算符 说明 示例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否不相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否不为 0，不为 0 返回 true。 [ -n \"$a\" ] 返回 true。 $ 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 示例代码如下: a=\"abc\" b=\"efg\" if [ $a = $b ] then echo \"$a = $b : a 等于 b\" else echo \"$a = $b: a 不等于 b\" fi if [ $a != $b ] then echo \"$a != $b : a 不等于 b\" else echo \"$a != $b: a 等于 b\" fi if [ -z $a ] then echo \"-z $a : 字符串长度为 0\" else echo \"-z $a : 字符串长度不为 0\" fi if [ -n \"$a\" ] then echo \"-n $a : 字符串长度不为 0\" else echo \"-n $a : 字符串长度为 0\" fi if [ $a ] then echo \"$a : 字符串不为空\" else echo \"$a : 字符串为空\" fi 执行脚本，输出结果如下所示： abc = efg: a 不等于 b abc != efg : a 不等于 b -z abc : 字符串长度不为 0 -n abc : 字符串长度不为 0 abc : 字符串不为空 文件测试运算符 文件测试运算符用于检测 Unix 文件的各种属性。 属性检测描述如下： 运算符 说明 示例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 示例代码如下: file=\"/var/www/runoob/test.sh\" if [ -r $file ] then echo \"文件可读\" else echo \"文件不可读\" fi if [ -w $file ] then echo \"文件可写\" else echo \"文件不可写\" fi if [ -x $file ] then echo \"文件可执行\" else echo \"文件不可执行\" fi if [ -f $file ] then echo \"文件为普通文件\" else echo \"文件为特殊文件\" fi if [ -d $file ] then echo \"文件是个目录\" else echo \"文件不是个目录\" fi if [ -s $file ] then echo \"文件不为空\" else echo \"文件为空\" fi if [ -e $file ] then echo \"文件存在\" else echo \"文件不存在\" fi 执行脚本，输出结果如下所示： 文件可读 文件可写 文件可执行 文件为普通文件 文件不是个目录 文件不为空 文件存在 双圆括号操作符 下面，我们来了解一下如何使用双圆括号进行算术运算： a=10 (( a++ )) echo $a b=$(( a * 2)) echo $b 可以看出，在双圆括号中，我们可以让 shell 正常执行相关的算术运算符。 中括号操作符 在上面的内容中，我们已经知道，在 shell 中，中括号可以用于一个条件判断相关的计算，例如 [ 10 -gt 5 ] echo $? 双中括号操作符 可以看出，上述的判断方式其实并不是非常的自然，比如，我们要使用 -gt 来表示大于，而不能直接使用大于号进行判断。 为此，shell 其实是支持通过双中括号进行更加友好的条件判断的，这就用到了双中括号，例如: [[ 10 > 1 ]] echo $? Ps: 需要注意的是，双方括号进行的是字符串比较，如果是数字运算或比较，需要使用双圆括号。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/string.html":{"url":"language/shell/string.html","title":"Shell 文本处理","keywords":"","body":"Shell 文本处理 在之前的 Shell 变量详解 一文中，我们简单的讲解了 shell 中的一些字符串基本用法， 比如字符串的截断、计算字符串的长度等。 但实际上，shell 对于本文/字符串的操作的能力远比这个强大的多，下面，我们来以使用场景为例，来说明如果使用 shell 来完成相关功能。 string.replace 功能 字符串处理中，一个最常用的方式就是将指定字符串中的某个字符串替换为其他字符串，下面，我们来看一下如何实现。 例如，对于一个字符串: apple,pear,banana，我们希望能够将',' 替换为 ' '。 {str//,/ } 来处理 我们先来讲述一个最简单的方法，就是直接用 ' ' 来替换 ',' 字符串，并将用 ' ' 分割的字符串转化为数组。 基本语法如上表达式。 ${string//字符串1/字符串2} 上述操作的函数表示将 string 中的所有 字符串1 替换为 字符串2 。 那么，我们来看一下如果想要将 , 转换成为 空格 需要怎么实现，没错，就是这样: ${string//,/ } 即此时字符串1对应','，而字符串2对应' '即可。 完整示例代码如下: old_str=\"apple,pear,banana\" new_str=${old_str//,/ } echo $new_str tr 命令 下面，我们来讲解第二种可以用于字符串替换的方法，tr 命令。 Linux tr 命令用于转换或删除文件中的字符。 具体来说: tr 指令从标准输入设备读取数据，经过字符串转译后，将结果输出到标准输出设备，常常可以用于管道命令中。 tr 命令的基本语法如下： tr [第一字符集] [第二字符集] 即可以将输入输出中包含的第一字符集中的字符全部转换为第二字符集中的对应的字符。 还是用一个完整的代码来看一下: old_str=\"apple,pear,banana\" new_str=`echo $old_str | tr ',' ' '` echo $new_str 不过从上面的功能描述中，我们就已经可以感受到tr命令的强大了，tr可以针对一组字符进行一一映射的替换到另外一组字符上。 awk 命令 awk 是一个更加强大的文本处理语言，在文本分析的场景中非常重要。 此处，我们先不对 awk 命令进行展开介绍，使用示例如下: old_str=\"apple,pear,banana\" new_str=`echo $old_str | awk 'BEGIN{FS=\",\";OFS\" \"} {print $1,$2,$3}'` echo $new_str string.split 功能 在 shell 脚本中，我们经常会有一个需求，就是将一个字符串按照指定关键字符进行切分，从而得到一个数组。 例如，对于一个字符串: apple,pear,banana，我们希望能够按照 , 进行切分，从而得到一个 (apple pear banana) 的数组。 那么，我们首先需要了解在 shell 中怎么才能创建一个数组。 在 shell 中创建一个数组的方式非常简单，基本格式如下： arr=(element1 element2 element3) 可以看到，在 shell 中创建一个数组的方式非常简单，只需要用 () 包围一个字符串，且字符串中各个元素用空白符进行间隔，那么就会自动创建出来一个数组。 而在上文的介绍中，我们已经介绍了多种方式可以用 ',' 替换为空白符，那么此时我们只需要用 () 将替换后的结果包围起来就可以完成 split 的功能了。 完整的代码如下所示（以tr命令为例）: str=\"apple,pear,banana\" arr=(`echo $str | tr ',' ' '`) echo \"first element is ${arr[0]}\" echo \"total number is ${#arr[*]}\" for element in ${arr[*]} ; do echo \"element is ${element}\" done Ps: 其他替换的方式原理是一致的。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/condition.html":{"url":"language/shell/condition.html","title":"Shell 条件语句","keywords":"","body":"Shell 条件语句 在本文中，我们将会介绍在 shell 中，如何实现条件控制。 if else 语法 if 语句的语法格式如下: if condition then command1 command2 ... commandN fi 写成一行其实也是可以的: if [ `ps -ef | grep -c \"ssh\"` -gt 1 ]; then echo \"true\"; fi Ps: 末尾的 fi 就是 if 倒过来拼写，后面还会遇到类似的写法。 if else 的语法格式如下: if condition then command1 command2 ... commandN else command fi if else-if else 语法格式如下: if condition1 then command1 elif condition2 then command2 else commandN fi 完整示例代码如下: a=10 b=20 if [ $a == $b ] then echo \"a 等于 b\" elif [ $a -gt $b ] then echo \"a 大于 b\" elif [ $a -lt $b ] then echo \"a 小于 b\" else echo \"没有符合的条件\" fi 输出结果如下: a 小于 b if else 语句经常与 test 命令结合使用，如下所示： num1=$[2*3] num2=$[1+5] if test $[num1] -eq $[num2] then echo '两个数字相等!' else echo '两个数字不相等!' fi 关于 test 命令的更多介绍，可以参考 文档 。 Ps: test 其实可以简单为 [] 方括号~ case .. esac 语句 case ... esac 为多选择语句，与其他语言中的 switch ... case 语句类似，是一种多分枝选择结构。 每个 case 分支用右圆括号开始，用两个分号 ;; 表示 break，即执行结束，跳出整个 case ... esac 语句，esac（就是 case 反过来）作为结束标记。 可以用 case 语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。 case ... esac 语法格式如下： case 值 in 模式1) command1 command2 ... commandN ;; 模式2） command1 command2 ... commandN ;; esac case 工作方式如上所示，取值后面必须为单词 in，每一模式必须以右括号结束。 取值可以为变量或常数，匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。 取值将检测匹配的每一个模式。 一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。 如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 示例代码如下: echo '输入 1 到 5 之间的数字:' echo '你输入的数字为:' read aNum case $aNum in 1) echo '你选择了 1' ;; 2) echo '你选择了 2' ;; 3) echo '你选择了 3' ;; 4|5) echo '你选择了 4 或者 5' ;; *) echo '你没有输入 1 到 5 之间的数字' ;; esac By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/loop.html":{"url":"language/shell/loop.html","title":"Shell 循环语句","keywords":"","body":"Shell 循环语句 在本文中，我们将会介绍在 shell 中，如何实现循环控制。 for 循环 与其他编程语言类似，Shell支持for循环。 for循环一般格式为： for var in item1 item2 ... itemN do command1 command2 ... commandN done 同时，上述代码也可以简化成一行: for var in item1 item2 ... itemN; do command1; command2; done; 当变量值在列表里，for 循环即执行一次所有命令，使用变量名获取列表中的当前取值。 命令可为任何有效的 shell 命令和语句。 示例代码如下： for str in This is a string do echo $str done 此外，for 训练的遍历对象还可以是 {} 展开的列表，例如: for i in {1..9}; do echo \"i is ${i}\" done 同时，shell 的 for 循环还支持 C 语言风格的循环: for (( i=1; i while 循环 while 循环用于不断执行一系列命令，也用于从输入文件中读取数据。其语法格式为： while condition do command done 以下是一个基本的 while 循环，测试条件是：如果 int 小于等于 5，那么条件返回真。int 从 1 开始，每次循环处理时，int 加 1。 运行上述脚本，返回数字 1 到 5，然后终止。 #!/bin/bash int=1 while (( $int 上述代码中，使用 (( )) 包围了一个数学表达式用于条件判断。 同时，在循环体中，使用了 expr 来实现了变量值加一。 无限循环 无限循环语法格式： while : do command done 或 while true do command done 或 for (( ; ; )) until 循环 until 循环执行一系列命令直至条件为 true 时停止。 until 循环与 while 循环在处理方式上刚好相反。 一般 while 循环优于 until 循环，但在某些时候—也只是极少数情况下，until 循环更加有用。 until 语法格式: until condition do command done condition 一般为条件表达式，如果返回值为 false，则继续执行循环体内的语句，否则跳出循环。 以下实例我们使用 until 命令来输出 0 ~ 9 的数字： a=0 until [ ! $a -lt 10 ] do echo $a a=`expr $a + 1` done break 和 continue 在循环过程中，有时候需要在未达到循环结束条件时强制跳出循环，Shell使用两个命令来实现该功能：break 和 continue。 break 命令 break命令允许跳出所有循环（终止执行后面的所有循环）。 下面的例子中，脚本进入死循环直至用户输入数字大于5。要跳出这个循环，返回到shell提示符下，需要使用break命令。 #!/bin/bash while : do echo -n \"输入 1 到 5 之间的数字:\" read aNum case $aNum in 1|2|3|4|5) echo \"你输入的数字为 $aNum!\" ;; *) echo \"你输入的数字不是 1 到 5 之间的! 游戏结束\" break ;; esac done continue 命令 continue命令与break命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。 对上面的例子进行修改： #!/bin/bash while : do echo -n \"输入 1 到 5 之间的数字: \" read aNum case $aNum in 1|2|3|4|5) echo \"你输入的数字为 $aNum!\" ;; *) echo \"你输入的数字不是 1 到 5 之间的!\" continue echo \"游戏结束\" ;; esac done Ps: 运行代码发现，当输入大于5的数字时，该例中的循环不会结束，语句 echo \"游戏结束\" 永远不会被执行。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/execute_method.html":{"url":"language/shell/execute_method.html","title":"Shell 脚本的执行方式","keywords":"","body":"Shell 脚本的执行方式 在本文中，我们将会讲解几种不同的 shell 命令的执行方式，并对它们的不同之处进行对比。 bash filename.sh 首先，我们来介绍最常用的一种执行方式。 以一个 test1.sh 脚本为例： a=\"hello world!\" echo a 当我们执行 bash test1.sh 命令时，实际是我 fork 一个子进程，并通过 bash 解释器来执行来脚本。 ./filename.sh 当一个 shell 脚本本身有执行权限时，我们可以执行执行该文件，而无须添加 bash 命令即可。 但是，此时具体该文件使用哪种解释器来执行呢？其实是取决与该文件头的 Sha-Bang。 例如，test2.sh 脚本如下： #!/usr/bin/env bash a=\"hello world!\" echo a 注意上述文件的第一行，表名了直接执行该文件时，是通过 bash 的方式进行执行。 source filename.sh source 的方式执行一个文件与上述方式最大的区别是：source 方式是在当前进程下执行该命令，而不是 fork 了一个新的进程。 是否是 fork 新的进程实际上会有什么影响呢？ 从之前的文章中，我们都知道在 shell 中变量是有作用域的，例如函数内部的局部变量，默认的全局变量以及环境变量的。 还记得环境变量和全局变量的区别嘛？ 环境变量可以在当前的进程及其子进程中都生效，而全局变量仅仅能在当前进程下生效。 因此，可以看出，是否 fork 子进程执行命令其实更多的是影响了全局变量/环境变量的生效。 例如，如果我们在一个脚本 test3.sh 中，定义了各种全局变量和环境变量： export NAME=wangzhe12 export AGE=29 message=\"hello world!\" 如果我们使用 sh test3.sh 的方式执行完成后，再次查询NAME和message等变量其实并没有实际生效。 其原因就是在子进程中，设置的全局变量和环境变量都不会影响到父进程或其他进程。 而如果我们使用 source test3.sh 的方式执行后，再次查询NAME和message等变量可以看到全部都生效了，因为它们始终在同一进程中。 除了变量的设置外，例如，我们在 shell 脚本中包含了 cd 等之类的命令， 如果通过 bash 的方式执行，执行完成后，当前终端所在的目录也是不会发现变化的，真正切换目录的只是 fork 出的子进程而已。 而通过 source 的方式执行，实际上相当于在当前进程中依次执行了 shell 中的命令，当前终端所在目录也会实际变化。 . filename.sh 最后，我们来看一下 . filename.sh 这种执行方式： . filename.sh 的执行方式等价于 source filename.sh。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/redirect.html":{"url":"language/shell/redirect.html","title":"Shell 重定向","keywords":"","body":"Shell 重定向 对于一个进程而言，其默认会接收来自终端键盘输入的内容作为输入信息，而准备输出和错误输出信息则默认同样也会打印到终端中。 而重定向其实就是指修改输入输出的默认位置，使得进程的输入输出与文件进行交互，而非默认的终端终端。 输入重定向符号 对于重定向是指将一个文件的内容作为输入传给某个 shell 进程。 我们以 wc -l 命令为例，它本身可以接收一段文本输入，进行文本中包含的行数。 因此，假设我们需要统计 readme.md 文件的行数，那么可以执行如下命令: wc -l 对于接收变量赋值也可以使用输入重定向符号： read var1 输出重定向符号 >, >>, 2>, &> 对于一个shell命令而言，默认它的输出信息会打印到终端。（包括标准输出和标准错误输出） 而很多时候，我们希望能够将相关输出到一个文件中进行持久化保存。 针对输出的重定向，shell 支持了如下几个操作符： > 将标准输出重定向到指定文件中，如果之前文件中已有内容，已有内容会被清空。 >> 将标准输出重定向到指定文件中，如果之前文件中已有内容，会在已有内容上追加。 2> 将标准错误输出重定向到指定文件中，如果之前文件中已有内容，已有内容会被清空。 &> 将标准输出和标准错误输出重定向到指定文件中，如果之前文件中已有内容，已有内容会被清空。 Ps: 2>>, &>> 也均可以实现追加的功能，此处不再赘述。 输入输出组合重定向使用 在 shell 脚本中，有时在一些场景（如生成配置文件时），我们可能会将输入和输出组合在一起使用。 我可能来看一个示例： cat > a.conf 我们来解读一下上述 shell 命令： 首先，cat 命令的输出被重定向到了 a.conf 文件中，即 a.conf 是我们希望生成的一个文件。 cat 命令的输入是以 EOF 开头，EOF结尾的一段输入文本（不包含EOF）。 其中，EOF 仅仅是此处指定的开头结尾的标识，实际也可以换成其他任意标识，只要保证开头结尾一致即可。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/shell/script_control.html":{"url":"language/shell/script_control.html","title":"Shell 脚本控制","keywords":"","body":"Shell 脚本控制 脚本优先级设置 当机器资源不足以满足大量进程全速运行时，Linux 系统很根据进程的优先级来判断哪些进程高优执行、哪些进程低优执行。 而控制脚本的优先级则可以使用 nice 和 renice 命令。 脚本资源控制 很多时候，我们会在一台机器上执行多个进程，为了避免其中个别进程运行异常从而占用大量资源，导致影响其他进程，我们可以对进程的资源进行限制。 信号捕获 先来了解一下什么是信号捕获，当我们一个脚本在执行过程中，我们可能希望给脚本发送一些信号，从而可以让脚本进行一些操作，比如优雅退出等。 例如: kill 操作默认会发送15号信号给引用程序。 control + C 会发送 2 号信号给应用程序。 9 号信号是强制杀进程，不可以被捕获。 示例代码如下： trap \"echo sig 15\" 15 echo $$ while : ; do : done 当该命令启动后，我们通过默认的 kill 命令终止该进程时，是无法正常退出该进程的，就是因为默认的 15 号进程被捕获了。 此时，只能通过 kill -9 来杀死指定进程。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/kotlin/beginning.html":{"url":"language/kotlin/beginning.html","title":"Kotlin快速入门","keywords":"","body":"Kotlin快速入门 在本节中，我们将会从0开始进入Kotlin语言的学习。 目前，Kotlin最主要的应用场景是以Android开发为主。 但是，在本节的学习中，我们的重点并不会放在Android开发上面，而是以Kotlin的基本语法为主。 如果对Android开发感兴趣的同学可以继续学习后续的Android开发相关的内容。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/kotlin/basic_grammer.html":{"url":"language/kotlin/basic_grammer.html","title":"Kotlin基本语法","keywords":"","body":"Kotlin基本语法 Kotlin 文件以 .kt 为后缀。 包声明 代码文件的开头一般为包的声明： package com.runoob.main import java.util.* fun test() {} class Runoob {} kotlin源文件名称不需要相匹配的目录和包，源文件可以放在任何文件目录。 以上例中 test() 的全名是 com.runoob.main.test、Runoob 的全名是 com.runoob.main.Runoob。 如果没有指定包，默认为 default 包。 默认导入的包 在Kotlin中，在每个Kotlin文件中默认会导入如下的包： kotlin.* kotlin.annotation.* kotlin.collections.* kotlin.comparisons.* kotlin.io.* kotlin.ranges.* kotlin.sequences.* kotlin.text.* 函数定义 函数定义使用关键字 fun，参数格式为：参数 : 类型。 fun sum(a: Int, b: Int): Int { // Int 参数，返回值 Int return a + b } 此外，还可以将表达式作为函数体，返回类型自动推断： fun sum(a: Int, b: Int) = a + b public fun sum(a: Int, b: Int): Int = a + b // public 方法则必须明确写出返回类型 此外，一个函数也可以没有返回值： fun printSum(a: Int, b: Int): Unit { // Unit表示没有返回值 print(a + b) } // 如果是返回 Unit类型，则可以省略(对于public方法也是这样)： public fun printSum(a: Int, b: Int) { print(a + b) } 不定输入参数的函数 对于一个函数而言，可以接收的参数个数可以不固定，此时可以使用vararg关键词来进行标识。 fun vars(vararg v:Int){ for(vt in v){ print(vt) } } // 测试 fun main(args: Array) { vars(1,2,3,4,5) // 输出12345 } lambda(匿名函数) 对于Lambda函数而言，我们可以不需要单独定义一个函数，而是可以在表达式中直接使用或者将一个变量定义为函数： // 测试 fun main(args: Array) { val sumLambda: (Int, Int) -> Int = {x,y -> x+y} // lambda函数的定义格式 println(sumLambda(1,2)) // 输出 3 } 定义常量与变量 可变的变量定义: var关键字 var : = 不可变变量定义：val 关键字，只能赋值一次的变量(类似Java中final修饰的变量) val : = 常量与变量都可以没有初始化值,但是在引用前必须初始化。 编译器支持自动类型判断,即声明时可以不指定类型,由编译器判断。 val a: Int = 1 val b = 1 // 系统自动推断变量类型为Int val c: Int // 如果不在声明时初始化则必须提供变量类型 c = 1 // 明确赋值 var x = 5 // 系统自动推断变量类型为Int x += 1 // 变量可修改 注释 Kotlin 支持单行和多行注释，示例如下： // 这是一个单行注释 /* 这是一个多行的 块注释。 */ 与 Java 不同, Kotlin 中的块注释允许嵌套。 字符串模板 $ 表示一个变量名或者变量值 $varName 表示变量值 ${varName.fun()} 表示变量的方法返回值: var a = 1 // 模板中的简单名称： val s1 = \"a is $a\" a = 2 // 模板中的任意表达式： val s2 = \"${s1.replace(\"is\", \"was\")}, but now is $a\" NULL检查机制 Kotlin的空安全设计对于声明可为空的参数，在使用时要进行空判断处理，有两种处理方式: 第一种方式是字段后加!!像Java一样抛出空异常 另一种字段后加?可不做处理返回值为null或配合?:做空判断处理 //类型后面加?表示可为空 var age: String? = \"23\" //抛出空指针异常 val ages = age!!.toInt() //不做处理返回 null val ages1 = age?.toInt() //age为空返回-1 val ages2 = age?.toInt() ?: -1 当一个引用可能为 null 值时, 对应的类型声明必须明确地标记为可为 null。 当 str 中的字符串内容不是一个整数时, 返回 null: fun parseInt(str: String): Int? { // 该函数可以返回Int类型或NULL // ... } 以下实例演示如何使用一个返回值可为 null 的函数: fun main(args: Array) { if (args.size 类型检测及自动类型转换 我们可以使用 is 运算符检测一个表达式是否某类型的一个实例(类似于Java中的instanceof关键字)。 fun getStringLength(obj: Any): Int? { if (obj is String) { // 做过类型判断以后，obj会被系统自动转换为String类型 return obj.length } // 这里的obj仍然是Any类型的引用 return null } 或者： fun getStringLength(obj: Any): Int? { if (obj !is String) return null // 在这个分支中, `obj` 的类型会被自动转换为 `String` return obj.length } 甚至还可以： fun getStringLength(obj: Any): Int? { // 在 `&&` 运算符的右侧, `obj` 的类型会被自动转换为 `String` if (obj is String && obj.length > 0) return obj.length return null } 区间 区间表达式由具有操作符形式 .. 的 rangeTo 函数辅以 in 和 !in 形成。 区间是为任何可比较类型定义的，但对于整型原生类型，它有一个优化的实现。以下是使用区间的一些示例: for (i in 1..4) print(i) // 输出“1234” for (i in 4..1) print(i) // 什么都不输出 if (i in 1..10) { // 等同于 1 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/kotlin/basic_data_type.html":{"url":"language/kotlin/basic_data_type.html","title":"Kotlin基本数据类型","keywords":"","body":"Kotlin基本数据类型 Kotlin 的基本数值类型包括 Byte、Short、Int、Long、Float、Double 等。 不同于 Java 的是，字符不属于数值类型，是一个独立的数据类型。 类型 位宽度 Double 64 Float 32 Long 64 Int 32 Short 16 Byte 8 字面常量 下面是所有类型的字面常量： 十进制: 123 长整型以大写的 L 结尾：123L 16 进制以 0x 开头：0x0F 2 进制以 0b 开头：0b00001011 Ps: Kotlin并不支持八进制 fun main(args: Array) { val number1 = 123 val number2 = 123L val number3 = 0x123 val number4 = 0b01010110 println( \"${number1}\\n${number2}\\n${number3}\\n${number4}\\n\" ) } Kotlin 同时也支持传统符号表示的浮点数值： Doubles 默认写法: 123.5, 123.5e10 Floats 使用 f 或者 F 后缀：123.5f fun main(args: Array) { val number1 = 123.5 val number2 = 123.5e10 val number3 = 123.5f println( \"${number1}\\n${number2}\\n${number3}\\n\" ) } 此外，我们在代码中还可以使用下划线是的数字常量更加易读: fun main(args: Array) { val oneMillion = 1_000_000 val creditCardNumber = 1234_5678_9012_3456L val socialSecurityNumber = 999_99_9999L val hexBytes = 0xFF_EC_DE_5E val bytes = 0b11010010_01101001_10010100_10010010 println( \"${oneMillion}\\n${creditCardNumber}\\n${socialSecurityNumber}\\n${hexBytes}\\n${bytes}\\n\" ) } 比较两个数字 Kotlin 中没有基础数据类型，只有封装的数字类型，你每定义的一个变量，其实 Kotlin 帮你封装了一个对象，这样可以保证不会出现空指针。 数字类型也一样，所以在比较两个数字的时候，就有比较数据大小和比较两个对象是否相同的区别了。 在 Kotlin 中，三个等号 === 表示比较对象地址，两个 == 表示比较两个值大小。 fun main(args: Array) { val a: Int = 10000 println(a === a) // true，值相等，对象地址相等 //经过了装箱，创建了两个不同的对象 val boxedA: Int? = a val anotherBoxedA: Int? = a //虽然经过了装箱，但是值是相等的，都是10000 println(boxedA === anotherBoxedA) // false，值相等，对象地址不一样 println(boxedA == anotherBoxedA) // true，值相等 } 类型转化 由于不同的表示方式，较小类型并不是较大类型的子类型，较小的类型不能隐式转换为较大的类型。 这意味着在不进行显式转换的情况下我们不能把 Byte 型值赋给一个 Int 变量。 val b: Byte = 1 // OK, 字面值是静态检测的 val i: Int = b // 错误 为了解决这一问题，我们使用使用其toInt()方法： fun main(args: Array) { val b: Byte = 1 // OK, 字面值是静态检测的 val i: Int = b.toInt() // OK } 每种数据类型都有下面的这些方法，可以转化为其它的类型： toByte(): Byte toShort(): Short toInt(): Int toLong(): Long toFloat(): Float toDouble(): Double toChar(): Char 位操作符 对于Int和Long类型，还有一系列的位操作符可以使用，分别是： shl(bits) – 左移位 (Java’s >) ushr(bits) – 无符号右移位 (Java’s >>>) and(bits) – 与 or(bits) – 或 xor(bits) – 异或 inv() – 反向 字符 和 Java 不一样，Kotlin 中的 Char 不能直接和数字操作，Char 必需是单引号 ' 包含起来的。比如普通字符 '0'，'a'。 例如： fun check(c: Char) { if (c == 1) { // 错误：类型不兼容，字符字面值用单引号括起来: '1'。 // …… } } 特殊字符可以用反斜杠转义。 Kotlin支持这几个转义序列：\\t、 \\b、\\n、\\r、\\'、\\\"、\\ 和 $。 编码其他字符要用 Unicode 转义序列语法：'\\uFF00'。 我们可以显式把字符转换为 Int 数字： fun decimalDigitValue(c: Char): Int { if (c !in '0'..'9') throw IllegalArgumentException(\"Out of range\") return c.toInt() - '0'.toInt() // 显式转换为数字 } 当需要可空引用时，像数字、字符会被装箱。装箱操作不会保留同一性。 布尔 布尔用 Boolean 类型表示，它有两个值：true 和 false。 若需要可空引用布尔会被装箱。 内置的布尔运算有： || – 短路逻辑或 && – 短路逻辑与 ! - 逻辑非 数组 数组用类 Array 实现，并且还有一个 size 属性及 get 和 set 方法。 由于使用 [] 重载了 get 和 set 方法，所以我们可以通过下标很方便的获取或者设置数组对应位置的值。 数组的创建两种方式： 一种是使用函数arrayOf()，例如： fun main(args: Array) { //[1,2,3] val a = arrayOf(1, 2, 3) //读取数组内容 println(a[0]) // 输出结果：1 println(b[1]) // 输出结果：2 } 另外一种是使用工厂函数。如下所示，我们分别是两种方式创建了两个数组： fun main(args: Array) { //[0,2,4] val b = Array(3, { i -> (i * 2) }) // 类似于lambda表达式 //读取数组内容 println(a[0]) // 输出结果：1 println(b[1]) // 输出结果：2 } 如上所述，[] 运算符代表调用成员函数 get() 和 set()。 注意: 与 Java 不同的是，Kotlin 中数组是不协变的（invariant）。 除了类Array，还有ByteArray, ShortArray, IntArray，用来表示各个类型的数组，省去了装箱操作，因此效率更高，其用法同Array一样： fun main(args: Array) { var arr1 = intArrayOf(1, 2, 3) for (i in arr1) { println(i) } } 字符串 和 Java 一样，String 是不可变的。方括号 [] 语法可以很方便的获取字符串中的某个字符，也可以通过 for 循环来遍历： for (c in str) { println(c) } 和Python一样，Kotlin 支持三个引号 \"\"\" 扩起来的字符串，支持多行字符串，比如： fun main(args: Array) { val text = \"\"\" 多行字符串 多行字符串 \"\"\" println(text) // 输出有一些前置空格 } String 可以通过 trimMargin() 方法来删除多余的空白： fun main(args: Array) { val text = \"\"\" |多行字符串 |菜鸟教程 |多行字符串 |Runoob \"\"\".trimMargin() println(text) // 前置空格删除了 } trimMargin函数默认 | 用作边界前缀，但你可以选择其他字符并作为参数传入，比如 trimMargin(\">\")。 字符串模板 字符串可以包含模板表达式 ，即一些小段代码，会求值并把结果合并到字符串中。 模板表达式以美元符（$）开头，由一个简单的名字构成: fun main(args: Array) { val i = 10 val s = \"i = $i\" // 求值结果为 \"i = 10\" println(s) } 此外，Kotlin的字符串模板还可以是花括号扩起来的任意表达式: fun main(args: Array) { val s = \"runoob\" val str = \"$s.length is ${s.length}\" // 求值结果为 \"runoob.length is 6\" println(str) } 原生字符串和转义字符串内部都支持模板。 如果你需要在原生字符串中表示字面值 $ 字符（它不支持反斜杠转义），你可以用下列语法： fun main(args: Array) { val price = \"\"\" ${'$'}9.99 \"\"\" println(price) // 求值结果为 $9.99 } By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/kotlin/condition_control.html":{"url":"language/kotlin/condition_control.html","title":"Kotlin条件控制","keywords":"","body":"Kotlin条件控制 if 表达式 一个 if 语句包含一个布尔表达式和一条或多条语句。 // 传统用法 var max = a if (a b) { max = a } else { max = b } 我们也可以把 if 表达式的结果赋值给一个变量。 val max = if (a > b) { print(\"Choose a\") a } else { print(\"Choose b\") b } 即在 if 语句块中最后一行的表达式可以作为结果对变量赋值。 最终，我们可以用如下的表示方式来代替三元操作符: val max = if (a > b) a else b 遍历区间 使用 in 运算符来检测某个数字是否在指定区间内，区间格式为 x..y ，对于 .. 操作符表示的区间，需要注意的是它的左右区间都是闭区间。 fun main(args: Array) { val x = 5 val y = 9 if (x in 1..8) { println(\"x 在区间内\") } } when表达式 when 将它的参数和所有的分支条件顺序比较，直到某个分支满足条件，对标于其他语言的 switch 语句。 when 既可以被当做表达式使用也可以被当做语句使用。如果它被当做表达式，符合条件的分支的值就是整个表达式的值，如果当做语句使用， 则忽略个别分支的值。 一个最简单的 when 的使用示例如下： when (x) { 1 -> print(\"x == 1\") 2 -> print(\"x == 2\") else -> { // 注意这个块 print(\"x 不是 1 ，也不是 2\") } } 在 when 中，else 同 switch 的 default。 如果其他分支都不满足条件将会求值 else 分支。 如果很多分支需要用相同的方式处理，则可以把多个分支条件放在一起，用逗号分隔： when (x) { 0, 1 -> print(\"x == 0 or x == 1\") else -> print(\"otherwise\") } 我们也可以检测一个值在（in）或者不在（!in）一个区间或者集合中： when (x) { in 1..10 -> print(\"x is in the range\") in validNumbers -> print(\"x is valid\") !in 10..20 -> print(\"x is outside the range\") else -> print(\"none of the above\") } 另一种可能性是检测一个值是（is）或者不是（!is）一个特定类型的值。 注意： 由于智能转换，你可以访问该类型的方法和属性而无需 任何额外的检测。 fun hasPrefix(x: Any) = when(x) { is String -> x.startsWith(\"prefix\") else -> false } when 也可以用来取代 if-else if链。 如果不提供参数，所有的分支条件都是简单的布尔表达式，而当一个分支的条件为真时则执行该分支： when { x.isOdd() -> print(\"x is odd\") x.isEven() -> print(\"x is even\") else -> print(\"x is funny\") } By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/kotlin/loop.html":{"url":"language/kotlin/loop.html","title":"Kotlin循环语句","keywords":"","body":"Kotlin循环语句 for 循环 for 循环可以对任何提供迭代器（iterator）的对象进行遍历，语法如下: for (item in collection) { print(item) } 如上所述，for 可以循环遍历任何提供了迭代器的对象。 如果你想要通过索引遍历一个数组或者一个 list，你可以这么做： for (i in array.indices) { print(array[i]) } 注意这种\"在区间上遍历\"会编译成优化的实现而不会创建额外对象。 或者你可以用库函数 withIndex： for ((index, value) in array.withIndex()) { println(\"the element at $index is $value\") } Ps: Kotlin中的for循环与Python中的for循环非常的类似。 while 与 do ... while 循环 while是最基本的循环，它的结构为： while( 布尔表达式 ) { //循环内容 } do ... while 循环 对于 while 语句而言，如果不满足条件，则不能进入循环。 但有时候我们需要即使不满足条件，也至少执行一次。 也就是说， do ... while 循环和 while 循环相似，不同的是，do .. while 循环至少会执行一次。 do { //代码语句 } while(布尔表达式); 返回和跳转 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go/beginning.html":{"url":"language/go/beginning.html","title":"go语言快速入门","keywords":"","body":"GO语言学习 在本节中，我们将会从0开始进入GO语言的学习。 包括GO语言的基本语法、高级用法以及一些常用方式，希望通过本文的学习，你能够在日常的工作中熟练使用GO语言完成相关的任务。 我们假设读者已经具备了一定的计算机基础，比如，你要知道操作系统是什么、环境变量怎么设置、怎样正确使用命令行，等等。 参考文档： Go语言规范文档 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go/gopath.html":{"url":"language/go/gopath.html","title":"Go的工作区与GOPATH","keywords":"","body":"工作区和GOPATH 前言 我们学习 Go 语言时，要做的第一件事，都是根据自己电脑的计算架构（比如，是 32 位的计算机还是 64 位的计算机）以及操作系统（比如，是 Windows、 Linux还是Mac）从Go语言官网下载对应的二进制包。 随后，我们会解压缩安装包、放置到某个目录、配置环境变量，并通过在命令行中输入go version来验证是否安装成功。 在这个过程中，我们还需要配置 3 个环境变量，也就是 GOROOT、GOPATH 和 GOBIN。 下面我们来分别看一下这三个环境变量的含义。 GOROOT：Go 语言安装根目录的路径，也就是 GO 语言的安装路径。 GOPATH：若干工作区目录的路径。是我们自己定义的工作空间。 GOBIN：GO 程序生成的可执行文件（executable file）的路径。 其中，GOPATH 背后的概念是最多的，也是最重要的。 GOPATH详解 那么GOPATH具体是用来干嘛的呢？ 简单的说，把 GOPATH 简单理解成 Go 语言的工作目录，它的值是一个目录的路径，也可以是多个目录路径，每个目录都代表 Go 语言的一个工作区（workspace）。我们需要利于这些工作区，去放置 Go 语言的源码文件（source file），以及安装（install）后的归档文件（archive file，也就是以“.a”为扩展名的文件）和可执行文件（executable file）。 而具体来说，其实Go语言项目在其生命周期内的所有操作（编码、依赖管理、构建、测试、安装等）基本上都是围绕着 GOPATH 和工作区进行的。 针对GOPATH，我们至少需要了解如下内容： Go语言源码的组织方式是怎样的？ 源码安装后的结果是什么？（只有在安装后，Go 语言源码才能被我们或其他代码使用） 构建和安装Go程序的过程是怎样的？ Go语言源码的组织方式是怎样的？ Go 语言的源码也是以代码包为基本组织单位的。在文件系统中，这些代码包其实是与目录一一对应的。由于目录可以有子目录，所以代码包也可以有子包。 一个代码包中可以包含任意个以.go为扩展名的源码文件，这些源码文件都需要被声明属于同一个代码包。 代码包的名称一般会与源码文件所在的目录同名。如果不同名，那么在构建、安装的过程中会以代码包名称为准。 每个代码包都会有导入路径。 代码包的导入路径是指其他代码在使用该包中的程序实体时，需要引入的路径。 在实际使用程序实体之前，我们必须先导入其所在的代码包。 具体的方式就是import该代码包的导入路径。如下所示： import \"github.com/labstack/echo\" 在工作区中，一个代码包的导入路径实际上就是从 src 子目录到该包的实际存储位置的相对路径。 所以说，Go语言源码的组织方式就是以环境变量 GOPATH、工作区、src 目录和代码包为主线的。 一般情况下，Go语言的源码文件都需要被存放在环境变量GOPATH包含的某个工作区（目录）中的 src 目录下的某个代码包（目录）中。 源码安装后的结果是什么？ 了解了 Go 语言源码的组织方式后，我们很有必要知道 Go 语言源码在安装后会产生怎样的结果。 源码文件以及安装后的结果文件都会放到哪里呢？ 我们都知道，源码文件通常会被放在某个工作区的 src 子目录下。 那么在安装后如果产生了归档文件（以“.a”为扩展名的文件），就会放进该工作区的 pkg 子目录；如果产生了可执行文件，就可能会放进该工作区的 bin 子目录。 下面我们来详细说一下归档文件存放的具体位置和规则： 源码文件会以代码包的形式组织起来，一个代码包其实就对应一个目录。而安装某个代码包而产生的归档文件是与这个代码包同名的。 放置它的相对目录就是该代码包的导入路径的直接父级。比如，一个已存在的代码包的导入路径是： github.com/labstack/echo 那么执行命令： go install github.com/labstack/echo 生成的归档文件的相对目录就是 github.com/labstack， 文件名为 echo.a。 顺便说一下，上面这个代码包导入路径还有另外一层含义，那就是：该代码包的源码文件存在于 GitHub 网站的 labstack 组的代码仓库 echo 中。 再说回来，归档文件的相对目录与 pkg 目录之间还有一级目录，叫做平台相关目录。 平台相关目录的名称是由 build（也称“构建”）的目标操作系统、下划线和目标计算架构的代号组成的。 比如，构建某个代码包时的目标操作系统是 Linux，目标计算架构是 64 位的，那么对应的平台相关目录就是 linux_amd64。 因此，上述代码包的归档文件就会被放置在当前工作区的子目录 pkg/linux_amd64/github.com/labstack 中。 总之，你需要记住的是，某个工作区的 src 子目录下的源码文件在安装后一般会被放置到当前工作区的 pkg 子目录下对应的目录中，或者被直接放置到该工作区的 bin 子目录中。 构建和安装Go程序的过程是怎样的？ 我们再来说说构建和安装 Go 程序的过程都是怎样的，以及它们的异同点。 构建使用命令go build，安装使用命令go install。构建和安装代码包的时候都会执行编译、打包等操作，并且，这些操作生成的任何文件都会先被保存到某个临时的目录中。 如果构建的是库源码文件，那么操作后产生的结果文件只会存在于临时目录中。 这里的构建的主要意义在于检查和验证。 如果构建的是命令源码文件，那么操作的结果文件会被搬运到源码文件所在的目录中。 安装操作会先执行构建，然后还会进行链接操作，并且把结果文件搬运到指定目录。 进一步说，如果安装的是库源码文件，那么结果文件会被搬运到它所在工作区的 pkg 目录下的某个子目录中。 如果安装的是命令源码文件，那么结果文件会被搬运到它所在工作区的 bin 目录中，或者环境变量GOBIN指向的目录中。 这里你需要记住的是，构建和安装的不同之处，以及执行相应命令后得到的结果文件都会出现在哪里。 总结 工作区和 GOPATH 的概念和含义是每个 Go 工程师都需要了解的。虽然它们都比较简单，但是说它们是 Go 程序开发的核心知识并不为过。 Go 语言提供的很多工具都是在 GOPATH 和工作区的基础上运行的，比如上面提到的go build、go install和go get，这三个命令也是我们最常用到的。 思考 Go 语言在多个工作区中查找依赖包的时候是以怎样的顺序进行的？ 如果在多个工作区中都存在导入路径相同的代码包会产生冲突吗？ 通过实验就可以知道，这个加载的先后顺序是按照GOPATH的环境变量顺序依次进行读取的，会优先GOPATH中最早的代码包。 补充阅读 go build部分参数说明 在运行go build命令的时候，默认不会编译目标代码包所依赖的那些代码包。 当然，如果被依赖的代码包的归档文件不存在，或者源码文件有了变化，那它还是会被编译。 如果要强制编译它们，可以在执行命令的时候加入标记-a。 此时，不但目标代码包总是会被编译，它依赖的代码包也总会被编译，即使依赖的是标准库中的代码包也是如此。 另外，如果不但要编译依赖的代码包，还要安装它们的归档文件，那么可以加入标记-i。 那么我们怎么确定哪些代码包被编译了呢？有两种方法： 运行go build命令时加入标记-x，这样可以看到go build命令具体都执行了哪些操作。另外也可以加入标记-n，这样可以只查看具体操作而不执行它们。 运行go build命令时加入标记-v，这样可以看到go build命令编译的代码包的名称。它在与-a标记搭配使用时很有用。 go get及常用参数 下面再说一说与 Go 源码的安装联系很紧密的一个命令：go get。 命令go get会自动从一些主流公用代码仓库（比如 GitHub）下载目标代码包，并把它们安装到环境变量GOPATH包含的第1工作区的相应目录中。 如果存在环境变量GOBIN，那么仅包含命令源码文件的代码包会被安装到GOBIN指向的那个目录。 其中，go get常用的参数如下： -u：下载并安装代码包，不论工作区中是否已存在它们。 -d：只下载代码包，不安装代码包。 -fix：在下载代码包后先运行一个用于根据当前 Go 语言版本修正代码的工具，然后再安装代码包。 -t：同时下载测试所需的代码包。 -insecure：允许通过非安全的网络协议下载和安装代码包。HTTP 就是这样的协议。 Go 语言官方提供的go get命令是比较基础的，其中并没有提供依赖管理的功能。 目前 GitHub 上有很多提供这类功能的第三方工具，比如glide、gb以及官方出品的dep、vgo等等，它们在内部大都会直接使用go get。 有时候，我们可能会出于某种目的变更存储源码的代码仓库或者代码包的相对路径。 这时，为了让代码包的远程导入路径不受此类变更的影响，我们会使用自定义的代码包导入路径。 对代码包的远程导入路径进行自定义的方法是：在该代码包中的库源码文件的包声明语句的右边加入导入注释，像这样： package semaphore // import \"golang.org/x/sync/semaphore\" 这个代码包原本的完整导入路径是github.com/golang/sync/semaphore。 这与实际存储它的网络地址对应的。 该代码包的源码实际存在 GitHub 网站的 golang 组的 sync 代码仓库的 semaphore 目录下。 而加入导入注释之后，用以下命令即可下载并安装该代码包了： go get golang.org/x/sync/semaphore 而 Go 语言官网 golang.org 下的路径 /x/sync/semaphore 并不是存放semaphore包的真实地址。 我们称之为代码包的自定义导入路径。 不过，这还需要在 golang.org 这个域名背后的服务端程序上，添加一些支持才能使这条命令成功。 关于自定义代码包导入路径的完整说明可以参考文档 本文来源：极客时间Go语言核心36讲。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go/command_source_file.html":{"url":"language/go/command_source_file.html","title":"命令源码文件","keywords":"","body":"命令源码文件 前言 我们已经知道，环境变量 GOPATH 指向的是一个或多个工作区，每个工作区中都会有以代码包为基本组织形式的源码文件。 这里的源码文件又分为三种，即：命令源码文件、库源码文件和测试源码文件，它们都有着不同的用途和编写规则。 今天，我们就沿着命令源码文件的知识点展开进行学习。 一旦开始学习用编程语言编写程序，我们就一定希望在编码的过程中及时地得到反馈，只有这样才能清楚对错。 实际上，我们的有效学习和进步，都是通过不断地接受反馈和执行修正实现的。 对于 Go 语言学习者来说，你在学习阶段中，也一定会经常编写可以直接运行的程序。这样的程序肯定会涉及命令源码文件的编写，而且，命令源码文件也可以很方便地用go run命令启动。 那么，命令源码文件的用途是什么，怎样编写它？ 命令源码文件是程序的运行入口，是每个可独立运行的程序必须拥有的。我们可以通过构建或安装，生成与其对应的可执行文件，后者一般会与该命令源码文件的直接父目录同名。 如果一个源码文件声明属于main包，并且包含一个无参数声明且无结果声明的main函数，那么它就是命令源码文件。 就像下面这段代码： package main import \"fmt\" func main() { fmt.Println(\"Hello, world!\") } 如果你把这段代码存成 demo1.go 文件，那么运行go run demo1.go命令后就会在屏幕（标准输出）中看到Hello, world! PS：当需要模块化编程时，我们往往会将代码拆分到多个文件，甚至拆分到不同的代码包中。但无论怎样，对于一个独立的程序来说，命令源码文件永远只会也只能有一个。如果有与命令源码文件同包的源码文件，那么它们也应该声明属于main包。 知识精讲 命令源码文件怎样接收参数 无论是 Linux 还是 Windows，如果你用过命令行（command line）的话，肯定就会知道几乎所有命令（command）都是可以接收参数（argument）的。 通过构建或安装命令源码文件，生成的可执行文件就可以被视为“命令”，既然是命令，那么就应该具备接收参数的能力。 我们先看一段不完整的代码： package main import ( // 需在此处添加代码。[1] \"fmt\" ) var name string func init() { // 需在此处添加代码。[2] } func main() { // 需在此处添加代码。[3] fmt.Printf(\"Hello, %s!\\n\", name) } 下面，我们一起来看看如何补齐这一段代码吧。 首先，Go 语言标准库中有一个代码包专门用于接收和解析命令参数。这个代码包的名字叫flag。 如果想要在代码中使用某个包中的程序实体，那么应该先导入这个包。 因此，我们需要在[1]处添加代码\"flag\"。 注意，这里应该在代码包导入路径的前后加上英文半角的引号。 如此一来，上述代码导入了flag和fmt这两个包。 其次，人名肯定是由字符串代表的。所以我们要在[2]处添加调用flag包的StringVar函数的代码。就像这样： flag.StringVar(&name, \"name\", \"everyone\", \"The greeting object.\") 其中，函数flag.StringVar接受 4 个参数： 第 1 个参数是用于存储该命令参数值的地址，具体到这里就是在前面声明的变量name的地址了，由表达式&name表示。 第 2 个参数是为了指定该命令参数的名称，这里是name。 第 3 个参数是为了指定在未追加该命令参数时的默认值，这里是everyone。 至于第 4 个函数参数，即是该命令参数的简短说明了，这在打印命令说明时会用到。 顺便说一下，还有一个与flag.StringVar函数类似的函数，叫flag.String。 这两个函数的区别是，后者会直接返回一个已经分配好的用于存储命令参数值的地址。 例如： var name = flag.String(\"name\", \"everyone\", \"The greeting object.\") 再说最后一个填空。我们需要在[3]处添加代码flag.Parse()。 函数flag.Parse用于真正解析命令参数，并把它们的值赋给相应的变量。 对该函数的调用必须在所有命令参数存储载体的声明（这里是对变量name的声明）和设置（这里是在[2]处对flag.StringVar函数的调用）之后，并且在读取任何命令参数值之前进行。 正因为如此，我们最好把flag.Parse()放在main函数的函数体的第一行。 修改的代码如下： package main import ( \"flag\" \"fmt\" ) var name string func init() { flag.StringVar(&name, \"name\", \"everyone\", \"The greeting object.\") } func main() { flag.Parse() fmt.Printf(\"Hello, %s!\\n\", name) } 运行命令源码文件时如何传入参数？ 如果我们把上述代码存成名为 demo2.go 的文件，那么运行如下命令就可以为参数name传值： go run demo2.go -name=\"Robert\" 运行后，打印到标准输出（stdout）的内容会是：Hello, Robert! 另外，如果想查看该命令源码文件的参数说明，可以这样做： go run demo2.go --help 运行输出后可以得到如下结果： Usage of /var/folders/ts/7lg_tl_x2gd_k1lm5g_48c7w0000gn/T/go-build155438482/b001/exe/demo2: -name string The greeting object. (default \"everyone\") exit status 2 你可能不明白下面这段输出代码的意思，下面我们来进行详细的说明： /var/folders/ts/7lg_tl_x2gd_k1lm5g_48c7w0000gn/T/go-build155438482/b001/exe/demo2 其实是go run命令构建上述命令源码文件时临时生成的可执行文件的完整路径。 如果我们先构建这个命令源码文件再运行生成的可执行文件，像这样： go build demo2.go ./demo2 --help 那么输出结果会是： Usage of ./demo2: -name string The greeting object. (default \"everyone\") 怎样自定义命令源码文件的参数使用说明？ Golang支持多种方式自定义参数的使用说明，最简单的一种方式就是对变量flag.Usage重新赋值。 flag.Usage的类型是func()，即一种无参数声明且无结果声明的函数类型。 flag.Usage变量在声明时就已经被赋值了，所以我们才能够在运行命令go run demo2.go --help时看到正确的结果。 Ps：对flag.Usage的赋值必须在调用flag.Parse函数之前。 现在，我们把 demo2.go 另存为 demo3.go，然后在main函数体的开始处加入如下代码： package main import ( \"flag\" \"fmt\" ) var name string func init() { flag.StringVar(&name, \"name\", \"everyone\", \"The greeting object.\") } func main() { flag.Usage = func() { _, _ = fmt.Fprintf(os.Stderr, \"Usage of %s:\\n\", \"question\") flag.PrintDefaults() } flag.Parse() fmt.Printf(\"Hello, %s!\\n\", name) } 那么，再次运行如下命令时： go run demo3.go --help 可以看到： Usage of question: -name string The greeting object. (default \"everyone\") exit status 2 现在再深入一层，我们在调用flag包中的一些函数（比如StringVar、Parse等等）的时候， 实际上是在调用flag.CommandLine变量的对应方法。 flag.CommandLine相当于默认情况下的命令参数容器。 所以，通过对flag.CommandLine重新赋值，我们可以更深层次地定制当前命令源码文件的参数使用说明。 总结 你现在已经走出了 Go 语言编程的第一步。 你可以用 Go 编写命令，并可以让它们像众多操作系统命令那样被使用，甚至可以把它们嵌入到各种脚本中。 另外，如果你想详细了解flag包的用法，可以到这个网址查看文档。 或者直接使用godoc命令在本地启动一个 Go 语言文档服务器。怎样使用godoc命令？你可以参看这里。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go/lib_source_file.html":{"url":"language/go/lib_source_file.html","title":"库源码文件","keywords":"","body":"库源码文件 在上一节中，我们已经用Go语言编写了一个小命令了。 但是这些\"小命令\"其实并没有什么实际的作用，但是别着急，下面我们会一点点的学习，逐步写出完整功能的程序。 什么是库源码文件 库源码文件是不能被直接运行的源码文件，它仅用于存放程序实体，这些程序实体可以被其他代码使用（只要遵从 Go 语言规范的话）。 这里的“其他代码”可以与被使用的程序实体在同一个源码文件内，也可以在其他源码文件，甚至其他代码包中。 那么，什么是程序实体呢？ 在 Go 语言中，程序实体是变量、常量、函数、结构体和接口的统称。 我们总是会先声明（或者说定义）程序实体，然后再去使用。比如在上一篇的例子中，我们先定义了变量name，然后在main函数中调用fmt.Printf函数的时候用到了它。 Ps：程序实体的名字被统称为标识符。标识符可以是任何 Unicode 编码可以表示的字母字符、数字以及下划线“_”，但是其首字母不能是数字。 从规则上说，我们可以用中文作为变量的名字。但是，这种命名方式非常不好，大部分开发团队中明令禁止这种做法。作为一名合格的程序员，我们应该向着编写国际水准的程序无限逼近。 知识精讲 下面，我们来看下怎么把命令源码文件中的代码拆分到其他库源码文件？下面，我们来用代码进行说明： 如果在某个目录下，有一个命令源码文件为demo4.go： package main import ( \"flag\" ) var name string func init() { flag.StringVar(&name, \"name\", \"everyone\", \"The greeting object.\") } func main() { flag.Parse() hello(name) } 其中，可以看到在上述代码的main函数中调用了一个不在当前文件定义的hello函数。 因此，我们需要在demo4.go的相同目录下创建一个源码文件demo4_lib.go文件，内容如下： package main import \"fmt\" func hello(name string) { fmt.Printf(\"Hello, %s!\\n\", name) } Ps：需要注意的是，在demo4_lib.go文件的第一行中，我们定义该文件同样属于main package。 这就是我们之前说的，在Go语言中同一个目录下的文件都需要属于同一个package。 此时，我们就可以运行他们了。 $ go run demo4.go demo4_lib.go Hello, everyone! Ps：从上述内容可以看出，在Go语言中，同一个包的不同文件中的函数在调用时无需import语句，就可以直接使用。 对于编写一个大型的项目而言，仅仅将代码拆分到几个源码文件是不够的，我们往往会使用模块化的方式进行编程。 从而，根据代码的功能和用途把它们放置到不同的代码包中。 那么，把代码拆分到不同的package中时，又需要注意哪些问题呢？ 还是以上述内容为例，假设目录结构如下： . ├── lib5 │ └── lib.go └── main └── demo5.go 此时，lib.go的文件内容如下： package lib5 import \"fmt\" func Hello(name string) { fmt.Printf(\"Hello, %s!\\n\", name) } 可以看到，该文件和之前文件内容主要有如下两个区别： 把package main修改为了package lib5。 hello函数的定义修改为了Hello。 其中： 第一点说明了对于不同的目录需要使用不同的package名称。 第二点说明了在Go语言中，大写字母开头的函数、变量是可以在当前包外被引用的，而小写字母开头的函数、变量只能在包内使用。 此外，我们还需要修改demo4.go的文件中增加一行： import \"lib5\" 总结 我们在本篇文章中详细讨论了把代码从命令源码文件中拆分出来的方法，这包括拆分到其他库源码文件，以及拆分到其他代码包。 这里涉及了几条重要的 Go 语言基本编码规则，即：代码包声明规则、代码包导入规则等。 你必须记住这些规则，否则你的代码很可能无法通过编译。 思考 问题1. 如果你需要导入两个代码包，而这两个代码包的导入路径的最后一级是相同的，比如：dep/lib/flag和flag，那么会产生冲突吗？ 答：import后路径最后一级相同，不一定会冲突。 分为两种情况: a.如果文件夹下文件声明的包名相同，则肯定冲突，会报错redeclared。 b.如果文件夹下文件声明的包名不同，也不会冲突。 问题2. 如果会产生冲突，那么怎样解决这种冲突，有几种方式？ 答：给包设置别名,调用的时候来区分开不同的package,比如: import b \"bbbb\" 格式如下： import alias \"${package}\" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go/entity.html":{"url":"language/go/entity.html","title":"程序实体概述","keywords":"","body":"程序实体概述 在本节中，我们将会初步学习Go语言中的实体的通用逻辑，包括变量、常量、函数、结构体、接口等。 Go 语言是静态类型的编程语言，所以我们在声明变量或常量的时候，都需要指定它们的类型，或者给予足够的信息，这样才可以让 Go 语言能够推导出它们的类型。 PS：在 Go 语言中，变量的类型可以是其预定义的那些类型，也可以是程序自定义的函数、结构体或接口。常量的合法类型不多，只能是那些 Go 语言预定义的基本类型。它的声明方式也更简单一些。 变量的声明 一种常用方式如下： var name string name = \"hello world\" 另外一种更加简单的方式如下： name := \"hello world\" 看起来在上面的方法好像并没有明确指名name的变量类型，但实际上，这里利用了Go语言自身的类型推断，可以从赋值的信息中自动推断出新的变量一定是string类型。 Ps：需要说明的是，第二种方式仅限于在函数内部使用。 这样使用的一个好处是可以大大增加程序的灵活性： package main import ( \"flag\" \"fmt\" ) func main() { name := getTheFlag() flag.Parse() fmt.Printf(\"Hello, %v!\\n\", *name) } func getTheFlag() *string { return flag.String(\"name\", \"everyone\", \"The greeting object.\") } 以上述程序为例，name其实可以是任意类型变量，我们可以对getTheFlag函数进行任意修改，甚至修改其返回类型，外部程序都能很多的做到兼容。 变量的重声明 重声明就是指对已经声明过的变量再次声明。变量重声明的前提条件如下: 由于变量的类型在其初始化时就已经确定了，所以对它再次声明时赋予的类型必须与其原本的类型相同，否则会产生编译错误。 变量的重声明只可能发生在某一个代码块中。如果与当前的变量重名的是外层代码块中的变量，那么就是另外一种含义了，后续我们会提及。 变量的重声明只有在使用短变量声明时才会发生，否则也无法通过编译。如果要在此处声明全新的变量，那么就应该使用包含关键字var的声明语句，但是这时就不能与同一个代码块中的任何变量有重名了。 被“声明并赋值”的变量必须是多个，并且其中至少有一个是新的变量。这时我们才可以说对其中的旧变量进行了重声明。 示例如下： var err error n, err := io.WriteString(os.Stdout, \"Hello, everyone!\\n\") 程序实体的作用域 在 Go 语言中，代码块一般就是一个由花括号括起来的区域，里面可以包含表达式和语句。 Go 语言本身以及我们编写的代码共同形成了一个非常大的代码块，也叫全域代码块。 这主要体现在，只要是公开的全局变量，都可以被任何代码所使用。 相对小一些的代码块是代码包，一个代码包可以包含许多子代码包，所以这样的代码块也可以很大。 接下来，每个源码文件也都是一个代码块，每个函数也是一个代码块，每个if语句、for语句、switch语句和select语句都是一个代码块。 甚至，switch或select语句中的case子句也都是独立的代码块。 走个极端，我就在main函数中写一对紧挨着的花括号算不算一个代码块？当然也算，这甚至还有个名词，叫“空代码块”。 也就是说：一个代码块可以有若干个子代码块；但对于每个代码块，最多只会有一个直接包含它的代码块（后者可以简称为前者的外层代码块）。 这种代码块的划分，也间接地决定了程序实体的作用域。下面，我们来进行详细说明。 大家都知道，一个程序实体被创造出来，是为了让别的代码引用的。那么，哪里的代码可以引用它呢，这就涉及了它的作用域。 程序实体的访问权限有三种：包级私有的、模块级私有的和公开的。 包级私有和模块级私有访问权限对应的都是代码包代码块，公开的访问权限对应的是全域代码块。 然而，这个粒度是比较粗的，我们往往需要利用代码块再细化程序实体的作用域。 比如，我在一个函数中声明了一个变量，那么在通常情况下，这个变量是无法被这个函数以外的代码引用的。这里的函数就是一个代码块，而变量的作用域被限制在了该代码块中。 简单的说：一个程序实体的作用域总是会被限制在某个代码块中，而这个作用域最大的用处，就是对程序实体的访问权限的控制。 思考一个问题：如果一个变量与其外层代码块中的变量重名会出现什么状况？我们通过一段代码来验证一下： package main import \"fmt\" var block = \"package\" func main() { block := \"function\" { block := \"inner\" fmt.Printf(\"The block is %s.\\n\", block) } fmt.Printf(\"The block is %s.\\n\", block) } 这个命令源码文件中有四个代码块，它们是：全域代码块、main包代表的代码块、main函数代表的代码块，以及在main函数中的一个用花括号包起来的代码块。 我在后三个代码块中分别声明了一个名为block的变量，并分别把字符串值\"package\"、\"function\"和\"inner\"赋给了它们。 此外，我在后两个代码块的最后分别尝试用fmt.Printf函数打印出“The block is %s.”。 那么，上述代码可以通过编译吗？如果能，会打印的结果是什么呢？ 实际上，上述代码是可以通过编译的，打印的结果如下： The block is inner. The block is function. 如果不了解作用域的概念的话，你可能会觉得这段代码在三处都声明了相同名称的变量，可能会导致编译失败。 但是实际上，对于不同的代码块中的代码，变量重名是没什么影响的。 那么，在不同代码块中的包含相同的变量声明时，真正引用的变量是哪一个呢？ 首先，代码引用变量的时候总会最优先查找当前代码块中的那个变量。 其次，如果当前代码块中没有声明以此为名的变量，那么程序会沿着代码块的嵌套关系，从直接包含当前代码块的那个代码块开始，一层一层地向上查找。 一般情况下，程序会一直查到当前代码包代表的代码块。如果仍然找不到，那么 Go 语言的编译器就会报错了。 PS：如果我们在当前源码文件中导入了其他代码包，那么引用其中的程序实体时，是需要以限定符为前缀的。 所以程序在找代表变量未加限定符的名字（即标识符）的时候，是不会去被导入的代码包中查找。 但有个特殊情况，如果我们把代码包导入语句写成import . \"XXX\"的形式（注意中间的那个“.”），那么就会让这个“XXX”包中公开的程序实体，被当前源码文件中的代码，视为当前代码包中的程序实体。 现在，再看一下刚才的代码，是否已经非常清晰了呢？ 变量类型检查 在Go语言中，除了Go语言自带的编译器变量类型检查外，往往还需要主动进行相关的变量类型检查。 以如下代码为例： package main import \"fmt\" var container = []string{\"zero\", \"one\", \"two\"} func main() { container := map[int]string{0: \"zero\", 1: \"one\", 2: \"two\"} fmt.Printf(\"The element is %q.\\n\", container[1]) } 在上述代码段中，有两个都叫做container的变量，分别位于main包代码块和main函数代码块。 main包代码块中的变量是切片（slice）类型的，另一个是字典（map）类型的。在main函数的最后，我们试图打印出container变量的值中索引为1的那个元素。 很显然，无论是切片类型还是字典类型，都是支持索引进行数据查询的。 但是，如果我们想要确切的查询变量类型的时候，索引表达式就不再够用了，此时需要使用类型断言表达式。 value, ok := interface{}(container).([]string) 上述是一条赋值语句。在赋值符号的右边，是一个类型断言表达式。 它包括了用来把container变量的值转换为空接口值的interface{}(container) 以及 一个用于判断前者的类型是否为切片类型 []string 的 .([]string)。 这个表达式的结果可以被赋给两个变量，在这里由value和ok代表。 变量ok是布尔（bool）类型的，它将代表类型判断的结果，true或false。 如果是true，那么被判断的值将会被自动转换为[]string类型的值，并赋给变量value，否则value将被赋予nil（即“空”）。 顺便提一下，这里的ok也可以没有。也就是说，类型断言表达式的结果，可以只被赋给一个变量，在这里是value。但是这样的话，当判断为否时就会引发异常。 这种异常在 Go 语言中被叫做panic，我把它翻译为运行时恐慌。 除非显式地“恢复”这种“恐慌”，否则它会使 Go 程序崩溃并停止。所以，在一般情况下，我们还是应该使用带ok变量的写法。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go_action/beginning.html":{"url":"language/go_action/beginning.html","title":"Go实战开发","keywords":"","body":"Go实战开发 在本系列文章中，我们将会以实战为抓手， 依次介绍如何搭建 Go 开发环境、编写 Go 命令行工具、编写 WEB 服务等最佳实践。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go_action/go_action_env.html":{"url":"language/go_action/go_action_env.html","title":"Go开发环境搭建","keywords":"","body":"Go开发环境搭建 在本文中，我们将会介绍如何搭建 Go 的开发环境，包括 Go 基础环境、 GoLand IDE 等。 Ps: 本文基于最新的 Golang 1.16.6 版本编写。 下载 golang 要搭建Go语言开发环境，我们第一步要下载go的开发工具包，目前最新稳定版本是 1.16.6 。 Go为我们所熟知的所有平台架构提供了开发工具包，比如我们熟知的Linux、Mac和Windows，其他的还有FreeBSD等。 Golang 下载地址: https://golang.org/dl/ 我们选择 Apple macOS 版本的 pkg 安装包进行下载。 Mac安装版下载后双击可以看到安装界面，按照提示一步步选择操作即可。 安装版默认安装目录(GOROOT)是/usr/local/go，并且也会自动的把/usr/local/go/bin目录加入到PATH环境变量中， 重新打开一个终端，就可以使用go version进行测试了. go version # go version go1.16.6 darwin/amd64 GOPATH目录 自从 Golang 采用 Module 的方式管理项目后，GOPATH 目录已经不是那么重要了， 目前主要用来存放依赖的 Module 库，生成的可执行文件等。 我们可以在 ~/.bash_profile 文件中增加 GOPATH 环境变量的配置，具体的路径可以根据自己的需求来配置。 export GOPATH=/Users/wangzhe/Desktop/go 该目录下有3个子目录，他们分别是： bin: 存放go install命名生成的可执行文件，可以把GOPATH/bin路径加入到PATH环境变量里，就和我们上面配置的GOROOT/bin一样， 这样就可以直接在终端里使用我们go开发生成的程序了。 pkg: pkg文件夹是存在go编译生成的文件。 src: src存放的是非Go Module项目源代码。 Go 项目工程结构 配置好工作环境后，就可以编码开发了，在这之前，我们看下go的通用项目结构,这里的结构主要是源代码相应地资源文件存放目录结构。 基于Go Module，你可以在任意位置创建一个Go项目，而不再像以前一样局限在$GOPATH/src目录下。 假设我要创建一个tour项目，它位于~/Desktop/tour目录下，那我现在打开终端，cd 到~/Desktop/tour目录下， 输入如下命令即可创建一个Go Module工程。 mkdir ~/Desktop/tour cd ~/Desktop/tour go mod init flysnow.org/tour # go: creating new go.mod: module flysnow.org/tour 上述命令会生成Go Module工程中的 go.mod 文件，文件内容如下： module flysnow.org/tour go 1.16 其中module flysnow.org/tour代表该项目的path,也就是最顶层的package， go 1.16 表示该项目需要go 1.16版本及其以上才能编译运行。 go.mod文件是Go语言工具链用于管理Go语言项目的一个配置文件，我们不用手动修改它，Go语言的工具链会帮我们自动更新，比如当我们的项目添加一个新的第三方库的时候。 使用第三方库，也就是使用第三方库里的包，那么我们如何引用一个包呢，使用的就是go语言的import关键字，比如： import ( \"github.com/gohugoio/hugo/commands\" ) 以上引入的github.com/gohugoio/hugo/commands这个包是属于 github.com/gohugoio/hugo/这个Go Module的。 所以相应的，我们也可以在我们自己的Go Module工程里创建一些包(其实就是子目录), 比如我创建了lib1目录，那么它的对应的包就是flysnow.org/tour/lib1, 其他包只有通过这个包名才能使用flysnow.org/tour/lib1包中的函数方法等。 . ├── go.mod ├── lib1 ├── lib2 └── main.go 所以最后你的项目目录类似上面的结构，每个子目录都是一个包，子目录里可以放go文件。 Hello World 好了，有了tour项目，就可以演示下Go语言版本的Hello World了，在tour根目录下的main.go（如没有这个文件，就新建一个）文件中，添加如下Go代码。 package main import ( \"fmt\" ) func main() { fmt.Println(\"Hello World\") } Go版Hello World非常简单。在~/Desktop/tour目录下运行go run main.go命令就可以看到打印的输出Hello World，下面解释下这段代码: package 是一个关键字，定义一个包，和Java里的package一样，也是模块化的关键。 main包是一个特殊的包名，它表示当前是一个可执行程序，而不是一个库。 import 也是一个关键字，表示要引入的包，和Java的import关键字一样，引入后才可以使用它。 fmt是一个包名，这里表示要引入fmt这个包，这样我们就可以使用它的函数了。 main函数是主函数，表示程序执行的入口，Java也有同名函数，但是多了一个String[]类型的参数。 Println是fmt包里的函数，和Java里的system.out.println作用类似，这里输出一段文字。 整段代码非常简洁，关键字、函数、包等和Java非常相似，不过注意，go是不需要以;(分号)结尾的。 安装程序 安装的意思，就是生成可执行的程序，以供我们使用，为此go为我们提供了很方便的install命令，可以快速的把我们的程序安装到$GOAPTH/bin目录下。 在~/Desktop/tour目录下运行如下代码即可安装。 go install flysnow.org/tour 打开终端，运行上面的命令即可，install后跟全路径的包名。 然后我们在终端里运行tour就看到打印的Hello World了: ~/Desktop/go/bin/tour # Hell World 跨平台编译 之前的运行和安装，都是默认根据我们当前的机器生成的可执行文件，比如你的是Linux 64位，就会生成Linux 64位下的可执行文件， 比如我的Mac，可以使用go env查看编译环境,以下截取重要的部分。 GOARCH=\"amd64\" GOEXE=\"\" GOHOSTARCH=\"amd64\" GOHOSTOS=\"darwin\" GOOS=\"darwin\" GOROOT=\"/usr/local/go\" GOTOOLDIR=\"/usr/local/go/pkg/tool/darwin_amd64\" 注意里面两个重要的环境变量GOOS和GOARCH,其中GOOS指的是目标操作系统，它的可用值为： aix android darwin dragonfly freebsd illumos js linux netbsd openbsd plan9 solaris windows 一共支持13种操作系统。GOARCH指的是目标处理器的架构，目前支持的有： arm arm64 386 amd64 ppc64 ppc64le mips mipsle mips64 mips64le s390x wasm 一共支持12种处理器的架构，GOOS和GOARCH组合起来，支持生成的可执行程序种类很多，具体组合参考 https://golang.org/doc/install/source#environment 。 如果我们要生成不同平台架构的可执行程序，只要改变这两个环境变量就可以了，比如要生成linux 64位的程序，命令如下： GOOS=linux GOARCH=amd64 go build flysnow.org/tour 前面两个赋值，是更改环境变量，这样的好处是只针对本次运行有效，不会更改我们默认的配置。 拉取远程包 由于国内的网络访问 google 等仓库时，存在一定的网络限制，因此，我们需要先配置代理，同时启用 go modules 模块来管理依赖库。 设置命令如下： go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.io,direct # 或者 https://goproxy.cn 设置好代理后，就可以使用go提供的一个获取远程包的工具go get来获取远程包了,它需要一个完整的包名作为参数， 只要这个完整的包名是可访问的，就可以被获取到，比如我们获取一个CLI的开源库： go get -v github.com/spf13/cobra 就可以下载这个库到我们$GOPATH/pkg/mod目录下了，这样我们就可以像导入其他包一样import了。 同时，在执行 go get 命令时，还会将对应的第三方依赖库的信息会写入 go.mod 文件中。 require github.com/spf13/cobra v1.2.1 // indirect 此外，还会生成一个对应的 go.sum 文件，来记录对应的依赖的版本信息。 如果我们使用的远程包有更新，我们可以使用如下命令进行更新,多了一个-u标识: go get -u -v github.com/spf13/cobra 此外，如果我们想要下载指定版本的第三方依赖时，下载的方式如下： go get -v knative.dev/pkg@v0.0.0-20191024051936-4befa47ec54b 即可以在依赖模块名称后使用@追加版本号下载。 如果是对于一个已有的项目（已经存在对应的 go.mod 文件），我们想要本地安装全部依赖的话其实非常简单，只要执行如下命令即可： go mod download 获取 gitlab 私有库包 如果是私有的git库怎么获取呢？比如在公司使用gitlab搭建的git仓库，设置的都是private权限的。 这种情况下我们可以配置下git，就可以了，在此之前你公司使用的gitlab必须要在7.8之上。然后要把我们http协议获取的方式换成ssh， 假设你要获取http://git.flysnow.org，对应的ssh地址为git@git.flysnow.org，那么要在终端执行如下命令。 git config --global url.\"git@git.flysnow.org:\".insteadOf \"http://git.flysnow.org/\" 这段配置的意思就是，当我们使用http://git.flysnow.org/获取git库代码的时候，实际上使用的是git@git.flysnow.org这个url地址获取的， 也就是http到ssh协议的转换，是自动的，他其实就是在我们的~/.gitconfig配置文件中，增加了如下配置: [url \"git@git.flysnow.org:\"] insteadOf = http://git.flysnow.org/ 然后需要把git.flysnow.org加入GOPRIVATE环境变量中，因为它是你的私有仓库，不需要走GOPROXY代理: # 设置不走 proxy 的私有仓库，多个用逗号相隔（可选） go env -w GOPRIVATE=git.flysnow.org 现在我们就可以使用go get直接获取了，比如： go get -v -insecure git.flysnow.org/hello 仔细看，多了一个-insecure标识，因为我们使用的是http协议，是不安全的。 当然如果你自己搭建的gitlab支持https协议，就不用加-insecure了，同时把上面的url insteadOf换成https的就可以了。 Goland 安装 Go采用的是UTF-8的文本文件存放源代码，所以原则上你可以使用任何一款文本编辑器。 目前，关于 Go 语言开发有一款非常流行的 IDE: GoLand，它是 jetbrains 针对 Go 这门语言提供的 IDE，可以去 https://www.jetbrains.com/go/ 下载使用。 Goland 的安装非常简单，直接使用下一步进行正常安装即可，此处不再赘述。 关于 Goland 的更多使用介绍可以参考 文档 。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/go_action/gin.html":{"url":"language/go_action/gin.html","title":"Go Web框架gin快速上手","keywords":"","body":"Go Web框架gin快速上手 在本文中，我们将讲解一个流行的 Go Web 框架 gin 的快速入门与使用。 Gin 简介 Gin 是一个用 Go (Golang) 编写的 web 框架。 Gin 最大的优点之一就是其出色的性能。 Gin 的特性： 快速 支持中间件（AOP编程），传入的HTTP请求可以由一系列中间件来处理，例如Logger, Auth, gzip等。 Crash处理 入参JSON验证 路由组织 错误管理 内置渲染 可扩展 项目初始化与安装 首先，我们需要初始化一个项目： cd ~/Desktop/gin-project go mod init gin-project gin 的依赖包安装非常简单: go get -u github.com/gin-gonic/gin 此时，会在当前目录下生成一个 go.mod 和 go.sum 文件。 创建 demo 文件 下面，我们来编写一个最简单的 gin 的项目: package main import \"github.com/gin-gonic/gin\" func main() { r := gin.Default() r.GET(\"/ping\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"pong\", }) }) r.Run() // 监听并在 0.0.0.0:8080 上启动服务 } 然后，可以执行如下命令来启动服务： go run example.go 接下来，我们可以打开浏览器，并访问 http://localhost:8080/ping ，是不是一个最简单的 Web 服务已经运行起来了呢？ 编译扩展 Gin 框架默认使用了 encoding/json 这一 JSON 处理包，不过，我们可以在编译的过程中通过 tag 来自主指定希望使用的 JSON 包版本： go build -tags=jsoniter . Gin 默认启用 MsgPack 渲染功能。但是您可以通过指定 nomsgpack 构建标记来禁用此功能: go build -tags=nomsgpack . 这一操作可以有效减少二进制执行文件的大小。 Ps: 多个tag之间可以使用,来分隔。 示例程序 接下来，我们将会通过一系列的示例程序来演示 gin 框架的使用。 支持 GET, POST, PUT, PATCH, DELETE, OPTIONS 等请求方法 func main() { // Creates a gin router with default middleware: // logger and recovery (crash-free) middleware router := gin.Default() router.GET(\"/someGet\", getting) router.POST(\"/somePost\", posting) router.PUT(\"/somePut\", putting) router.DELETE(\"/someDelete\", deleting) router.PATCH(\"/somePatch\", patching) router.HEAD(\"/someHead\", head) router.OPTIONS(\"/someOptions\", options) // By default it serves on :8080 unless a // PORT environment variable was defined. router.Run() // router.Run(\":3000\") for a hard coded port } 获取 url 中的参数 func main() { router := gin.Default() // This handler will match /user/john but will not match /user/ or /user router.GET(\"/user/:name\", func(c *gin.Context) { name := c.Param(\"name\") c.String(http.StatusOK, \"Hello %s\", name) }) // However, this one will match /user/john/ and also /user/john/send // If no other routers match /user/john, it will redirect to /user/john/ router.GET(\"/user/:name/*action\", func(c *gin.Context) { name := c.Param(\"name\") action := c.Param(\"action\") message := name + \" is \" + action c.String(http.StatusOK, message) }) // For each matched request Context will hold the route definition router.POST(\"/user/:name/*action\", func(c *gin.Context) { c.FullPath() == \"/user/:name/*action\" // true }) // This handler will add a new router for /user/groups. // Exact routes are resolved before param routes, regardless of the order they were defined. // Routes starting with /user/groups are never interpreted as /user/:name/... routes router.GET(\"/user/groups\", func(c *gin.Context) { c.String(http.StatusOK, \"The available groups\") }) router.Run(\":8080\") } 从上述示例中，我们可以学习到： 如何从 url 中提取参数。 url 中参数匹配的规则是，:${key} 表示不匹配空，*{key} 表示兼容匹配空。 url 匹配服从最短路径匹配，与 router 块的上下位置无关。 从 get 请求中获取 url 参数 func main() { router := gin.Default() // Query string parameters are parsed using the existing underlying request object. // The request responds to a url matching: /welcome?firstname=Jane&lastname=Doe router.GET(\"/welcome\", func(c *gin.Context) { firstname := c.DefaultQuery(\"firstname\", \"Guest\") // default value lastname := c.Query(\"lastname\") // shortcut for c.Request.URL.Query().Get(\"lastname\") c.String(http.StatusOK, \"Hello %s %s\", firstname, lastname) }) router.Run(\":8080\") } 从 post 请求中获取 form 参数 func main() { router := gin.Default() router.POST(\"/form_post\", func(c *gin.Context) { message := c.PostForm(\"message\") nick := c.DefaultPostForm(\"nick\", \"anonymous\") c.JSON(200, gin.H{ \"status\": \"posted\", \"message\": message, \"nick\": nick, }) }) router.Run(\":8080\") } 此外，当form参数为map格式时，可以按照如下方式进行接收： // POST /post?ids[a]=1234&ids[b]=hello HTTP/1.1 // Content-Type: application/x-www-form-urlencoded // names[first]=thinkerou&names[second]=tianou func main() { router := gin.Default() router.POST(\"/post\", func(c *gin.Context) { ids := c.QueryMap(\"ids\") names := c.PostFormMap(\"names\") fmt.Printf(\"ids: %v; names: %v\", ids, names) }) router.Run(\":8080\") } 文件上传 func main() { router := gin.Default() // Set a lower memory limit for multipart forms (default is 32 MiB) router.MaxMultipartMemory = 8 示例测试代码: curl -X POST http://localhost:8080/upload \\ -F \"file=@/Users/appleboy/test.zip\" \\ -H \"Content-Type: multipart/form-data\" url 分组 func main() { router := gin.Default() // Simple group: v1 v1 := router.Group(\"/v1\") { v1.POST(\"/login\", loginEndpoint) v1.POST(\"/submit\", submitEndpoint) v1.POST(\"/read\", readEndpoint) } // Simple group: v2 v2 := router.Group(\"/v2\") { v2.POST(\"/login\", loginEndpoint) v2.POST(\"/submit\", submitEndpoint) v2.POST(\"/read\", readEndpoint) } router.Run(\":8080\") } 中间件的使用 func main() { // Creates a router without any middleware by default r := gin.New() // Global middleware // Logger middleware will write the logs to gin.DefaultWriter even if you set with GIN_MODE=release. // By default gin.DefaultWriter = os.Stdout r.Use(gin.Logger()) // Recovery middleware recovers from any panics and writes a 500 if there was one. r.Use(gin.Recovery()) // Per route middleware, you can add as many as you desire. r.GET(\"/benchmark\", MyBenchLogger(), benchEndpoint) // Authorization group // authorized := r.Group(\"/\", AuthRequired()) // exactly the same as: authorized := r.Group(\"/\") // per group middleware! in this case we use the custom created // AuthRequired() middleware just in the \"authorized\" group. authorized.Use(AuthRequired()) { authorized.POST(\"/login\", loginEndpoint) authorized.POST(\"/submit\", submitEndpoint) authorized.POST(\"/read\", readEndpoint) // nested group testing := authorized.Group(\"testing\") testing.GET(\"/analytics\", analyticsEndpoint) } // Listen and serve on 0.0.0.0:8080 r.Run(\":8080\") } 请求参数与数据对象绑定 在 Go 语言中，针对 JSON, Yaml, XML 的请求体而言，我们需要设置对应的 Struct 来与之绑定并接收请求，示例如下： // Binding from JSON type Login struct { User string `form:\"user\" json:\"user\" xml:\"user\" binding:\"required\"` Password string `form:\"password\" json:\"password\" xml:\"password\" binding:\"required\"` } func main() { router := gin.Default() // Example for binding JSON ({\"user\": \"manu\", \"password\": \"123\"}) router.POST(\"/loginJSON\", func(c *gin.Context) { var json Login if err := c.ShouldBindJSON(&json); err != nil { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) return } if json.User != \"manu\" || json.Password != \"123\" { c.JSON(http.StatusUnauthorized, gin.H{\"status\": \"unauthorized\"}) return } c.JSON(http.StatusOK, gin.H{\"status\": \"you are logged in\"}) }) // Example for binding XML ( // // // manu // 123 // ) router.POST(\"/loginXML\", func(c *gin.Context) { var xml Login if err := c.ShouldBindXML(&xml); err != nil { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) return } if xml.User != \"manu\" || xml.Password != \"123\" { c.JSON(http.StatusUnauthorized, gin.H{\"status\": \"unauthorized\"}) return } c.JSON(http.StatusOK, gin.H{\"status\": \"you are logged in\"}) }) // Example for binding a HTML form (user=manu&password=123) router.POST(\"/loginForm\", func(c *gin.Context) { var form Login // This will infer what binder to use depending on the content-type header. if err := c.ShouldBind(&form); err != nil { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) return } if form.User != \"manu\" || form.Password != \"123\" { c.JSON(http.StatusUnauthorized, gin.H{\"status\": \"unauthorized\"}) return } c.JSON(http.StatusOK, gin.H{\"status\": \"you are logged in\"}) }) // Listen and serve on 0.0.0.0:8080 router.Run(\":8080\") } 此外，从上述代码中可以看出，该方法不仅仅局限于 JSON 请求，也可以同时接收 Form 请求， XML 请求等。 除了字段级别的验证，还可以根据相关内容进行进行校验来自定义校验器， 可以参考 示例代码 。 此外，相关的功能不仅仅能 bind body 体，还可以 bind params, headers 甚至是 url 参数等。 研发自定义中间件 func Logger() gin.HandlerFunc { return func(c *gin.Context) { // before request t := time.Now() // Set example variable c.Set(\"example\", \"12345\") // request c.Next() // after request latency := time.Since(t) log.Print(latency) // access the status we are sending status := c.Writer.Status() log.Println(status) } } func main() { r := gin.New() r.Use(Logger()) r.GET(\"/test\", func(c *gin.Context) { example := c.MustGet(\"example\").(string) // it would print: \"12345\" log.Println(example) }) // Listen and serve on 0.0.0.0:8080 r.Run(\":8080\") } By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/cmake/beginning.html":{"url":"language/cmake/beginning.html","title":"Cmake快速入门","keywords":"","body":"Cmake 快速入门 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/cmake/tutorial.html":{"url":"language/cmake/tutorial.html","title":"Cmake入门教程","keywords":"","body":"Cmake入门教程 引言 CMake教程提供了分步指南，其中涵盖了CMake可以解决的常见构建系统问题。 了解示例项目中各个主题如何协同将对后续的工作非常有帮助。 示例的教程文档和源代码可以 目录 中找到。 每个步骤都有其自己的子目录，该子目录下的 init 目录包含可用作起点的示例代码，目录下的 final 目录包含了该步骤结束后的完整代码。 教程示例是渐进式的，因此每个步骤都为上一步提供了完整的解决方案。 第一步: 基本出发点 最基本的项目是从源代码文件来构建可执行文件。 对于一个最简单的项目，只需要三行CMakeLists.txt文件。 这将是本教程的起点。 下面，在 step1/init目录 中创建一个CMakeLists.txt文件，如下所示： # Cmake 的版本要求声明 cmake_minimum_required(VERSION 3.10) # set the project name project(Tutorial) # add the executable add_executable(Tutorial tutorial.cxx) Ps: 此示例在CMakeLists.txt文件中使用小写命令。 CMake支持大写，小写和大小写混合命令。 step1/init 目录中提供了 tutorial.cxx 的源代码，可用于计算数字的平方根。 添加版本号和配置头文件 我们将添加的第一个功能是为我们的可执行文件和项目提供版本号。 尽管我们可以仅在源代码中执行此操作，但是使用CMakeLists.txt可以提供更大的灵活性。 首先，修改 CMakeLists.txt 文件以使用 project() 命令设置项目名称和版本号。 cmake_minimum_required(VERSION 3.10) # set the project name and version project(Tutorial VERSION 1.0) 然后，配置头文件以将版本号传递给源代码： configure_file(TutorialConfig.h.in TutorialConfig.h) 由于已配置的文件将被写入二进制树，因此我们必须将该目录添加到路径列表中以搜索包含文件。 将以下行添加到 CMakeLists.txt 文件的末尾： target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" ) 使用您喜欢的编辑器，在源目录中使用以下内容创建 TutorialConfig.h.in： // the configured options and settings for Tutorial #define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@ #define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@ 当 CMake 配置此头文件时，@Tutorial_VERSION_MAJOR@ 和 @Tutorial_VERSION_MINOR@ 的值将被替换，从而生成 TutorialConfig.h 文件。 接下来，修改 tutorial.cxx 以引用配置的头文件 TutorialConfig.h。 最后，让我们通过更新 tutorial.cxx 来打印出可执行文件的名称和版本号，如下所示： if (argc 指定 C++ 版本 接下来，通过在 tutorial.cxx 中用 std :: stod 替换 atof，将一些C ++ 11功能添加到我们的项目中。 同时，删除 #include 引用。 const double inputValue = std::stod(argv[1]); 我们将需要在 CMake 代码中明确声明使用的 C++ 版本。 在 CMake 中启用对特定 C++ 标准的支持的最简单方法是使用 CMAKE_CXX_STANDARD变量。 对于本教程，将 CMakeLists.txt 文件中的 CMAKE_CXX_STANDARD 变量设置为11，并将 CMAKE_CXX_STANDARD_REQUIRED 设置为True。 确保在对 add_executable 的调用上方添加 CMAKE_CXX_STANDARD 声明。 cmake_minimum_required(VERSION 3.10) # set the project name and version project(Tutorial VERSION 1.0) # specify the C++ standard set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED True) 构建和测试 下面，我们来运行 cmake 可执行文件或 cmake-gui 来配置项目，然后使用所选的构建工具对其进行构建。 例如: cd ./tutorial/step1/init mkdir build cd ./build # 运行 cmake 来配置项目并生成构建文件 cmake .. # 实际运行编译/链接功能，等同于 make cmake --build . 最后，我们来运行一些 Case 测试一下吧: ./Tutorial 4294967296 ./Tutorial 10 ./Tutorial 第二步: 添加一个 Lib 库 现在，我们需要将 Lib 库添加到我们的项目中，该库将包含我们自己的实现，用于计算数字的平方根， 然后可执行文件可以使用此库，而不是使用编译器提供的标准平方根函数。 在本教程中，我们将库放入名为 MathFunctions 的子目录中。 该目录已经包含头文件 MathFunctions.h 和源文件 mysqrt.cxx。 源文件具有一个称为 mysqrt 的函数，该函数提供与编译器的 sqrt 函数类似的功能。 将以下一行 CMakeLists.txt 文件添加到 MathFunctions 目录中： add_library(MathFunctions mysqrt.cxx) 为了利用新库，我们将在顶层 CMakeLists.txt 文件中添加一个 add_subdirectory() 调用，以便构建该库。 我们将新库添加到可执行文件，并将MathFunctions添加为包含目录，以便可以找到 mysqrt.h 头文件。 顶级 CMakeLists.txt 文件的最后几行现在应如下所示： # add the MathFunctions library add_subdirectory(MathFunctions) # add the executable add_executable(Tutorial tutorial.cxx) target_link_libraries(Tutorial PUBLIC MathFunctions) # add the binary tree to the search path for include files # so that we will find TutorialConfig.h target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" \"${PROJECT_SOURCE_DIR}/MathFunctions\" ) 现在让我们将 MathFunctions 库设为可选。 虽然对于本教程而言确实没有任何必要，但是对于较大的项目，这是常见的情况。 第一步是向顶级 CMakeLists.txt 文件添加一个选项。 # support compile option option(USE_MYMATH \"Use tutorial provided math implementation\" ON) # configure a header file to pass some of the CMake settings # to the source code configure_file(TutorialConfig.h.in TutorialConfig.h) 此选项将显示在 cmake-gui 和 ccmake 中，默认值 ON 可由用户更改。 此设置将存储在缓存中，因此用户无需在每次在构建目录上运行CMake时都设置该值。 下一个更改是使条件构建和链接 MathFunctions 库成为可选项。 为此，我们将顶级 CMakeLists.txt 文件的结尾更改为如下所示： if(USE_MYMATH) add_subdirectory(MathFunctions) list(APPEND EXTRA_LIBS MathFunctions) # variable set value list(APPEND EXTRA_INCLUDES \"${PROJECT_SOURCE_DIR}/MathFunctions\") endif() # add the executable add_executable(Tutorial tutorial.cxx) target_link_libraries(Tutorial PUBLIC ${EXTRA_LIBS}) # not effective when EXTRA_LIBS is null # add the binary tree to the search path for include files # so that we will find TutorialConfig.h target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" ${EXTRA_INCLUDES} ) PS: 此处，我们使用变量 EXTRA_LIBS 来收集所有可选库，以供以后链接到可执行文件中，变量 EXTRA_INCLUDES 类似地用于可选的头文件。 当处理许多可选组件时，这是一种经典方法，我们将在下一步中介绍现代方法。 对源代码的相应更改非常简单。 首先，在 tutorial.cxx 中引用 MathFunctions.h 的 Header ： #ifdef USE_MYMATH # include \"MathFunctions.h\" #endif 然后，在同一文件中，使 USE_MYMATH 控制使用哪个平方根函数： #ifdef USE_MYMATH const double outputValue = mysqrt(inputValue); #else const double outputValue = sqrt(inputValue); #endif 由于源代码现在需要使用 USE_MYMATH，因此我们可以使用以下行将其添加到 TutorialConfig.h.in 中： #cmakedefine USE_MYMATH Ps: 在项目顶层的 CMakeLists.txt 文件中，USE_MYMATH 的 option 定义务必在 TutorialConfig.h.in 配置声明之前， 否则，生成的 TutorialConfig.h 文件中，是无法找到 USE_MYMATH 变量值的。 现在，我们可以构建项目并运行了: mkdir build cd ./build # 使用自定义的函数 cmake .. cmake --build . # 使用非自定义的函数 cmake .. -DUSE_MYMATH=OFF cmake --build . 第三步: 添加 Lib 库的使用要求 添加 Lib 库的使用要求可以更好地控制 Lib库或可执行文件的链接，同时还可以更好地控制CMake内部目标的传递属性。 利用使用需求的主要命令是： target_compile_definitions() target_compile_options() target_include_directories() target_link_libraries() 让我们来重构我们 Step2 中的代码增加现代 CMake 的方法中的使用要求约束。 我们首先需要声明链接到 MathFunctions 的所有人（除 MathFunctions 本身外）都需要去引用当前的源码目录，也就是说它可以认为是一个接口使用规范。 将以下行添加到 MathFunctions/CMakeLists.txt 的末尾： target_include_directories(MathFunctions INTERFACE ${CMAKE_CURRENT_SOURCE_DIR} ) 现在，我们已经指定了 MathFunction 的使用要求。因此，我们可以安全地从顶级 CMakeLists.txt 中删除对 EXTRA_INCLUDES 变量的使用， 修改后如下： if(USE_MYMATH) add_subdirectory(MathFunctions) list(APPEND EXTRA_LIBS MathFunctions) endif() 以及: target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" ) 完成此操作后，可以再次运行 cmake 可执行文件或 cmake-gui 来配置项目，然后使用所选的构建工具或使用 cmake --build 进行构建。 第四步: 安装和测试 接下来，我们需要向项目中添加一些安装规则和测试支持的内容了。 安装规则 安装规则非常简单：对于MathFunctions，我们要安装库和头文件，对于应用程序，我们要安装可执行文件和配置的头文件。 因此，在 MathFunctions/CMakeLists.txt 的末尾，我们添加： install(TARGETS MathFunctions DESTINATION lib) # 对应lib install(FILES MathFunctions.h DESTINATION include) # 对应include 同时，在顶层 CMakeLists.txt 文件末尾，我们需要添加如下内容: install(TARGETS Tutorial DESTINATION bin) # 对应 bin install(FILES \"${PROJECT_BINARY_DIR}/TutorialConfig.h\" # 对应 include DESTINATION include ) 这就是基本的本地安装时所需的全部改动内容。 现在，可以运行 cmake 可执行文件或 cmake-gui 来配置项目，然后使用所选的构建工具对其进行构建。 然后，通过命令行使用 cmake 命令的安装选项来运行安装步骤。 此步骤将安装适当的头文件，库和可执行文件。 例如： cmake --install . # 等价于之前的 make install 此外，在 install 的过程中，我们还可以通过 --prefix 参数来指定安装前缀，也可以在 CMAKE_INSTALL_PREFIX Cmake 变量中设置默认值。 例如: cmake --install . --prefix \"/home/myuser/installdir\" 现在，你就可以去对应的安装目录下检查一下是否已经正确安装好了相关的文件。 测试支持 接下来让我们测试我们的应用程序。 在顶级 CMakeLists.txt 文件的末尾，我们可以启用测试，然后添加一些基本测试以验证应用程序是否正常运行。 enable_testing() # does the application run add_test(NAME Runs COMMAND Tutorial 25) # does the usage message work? add_test(NAME Usage COMMAND Tutorial) set_tests_properties(Usage PROPERTIES PASS_REGULAR_EXPRESSION \"Usage:.*number\" ) # define a function to simplify adding tests function(do_test target arg result) add_test(NAME Comp${arg} COMMAND ${target} ${arg}) set_tests_properties(Comp${arg} PROPERTIES PASS_REGULAR_EXPRESSION ${result} ) endfunction(do_test) # do a bunch of result based tests do_test(Tutorial 4 \"4 is 2\") do_test(Tutorial 9 \"9 is 3\") do_test(Tutorial 5 \"5 is 2.236\") do_test(Tutorial 7 \"7 is 2.645\") do_test(Tutorial 25 \"25 is 5\") do_test(Tutorial -25 \"-25 is [-nan|nan|0]\") do_test(Tutorial 0.0001 \"0.0001 is 0.01\") 第一个测试只是验证应用程序正在运行，没有段错误或其他崩溃，并且返回值为零。这是CTest测试的基本形式。 下一个测试使用 PASS_REGULAR_EXPRESSION 测试属性来验证测试的输出是否包含某些字符串。在这种情况下， 请验证在提供了错误数量的参数时是否打印了用法消息。 最后，我们有一个名为 do_test 的函数，该函数运行应用程序并验证所计算的平方根对于给定输入是否正确。 对于do_test的每次调用，都会根据传递的参数将另一个测试（带有名称，输入和预期结果）添加到项目中。 重新构建应用程序，然后切换到二进制目录并运行 ctest 可执行文件： ctest -N # 显示有哪些testcase ctest -VV # 运行全部testcase 此外，我们也可以在 build 目录下执行如下内容进行 debug 验证： ctest -C Debug -VV 第五步: 添加系统自检 有时，我们需要根据目标平台是否支持某个功能从而确定是否需要我们引入自己编写的代码。 在本示例中，我们将会根据目标平台是否具备 log 和 exp 函数来决定是否需要添加我们的代码。 Ps: 几乎所有的平台都会支持 log 和 exp 函数，此处，我们仅仅用于示例说明而已。 具体来说，如果平台具有 log 和 exp 函数，那么我们将使用它们来计算 mysqrt 函数中的平方根，否则，保留我们之前的逻辑。 我们首先使用 MathFunctions/CMakeLists.txt 中的 CheckSymbolExists 模块测试这些功能的可用性。 在某些平台上，我们将需要链接到m库。 如果最初没有找到log和exp，则需要m库，然后重试。 include(CheckSymbolExists) check_symbol_exists(log \"math.h\" HAVE_LOG) check_symbol_exists(exp \"math.h\" HAVE_EXP) if(NOT (HAVE_LOG AND HAVE_EXP)) unset(HAVE_LOG CACHE) unset(HAVE_EXP CACHE) set(CMAKE_REQUIRED_LIBRARIES \"m\") check_symbol_exists(log \"math.h\" HAVE_LOG) check_symbol_exists(exp \"math.h\" HAVE_EXP) if(HAVE_LOG AND HAVE_EXP) target_link_libraries(MathFunctions PRIVATE m) endif() endif() 如果可用，请使用 target_compile_definitions() 将 HAVE_LOG 和 HAVE_EXP 指定为 PRIVATE 编译定义。 if(HAVE_LOG AND HAVE_EXP) target_compile_definitions(MathFunctions PRIVATE \"HAVE_LOG\" \"HAVE_EXP\") endif() 如果 log 和 exp 在系统上可用，那么我们将使用它们来计算 mysqrt 函数中的平方根。 将以下代码添加到 MathFunctions/mysqrt.cxx 中的 mysqrt 函数中： #if defined(HAVE_LOG) && defined(HAVE_EXP) double result = exp(log(x) * 0.5); std::cout 此外，我们还需要在 mysqrt.cxx 文件中，引入 cmath。 #include 重新编译来验证一下看看吧~ 第六步: 添加自定义命令和生成的文件 假设我们决定不再使用平台的 log 和 exp 函数，而是希望生成一个可在 mysqrt 函数中使用的预计算值表。 在本节中，我们将在构建过程中创建预计算值表，然后将该表编译到我们的应用程序中。 首先，让我们在 MathFunctions/CMakeLists.txt 中删除对log和exp函数的检查。 然后，从 mysqrt.cxx 中删除对 HAVE_LOG 和 HAVE_EXP 的检查。 同时，我们可以删除 #include 。 在 MathFunctions 子目录中，我们提供了一个名为 MakeTable.cxx 的新源文件来生成表。 简单浏览该文件，我们可以看到知道这是一段用于生成预计算表的 C++ 代码，并且输出文件的文件名可以作为参数传入。 下一步是将适当的命令添加到 MathFunctions/CMakeLists.txt 文件中，以构建 MakeTable可执行文件， 然后在构建过程中运行它。 下面，我们需要一些命令来完成此操作: 首先，在 MathFunctions/CMakeLists.txt 的顶部，添加 MakeTable 的可执行文件，就像添加任何其他可执行文件一样。 add_executable(MakeTable MakeTable.cxx) 然后，我们添加一个自定义命令，该命令指定如何通过运行 MakeTable 来产生 Table.h。 add_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/Table.h COMMAND MakeTable ${CMAKE_CURRENT_BINARY_DIR}/Table.h DEPENDS MakeTable ) 接下来，我们必须让 CMake 知道 mysqrt.cxx 取决于生成的文件 Table.h。 这是通过将生成的 Table.h 添加到库 MathFunctions 的源列表中来完成的。 add_library(MathFunctions mysqrt.cxx ${CMAKE_CURRENT_BINARY_DIR}/Table.h ) 我们还必须将当前的二进制目录添加到包含目录列表中，以便 mysqrt.cxx 可以找到并包含 Table.h。 target_include_directories(MathFunctions INTERFACE ${CMAKE_CURRENT_SOURCE_DIR} PRIVATE ${CMAKE_CURRENT_BINARY_DIR} ) 现在，让我们在自定义函数中使用生成的表。 首先，修改 mysqrt.cxx 以包含 Table.h 。 接下来，我们可以重写 mysqrt 函数以使用该表： double mysqrt(double x) { if (x = 1 && x (x)]; } // do ten iterations for (int i = 0; i 重新编译来验证一下看看吧~ Ps：构建此项目时，它将首先构建 MakeTable 可执行文件。 然后它将运行 MakeTable 生成 Table.h。 最后，它将编译包括 Table.h 的 mysqrt.cxx，以生成 MathFunctions 库。 第七步: 构建安装程序 第八步: 添加对仪表板的支持 第九步: 混合静态链接和共享链接 第十步: 添加生成器表达式 第十一步: 添加导出配置 第十二步: 打包调试和发布 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"language/cpp/beginning.html":{"url":"language/cpp/beginning.html","title":"C++快速入门","keywords":"","body":"初识 C++ 欢迎来到 C++ 的世界。 C++ 继承了 C 语言高效、简捷、快速、可移植性的传统，同时针对面向对象的特性提供了全新的编程方法，这种方法是为应对复杂程度不断提高的现代编程 任务来设计的。 同时，C++ 的模板特性提供了一种全新的编程方法: 范型编程。 C++ 简介 C++ 融合了3中不同的编程方式: C 语言代表的过程性语言；C++ 扩展的类从而支持的面向对象编程；C++ 模板支持的泛型编程。 而本系列的文章也会围绕这三个部分逐步展开，从而帮助你更快的了解 C++ 这门语言。 C++ 简史 C 语言介绍 我们都知道，C++ 是基于 C 语言延伸和扩展而来的，那么，我们需要首先了解一下 C 语言的基本特点。 在 C 语言之前，我们编程用到的往往都是汇编语言。而汇编语言总是针对于特定的计算机处理器而编写的。 这也就意味着如果我们想要将汇编程序从一台计算机上移植到另外一台计算机上时，必须使用不同的汇编语言重新编写程序。 而 UNIX 操作系统的出现则是出现了一个契机，UNIX 就是为不同的计算机(平台) 上进行工作而设计的。 因此，C 语言也在 UNIX 平台下被开发了出来，它可以通过编译器将 C 语言翻译成特定计算机的内部语言，从而实现代码的可移植。 对于一个计算机语言而言，往往要处理的两个核心概念是: 数据 和 算法 。 其中: 数据是程序要使用和处理的信息。 算法是程序使用的方法和处理步骤。 对于 C 语言这样的面向过程性的语言而言，它更加强调的是程序的 算法 过程，及更关注的是程序的整体流程和逻辑的。 随着项目规模的不断扩大，为了保证项目的可控性，在编程过程中，逐渐形成了一种 自顶向下 的设计原则: 将一个大型的程序拆分成为若干个小型的、便于管理的程序。 例如一个项目拆分为多个模块，每个模块在拆分为多个函数等等。 C++ 面向对象编程 然而，即使有了 自顶向下 的设计原则，再面对一些更大规模的项目时，仍然面临着大量的挑战。 此时，一种新的编程思想被提出了: 面向对象编程 。 与面向过程性的方法不同，面向对象编程语言中的核心是 数据。 而我们在编程过程中，首先要做的是定义程序要处理的核心对象是什么？同时，针对每个对象定义其可以进行的操作，并实现这个对象的程序。 最后，只需要最后通过一个程序将各个对象的处理串连起来即可。 这种方法也称之为 自下向上 编程。 而为了具备这种 面向对象编程 的能力，C++ 中提供了类的概念，它可以用来描述一种数据对象，并且可以规定可以进行哪些操作等。 除了思路的转变之外，面向对象编程的这种方法还带来了很多实际的好处： 代码可重用。 信息隐藏，避免数据被不适当的访问。 多态可以为运算符和函数创建多个定义。 继承可以根据旧的类扩展出新的类。 C++ 泛型编程 泛型编程是 C++ 支持的又一个核心编程模式，它的目的也是让我们编程更加的方便。 但是与面向对象编程不同，面向对象编程强调的是以数据对象为核心，而泛型编程则是希望程序可以与数据解绑。 即我们不需要针对不同的数据类型编写多份相同处理逻辑的代码。 C++ 泛型编程主要是依赖 模板 功能来实现的。 C++ 程序创建 编写一个 C++ 程序并将其运行起来，大约需要分为如下这些步骤： 使用文本编辑器编写源代码并保存。 编译源代码，将源代码翻译为主机使用的机器语言，即得到目标代码。 将目标代码和其他代码链接起来，例如和lib库函数等，最终得到可执行程序。 运行可执行程序即可。 如下图所示: 源代码编写 在不同平台开发 C++ 程序时，依赖的 C++ 程序编译器并不一样，因此，对于编写源代码的方式也不完全相同。 主要体现在以下两点： 不同平台依赖的开发工具不一样，例如 Windows 下可以用 VisualStudio 等IDE，而在 Linux 下，则可能需要使用 vim 等编辑器。 不同编译器对源代码的文件名后缀的要求也不一样，如下表所示。 平台 源代码文件的扩展名 UNIX C, cc, cxx, c GNU C++ C, cc, cxx, cpp, c++ Microsoft Visual C++ cpp, cxx, cc 编译和链接 之前已经提到了，在不同的平台下，编译器并不一样，编译和链接的方法也不同，下面，我们来看看各个平台的编译工具怎么用吧。 平台 编译/链接工具 UNIX CC Linux(GNU C++) g++ Windows命令行 g++(Cygwin/MinGW) Windows IDE Microsoft Visual C++ 2010 Mac Xcode、Terminal进行UNIX模式 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/mongo/beginning.html":{"url":"databases/mongo/beginning.html","title":"mongodb","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/mongo/install.html":{"url":"databases/mongo/install.html","title":"MongoDB的安装","keywords":"","body":"MongoDB的安装 本文中，我们将会讲解MongoDB在各种平台下的安装方式。 Ubuntu下安装MongoDB 在Ubuntu系统下，MongoDB的安装非常简单，可以直接使用 apt-get 命令安装即可。 sudo apt-get install mongodb 安装完成后，我们可以检查服务状态已经端口是否正常启动： # 检查服务状态 service mongodb status # 检查端口是否正常启动 sudo lsof -i:27017 默认情况下，mongoDB服务仅允许在127.0.0.1进行本地访问。 因此，我们需要修改配置文件使得它运行外网访问。 mongodb的配置文件位于: /etc/mongodb.conf。 bind_ip = 0.0.0.0 Ps：修改配置文件中bind_ip的值为0.0.0.0即可。 配置文件修改完成后，需要重新启动mongodb服务使之生效： service mongodb restart Linux下MongoDB集群环境搭建 搭建一个多节点的副本集MongoDB时，至少需要3个节点（机器）。 分别在每个机器上执行如下命令： Step1：下载指定版本的MongoDB并解压到/home/zhiyun/mongodb-4.2.2目录中。 Step2：创建服务创建相关目录和配置文件： cd /home/zhiyun/mongodb-4.2.2 mkdir logs mkdir -p ./data/db mkdir conf vim ./conf/config.yaml 其中config.yaml文件如下： systemLog: destination: file path: /home/zhiyun/mongodb-4.2.2/logs/mongod.log logAppend: true storage: dbPath: /home/zhiyun/mongodb-4.2.2/data/db net: bindIp: 0.0.0.0 port: 8017 replication: replSetName: zhiyunrs processManagement: fork: true Step3：依次启动每台机器的MongoDB服务： cd /home/zhiyun/mongodb-4.2.2 ./bin/mongod -f ./conf/config.yaml Step4：当所有节点的mongodb服务均启动成功后，在任一节点中执行如下命令，将其设置为副本集模式： ./bin/mongo --port 8017 然后在mongo交互式命令行中输入如下内容： rs.initiate({ _id: \"zhiyunrs\", members: [ { _id: 0, host: \"${IP1}:8017\" }, { _id: 1, host: \"${IP2}:8017\" }, { _id: 2, host: \"${IP3}:8017\" } ] }) 至此为止，一个三副本的MongoDB服务就搭建完成了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/mongo/install_package.html":{"url":"databases/mongo/install_package.html","title":"MongoDB安装包剖析","keywords":"","body":"MongoDB安装包剖析 在上一节中，我们已经以Ubuntu为例，讲解了如何快速安装MongoDB。 而在本节中，我们将通过安装包下载的方式来详细讲解MongoDB的安装包中包含了哪些内容，以及相关的工具的介绍。 安装包下载 我们可以从 MongoDB官方网站 下载MongoDB的安装包。 我们以Mac系统为例，下载完成后，我们可以解压该压缩包： tar -zxvf mongodb-macos-x86_64-4.4.3.tgz 进入该目录后，我们看到如下内容： . ├── LICENSE-Community.txt ├── MPL-2 ├── README ├── THIRD-PARTY-NOTICES └── bin ├── install_compass ├── mongo ├── mongod └── mongos 其中： LICENSE-Community.txt、MPL-2以及THIRD-PARTY-NOTICES文件都是开源协议以及第三方使用相关授权事项等信息，不在本文展开讨论。 README是MongoDB安装包相关的介绍文档，建议完整阅读，下文中也会给出相关的中文翻译版本。 bin目录下是可以直接运行的MongoDB二进制包以及一些配套的工具，都会在README中提及。 README 下面，我们来看一下MongoDB安装包中的README文档。 欢迎使用MongoDB！ MongoDB安装包中包含如下内容： mongod: 数据库服务端程序。 mongos: 分片路由程序。 mongo: 数据库交互式shell工具。 其他工具： install_compass: 可以快速安装MongoDB Compass的工具。 源码构建方式 参考docs/building.md文件 服务启动： 查询命令行参数的方式: ./mongod --help 快速启动一个单实例的数据库： ```bash sudo mkdir -p /data/db ./mongod # 启动mongodb服务端 mongo javascript 交互式Shell默认连接localhost的test数据库: ./mongo > help ### 安装Compass 你可以使用bin目录下的install_compass脚本来快速安装Compass： ```bash ./install_compass 上述脚本会下载适用于你的平台的Compass部署包并执行相关的安装操作。 驱动 大部分语言的客户端驱动可以在 https://docs.mongodb.com/manual/applications/drivers/ 找到。 此外，还可以使用mongo交互式shell工具来进行相关的管理任务。 Bug反馈 详见: https://github.com/mongodb/mongo/wiki/Submit-Bug-Reports 打包 在buildscripts目录中，有一个package.py脚本可以自动的创建对应的RPM和Debian包。 文档 使用文档详见: https://docs.mongodb.com/manual/ MongoDB云服务 见: https://www.mongodb.com/cloud/atlas 论坛 MongoDB使用问题相关论坛: https://community.mongodb.com MongoDB构建和开发问题相关论坛: https://community.mongodb.com/c/server-dev 学习MongoDB https://university.mongodb.com/ 许可 MongoDB是免费和开源的。 2018年10月16日之前发布的版本适用于AGPL许可。 2018年10月16日之后发布的所有版本（包括先前版本的修补程序修复）均根据服务器端公共许可证（SSPL）v1发布。 二进制程序 mongod mongod 是mongodb服务端的二进制执行程序，通过mongod我们可以快速启动一个MongoDB服务。 mongos 对于分片群集，mongos实例提供客户端应用程序和分片群集之间的接口。 通过mongos服务，可以实现MongoDB集群横向扩展。 mongo mongo 是一个交互示shell的MongoDB交互工具，通过mongo命令行工具，可以对MongoDB服务端进行相关管理操作，基本使用格式如下： usage: ./mongo [options] [db address] [file names (ending in .js)] install_compass install_compass是一个Python脚本。 它的功能是可以在除Windows之外的操作系统中，根据当前的操作系统下载适合版本的Compass工具并安装。 使用方式非常简单，直接执行如下命令即可： ./install_compass By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/mongo/tool_package.html":{"url":"databases/mongo/tool_package.html","title":"MongoDB工具包剖析","keywords":"","body":"MongoDB工具包剖析 在上一篇文章中，我们了解了MongoDB的安装包的内容。 接下来，我们来讲述MongoDB工具包中提供的MongoDB相关的配套工具。 工具包概述 MongoDB数据库工具是用于处理MongoDB实例的命令行实用程序的集合。 数据库工具包括以下二进制文件： 二进制导入导出类 mongodump: 将mongod数据库实例中的数据导出到一个二进制文件中。 mongorestore: 将mongodump导出得到的文件恢复到mongod或mongos实例中。 bsondump: 把BSON文件转化为JSON。 数据导入导出类 mongoimport: 将Extended JSON, CSV或TSV中的数据导入到MongoDB中。 mongoexport: 将mongod实例中的数据存储到JSON或CSV文件中。 问题分析工具 mongostat: 一个用于查询运行状态的mongod或mongods实例的概览指标的工具。 mongotop: 一个用于查询mongod实例读写耗时指标的工具。 网格文件系统相关工具 mongofiles: 支持在GridFS中处理文件。 下载与安装 MongoDB Tools的下载地址如下: https://www.mongodb.com/try/download/database-tools?tck=docs_databasetools 选择对应的平台版本下载即可。 MongoDB Tools的安装方式非常简单，只需要将工具包解压，并将其中的二进制工具文件放到环境变量PATH包含的目录中即可，例如/usr/local/bin/下。 工具使用方式详解 mongodump mongodump工具的作用是将运行中的mongodb实例中的数据导出到一组.bson文件中。 其中，可以使用-d指定database，-c指定collection。 mongodb连接地址字符串应该是一个以mongodb://或mongodb+srv://开头的。 完整的参数列表如下： 通用参数： --help 打印帮助信息 --version 打印版本信息 日志级别参数： -v, --verbose= 打印更详细的日志信息 --quiet 忽略所有日志打印 连接连接参数： -h, --host= mongodb实例主机（对于副本集而言，应该是setname/host1,host2） --port= mongodb服务端口，也可以统一在--host hostname:port中设置 uri参数： --uri= mongodb uri连接字符串 ssl参数： --ssl 连接mongo或mongos实例时，开启ssl --sslCAFile= 包含证书颁发机构的根证书链的.pem文件 --sslPEMKeyFile= 包含证书和密钥的.pem文件 --sslPEMKeyPassword= 解密sslPEMKeyFile的密码（如果加密了的话） --sslCRLFile= 包含证书吊销列表的.pem文件 --sslFIPSMode 使用已安装的openssl库的FIPS模式 --tlsInsecure 跳过服务器证书链和主机名的验证 鉴权参数： -u, --username= 数据库用户名 -p, --password= 数据库密码 --authenticationDatabase= 存放用户登录凭证的数据库 --authenticationMechanism= 使用的认证机制 --awsSessionToken= AWS IAM的授权Token kerberos参数: --gssapiServiceName= 使用GSSAPI / Kerberos进行身份验证时要使用的服务名称（默认：mongodb） --gssapiHostName= 使用GSSAPI / Kerberos进行身份验证时使用的主机名（默认值：） 生效空间参数： -d, --db= 指定数据库 -c, --collection= 指定database 查询参数： -q, --query= 查询过滤器，扩展JSON字符串，例如'{\"x\"：{\"$gt\"：1}}' --queryFile= 包含查询过滤器JSON字符串的文件 --readPreference=| 指定首选项模式（例如'nearest'）或首选项json对象（例如'{mode：\"nearest\"，tagSets：[{a：\"b\"}]，maxStalenessSeconds：123}'） 输出参数： -o, --out= 导出目录，用'-'可以表示导出至标准输出，默认为'dump' --gzip 导出目录使用gzip压缩 --oplog 使用oplog用于快照 --archive= 作为存档转储到指定路径。如果指定的标志没有值，则将存档写入stdout。 --dumpDbUsersAndRoles 导出指定数据库的用户和角色信息 --excludeCollection= 过滤指定collection排除出导出内容 --excludeCollectionsWithPrefix= 过滤指定开头的collections，排除出导出内容 -j, --numParallelCollections= 指定多个collections并行导出 --viewsAsCollections 将视图与生成的数据一起作为普通集合转储，而忽略标准集合 mongorestore mongorestore工具的作用是将mongodump生成的备份数据恢复到一个运行的数据库实例中。 其中，可以使用-d指定database，-c指定collection。 mongodb连接地址字符串应该是一个以mongodb://或mongodb+srv://开头的。 完整的参数列表如下： 通用参数（同mongodump） 日志级别参数（同mongodump） 连接连接参数（同mongodump） uri参数（同mongodump） ssl参数（同mongodump） 鉴权参数（同mongodump） kerberos参数（同mongodump） 生效空间参数： -d, --db= 指定数据库 -c, --collection= 指定database --nsExclude= --nsInclude= --nsFrom= --nsTo= 输入参数： --objcheck --oplogReplay --oplogLimit=[:ordinal] --oplogFile= --archive= --restoreDbUsersAndRoles --dir= --gzip 恢复参数： --drop --dryRun --writeConcern= --noIndexRestore --convertLegacyIndexes --noOptionsRestore --keepIndexVersion --maintainInsertionOrder -j, --numParallelCollections= --numInsertionWorkersPerCollection= --stopOnError --bypassDocumentValidation --preserveUUID --fixDottedHashIndex bsondump mongoimport mongoexport mongostat mongotop mongofiles By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/mongo/server_args.html":{"url":"databases/mongo/server_args.html","title":"MongoDB Server命令行与配置文件解析","keywords":"","body":"MongoDB Server命令行与配置文件解析 本节中，我们会详细剖析MongoDB Server端的启动参数/配置文件。 通过本文的学习，希望你可以详细了解如何给你的MongoDB Server设置合适的配置。 命令行参数初识 首先，我们来通过mongod自带的help来大致了解一下mongod支持哪些命令行参数。 mongod --help 可以看到打印的help信息如下： Options: --networkMessageCompressors arg (=snappy,zstd,zlib) Comma-separated list of compressors to use for network messages General options: -h [ --help ] Show this usage information --version Show version information -f [ --config ] arg Configuration file specifying additional options --configExpand arg Process expansion directives in config file (none, exec, rest) --port arg Specify port number - 27017 by default --ipv6 Enable IPv6 support (disabled by default) --listenBacklog arg (=128) Set socket listen backlog size --maxConns arg (=1000000) Max number of simultaneous connections --pidfilepath arg Full path to pidfile (if not set, no pidfile is created) --timeZoneInfo arg Full path to time zone info directory, e.g. /usr/share/zoneinfo --nounixsocket Disable listening on unix sockets --unixSocketPrefix arg Alternative directory for UNIX domain sockets (defaults to /tmp) --filePermissions arg Permissions to set on UNIX domain socket file - 0700 by default --fork Fork server process -v [ --verbose ] [=arg(=v)] Be more verbose (include multiple times for more verbosity e.g. -vvvvv) --quiet Quieter output --logpath arg Log file to send write to instead of stdout - has to be a file, not directory --syslog Log to system's syslog facility instead of file or stdout --syslogFacility arg syslog facility used for mongodb syslog message --logappend Append to logpath instead of over-writing --logRotate arg Set the log rotation behavior (rename|reopen) --timeStampFormat arg Desired format for timestamps in log messages. One of iso8601-utc or iso8601-local --setParameter arg Set a configurable parameter --bind_ip arg Comma separated list of ip addresses to listen on - localhost by default --bind_ip_all Bind to all ip addresses --noauth Run without security --transitionToAuth For rolling access control upgrade. Attempt to authenticate over outgoing connections and proceed regardless of success. Accept incoming connections with or without authentication. --slowms arg (=100) Value of slow for profile and console log --slowOpSampleRate arg (=1) Fraction of slow ops to include in the profile and console log --profileFilter arg Query predicate to control which operations are logged and profiled --auth Run with security --clusterIpSourceWhitelist arg Network CIDR specification of permitted origin for `__system` access --profile arg 0=off 1=slow, 2=all --cpu Periodically show cpu and iowait utilization --sysinfo Print some diagnostic system information --noscripting Disable scripting engine --notablescan Do not allow table scans --keyFile arg Private key for cluster authentication --clusterAuthMode arg Authentication mode used for cluster authentication. Alternatives are (keyFile|sendKeyFile|sendX509|x509) Replication options: --oplogSize arg Size to use (in MB) for replication op log. default is 5% of disk space (i.e. large is good) Replica set options: --replSet arg arg is [/] --enableMajorityReadConcern [=arg(=1)] (=1) Enables majority readConcern Sharding options: --configsvr Declare this is a config db of a cluster; default port 27019; default dir /data/configdb --shardsvr Declare this is a shard db of a cluster; default port 27018 Storage options: --storageEngine arg What storage engine to use - defaults to wiredTiger if no data files present --dbpath arg Directory for datafiles - defaults to /data/db --directoryperdb Each database will be stored in a separate directory --syncdelay arg (=60) Seconds between disk syncs --journalCommitInterval arg (=100) how often to group/batch commit (ms) --upgrade Upgrade db if needed --repair Run repair on all dbs --journal Enable journaling --nojournal Disable journaling (journaling is on by default for 64 bit) --oplogMinRetentionHours arg (=0) Minimum number of hours to preserve in the oplog. Default is 0 (turned off). Fractions are allowed (e.g. 1.5 hours) AWS IAM Options: --awsIamSessionToken arg AWS Session Token for temporary credentials Free Monitoring Options: --enableFreeMonitoring arg Enable Cloud Free Monitoring (on|runtime|off) --freeMonitoringTag arg Cloud Free Monitoring Tags WiredTiger options: --wiredTigerCacheSizeGB arg Maximum amount of memory to allocate for cache; Defaults to 1/2 of physical RAM --wiredTigerJournalCompressor arg (=snappy) Use a compressor for log records [none|snappy|zlib|zstd] --wiredTigerDirectoryForIndexes Put indexes and data in different directories --wiredTigerCollectionBlockCompressor arg (=snappy) Block compression algorithm for collection data [none|snappy|zlib|zstd] --wiredTigerIndexPrefixCompression arg (=1) Use prefix compression on row-store leaf pages TLS Options: --tlsOnNormalPorts Use TLS on configured ports --tlsMode arg Set the TLS operation mode (disabled|allowTLS|preferTLS|requireTLS) --tlsCertificateKeyFile arg Certificate and key file for TLS --tlsCertificateKeyFilePassword arg Password to unlock key in the TLS certificate key file --tlsClusterFile arg Key file for internal TLS authentication --tlsClusterPassword arg Internal authentication key file password --tlsCAFile arg Certificate Authority file for TLS --tlsClusterCAFile arg CA used for verifying remotes during inbound connections --tlsCRLFile arg Certificate Revocation List file for TLS --tlsDisabledProtocols arg Comma separated list of TLS protocols to disable [TLS1_0,TLS1_1,TLS1_2] --tlsAllowConnectionsWithoutCertificates Allow client to connect without presenting a certificate --tlsAllowInvalidHostnames Allow server certificates to provide non-matching hostnames --tlsAllowInvalidCertificates Allow connections to servers with invalid certificates --tlsFIPSMode Activate FIPS 140-2 mode at startup --tlsCertificateSelector arg TLS Certificate in system store --tlsClusterCertificateSelector arg SSL/TLS Certificate in system store for internal TLS authentication --tlsLogVersions arg Comma separated list of TLS protocols to log on connect [TLS1_0,TLS1_1,TLS1_2] 下面，我们来依次分析相关的参数。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/mongo/mongo_charts.html":{"url":"databases/mongo/mongo_charts.html","title":"MongoCharts的安装与使用","keywords":"","body":"MongoCharts的安装与使用 安装 前置条件： 已经安装Docker 18.03及以上版本。 搭建一个MongoDB实例用于作为MongoChart的后端存储数据库。 Step1: 初始化swarm集群 sudo docker swarm init Step2: 拉取MongoChart镜像 docker pull quay.io/mongodb/charts:19.12.1 Step3: 验证提前搭建的作为MongoChart的后端存储数据库的MongoDB实例是否正常工作 sudo docker run --rm quay.io/mongodb/charts:19.12.1 charts-cli test-connection 'mongodb://${ip}:${port}' Step4: 创建Secret对象 echo \"mongodb://${ip}:${port}\" | sudo docker secret create charts-mongodb-uri - Step5: 创建部署对象 MongoCharts需要使用Docker Swarm进行安装，其中Yaml文件如下: version: '3.3' services: charts: image: quay.io/mongodb/charts:19.12.1 hostname: charts ports: - 8811:80 volumes: - keys:/mongodb-charts/volumes/keys - logs:/mongodb-charts/volumes/logs - db-certs:/mongodb-charts/volumes/db-certs - web-certs:/mongodb-charts/volumes/web-certs environment: # The presence of following 2 environment variables will enable HTTPS on Charts server. # All HTTP requests will be redirected to HTTPS as well. # To enable HTTPS, upload your certificate and key file to the web-certs volume, # uncomment the following lines and replace with the names of your certificate and key file. # CHARTS_HTTPS_CERTIFICATE_FILE: charts-https.crt # CHARTS_HTTPS_CERTIFICATE_KEY_FILE: charts-https.key # This environment variable controls the built-in support widget and # metrics collection in MongoDB Charts. To disable both, set the value # to \"off\". The default is \"on\". CHARTS_SUPPORT_WIDGET_AND_METRICS: 'on' # Directory where you can upload SSL certificates (.pem format) which # should be considered trusted self-signed or root certificates when # Charts is accessing MongoDB servers with ?ssl=true SSL_CERT_DIR: /mongodb-charts/volumes/db-certs networks: - backend secrets: - charts-mongodb-uri networks: backend: volumes: keys: logs: db-certs: web-certs: secrets: charts-mongodb-uri: external: true 我们将其命名为 charts-docker-swarm.yaml 。然后执行如下命令： sudo docker stack deploy -c charts-docker-swarm.yaml mongodb-charts Step6: 检查服务是否正常部署 sudo docker service ls Step7: 创建管理用户 sudo docker exec -it \\ $(sudo docker container ls --filter name=_charts -q) \\ charts-cli add-user --first-name \"\" --last-name \"\" \\ --email \"\" --password \"\" \\ --role \"UserAdmin\" Step8: 登录Web页面进行查看 Web页面的地址为： http://${host_ip}:8811 Step9: 密钥备份相关信息 mkdir /tmp/mongo-charts-keys sudo docker run -it \\ --volume mongodb-charts_keys:/volume \\ --volume /tmp/mongo-charts-keys:/backup \\ quay.io/mongodb/charts:19.12.1 sh -c 'cp /volume/* /backup' By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/elasicsearch/beginning.html":{"url":"databases/elasicsearch/beginning.html","title":"Elasticsearch","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/etcd/beginning.html":{"url":"databases/etcd/beginning.html","title":"etcd","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/etcd/install.html":{"url":"databases/etcd/install.html","title":"etcd的安装","keywords":"","body":"ETCD的安装 本文中，我们将会讲解ETCD在各种平台下的安装方式。 Ubuntu下安装ETCD 在Ubuntu系统下，ETCD的安装非常简单，可以直接使用 apt-get 命令安装即可。 sudo apt-get install etcd 安装完成后，我们可以检查服务状态已经端口是否正常启动： # 检查服务状态 service etcd status # 检查端口是否正常启动 sudo lsof -i:2379 此时，我们已经可以在本机访问ETCD服务了，但是如果你尝试跨主机访问ETCD的服务的话，会发现端口无法正常连接。 其原因是etcd的默认配置仅运行127.0.0.1地址进行进行访问，因此，我们需要修改etcd的配置文件。 默认情况下，etcd的配置文件位于: /etc/default/etcd。 在这个配置文件中，我们主要需要修改如下两项： ETCD_LISTEN_CLIENT_URLS=\"http://0.0.0.0:2379\" ETCD_ADVERTISE_CLIENT_URLS=\"http://0.0.0.0:2379\" 修改完成后，重启ETCD并检查状态即可： service etcd restart service etcd status By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/etcd/quickstart.html":{"url":"databases/etcd/quickstart.html","title":"etcd的快速入门","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/etcd/etcd_in_python.html":{"url":"databases/etcd/etcd_in_python.html","title":"在Python中使用ETCD","keywords":"","body":"在Python中使用ETCD 在本文中，我们将会学习如何在Python中快速的使用ETCD进行数据读写等相关操作。 安装 在Python中使用etcd时，我们首先需要安装etcd第三方库。 pip install python-etcd==0.4.5 快速入门 在下面的内容中，我们将会讲述Python的ETCD库的一些标准使用方式，了解这些方式可以帮助你快速入门在Python中使用ETCD。 创建一个Client对象 import etcd # 几种初始化客户端的方式 # 单实例连接 client = etcd.Client(host='127.0.0.1', port=4003) # 多实例连接 client = etcd.Client(host=(('127.0.0.1', 4001), ('127.0.0.1', 4002), ('127.0.0.1', 4003))) # https://example.com client = etcd.Client(srv_domain='example.com', protocol=\"https\") # https://api.example.com:443/etcd client = etcd.Client(host='api.example.com', protocol='https', port=443, version_prefix='/etcd') 写入一个key client.write('/nodes/n1', 1) # with ttl client.write('/nodes/n2', 2, ttl=4) # 4s后过期 读取一个key client.read('/nodes/n2').value client.read('/nodes', recursive = True).children # 递归获取该目录下的所有key-value数据 # 读取一个不存在的key时会抛出异常 try: client.read('/invalid/path') except etcd.EtcdKeyNotFound: print \"error\" 删除一个Key client.delete('/nodes/n1') 监听一个key client.read('/nodes/n1', wait=True) # wait直到该key变化，返回变化信息 client.read('/nodes/n1', wait=True, timeout=30) # wait直到该key变化或超时，返回变化信息或抛出超时异常 client.read('/nodes/n1', wait=True, recursive=True) # wait直到该key或子key变化，返回变化信息 刷新ttl过期时间 client.write('/nodes/n1', 'value', ttl=30) # 设置过期时间为30s client.refresh('/nodes/n1', ttl=600) # 修改过期时间为600s etcd用户分布式锁 client = etcd.Client() # Or you can custom lock prefix, default is '/_locks/' if you are using HEAD client = etcd.Client(lock_prefix='/my_etcd_root/_locks') lock = etcd.Lock(client, 'my_lock_name') # Use the lock object: lock.acquire(blocking=True, # will block until the lock is acquired lock_ttl=None) # lock will live until we release it lock.is_acquired # True lock.acquire(lock_ttl=60) # renew a lock lock.release() # release an existing lock lock.is_acquired # False # The lock object may also be used as a context manager: client = etcd.Client() with etcd.Lock(client, 'customer1') as my_lock: do_stuff() my_lock.is_acquired # True my_lock.acquire(lock_ttl=60) my_lock.is_acquired # False 获取集群中的机器列表 client.machines 获取集群中的leader节点 client.leader By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/redis/beginning.html":{"url":"databases/redis/beginning.html","title":"redis","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/redis/install.html":{"url":"databases/redis/install.html","title":"redis的安装","keywords":"","body":"Redis的安装 本文中，我们将会讲解Redis在各种平台下的安装方式。 Ubuntu下安装Redis 在Ubuntu系统下，Redis的安装非常简单，可以直接使用 apt-get 命令安装即可。 sudo apt-get install redis-server 安装完成后，我们可以检查服务状态已经端口是否正常启动： # 检查服务状态 service redis-server status # 检查端口是否正常启动 sudo lsof -i:6379 默认情况下，Redis服务仅允许通过使用127.0.0.1进行本地访问。 因此，我们需要修改配置文件使得它运行外网访问。 redis的配置文件位于: /etc/redis/redis.conf。 bind 0.0.0.0 Ps：修改配置文件中bind_ip的值为0.0.0.0即可。 配置文件修改完成后，需要重新启动redis服务使之生效： service redis-server restart By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/beginning.html":{"url":"databases/neo4j/beginning.html","title":"neo4j","keywords":"","body":"neo4j 概述 neo4j 可以说是目前最流行的 图数据库 了。 本系列的文章主要会讲解 neo4j 数据库的安装、基本功能和相关的使用，跟着文章一起来学习吧。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/install.html":{"url":"databases/neo4j/install.html","title":"neo4j的安装","keywords":"","body":"neo4j 的安装 在本文中，我们会介绍介绍几种在不同场景下适用的搭建 neo4j 数据库的方法。 Mac/Window 下安装 Neo4j Desktop 如果你想要在 Mac/Windows 下本地学习 Neo4j 相关的功能和使用，那么，Neo4j Desktop 就是最推荐的安装方法了。 你可以从 下载链接 中下载 Neo4j Desktop。 下载得到的会是一个 exe 安装包（Windows）或 pkg 安装包（MacOS），然后就像普通软件安装一样正常安装即可。 安装后的页面如下图所示： Neo4j Desktop 不仅仅内置了 Neo4j 数据库，同时还带有了数据库管理系统，并集成了 Neo4j Brower, Neo4j Bloom 等应用， 对于新人学习而言，应该是一个非常棒的选择。 Linux 下安装 Neo4j 如果我们想要在 Linux 服务器上搭建一个 Neo4j 的数据库，这时，Desktop 的安装方法就不再适用了。 此时，我们需要从 下载链接 中下载 tar 格式的安装包。 接下来，我们就可以解压并启动对应的 Neo4j Server 了： tar -xvf neo4j-community-4.3.2-unix.tar cd neo4j-community-4.3.2 解压后，你会看到其中包含如下一些目录: bin: 启动脚本和一些可执行文件 conf: neo4j 的一些配置文件 data: 数据库中数据存储的目录 lib: 依赖的lib库 plugins: 用户可扩展的插件 logs: 日志文件目录 import: 可导入的 CSV 文件目录 下面，我们就准备来启动 neo4j 服务。 ./bin/neo4j console # 前台启动 # Directories in use: # home: /home/neo4j/neo4j-community-4.3.2 # config: /home/neo4j/neo4j-community-4.3.2/conf # logs: /home/neo4j/neo4j-community-4.3.2/logs # plugins: /home/neo4j/neo4j-community-4.3.2/plugins # import: /home/neo4j/neo4j-community-4.3.2/import # data: /home/neo4j/neo4j-community-4.3.2/data # certificates: /home/neo4j/neo4j-community-4.3.2/certificates # licenses: /home/neo4j/neo4j-community-4.3.2/licenses # run: /home/neo4j/neo4j-community-4.3.2/run # Starting Neo4j. # 2021-07-21 10:58:10.981+0000 INFO Starting... # 2021-07-21 10:58:13.124+0000 INFO ======== Neo4j 4.3.2 ======== # 2021-07-21 10:58:14.900+0000 INFO org.neo4j.internal.kernel.api.security.AbstractSecurityLog$SecurityLogLine@4b5cdd07 # 2021-07-21 10:58:14.907+0000 INFO org.neo4j.internal.kernel.api.security.AbstractSecurityLog$SecurityLogLine@65f470f8 # 2021-07-21 10:58:14.908+0000 INFO org.neo4j.internal.kernel.api.security.AbstractSecurityLog$SecurityLogLine@531299d3 # 2021-07-21 10:58:14.913+0000 INFO org.neo4j.internal.kernel.api.security.AbstractSecurityLog$SecurityLogLine@332fa1c # 2021-07-21 10:58:14.914+0000 INFO org.neo4j.internal.kernel.api.security.AbstractSecurityLog$SecurityLogLine@1d0f7bcf # 2021-07-21 10:58:14.916+0000 INFO org.neo4j.internal.kernel.api.security.AbstractSecurityLog$SecurityLogLine@1978b0d5 # 2021-07-21 10:58:15.069+0000 INFO Bolt enabled on localhost:7687. # 2021-07-21 10:58:15.959+0000 INFO Remote interface available at http://localhost:7474/ # 2021-07-21 10:58:15.961+0000 INFO Started. # ./bin/neo4j start 后台启动 # ./bin/neo4j stop 后台停止 # ./bin/neo4j restart 后台重启 # ./bin/neo4j status 状态检查 Ps: 启动 neo4j 之前，需要保证已经有了对应的 JVM 环境，其中，neo4j 4.x 版本依赖的 Java 版本为 Java11。 此时，我们就可以打开浏览器访问 http://localhost:7474/ 。 其中，初始的用户名和密码都是 neo4j 。 首次登录后会要求你进行修改密码，修改密码后，就可以正常使用 neo4j 相关的功能了。 Docker 镜像启动 Neo4j 最后，我们再来讲解一个简单的安装 neo4j 的方法，那就是利用 Docker 镜像直接启动 neo4j 服务。 启动命令如下： docker run \\ --publish=7474:7474 --publish=7687:7687 \\ --volume=$HOME/neo4j/data:/data \\ neo4j 其中，分别将 7474 和 7687 端口映射到了宿主上，同时将宿主机的 /data 目录挂载至容器中，用于数据的持久化。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/quick_start.html":{"url":"databases/neo4j/quick_start.html","title":"neo4j的快速使用","keywords":"","body":"neo4j的快速使用 当我们完成 neo4j 的环境搭建后，我们就赶快来体验一下 neo4j 相关的功能吧。 在Neo4dj的 安装 中，我们已经完成了 neo4j 的安装并进入到了 Neo4j 的浏览器中 WEB 页面中。 那么，在本文中，我们就将会基于 Neo4j Browser 来体验一下 Neo4j 的相关功能。 Neo4j Browser 概述 Neo4j Browser 是 Neo4j 提供的一款开发者工具，通过 Neo4j Browser ，开发者可以查看 Neo4j 数据库中的数据、 执行 Cypher 语句、查询结果和查询图表。 此外，还可以通过 Neo4j Browser 来： 导入数据。 调用自定义的 Java 程序 Profile 查询等 示例数据演示 下面，我们就在 Neo4j Browser 上针对 Neo4j 提供的示例数据进行相关功能的演示和学习。 输入如下指令: :play movie graph 可以看到如下页面，即我们可以使用 Movie Graph 示例数据集来进行学习。 这个示例可以带着我们学习如何进行： 数据写入: 将电影数据写入至 graph 中。 检索: 检索指定的电影和演员。 查询: 查询相关的演员和导演。 关系链路查询。 数据写入 右侧是一个巨大的代码块，其中包含由多个 CREATE 子句组成的单个 Cypher 语句。 这些指令将会创建一个电影的 Graph。 点击代码块就可以执行对应的数据写入命令了。 命令执行完成后，可以看到一个如下的图： 可以看到，在上图中包含了10部电影和9个人。其中，一共包含了20个『关系』，10个是『导演』的关系，10个是『演员』的关系。 数据检索 下面，我们可以演示一些 Cypher 的基本语句来进行一些数据检索： MATCH (tom {name: \"Tom Hanks\"}) RETURN tom 执行上述命令，可以看到你会检索得到一个 Person，该 Person 的姓名是 \"Tom Hanks\"。 MATCH (cloudAtlas {title: \"Cloud Atlas\"}) RETURN cloudAtlas 执行上述命令，可以看到你会检索得到一个 Movie，该 Movie 的名称是 \"Cloud Atlas\"。 MATCH (people:Person) RETURN people.name LIMIT 10 执行上述命令，可以看到你会检索得到一个列表，列表中罗列了10个人的名称，即根据数据类型进行检索。 MATCH (nineties:Movie) WHERE nineties.released >= 1990 AND nineties.released 执行上述命令，可以看到你会检索得到一个列表，列表中罗列 1990 年到 2000 年发布的电影的名称。 数据查询 至此，看起来相关的功能还是传统的数据库非常的类似，但是下面的内容会让你了解到图数据库的强大。 下面，我们可以演示一些 Cypher 的基本语句来进行一些数据查询： MATCH (tom:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(tomHanksMovies) RETURN tom,tomHanksMovies 可以看到，上述命令可以直接查询出 Tom Hanks 饰演的全部电影，并返回了 Tom Hanks 的信息和对应的电影的信息。 MATCH (cloudAtlas {title: \"Cloud Atlas\"})可以看到，上述命令可以直接查询出 Cloud Atlas 电影的导演姓名。 MATCH (tom:Person {name:\"Tom Hanks\"})-[:ACTED_IN]->(m)可以看到，上述命令可以直接查询出和 Tom Hanks 合作的的演员姓名。 MATCH (people:Person)-[relatedTo]-(:Movie {title: \"Cloud Atlas\"}) RETURN people.name, Type(relatedTo), relatedTo 可以看到，上述命令可以直接查询出所有和 Cloud Atlas 电影有关的人物信息以及他们在电影中承担的工作。 怎么样？通过上述命令是不是已经感受到了图数据库的便捷？ 关系链路查询 MATCH (bacon:Person {name:\"Kevin Bacon\"})-[*1..2]-(hollywood) RETURN DISTINCT hollywood 从上图可以看到，上述指令可以查询出与 Kevin Bacon 通过2个节点能存在关联的所有人和电影。 MATCH p=shortestPath( (bacon:Person {name:\"Kevin Bacon\"})-[*]-(meg:Person {name:\"Meg Ryan\"}) ) RETURN p 上述命令表示查询 Kevin Bacon 到 Meg Ryan 之间的最短路径。 推荐 图数据库常常还可以用于推荐场景，例如，我们可以找出一些推荐和 Tom Hanks 合作的演员。 MATCH (tom:Person {name:\"Tom Hanks\"})-[:ACTED_IN]->(m)(m2)() cocoActors RETURN cocoActors.name AS Recommended, count(*) AS Strength ORDER BY Strength DESC 我们来看一下上述指令的作用： 首先，我们需要找的演员是没有和 Tom Hanks 直接合作过的演员，但是其实是和 Tom Hanks 间接合作过的演员。 同时，按照间接合作的次数进行排序。 MATCH (tom:Person {name:\"Tom Hanks\"})-[:ACTED_IN]->(m)(m2)上述命令表示找出 Tom Hanks 和 Tom Cruise 间接合作过的完整的链路。 删除数据 当我们完成上述实验之后，就可以删除相关的数据了： MATCH (n) DETACH DELETE n 删除完成之后，可以使用如下指令验证数据是否已经删除干净了： MATCH (n) RETURN n 此时，我们关于对 Neo4j 的初步的了解就先告一段落了。 总结 Neo4j 适用于一些复杂关系的场景，例如内容欺诈、网络/IT分析、物联网等等。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/python_driver_neo4j.html":{"url":"databases/neo4j/python_driver_neo4j.html","title":"使用Python操作Neo4j数据库 - neo4j","keywords":"","body":"使用Python操作Neo4j数据库 - neo4j 概述 在上一节中，我们已经了解了如何在 neo4j 浏览器中进行 Neo4j 数据的相关操作了。 现在，我们会继续看一下如何使用 Python 编程语言来调用 Neo4j 数据库，这样，你就可以在自己的项目中使用它了。 其中： Neo4j 官方提供了 JS, Java, .Net 和 Python 的驱动程序。 此外， 社区 还提供了一些 PHP, Ruby, Go, Haskell 等编程语言的驱动。 下面，我们就以 Python 的官方驱动为例，还演示如何使用 Python 调用 Neo4j 数据库。 Python 驱动安装 Neo4j 的 Python 驱动安装非常简单，可以直接使用 Python 的包管理工具直接安装即可： pip install neo4j-driver # Successfully installed neo4j-driver-4.3.3 pytz-2021.1 HelloWorld 下面，我们来编写第一个用 Python 调用 Neo4j 数据的示例代码： from neo4j import GraphDatabase class HelloWorldExample(object): def __init__(self, uri, user, password): self._driver = GraphDatabase.driver(uri, auth=(user, password)) def close(self): self._driver.close() def print_greeting(self, message): with self._driver.session() as session: greeting = session.write_transaction(self._create_and_return_greeting, message) print(greeting) @staticmethod def _create_and_return_greeting(tx, message): result = tx.run(\"CREATE (a:Greeting) \" \"SET a.message = $message \" \"RETURN a.message + ', from node ' + id(a)\", message=message) return result.single()[0] if __name__ == \"__main__\": example = HelloWorldExample(\"neo4j://localhost:7687\", \"neo4j\", \"password\") example.print_greeting(\"Hello World!\") example.close() 运行一下看看结果吧: python3 ./hello_world.py # Hello World!, from node 0 python3 ./hello_world.py # Hello World!, from node 1 python3 ./hello_world.py # Hello World!, from node 2 可以看出，这种使用方法其实非常简单，仅仅就是直接用 Python 组装一个 Cypher 语句，然后调用 run 函数来执行即可。 通用示例 下面，我们再来看一个更加通用的示例: from neo4j import GraphDatabase driver = GraphDatabase.driver(\"neo4j://localhost:7687\", auth=(\"neo4j\", \"password\")) def add_friend(tx, name, friend_name): tx.run(\"MERGE (a:Person {name: $name}) \" \"MERGE (a)-[:KNOWS]->(friend:Person {name: $friend_name})\", name=name, friend_name=friend_name) def print_friends(tx, name): for record in tx.run(\"MATCH (a:Person)-[:KNOWS]->(friend) WHERE a.name = $name \" \"RETURN friend.name ORDER BY friend.name\", name=name): print(record[\"friend.name\"]) with driver.session() as session: session.write_transaction(add_friend, \"Arthur\", \"Guinevere\") session.write_transaction(add_friend, \"Arthur\", \"Lancelot\") session.write_transaction(add_friend, \"Arthur\", \"Merlin\") session.read_transaction(print_friends, \"Arthur\") driver.close() 虽然我们还没有详细学习 Cypher 的语法，但是我们其实也已经可以了解到，上述命令其实就是先向数据库中写入了几条数据，然后进行了依次进行了查询。 关于 Neo4j Driver 更多的介绍可以参考 官方文档 。 至此，我们基本就可以了解到 Neo4j 的 Python Driver 的使用也非常简单，其核心是需要我们了解 Cypher 的相关的语法。 接下来的文章中，我们将会详细介绍 Cypher 的相关语法。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/python_driver_py2neo.html":{"url":"databases/neo4j/python_driver_py2neo.html","title":"使用Python操作Neo4j数据库 - py2neo","keywords":"","body":"使用Python操作Neo4j数据库 - py2neo 概述 和官方提供了 neo4j 库一样，py2neo 也是一个 Python 用于操作 Neo4j 数据库的客户端库。 该库可以直接 bolt 和 HTTP 协议通信方式，还提供了 High Level API 、OGM、管理工具、交互式控制台等功能，整体来说，它的功能会比 neo4j 官方库更加强大和易用。 安装 和大部分的 Python 第三方库一样， py2neo 的安装也非常简单，直接使用 pip 包管理工具安装即可: pip install py2neo 快速示例 下面，我们就以一个最简单的示例开始，来演示一下 py2neo 的使用吧。 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) graph.run(\"UNWIND range(1, 3) AS n RETURN n, n * n as n_sq\") # n | n_sq # -----|------ # 1 | 1 # 2 | 4 # 3 | 9 这个例子实在是太简单了，简单到它本质上其实并没有真正与数据库进行增删改查操作。 不过，我们通过这个例子，至少可以知道: py2neo 提供了一个 Graph 类用于连接 neo4j 数据库。 Graph 类实例化的对象可以直接用 run 方法来执行 Cypher 语句。 常用操作 创建一个节点 from py2neo import Graph, Node graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = Node(\"Book\", name=\"Neo4j权威指南\", version=\"1.1\") graph.create(node) 根据属性查询一个节点 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = graph.nodes.match(\"Book\", name=\"Neo4j权威指南\").first() 根据节点ID查询节点信息 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = graph.nodes.get(38) print(dict(node)) # 将节点属性转为dict格式 查询属性全部匹配的节点 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = graph.nodes.match(\"Book\", name=\"Neo4j权威指南\").all() 根据关系查询关系 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = graph.nodes.get(38) current_subtopo_relations = graph.match((node,), r_type=\"write\").all() for relation in current_subtopo_relations: print(relation, relation.end_node) 创建两个节点并添加对应的关系 from py2neo import Graph, Node, Relationship graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node1 = Node(\"Book\", name=\"Neo4j权威指南\", version=\"1.1\") node2 = Node(\"Person\", name=\"张帜\", gender=\"man\") relation = Relationship(node1, \"write\", node2) graph.create(relation) 修改一个节点的属性 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = graph.nodes.get(38) node[\"age\"] = 53 graph.push(node) 删除节点 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = graph.nodes.get(38) graph.delete(node) 删除关系 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) node = graph.nodes.get(38) current_subtopo_relations = graph.match((node,), r_type=\"write\").all() for relation in current_subtopo_relations: graph.separate(relation) # 仅删除关系 执行 Cypher 语句 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) cypher = 'MATCH (resource:Book {name: \"Neo4j权威指南\"}) 事务性操作 from py2neo import Graph graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\")) tx = graph.begin() try: node = graph.nodes.get(38) graph.delete(node) tx.commit() except Exception as e: tx.rollback() raise Exception(e) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/cypher_basic.html":{"url":"databases/neo4j/cypher_basic.html","title":"cypher概述及基本语法","keywords":"","body":"cypher概述及基本语法 Cypher 概述 Cypher 是一种声明式的图数据库查询语言，具有丰富的表现力，能够高效的查询和更新图数据。 Cypher 借鉴了 SQL 语言的结构，可以组合各种语句来实现相关的功能。 最常用的语句包括： MATCH: 匹配图模式，Cypher 中最核心的语句。 WHERE: 添加额外的约束条件。 RETURN: 定义返回的结果。 一个简单的示例如下: MATCH (john {name: 'John'})-[:friend]->()-[:friend]->(fof) RETURN john.name, fof.name 上述语句的含义是找出 John 的朋友的朋友列表。 此外，我们还可以引入 WHERE 语句进行一些过滤: MATCH (user)-[:friend]->(follower) WHERE user.name IN ['Joe', 'John'] AND follower.name =~ 'S.*' RETURN user.name, follower.name Cypher 语句的含义非常直观，甚至对于一个完全没有接触过 Cypher 的同学，基本都可以直接了解到该数据的功能。 上述介绍的几个语句主要是用于数据查询相关，而对于数据修改而言，常用的语句包括: CREATE/DELETE: 创建/删除节点和关系。 SET/REMOVE: 使用SET设置属性值和标签，使用REMOVE移除属性值和标签。 MERGE: 匹配已经存在的或者创建新的节点和模式，这对于有唯一性约束的时候非常有效。 关于这些语句的具体使用，我们将会在 下一篇文章 中进行深入的讲解。 Cypher 模式 Cypyer 查询语句非常依赖于模式。 模式可以非常简单，例如某个人 LIVE_IN 某个城市；也可以非常复杂，例如多个模式可以组装在一起。 而 Cypyer 最大的魅力就在于其模式的语言表达能力。 在图数据库中包括两种对象，分别是 \"节点\" 和 \"关系\" 。 其中，在 Cypher 语法中，节点使用一对圆括号来表示: () # 匿名节点 (matrix) # 命名节点，matrix 变量可在后续语句中引用 (:Movie) # 指定节点标签为Movie的匿名节点 (matrix:Movie) # 指定节点标签为Movie的命名节点 (matrix:Movie {title: \"The Matrix\"}) # 指定节点标签和属性的命名节点 (matrix:Movie {title: \"The Matrix\", released: 1997}) # # 指定节点标签和多个属性的命名节点 从上述示例中可以看出，除了用一对圆括号来表示一个节点之外，我们还可以知道: 使用 :XXX 来指定节点类型。 使用 {key: value} 来指定节点属性。 此外，在 Cypher 语法中，关系使用一对短横线（--）来表示，有向关系使用（-->或 --> # 匿名关系 -[role]-> # 命名关系 -[:ACTED_IN]-> # 指定类型的匿名关系 -[role:ACTED_IN {roles: [\"Neo\"]}]-> # 指定类型、属性的命名关系 Ps: 需要注意的是，关系的属性值可以是数组。 当我们了解了如何表示节点和关系后，我们就可以组合它们来实现一些模式了，例如: (tom:Person:Actor {name:\"Tom\"})-[role:ACTED_IN {roles:[\"Neo\"]}]->(matrix:Movie {title: \"The Matrix\"}) 此外，我们还可以将一个模式赋值给一个变量，例如: acted_in = (:Person)-[:ACTED_IN]->(:Moive) Cypher 查询和更新数据 了解了 Cypher 的模式之后，我们再来看一下如何使用 Cypher 来查询和更新数据。 查询数据 Cypher 查询数据非常简单，只需要使用 MATCH 语句结合上述的模式表达式即可，例如: MATCH (person:Person)-[:ACTED_IN]->(:Moive) RETURN person 另外，我们还可以用 WITH 语句将多个查询语句连接在一起: MATCH (person:Person)-[:ACTED_IN]->(moive:Moive) WITH person, count(movie) AS movieCount WHERE movieCount > 3 RETURN person, movieCount 更新数据 使用 Cypher 更新数据时，常常用到 SET 等语句。 MATCH (person:Person)-[:ACTED_IN]->(moive:Moive) WITH person, count(movie) AS movieCount SET person.movieCount = movieCount RETURN person, movieCount 上述命令中，我们将 Person 参演的电影数量作为属性值设置给了 Person 节点。 Cypher 事务 Cypher 支持事务的功能，可以保证一个事务内的操作要么全部成功、要么全部失败。 当一个 Cypher 语句本身没有在一个事务的上下文中时，则该 Cypher 语句会作为一个独立的事务执行。 而当一个 Cypher 语句已经在某个上下文中时，整个过程就会基于已有的上下文进行操作，直到整个事务成功提交之后，才会持久化至磁盘中。 Cypher 的唯一性 Cypher 在进行模式匹配时，会保证单个模式中不会多次匹配到同一个图对象。 以一个示例为例: MATCH (a:Person)-[:friend]-()-[:Friend]-(b:Person) RETURN a, b 上述是一个无方向的模式，也就是说，a 的朋友的朋友理论上应该有可能是自己。 但是在 Cypher 的唯一性约束下，同一个模式中，不会多次匹配到同一个对象，因此，此时不会将a和b匹配到同一个人上。 那如果我们的确有这种需求时，应该怎么办呢？也非常简单，直接把它们拆分到多个模式中即可，例如: MATCH (a:Person)-[:friend]-(friend) MATCH (friend)-[:Friend]-(b:Person) RETURN a, b 此时，由于a和b已经不在同一个模式中，因此，二者可能会表示同一个节点。 Cypher 基本语法 Cypher 类型 Cypher 中所有处理的值都属于一个特定的类型，Cypher 支持的类型包括: 数值型 字符串型 布尔型 节点 关系 路径 MAP LIST Cypher 表达式 在 Cypher 中，包含的表达式有: 十进制数字: 13，3.14 十六进制数字: 0x12 八进制数字: 013 字符串: \"Hi\", 'Hello' 布尔值: true, false, TRUE, FALSE 变量: x, name 属性: x.name 动态属性: x[\"name\"] 参数: $param, $0 列表: ['a', 'b'] 函数调用: length(p) 聚合函数: avg(x.prop), count(*) 模式: (a)-->(b) 计算式: 1 + 2 and 3 断言表达式: a.prop = \"hello\" 或 exists(a.name) 正则表达式: a.name =~ 'Tob.*' 字符串匹配: a.username STARTS WITH 'wang' CASE 表达式 其中，我们来简单聊一下 CASE 表达式，CASE 表达式给 Cypher 提供了一种逻辑判断的能力，使用效果和通常编程语言中的 if-else 类似。 例如: CASE a.name WHEN \"wangzhe\" THEN \"admin\" WHEN \"rongsong\" THEN \"user\" ELSE \"invalid\" END 也可以扩展为如下格式: WHEN a.name = \"wangzhe\" THEN \"admin\" WHEN a.name = \"rongsong\" THEN \"user\" ELSE \"invalid\" END 该方式显得更加灵活，也与 if 语法更加类似。 一个完整是示例如下: MATCH (n) RETURN WHEN n.eyes = \"blue\" THEN 1 WHEN n.eyes = \"brown\" THEN 2 ELSE 3 END AS result Cypher 变量 在 Cypher 中的变量是区分大小写的，可以包含字母、数字、下划线，但必须是字母开头。 Cypher 参数 Cypher 支持带参数的查询，也就意味着开发任务无需拼接字符串来查询，也可以使后续讲的执行计划更容易缓存。 需要注意的是，参数不能用于属性名，关系类型和标签。 参数名称是字母和数字的组合。 参数: { \"name\": \"John\" } 查询语句: MATCH (n {name: $name}) RETURN n 创建带有属性的节点: 参数: { \"props\": { \"name\": \"Wangzhe\", \"age\": 30 } } 语句： CREATE (n:Person) SET n = $props RETURN n Cypher 运算符 Cypher 支持的运算符包括: 数学运算符: +, -, *, /, %, ^ 比较运算符: =, <>, >, =, IS NULL, IS NOT NULL 布尔运算符: AND, OR, XOR, NOT 字符串运算符: +, =~ 列表运算符: +, IN Cypher 注释 在 Cypher 中，使用 // 进行『行』注释。 模式 在上面的内容中，我们已经提到了，在 Cypher 中，节点用 () 来表示，关系有 -- 来表示。 此处，关于关系的描述，我们再进行一些补充: (a)-[r:TYPE1|TYPE2]->(b) 当我们想要支持多种关系类型任意查询时，可以使用 | 来分隔关系类型。 (a)-[*3..5]->(b) 当我们想要查询不定长关系时，可以在[]中添加 *min..max 来表示，其中，min和max后可以省略，例如: (a)-[:upstream*]->(b) 表示 b 是 a 的任意关联的上游。 Cypher List 与 Map 说明 Cypher 对 List 有很好的支持。 Cypher 中 List 的表达方式与 Python 一致，用方括号包括一组以逗号分隔的元素来表示一个列表。 例如: RETURN [0, 1, 2, 3, 4] AS list 和 Python 类似，Cypher 也可以用 range 函数来生成一个数组，与 Python 不一样的是，在 Cypher 中 range 函数生成的 list 是包含收尾元素的。 RETURN range(1, 10) 对于一个 list 而言，支持通过 [index] 来访问元素，例如: RETURN range(1, 10)[4] 其中，索引也可以是负数，即从末尾元素倒数。 RETURN range(1, 10)[-1] 此外，数组也支持分片的方式截取子数组: RETURN range(1, 10)[2..-1] 其中，分片截取时，包含索引头元素，不包含索引尾元素。 Cypher 中提供了一个 size() 函数可以用于计算数组的长度: RETURN size(range(1, 10)) 在 Cypher 中，还支持了 List 推导式： RETURN [x IN range(1,10) WHERE x % 2 = 0 | x^3] AS result 上述表达式的含义是将 1-10 的列表中，找出 % 2 为 0 的元素，并对每个元素计算三次方并返回。 其中，WHERE 条件过滤和 | 过滤计算都是可选的。 将列表推导式应用到模式中，可以产生有意思的效果: MATCH (a:Person {name:\"Wangzhe\"}) RETURN [(a)-->(b) WHERE b:Movie | b.year] AS years 其中，返回的 years 是一个列表，它表示的是与 Wangzhe 有关的所有的电影上映时间。 除了 LIST 之外， Cepher 还支持了 MAP 类型。 示例如下: RETURN {key: \"Value\", listKey: [{inner: \"Map1\"}, {inner: \"Map2\"}]} 此外，基于 MAP 类型，Cypher 还支持了 map 映射的功能： 例如: MATCH (actor:Person {name: \"Wangzhe\"})-->(movie:Movie) RETURN actor { .name, .realName, movies: collect(movie { .title, .year })} 上述 Cypher 语法的含义是指： 找出 Wangzhe 所有关联的电影，并按照人员粒度进行聚合，并返回人员的 name, realName 字段以及所有的关联的电影中的 title 和 year 字段。 在这个 map 映射中，除了上述我们介绍到的可以使用 .key 来表示返回字典中的指定字段外，还可以: variable_name: 表示key是变量名，value是变量对应的值，key对应的变量不存在时，设置的属性为 null。 *： 表示当前对象的全部属性。 Cypher NULL 说明 在 Cypher 中，NULL 是一个比较特殊的值，需要注意如下: null = null 返回的是 null ，不是 true null 参数的逻辑运算返回均为 null 索引越界的 LIST 时返回的是 null 包含 null 的算术运算结果均为 null 包含 null 的函数调用结果均为 null 访问不存在的关系或属性时，得到的结果为 null By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/cypher_language.html":{"url":"databases/neo4j/cypher_language.html","title":"cypher语句","keywords":"","body":"cypher语句 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"databases/neo4j/cypher_function_and_schema.html":{"url":"databases/neo4j/cypher_function_and_schema.html","title":"cypher函数及模式","keywords":"","body":"cypher函数及模式 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ci/teamcity/beginning.html":{"url":"ci/teamcity/beginning.html","title":"TeamCity","keywords":"","body":"TeamCity 简介 JetBrains TeamCity 是一款功能强大且使用简单的持续集成和部署的服务器，安装后即可快速使用。 接下来的一系列文章中，我们将会一步步带你了解 TeamCity 的相关使用。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ci/teamcity/install.html":{"url":"ci/teamcity/install.html","title":"TeamCity的安装","keywords":"","body":"TeamCity 的安装 TeamCity 的安装非常简单，下面，我们将会以不同的操作系统为例来演示如何进行安装。 MacOS 下安装 TeamCity 首先，我们以 MacOS 系统为例，来演示如何快速搭建 TeamCity 并用于相关的学习和验证。 其中，需要说明的是，TeamCity 分为服务端和Agent端，而在演示学习环境中，我们会同时在一台机器中安装服务端和Agent端。 如果是生产环境，则不建议如此使用。 Step1: 前置工作: 安装 JDK 并配置 JAVA_HOME 环境变量。 Step2: 下载 TeamCity 安装包， 下载地址 。 Step3: 解压 TeamCity 安装包。 tar -zxvf TeamCity.tar.gz Step4: 启动 TeamCity 服务 ./bin/runAll.sh start 默认情况下，TeamCity 启动后会绑定本地 8111 端口，即 http://localhost:8111/ 。 Step5: 配置开机自启动 假设本地的 TeamCity 安装目录为 /Users/wangzhe/Desktop/TeamCity 。 则创建一个文件 /Library/LaunchDaemons/jetbrains.teamcity.server.plist ，内容如下： WorkingDirectory /Users/wangzhe/Desktop/TeamCity Debug Label jetbrains.teamcity.server OnDemand KeepAlive ProgramArguments /bin/bash --login -c bin/runAll.sh run RunAtLoad StandardErrorPath logs/launchd.err.log StandardOutPath logs/launchd.out.log UserName wangzhe 创建完成后，可以用如下命令进行验证： launchctl load /Library/LaunchDaemons/jetbrains.teamcity.server.plist 该命令预期能够正常启动 TeamCity 服务。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/beginning.html":{"url":"middleware/rabbitmq/beginning.html","title":"RabbitMQ","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/install.html":{"url":"middleware/rabbitmq/install.html","title":"RabbitMQ的安装","keywords":"","body":"RabbitMQ的安装 本文中，我们将会讲解RabbitMQ在各种平台下的安装方式。 什么是 RabbitMQ RabbitMQ是一个消息代理：它的主要功能是接收和转发消息。 你可以把它想象成一个邮局：当你把你想要邮寄的邮件放在邮箱后，邮递员最终将邮件发送给你的收件人。在这个例子中，RabbitMQ充当的是邮政信箱，邮局和邮递员的角色。 RabbitMQ和邮局的主要区别在于它处理的不是实物邮件，而是接收，存储和转发二进制数据（我们称之为消息）。 在RabbitMQ中，我们有一些常用的术语： Producing（消息生产者）：在RabbitMQ的使用场景中，Producing表示消息的生产者，它是用来发送消息的。 Queue（队列）：RabbitMQ接收到消息后，会将其存放在队列中。一个队列受到主机内存和磁盘限制的约束，它本质上是一个很大的消息缓冲区。 许多生产者可以发送消息至同一个队列，许多消费者可以从一个队列中接收数据。 Consuming（消息消费者）：消费者又称为接收者，实际就是消息的接收者， Ps: 需要说明的是，在RabbitMQ的使用场景中，Producing、Queue和Consuming无需部署在同一机器上，仅仅需要互相之间网络联通即可。 什么场景会使用RabbitMQ？ 了解了什么是RabbitMQ以后，我们来思考一下，什么场景需要使用RabbitMQ？ RabbitMQ其中一个常用场景是分布式异步任务处理功能。 想象一下，在一个分布式系统中，模块A通过HTTP请求调用模块B的接口，而传递给模块B处理的任务又相对复杂，有一定的耗时。 如果是同步请求，所有的请求都等到模块B完整处理完成后再返回模块A的话，一个直接导致的后果是会在模块A和模块B之间阻塞大量的任务。一方面可能会由于给模块B的压力过大导致调度失败，同时也可能由于模块B连接打满无法接收任务。 此时，一种较好的解决方案如下： 模块A将任务信息发送给RabbitMQ即可，然后RabbitMQ将消息发送给模块B进行处理。一方面，避免了长连接导致的模块B无法访问，另一方面，可以通过调度任务处理机制以及部署多个模块B来进行分布式处理从而缓解服务压力。 Ubuntu下安装RabbitMQ 在Ubuntu系统下，RabbitMQ的安装非常简单，可以直接使用 apt-get 命令安装即可。 sudo apt-get install rabbitmq-server 安装完成后，我们可以检查服务状态已经端口是否正常启动： # 检查服务状态 service rabbitmq-server status # 检查端口是否正常启动 sudo lsof -i:5672 Docker 安装方式 下面，我们来讲解一下如何使用Docker来安装RabbitMQ。 首先，我们需要安装Docker服务，安装的方式此处不再赘述。 安装完成Docker后，我们可以执行如下命令来拉取最新的rabbitmq镜像： sudo docker pull rabbitmq 然后执行如下命令启动即可： sudo docker run -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672:25672 -p 15671:15671 -p 8439:15672 rabbitmq RabbitMQ配置与管理 RabbitMQ搭建完成后，我们需要添加一个管理员用户用于RabbitMQ的管理。 sudo rabbitmqctl add_user admin admin 赋予该用户管理员权限： sudo rabbitmqctl set_user_tags admin administrator 赋予virtual host中所有资源的配置、写、读权限以便管理其中的资源: sudo rabbitmqctl set_permissions -p / admin '.*' '.*' '.*' 启用RabbitMQ管理页面: sudo rabbitmq-plugins enable rabbitmq_management 之后在浏览器访问 http://server-ip:15672 ，账号与密码都是刚才设置的 admin。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/config.html":{"url":"middleware/rabbitmq/config.html","title":"RabbitMQ的配置详解","keywords":"","body":"RabbitMQ的配置详解 在上一节的内容中，我们讲解了如何快速安装一个 RabbitMQ 的服务。 因为仅仅是一个示例，我们没有对它的配置进行任何的修改就直接启动了服务。 然而，在生产环境中，我们常常需要对 rabbitmq 的配置进行一些修改，然后再启动服务，而在本文中，我们将会重点讲解 RabbitMQ 如何进行相关的配置。 概述 RabbitMQ 提供了三种方式来定制服务相关的配置: 环境变量: RabbitMQ 的部分服务端参数可以直接通过环境变量进行配置，例如节点名称、RabbitMQ配置文件地址、端口等。 配置文件: RabbitMQ 可以通过配置文件定义 RabbitMQ 的服务配置和相关的插件设置等，例如 TCP监听端口、内存磁盘限制等。 运行时参数和策略: RabbitMQ 的集群层面相关的配置可以在运行时通过参数和策略进行配置。 环境变量 RabbitMQ 的环境变量都是以 RABBITMQ_ 开头的，可以直接在 shell 中进行配置， 也可以在 rabbitmq-env.conf 这个 RabbitMQ 环境变量文件中统一设置（推荐）。 Ps: shell 配置的环境变量优先级高于 rabbitmq-env.conf 配置文件。 例如一个简单的 rabbitmq-env.conf 文件内容如下: # 定义节点名称 NODENAME=rabbit@node1 # 定义RabbitMQ对外通信端口号 NODE_PORT=5672 # 定义RabbitMQ配置文件地址，其中，如果配置文件的后缀是 .config ，则可以直接省略后缀 CONFIG_FILE=/opt/rabbitmq/etc/rabbitmq/rabbitmq 其中，rabbitmq-env.conf 文件默认位于 $RABBITMQ_HOME/etc/rabbitmq/ 目录下。 下面，我们来罗列一些常用的环境变量: 变量名称 描述 RABBITMQ_NODE_IP_ADDRESS 绑定某个特性的网络接口，默认为空，表示绑定到所有网络接口上。 RABBITMQ_NODE_PORT 监听客户端连接的端口，默认为5672 RABBITMQ_DIST_PORT 分布式通信的端口号，默认为 RABBITMQ_NODE_PORT + 20000 RABBITMQ_NODENAME 节点名称，默认为rabbit@$HOSTNAME，每个erlang和机器的组合中，节点名称必须唯一 RABBITMQ_CONFIG_FILE 配置文件地址，不需要.config文件后缀 RABBITMQ_CONF_ENV_FILE 环境变量配置文件地址，默认为$RABBITMQ_HOME/etc/rabbitmq/rabbitmq-env.conf RABBITMQ_USE_LONGNAME 当机器名称包含.时，默认取.前面的部分，设置为true时，会取完整名称 RABBITMQ_MNESIA_DIR 存储服务节点的数据库、数据存储、集群状态相关的目录，默认为$RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME RABBITMQ_MNESIA_BASE RABBITMQ_MNESIA_DIR的父目录，默认为$RABBITMQ_HOME/var/lib/rabbitmq/mnesia RABBITMQ_LOGS 日志目录，默认为$RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log RABBITMQ_LOG_BASE 日志父目录，默认为$RABBITMQ_HOME/var/log/rabbitmq RABBITMQ_SASL_LOGS RabbitMQ服务于erlang的SASL日志，默认为$RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log RABBITMQ_PLUGINS_DIR 插件所在的路径，默认为$RABBITMQ_HOME/plugins 配置文件 RabbitMQ 的配置文件指的是上述环境变量RABBITMQ_CONFIG_FILE对应的文件，可以用于设置 RabbitMQ 的详细配置。 一个极简单的 rabbitmq.config 文件的内容如下（不能遗漏最后的 .）: [ { rabbit, [ {tcp_listeners, [5673]} ] } ]. 上述配置的含义是将 RabbitMQ 的端口由默认的 5672 修改为了 5673。 关于 RabbitMQ 的详细配置文件可以参考官方文档 ，此处不再一一罗列了。 运行时参数和策略配置 对于 RabbitMQ 的绝大部分参数，其实都可以通过修改 RabbitMQ 的配置文件来完成。 但是也有一些参数，我们希望能够在服务运行的过程中进行动态的修改，这种参数我们就称之为\"运行时参数\"。 RabbitMQ 的运行时参数可以通过 rabbitmqctl 工具或者 RabbitMQ Management 插件提供的 HTTP API 来实现。 此处就不展开介绍了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/demo.html":{"url":"middleware/rabbitmq/demo.html","title":"RabbitMQ的Demo示例","keywords":"","body":"RabbitMQ的Demo示例 本文中，我们将会实现一个入门级的Demo程序来了解一下 RabbitMQ 的使用。 Producing Demo 实现 首先，我们需要实现一个Producing，来向RabbitMQ发送消息。 完整的示例代码send.py如下： #!/usr/bin/env python import pika # pika是Python连接RabbitMQ的工具 # 第一步是用于连接RabbitMQ # Demo程序中，send.py运行机器与RabbitMQ位于同一台机器中，因此使用localhost表示本机，如果部署在不同机器中，可以指定IP地址。 # Demo程序中，RabbitMQ默认启动占用的是5672端口，因此无需指定，如果RabbitMQ使用其他端口，需要使用port=****来指定端口信息。 connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() # 第二步，在发送消息之前，我们需要确保收件人队列存在。 # 如果我们发送消息到不存在的位置，RabbitMQ将只删除该消息。 # 下面，我们来创建一个将传递消息的hello队列 channel.queue_declare(queue='hello') # 创建完成收件人队列后，我们就可以发送消息了。 # 第一条消息此处是一个字符串Hello World # 在RabbitMQ中，消息永远不会直接发送到队列，它总是需要经过交换来实现的。 # 交换的功能细节我们会在后续进行讲解，现在只需要知道的使用由空字符串标识的默认交换。 # 我们可以使用routing_key参数中指定消息发送至哪个收件人队列。 channel.basic_publish(exchange='', routing_key='hello', body='Hello World!') print(\" [x] Sent 'Hello World!'\") # 在退出程序之前，我们需要确保网络缓冲区被刷新，并且我们的消息被实际传送到RabbitMQ。 # 因此，我们需要执行断开连接功能。 connection.close() Consuming Demo 实现 Producing代码完成后，我们来继续学习Consuming部分的代码receiver.py。 在这个Demo中Consuming实现的功能就是接收到消息后将其打印出来（标准输出）。 #!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() # 同样进行验证指定队列存在（如果不存在则创建该队列，如果已经存在则忽略） channel.queue_declare(queue='hello') # 下面，我们定义一个回调函数。 # 每当我们收到一条消息，这个回调函数就在收到消息后调用。 # 在我们的例子中，这个函数会在屏幕上打印消息的内容。 def callback(ch, method, properties, body): print(\" [x] Received %r\" % body) # 接下来，我们需要告诉RabbitMQ这个特定的回调函数应该从我们的hello队列接收消息 channel.basic_consume(callback, queue='hello', no_ack=True) # 最后，我们进入一个永无止境的循环，等待数据在必要时运行回调。 print(' [*] Waiting for messages. To exit press CTRL+C') channel.start_consuming() 运行实验 下面，我们来运行一下看看吧~ 首先，我们需要启动consumer来等待消息发送： python receiver.py 接下来，我们可以用 sender.py 来发送消息，每次执行后会发送一条消息： python sender.py 现在，我们可以看到每次发送消息后，在receiver.py运行的终端中，会打印出sender.py中发送的消息HelloWorld。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/work_queue.html":{"url":"middleware/rabbitmq/work_queue.html","title":"RabbitMQ的工作队列（均匀分配模式）","keywords":"","body":"RabbitMQ的工作队列（均匀分配模式） 在本文中，我们将会创建一个工作队列 ，用于在多个Worker之间分配任务。 循环调度 工作队列的主要思想是避免立即执行资源密集型任务，且任务完成后才返回请求信息。 相反，我们接收到一个任务后并不立即处理，返回信息已收到，并后续排队依次进行处理。 此时，我们可以将任务封装为消息并将其发送到队列。在后台运行的工作进程将会接收到消息并最终执行该任务。 当存在许多工作节点时，这些任务将在他们之间分配调度。 在本文的介绍中，我们将会发送一些表示复杂任务的消息。 在消息产生中，我们发送一些带有\".\"的字符串，其中，每一个\".\"表示等待1s。 例如，hello... 则表示等待3s钟。 下面，我们来编写一个消息产生的文件new_task.py: #!/usr/bin/env python # -*- coding: UTF-8 -*- import sys import pika # pika是Python连接RabbitMQ的工具 connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.queue_declare(queue='hello') # 接收所有输入的参数，并将每个参数用空格连接在一起 message = ' '.join(sys.argv[1:]) or \"Hello World!\" # 发布消息 channel.basic_publish(exchange='', routing_key='hello', body=message) print(\" [x] Sent %r\" % message) connection.close() 我们继续来实现一个任务处理端的代码worker.py： #!/usr/bin/env python # -*- coding: UTF-8 -*- import time import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.queue_declare(queue='hello') def callback(ch, method, properties, body): print(\" [x] Received %r\" % body) # 每个小数点表示1s time.sleep(body.count(b'.')) print(\" [x] Done\") channel.basic_consume(callback, queue='hello', no_ack=True) print(' [*] Waiting for messages. To exit press CTRL+C') channel.start_consuming() 使用任务队列的优点是可以对任务进行并行调度。也就是说我们可以启动多个Worker实例来共同完成任务。 下面，我们首先启动2个Worker的实例： # shell 1 python worker.py # => [*] Waiting for messages. To exit press CTRL+C # shell 2 python worker.py # => [*] Waiting for messages. To exit press CTRL+C 在Worker已经启动后，我们可以启动消息生成者来创建一些消息任务了： python new_task.py First message. python new_task.py Second message.. python new_task.py Third message... python new_task.py Fourth message.... python new_task.py Fifth message..... 此时，我们可以查看一下其他两个终端，从来看一下任务分配情况： 终端1: 终端2: 很明显，任务1,3,5分配给了第一个Worker处理，而任务2,4分配给了第二个Worker处理。 这种调度方法我们称之为循环调度，即依次将任务分配给每个Worker并循环进行任务分配。 消息确认 每个Worker完成一个任务可能需要几秒钟的时间。 在这个过程中，我们希望知道任务是成功完成了还是在任务执行的过程中由于一些原因导致任务未完成。 按照目前的实现方式，一旦RabbitMQ将消息传递给Worker，它将会立即将该任务删除。 在这种情况下，如果你终止了一个Worker进程，那么，它正在处理的消息以及已经分配至该Worker的任务都将会丢失。 但实际应用中，我们不希望消息丢失，即一旦某个节点挂掉，我们希望将任务交付给另一个节点进行处理。 为了确保消息永不丢失，RabbitMQ本身支持消息确认功能。即Worker发回ack（请求）告诉RabbitMQ已经收到并处理了该消息，此时，RabbitMQ才会删除该消息。 如果Worker挂掉（其通道关闭，连接关闭或TCP连接丢失），RabbitMQ将理解消息未被完全处理，并将重新进行任务分配。 如果有其他Worker同时在线，它会迅速将其重新发送给其他的Worker。 这样，即使有Worker节点挂点，也可以确保没有任何信息丢失。 消息确认功能默认是启用的。在之前的例子中，我们通过设置no_ack = True标志明确地将消息确认功能禁用。否则，只有当我们真正完成某个任务后，才会通知消息中心删除该消息。 消息确认的功能实现如下： def callback(ch, method, properties, body): print \" [x] Received %r\" % (body,) time.sleep( body.count('.') ) print \" [x] Done\" # 消息确认 ch.basic_ack(delivery_tag = method.delivery_tag) channel.basic_consume(callback, queue='hello') 此时，我们可以实验一下，当任务正在处理中时，我们直接杀死该Worker，会发现任务会重新发送给其他Worker。 消息持久化 我们已经知道如何确保即使Worker死亡，任务也不会丢失。 但是如果RabbitMQ服务器挂掉，我们的任务仍然会丢失。 默认情况下，当RabbitMQ退出或崩溃时，它会丢失队列和消息。 需要做两件事来确保消息不会丢失：我们需要将队列和消息进行持久化。 解决方案如下，在声明队列时将其设置为持久的： channel.queue_declare(queue='hello', durable=True) Ps：需要说明的是，由于我们之前已经声明过hello这个队列了，因此重复声明是无效的，也不会修改其持久性，因此，我们需要声明一个其他名称的队列，例如： channel.queue_declare(queue='test_durable', durable=True) 我们需要在消息产生者和消息处理者中都对该队列进行声明。 上面的部分是可以将队列进行持久化，此外，我们还需要对消息进行持久化，持久化的方式如下： channel.basic_publish(exchange='', routing_key=\"task_queue\", body=message, properties=pika.BasicProperties( delivery_mode = 2, # make message persistent )) 其中，delivery_mode = 2表示对消息进行持久化。 均匀调度 在之前的循环调度中，可能会有一些缺点。 例如，当我们存在两个节点时，如果所有奇数的任务耗时都很长，而所有偶数的任务耗时都很短，此时，就会导致一个节点始终会有任务堆积，而另一个节点则总是处于空闲的状态。 为了解决这种问题，RabbitMQ还支持了另外一种调度方法，即均匀调度。 我们可以使用basic.qos函数和prefetch_count = 1的参数设置来告诉RabbitMQ一次不要向一个Worker发送多个消息。 即只有当每个Worker确认当前任务已经处理完成后，才会将下一个任务发送给它。 总结一下，完整的实现代码如下： new_task.py: #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.queue_declare(queue='task_queue', durable=True) message = ' '.join(sys.argv[1:]) or \"Hello World!\" channel.basic_publish(exchange='', routing_key='task_queue', body=message, properties=pika.BasicProperties( delivery_mode = 2, # make message persistent )) print(\" [x] Sent %r\" % message) connection.close() worker.py: #!/usr/bin/env python import pika import time connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.queue_declare(queue='task_queue', durable=True) print(' [*] Waiting for messages. To exit press CTRL+C') def callback(ch, method, properties, body): print(\" [x] Received %r\" % body) time.sleep(body.count(b'.')) print(\" [x] Done\") ch.basic_ack(delivery_tag = method.delivery_tag) channel.basic_qos(prefetch_count=1) # 同时接收消息的数量 channel.basic_consume(callback, queue='task_queue') channel.start_consuming() By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/publish_subscribe.html":{"url":"middleware/rabbitmq/publish_subscribe.html","title":"RabbitMQ的Fanout类型的Exchange（发布订阅模式）","keywords":"","body":"RabbitMQ的Fanout类型的Exchange（发布订阅模式） 在之前的内容中，我们学习了RabbitMQ的介绍、安装和以工作队列的形式发布和接收消息。 在本文中，我们将会讲解另一种RabbitMQ消息传递模式。 即将同一条消息传递给多个接收者。这种模式也称之为发布、订阅模式。 场景描述 在本文中，我们将会实现一个日志处理系统。 该系统包含两个部分： 第一部分是产生日志。 第二部分是接收日志并打印日志。 在运行的过程中，我们会启动多个接收日志并打印日志的服务。 我们希望可以看到每个服务都接收到全部的日志信息。也就是说，服务1产生的日志最终会广播至所有的接收者。 Exchanges 在之前的文章中，我们讲解了一个RabbitMQ模型由以下几个部分组成： 消息生产者：产生消息的来源。 队列：存储尚未处理的消息。 消息处理者：接收消息并处理。 实际上，这个模型仅仅是一个简化版的RabbitMQ模型。 对于真实的RabbitMQ模型而言，消息生产者是不会直接将消息传入队列中的。相反，消息生产者会把消息发送给Exchanges（中转所），而Exchanges（中转所）在接收到消息后，才会把消息插入到队列中。 在Exchanges（中转所）中，实现的功能包括： 该消息是否需要插入某个队列中。 该消息仅需要发送至一个队列还是需要发送至多个队列。 该消息是否根据某些Exchanges（中转所）的类型需要被忽略等等。 Exchanges包含如下几个类型：direct, topic, headers以及fanout。 在本文中，我们首先来学习fanout类型。 fanout的含义是将每条消息都广播发送给所有的消息接收者。 例如，可以实现如下： channel.exchange_declare(exchange='logs', exchange_type='fanout') 即声明exchange的类型为fanout，且名称为logs。 在声明了exchange后，我们可以继续发布消息： channel.basic_publish(exchange='logs', routing_key='', body=message) 临时队列 在之前的文章中，我们需要指定一个特定的队列名称，因为我们需要将一组Worker用于接收某个指定的队列名称中的消息。 但是，对于发布、订阅模式场景而言，我们需要的是： 接收全部的消息，而不是其中的一部分消息。 只接收最新产生的消息，而忽略之前传入的消息。 因此，我们需要完成以下两个部分的工作： Step1: 每次在连接到RabbitMQ时，创建一个空的队列。实现该功能的方式是我们可以创建一个随机名称的队列。 result = channel.queue_declare() Ps: 在不指定参数时，默认将会产生一个随机字符串组成的队列。 Step2: 此外，我们需要在创建队列时添加一个额外的参数： result = channel.queue_declare(exclusive=True) Ps: exclusive=True表示当消息接收者断开连接时，自动删除该队列。 将 Exchange 与 Queue 进行关联 目前，我们已经创建了一个fanout类型的exchange。同时，在消息接收者中也创建了队列。 现在，我们需要做的是将exchange和消息队列关联起来。 channel.queue_bind(exchange='logs', queue=result.method.queue) 完整实现 最后，我们来给出消息生产者和消息接收者的完整实现： 消息生产者：emit_log.py #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='logs', exchange_type='fanout') message = ' '.join(sys.argv[1:]) or \"info: Hello World!\" channel.basic_publish(exchange='logs', routing_key='', body=message) print(\" [x] Sent %r\" % message) connection.close() 消息接收者：receive_logs.py #!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='logs', exchange_type='fanout') result = channel.queue_declare(exclusive=True) queue_name = result.method.queue channel.queue_bind(exchange='logs', queue=queue_name) print(' [*] Waiting for logs. To exit press CTRL+C') def callback(ch, method, properties, body): print(\" [x] %r\" % body) channel.basic_consume(callback, queue=queue_name, no_ack=True) channel.start_consuming() 实际来看一下效果吧： 我们可以先启动两个消息接收者： receiver1: python receive_logs.py receiver2: python receive_logs.py 然后，我们来发送几条消息： python emit_log.py python emit_log.py 怎么样？是不是每条消息都被两个消息接收者同时接收到了？~ By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/direct_mode.html":{"url":"middleware/rabbitmq/direct_mode.html","title":"RabbitMQ的Direct类型的Exchange（选择性订阅）","keywords":"","body":"RabbitMQ的Direct类型的Exchange（选择性订阅） 在之前的文章中，我们实现了一个简单的日志系统。 该日志系统在接收到一条日志消息后，可以将其分发给所有的消息接收者。 在本文中，我们将对该功能进行拓展，从而实现仅订阅其中的一部分消息。 例如，我们只能将重要的错误消息引导到日志文件（以节省磁盘空间），同时仍然能够在控制台上打印所有日志消息。 关联 回想一下，在之前的文章中，我们将exchange与队列通过如下方式进行关联： channel.queue_bind(exchange=exchange_name, queue=queue_name) 这种关联表示了该队列关注于这个exchange中的消息。 而在创建关联时，实际上我们还可以添加一个参数：routing_key。 例如： channel.queue_bind(exchange=exchange_name, queue=queue_name, routing_key='black') routing_key 的功能与 exchange 的类型有关，在我们之前使用的fanout类型的exchange中，routing_key是一个无用的参数。 Direct类型的exchange 之前我们仅仅学习了fanout类型的exchange。 接下来，我们将要学习的是direct类型的exchange。 direct类型的exchange的功能如下：根据routing_key进行完全匹配，将消息发送给所有routing_key匹配的通道中。 在上图所示的模型中，使用了direct类型的exchange，并包含了两个通道。 在通道1中，会接收所有routing_key='orange'的消息，而在通过2中，会接收所有routing_key='black'或者'green'的消息。而其他所有消息将会被忽略。 多绑定 当然，将某种类型的数据绑定给多个通过也是没问题的，例如下图所示： 当接收到routing_key='black'的消息时，将会同时传递给通道1和通道2。 具体实现 最后，我们来完成之前描述的功能，即实现一个日志管理系统，将重要的错误消息引导到日志文件（以节省磁盘空间），同时仍然能够在控制台上打印所有日志消息。 消息生产端 emit_log_direct.py 文件如下： #!/usr/bin/env python # -*- coding: UTF-8 -*- import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='direct_logs', exchange_type='direct') # 命令行中第一个参数表示severity，默认为info severity = sys.argv[1] if len(sys.argv) > 2 else 'info' # 命令行中第二个即以后的参数拼接表示message，默认为'Hello World!' message = ' '.join(sys.argv[2:]) or 'Hello World!' # 发送消息中添加routing_key channel.basic_publish(exchange='direct_logs', routing_key=severity, body=message) print(\" [x] Sent %r:%r\" % (severity, message)) connection.close() 消息处理端 receive_logs_direct.py 文件如下： #!/usr/bin/env python # -*- coding: UTF-8 -*- import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='direct_logs', exchange_type='direct') result = channel.queue_declare(exclusive=True) queue_name = result.method.queue # 接收参数作为severities severities = sys.argv[1:] if not severities: sys.stderr.write(\"Usage: %s [info] [warning] [error]\\n\" % sys.argv[0]) sys.exit(1) for severity in severities: # 一个通道中接收多个routing_key channel.queue_bind(exchange='direct_logs', queue=queue_name, routing_key=severity) print(' [*] Waiting for logs. To exit press CTRL+C') def callback(ch, method, properties, body): print(\" [x] %r:%r\" % (method.routing_key, body)) channel.basic_consume(callback, queue=queue_name, no_ack=True) channel.start_consuming() 下面，我们来启动服务验证一下效果吧！ 启动消息接收服务1： # 接收info warning error级别的日志并打印在屏幕上 python receive_logs_direct.py info warning error 启动消息接收服务2: # 接收error级别的日志并写入logs_from_rabbit.log文件 python receive_logs_direct.py error > logs_from_rabbit.log 发送一些消息看看吧： python emit_log_direct.py error \"Run. Run. Or it will explode.\" python emit_log_direct.py debug \"Run. Run. Or it will explode.\" python emit_log_direct.py info \"Run. Run. Or it will explode.\" python emit_log_direct.py warning \"Run. Run. Or it will explode.\" 怎么样？结果是否符合预期呢？欢迎大家一起讨论。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/topic_mode.html":{"url":"middleware/rabbitmq/topic_mode.html","title":"RabbitMQ的Topic类型的Exchange（高级选择性订阅）","keywords":"","body":"RabbitMQ的Topic类型的Exchange（多维度订阅） 在之前的文章中，我们分别学习了fanout和direct类型的Exchange。 相比fanout类型，direct类型已经支持我们部分有选择性的接收消息。 然而，在实际应用中，direct类型有时仍然无法支持我们的需求，本文将会继续讲解topic类型的Exchange。 场景描述 direct类型的Exchange可以根据某个维度进行有选择性的分发。 例如在之前的例子中，节点可以根据日志级别进行有选择的接收消息。 然而，在面对更复杂的需求时，将会显得无能为力。 例如: 日志来源来源于服务1和服务2两个服务。我们希望节点1接收所有服务的error级别的日志，而希望节点2接收服务2的所有级别的日志。 即direct类型的Exchange只能解决单维度选择的问题，无法解决多维度消息分发的问题。 为了解决上述描述的场景，我们需要使用topic类型的Exchange。 topic类型的Exchange 对于发送向topic类型的Exchange的消息而言，routing_key有着严格的格式研究：它必须是由点分隔的一组单词，例如service1.info。 这些有点分割的单词都表示某种含义，例如service1.info可以表示服务1的info级别的日志。 Ps: routing_key可以由任意的单词组成。 在绑定消息和通道时，也是有着类似的规则，区别在于绑定消息和通道可以使用一些有特殊含义的符号进行代替： *可以表示任意一个单词。 #可以表示任意0个至多个单词。 因此，在绑定通道时，可以使用*和#进行通配。 以上图为例： 消息中的routing_key由三个单词组成，分别表示动物的习性、颜色以及物种。 我们在Exchange和队列中绑定了三个部分： 将所有橙色的动物消息发送至队列1 将所有兔子信息发送至队列2 将所有懒惰的动物信息发送至队列3 完整实现 最后，我们来学习一下它的具体实现吧： 消息发送端：emit_log_topic.py: #!/usr/bin/env python # -*- coding: UTF-8 -*- import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='topic_logs', exchange_type='topic') # 第一个参数表示routing_key，即有.分割的一组词 routing_key = sys.argv[1] if len(sys.argv) > 2 else 'anonymous.info' # 第二个及后续的参数表示发送的消息 message = ' '.join(sys.argv[2:]) or 'Hello World!' channel.basic_publish(exchange='topic_logs', routing_key=routing_key, body=message) print(\" [x] Sent %r:%r\" % (routing_key, message)) connection.close() 消息接收端: receive_logs_topic.py: #!/usr/bin/env python # -*- coding: UTF-8 -*- import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='topic_logs', exchange_type='topic') result = channel.queue_declare(exclusive=True) queue_name = result.method.queue binding_keys = sys.argv[1:] if not binding_keys: sys.stderr.write(\"Usage: %s [binding_key]...\\n\" % sys.argv[0]) sys.exit(1) # 接收多个参数 # 每个参数表示一组bind，且参数为routing_key for binding_key in binding_keys: channel.queue_bind(exchange='topic_logs', queue=queue_name, routing_key=binding_key) print(' [*] Waiting for logs. To exit press CTRL+C') def callback(ch, method, properties, body): print(\" [x] %r:%r\" % (method.routing_key, body)) channel.basic_consume(callback, queue=queue_name, no_ack=True) channel.start_consuming() 测试 测试一下吧： 首先启动节点1接收所有服务的error级别的日志： python receive_logs_topic.py \"*.error\" 接着启动节点2接收服务2的所有级别的日志： python receive_logs_topic.py \"service2.*\" 下面，我们来发送一些消息： python emit_log_topic.py \"service1.error\" \"message1\" python emit_log_topic.py \"service2.error\" \"message2\" python emit_log_topic.py \"service2.info\" \"message3\" 怎么样？是否符合预期呢？ By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/rabbitmq/rpc.html":{"url":"middleware/rabbitmq/rpc.html","title":"利用RabbitMQ实现远程服务调用","keywords":"","body":"利用RabbitMQ实现远程服务调用 在之前的文章中，我们讲解了多种方式进行消息分发（任务分配）。 在本文中，我们将会讲解如何利用RabbitMQ来实现远程服务调用。 什么是远程服务调用 在之前的文章中，我们讲解了多种方式进行消息分发（任务分配）。 那么远程服务调用与消息分发有什么区别呢？ 以上图为例，在远程服务调用中，客户端发送一条消息到服务端，服务端处理完成后，会把结果再返回给客户端。 而对于消息分发而言，则只是存在第一步，即将消息分发给节点处理，但是不需要接收节点返回的结果。 在本文中，我们将会实例来实现一个基于RabbitMQ的远程服务调用。客户端可以输入一个数字到服务端，服务端会计算它的Fibonacci结果并返回客户端。 如何实现远程服务调用 简单来说，远程服务调用的功能就是客户端发送一条消息至服务端，服务端处理完成后，再发送一条消息到客户端。 为了能够让服务端处理完成后将消息发回给客户端，在客户端发送消息时，需要指明回调接收消息的队列，示例如下： result = channel.queue_declare(exclusive=True) callback_queue = result.method.queue channel.basic_publish( exchange='', routing_key='rpc_queue', properties=pika.BasicProperties( reply_to = callback_queue, ), body=request ) Ps：在发送消息时，我们设置了一个参数properties。该参数表示了消息的相关属性，可选属性包括： 属性 功能说明 delivery_mode 传输模式，例如2表示持久保存。 content_type 传输类型，例如application/json reply_to 指定接收回调的队列。 correlation_id 用于将远程调用的响应与请求关联起来。 下面，我们来详细说明correlation_id是如何将远程调用的响应与请求关联起来的。 在上面介绍的方法中，我们如果为每个远程调用请求创建一个回调队列，那这实际上是非常低效的。 一个推荐的方式是为每个客户端创建一个回调队列。 但是这引发了一个新问题，在该队列中收到回复后，不清楚回复属于具体哪个请求。 为了解决这个问题，我们使用correlation_id属性。 我们将把它设置为每个请求对应的一个唯一值。当我们在回调队列中收到消息时，我们会查看此属性，并基于此属性，我们将能够将响应与请求进行匹配。 如果我们看到一个未知的correlation_id值，我们客户忽略该消息，因为该消息并不属于我们请求的信息。 总结一下，整理的流程如下： 当客户端启动时，它创建一个匿名队列用于接收回调消息。 对于RPC请求，客户端将发送具有两个属性的消息：reply_to和correlation_id，其中reply_to表示该消息的回调队列、correlation_id为每个请求的唯一值。 该请求被发送到服务端接收队列。 RPC worker（Server）获取队列中的请求。当队列中存在请求时，它执行该任务，并根据reply_to字段将消息返回给指定队列。 客户端在回调队列中等待数据。当出现消息时，它会检查correlation_id属性。如果它匹配自己之前发出请求的correlation_id值，则返回对应用程序的响应。 具体实现 服务端：rpc_server.py： #!/usr/bin/env python # -*- coding: UTF-8 -*- import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) # 初始化服务端消息接收队列 channel = connection.channel() channel.queue_declare(queue='rpc_queue') def fib(n): # 定义fib实现 if n == 0: return 0 elif n == 1: return 1 else: return fib(n-1) + fib(n-2) # 接收到消息的处理函数 def on_request(ch, method, props, body): n = int(body) print(\" [.] fib(%s)\" % n) # 调用函数进行计算 response = fib(n) # 将计算得到的结果发送回客户端队列 ch.basic_publish( exchange='', routing_key=props.reply_to, properties=pika.BasicProperties(correlation_id = props.correlation_id), body=str(response) ) ch.basic_ack(delivery_tag = method.delivery_tag) # 设置最多仅同时处理1条消息 channel.basic_qos(prefetch_count=1) channel.basic_consume(on_request, queue='rpc_queue') print(\" [x] Awaiting RPC requests\") # 启动服务 channel.start_consuming() 客户端：rpc_client.py: #!/usr/bin/env python # -*- coding: UTF-8 -*- import pika import uuid class FibonacciRpcClient(object): # RPC请求客户端类 def __init__(self): # 初始化过程 self.connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) # 创建一个队列 self.channel = self.connection.channel() result = self.channel.queue_declare(exclusive=True) self.callback_queue = result.method.queue # 针对每个响应执行的'on_response'回调函数，判断是否为自己的消息的回复消息 self.channel.basic_consume(self.on_response, no_ack=True, queue=self.callback_queue) def on_response(self, ch, method, props, body): # 当correlation_id属性匹配自己之前发出请求的correlation_id值，记录响应值 if self.corr_id == props.correlation_id: self.response = body def call(self, n): # 向服务端发起一个调用 self.response = None # 随机初始化一个corr_id self.corr_id = str(uuid.uuid4()) # 向服务端队列发送一条消息 self.channel.basic_publish( exchange='', routing_key='rpc_queue', properties=pika.BasicProperties( reply_to = self.callback_queue, correlation_id = self.corr_id, ), body=str(n) ) # 循环等待接收到response while self.response is None: self.connection.process_data_events() return int(self.response) # 实例化FibonacciRpcClient fibonacci_rpc = FibonacciRpcClient() print(\" [x] Requesting fib(30)\") # 发送数字30至服务端 response = fibonacci_rpc.call(30) # 接收到服务端响应后打印出来 print(\" [.] Got %r\" % response) 测试一下吧~ By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/mqtt/beginning.html":{"url":"middleware/mqtt/beginning.html","title":"MQTT","keywords":"","body":"MQTT快速入门 MQTT是物联网消息传递的事实标准。 具体来说，MQTT是用于物联网（IoT）的OASIS标准消息传递协议。 它被设计为一种非常轻量级的发布/订阅消息传送，非常适合以较小的代码占用量和最小的网络带宽连接远程设备。 如今，MQTT被广泛用于汽车，制造业，电信，石油和天然气等行业。 MQTT的优点 轻量级且高效 MQTT的客户端非常小，需要的资源也非常小，因此可以在小微型嵌入式设备中使用。 同时，MQTT消息头也很小，从而可以大幅度的节省网络带宽。 支持双向通讯 MQTT允许设备到云之间以及云到设备之间的消息传递，这使得我们可以轻易的将消息广播到一组设备中。 支持横向扩容至数百万设备接入 MQTT可以轻松的扩展，从而能够支持数百万个IoT设备的连接。 高可靠的消息传递机制 对于许多物联网用例而言，消息传递的可靠性至关重要。 因此，MQTT具有3种定义的服务质量级别的原因：0-最多一次，1-至少一次，2-恰好一次。 在网络环境较差时也能获得较好的支持 许多物联网设备通过不可靠的蜂窝网络进行连接。 MQTT对持久会话的支持减少了将客户端与代理重新连接的时间，从而，即使在网络环境不佳的情况下，MQTT同样能够获得较好的表现。 内置安全保护机制 MQTT使您可以轻松地使用TLS加密消息。 同时，MQTT也使用了现代身份验证协议（例如OAuth）对客户端进行身份验证。 MQTT的发布订阅架构 MQTT的发布订阅架构如下图所示： By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/mqtt/install.html":{"url":"middleware/mqtt/install.html","title":"MQTT的安装","keywords":"","body":"MQTT的安装（Mosquitto） 首先，需要声明一点的是MQTT本身是一个通用的协议。 具体实现了MQTT协议的Broker软件非常多，例如我们经常听到的RabbitMQ，ActiveMQ等，其实都是可以通过插件等实现支持MQTT协议的。 而在本文中，我们主要介绍的是一块在MQTT协议中非常流行的开源MQTT Broker软件: mosquitto 。 mosquitto 简介 Mosquitto是一款开源软件（经EPL / EDL许可），它实现了MQTT协议版本5.0、3.1.1和3.1的消息代理。 Mosquitto非常轻巧，适合在从低功耗的嵌入式计算板到服务器的不同的设备上使用。 Mosquitto项目还提供了一个C库，用于实现MQTT客户端。同时，它还提供了非常流行的mosquitto_pub和mosquitto_sub命令行MQTT客户端。 下载与安装 Mosquitto提供了不同平台的安装方式： Mac: brew install mosquitto brew services start mosquitto 其中，配置文件位于/usr/local/etc/mosquitto/mosquitto.conf。 Ubuntu: sudo apt-add-repository ppa:mosquitto-dev/mosquitto-ppa sudo apt-get update sudo apt-get install mosquitto # 安装broker sudo apt-get install mosquitto-clients # 安装相关的二进制命令行客户端 Raspberry Pi: sudo apt install mosquitto mosquitto-clients sudo systemctl enable mosquitto sudo systemctl status mosquitto demo实战 Step1: 首先，我们需要先打开一个终端，创建一个消息订阅者接收消息： mosquitto_sub -h localhost -t \"test/message\" 此时，该命令将会同步阻塞在此处，等待test/message Topic中接收到的消息。 Step2：下面，我们需要新打开一个终端，并像该Topic中发送一条hello world的消息。 mosquitto_pub -h localhost -t \"test/message\" -m \"Hello, world\" 输入完成后，你回到mosquitto_sub的命令行终端，是不是已经收到的对应的消息了呢。 通过上述验证，我们可以看到我们的mosquitto broker已经能够正常的工作了。 rtsp://192.168.18.139/SampleVideo_1280x720_20mb.ts By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/beginning.html":{"url":"middleware/nginx/beginning.html","title":"nginx","keywords":"","body":"什么是Nginx Nginx是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。 Nginx 可以在大多数 UnixLinux OS 上编译运行，并有 Windows 移植版。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/getting_to_know.html":{"url":"middleware/nginx/getting_to_know.html","title":"初识Nginx","keywords":"","body":"初识Nginx Nginx 使用场景 首先，我们来看一下 Nginx 是什么？它主要用来做什么。 Nginx 有三个主要场景，分别是： 静态资源服务: 例如通过本地文件系统提供服务，将本地文件实现远程可访问。 反向代理服务: 得益于Nginx的强大性能，常用语于例如负载均衡，缓存等场景。 API服务: 主要是指通过OpenResty的扩展从而实现API服务，可以作为网关或流量代理。 Nginx 的优点 那么，Nginx 主要有哪些优点呢？大致总结一下，主要体现在： 高并发、高性能。 可扩展，丰富的生态圈。 高可靠性，可以长时间的为稳定运行。 热部署，可以在不停止服务的情况下对Nginx进行升级。 BSD许可，开源、免费、可以自定义修改。 相对来说，Nginx 同时具备了高并发和高性能的特点。 Nginx 的组成 Nginx 的组成非常简单，主要包含如下四个部分： Nginx 版本选择 Nginx 的下载地址如下: https://nginx.org/en/download.html 目前，Nginx 最新的 Mainline 版本是 1.21.0，Stable 稳定版本为 1.20.1。 Ps: 其中，中间版本号为奇数时，为主线开发版本，中间版本号为偶数时，为 Stable 稳定版本。 对于普通用户而言，建议使用Stable版本，而如果想要体验新功能的话，则可以使用mainline版本。 点击CHANGES，可以清楚的看到每个发布版本中的修改内容，包括新功能，Bugfix等以及发布信息。 上图表示了 nginx 近些年来发版、Bugfix、重构、新功能等的变化数量。 NginxPlus Nginx 本身是开源的，不过同时 Nginx 也提供了商业版本。 开源版本Nginx的地址是: nginx.org 商业版本NginxPlus的地址是：nginx.com 那他们有什么区别呢？ 商业版本的NginxPlus在第三方工具整合，使用支持方面有更好的支持，但是缺点是它并不开源，因此，其实我们并不常使用NginxPlus。 Tengine Tengine 是阿里巴巴在 Nginx 的基础上，针对大访问量的需求，添加了很多高级功能和特性。Tengine 在阿里的产品中得到的有效的验证， 同时，Tengine也是一个开源项目，我们也可以参与其中进行开发和共建，但是由于Tengine是基于Nginx历史版本进行改造的，无法始终与Nginx保持版本同步， 因此，Tengine的版本往往落后于Nginx版本很多，因此其实我们也并不推荐。 开源版OpenResty OpenResty 是针对 Nginx 扩展了 Lua 语言开发第三方插件。 通过 Lua 的扩展，OpenResty 可以同时以非常低成本和便捷的方式来开发第三方插件，从而快速的扩展Nginx的功能。 商业版OpenResty 商业版OpenResty相比社区版而言，主要是增加了技术支持，因此，我们其实并不常用商业版的OpenResty。 Nginx 的编译与安装 Nginx 的安装主要可以分为两种方式： yum, apt-get 等包管理工具快速安装。 源码编译安装。 其中，通过yum, apt-get等工具安装时，有一个非常大的问题，就是我们无法设置对应的编译参数，例如开启哪些模块等。 因此，在Nginx安装时，我们通常会使用源码编译的方式进行安装。 使用源码编译、安装Nginx主要分为以下4个步骤： 下载 Nginx 源码 Configure 编译 Nginx 安装 Nginx Step1: 下载所需的 nginx 包，我们以 1.20.1 的 stable 版本为例： wget https://nginx.org/download/nginx-1.20.1.tar.gz tar -zxvf nginx-1.20.1.tar.gz cd nginx-1.20.1 解压后的目录结构如下: 其中： auto目录：包含cc, lib, os, types 等相关目录，用于辅助编译和跟进操作系统进行相关判断。 CHANGES: 显示每个版本的迭代功能特性 conf: 示例配置文件目录 configure: 配置脚本 contrib: 包含 vim 的 nginx 高亮插件等，可以 cp -r contrib/vim/* ~/.vim/ 实现nginx vim页面高亮显示 html: 提供了index.html和50x的html页面 man目录包含了nginx的相关帮助文档 src目录包含nginx的源码 Step2: Configure 设置编译配置 首先，我们来看一下配置脚本支持哪些参数： 其中，一些常用参数如下： prefix 指定了nginx编译后的安装目录。 modules-path 指定了动态引入模块的模块路径。 with-xxx_module 表示启用哪些nginx内置模块。 without-xxx_module 表示禁用哪些nginx内置模块。 with-xxx 表示指定依赖对应的目录，例如pcre, openssl等依赖的目录等。 一个最简单的nginx配置命令如下： ./configure --prefix=/home/wangzhe/nginx 在执行完 configure 命令后，会生成一些中间文件，文件文件位于objs目录下。 其中，最核心的文件是nginx_modules.c文件，它表明了在接下来的编译过程中，有哪些模块需要编译进来。 Step3: 编译 接下来的操作就非常简单了，只需要执行make进行编译即可： make 其中，生成的二进制nginx文件同样位于objs目录下。 Step4: 安装 编译完成后，执行如下命令即可安装: make install Ps: 如果是首次安装，可以直接执行上述命令，但是如果希望做热升级，则不能直接进行make install，后续我们会讲解如何进行热升级。 Nginx 的配置文件语法概述 了解了如何进行 Nginx 安装后，下面我们先来初步了解一下 nginx 的配置文件语法。 nginx 的配置语言语法主要包含如下几点： 配置文件由指令块和指令组成。 每条指令以 ; 分号结尾，指令和参数之间使用空格进行分隔。 指令块以 {} 大括号将多条指令组织在一起。 include 语句允许组合多个配置以提升可维护性。 nginx配置文件中使用 # 进行行注释。 nginx配置文件中使用 $ 来使用变量。 部分指令的参数支持正则表达式。 一个示例如下： nginx 中涉及到时间的配置通常支持如下单位: ms: 毫秒 s: 秒 m: 分钟 h: 小时 d: 天 w: 周 M: 月 y: 年 nginx 中涉及到空间大小的配置通常支持如下单位: 无单位: 字节 k/K: KB m/M: MB g/G: GB nginx 中的指令块主要包含如下4个： http: 内部的所有指令均针对http协议，由http模块进行解析。 server: 对于一个/组域名，表示对外提供的服务。 upstream: 表示上游服务。 location: url表达式。 Nginx 的命令行常用操作 通过 nginx 的命令行，我们可以实现 nginx 管理的全部操作，例如 nginx 的启动、停止、重新加载配置文件、热升级等等一系列操作。 通过nginx -h可以查询nginx命令行的帮助文档。 基本的语法格式如下: nginx [-?hvVtTq] [-s signal] [-p prefix] [-e filename] [-c filename] [-g directives] 其中： -c 指定配置文件。 -g 指定配置指令，即可以在命令行中覆盖配置文件中的指令。 -p 指定运行目录。 -s 用于发送信号，常用的信号包括 stop（立即停止服务），quit（优雅停止服务），reload（重新加载配置文件），reopen（重新开始记录日志文件） -t/T 用于测试配置文件是否语法错误。 -v/V 用于打印版本和编译信息等。 常用的命令如下： 重载配置文件 当 nginx 的配置文件发生修改后，我们需要让 nginx 对配置文件进行重载后，修改后的配置文件才能生效。 ./sbin/nginx -s reload 热部署 热部署是指当前 nginx 已经处于生产环境中正在运行了，此时，我们下载了一个新的nginx，希望对nginx进行无损升级。 Step1: 替换 nginx 二进制文件 mv nginx nginx.old cp nginx_new nginx Step2: 发送热部署信号给Nginx Master kill -USR2 ${nginx master pid} Step3: 此时， nginx 会启动一个新的 Nginx Master 进行，并自动实现无损流量切换。 Step4: 发送优雅退出信号给旧的Nginx Master，让旧的Nginx Worker进程优雅退出。 kill -WINCH ${nginx master pid} Step5: 当确认升级没有问题后，可以再次kill掉旧的Nginx Master进程。 日志切割 通过nginx命令行，我们还可以实现Nginx日志的文件切割，避免单个文件过大。 # 第一步: 备份已经打印的nginx日志 mv logs/access.log logs/access.log.bk # 第二步: 发送命令让nginx重新打印日志 ./sbin/nginx -s reopen By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/install.html":{"url":"middleware/nginx/install.html","title":"nginx的安装","keywords":"","body":"Nginx的安装 本文中，我们将会讲解Nginx在各种平台下的安装方式。 Linux下安装Nginx 首先，第一步需要从官网下载nginx安装包：http://nginx.org/en/download.html 。 目前的稳定版本是1.18。 接下来， 我们首先需要解压安装包： mkdir ./Ngnix cp ~/nginx-1.18.1.tar.gz ./Ngnix cd ./Ngnix tar -zxvf nginx-1.18.1.tar.gz cd ./nginx-1.18.1 此时，解压缩得到nginx目录结构如下： 下一步是需要利用configure文件安装Nginx: mkdir -p /home/zhiyun/nginx ./configure --prefix=/home/zhiyun/nginx \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_addition_module \\ --with-http_sub_module \\ --with-http_dav_module \\ --with-http_flv_module \\ --with-http_mp4_module \\ --with-http_gunzip_module \\ --with-http_gzip_static_module \\ --with-http_random_index_module \\ --with-http_secure_link_module \\ --with-http_stub_status_module \\ --with-http_auth_request_module \\ --with-threads \\ --with-stream \\ --with-stream_ssl_module \\ --with-http_slice_module \\ --with-file-aio \\ --with-http_v2_module 其中，--prefix用于指定Nginx的安装路径。 在安装过程中可能会提示缺少PCRE库，此时需要执行如下命令进行安装： apt-get install libpcre3 libpcre3-dev openssl libssl-dev zlib1g zlib1g-dev 执行该命令后，可以看到命令行会有一系列的检查和安装日志，结束后会产生一个Makefile文件。 make make install 安装完成后，切换到/home/zhiyun/nginx目录下，当前的目录结构如下： 其中，sbin文件夹下只有一个nginx的文件，即为Nginx服务器的主程序。 执行如下命令可以直接启动nginx: ./sbin/ngnix 启动成功后，访问localhost，可以看到如下页面： 最后，为了能够高亮 vim 编辑器，我们可以将 Nginx 提供的配置拷贝到对应的目录下: cp -R ${NGINX_HOME}/contrib/vim ~/.vim By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/quick_start.html":{"url":"middleware/nginx/quick_start.html","title":"nginx的快速上手","keywords":"","body":"nginx的快速上手 在之前的文章中，我们已经讲解了一些 nginx 的基本概念并且安装了 nginx 的基础环境。 接下来，我们本文中，我们将会带着大家使用nginx完成一些基础的功能，简单的把nginx使用起来。 使用nginx搭建一个静态资源WEB服务器 基本服务启动 假设，我们在本机的 /home/wangzhe/nginx/books/ 目录下存在了一系列的静态资源，如index.html文件，jpg文件等。 下面，我们来看一下如何配置nginx，使得可以创建一个静态资源的WEB服务器。 首先，WEB服务器首先是属于http块内部的。 下面，我们来看一下http下的server块内容应该如何编写： 我们来解读一下上述配置文件： 首先，我们监听的端口设置为8080. 接下来，我们定义了一个 location 块，直接监听了所有访问 / 根目录的请求，同时，对于所有访问 / 根目录的请求，会将根目录转化为本地 books/ 目录下的文件，并对后缀进行匹配。 下面，我们来启动nginx看一下。 赞~现在我们的页面已经可以正常打开了。 gzip 压缩 打开network选项卡后，你可以发现我们发送请求查询静态资源时，得到的文件大小与真实的文件大小是一致的。 那么，我们有没有什么办法可以对传输的文件进行压缩呢？从而可以有效的节省我们的网络带宽。 对，是有的，就是 gzip 压缩。 下面，我们来继续修改 nginx 配置文件： 可以看到，我们在 http 块中加入了一些 gzip 相关的指令： 开启gzip压缩。 设置启用gzip压缩的最小文件大小为1字节。 gzip的压缩级别为2。 同时也指定了哪些数据传输类型需要进行gzip压缩。 完成上述配置后，我们重新加载一下nginx的配置来看一下效果，可以看到，我们对于同一个文件，从之前的80多k降低到了13k。 autoindex 下面，我们来看一下如果我们希望将本地的目录结构对外暴露到WEB服务中，使得用的可以根据需要自主选择文件进行进行查询和下载。 在 nginx 中提供了一个 autoindex 的模块，参见文档 。 autoindex 的模块可以在我们访问 / 结尾的url时，可以显示该目录的结构信息。 使用方式也非常简单，只需要在 location 块中增加 autoindex on; 指令即可。 接下来，我们再次访问一个 books/ 目录下包含的一个目录，例如service/。 此时，我们就可以看到该目录下对应的目录结构了。用户也可以自己根据目录进行嵌套查询相关的内容。 请求限速 有时，当我们的nginx WEB服务器会被很多用户访问时，为了避免个别请求打满整个带宽，导致其他用户无法正常访问的情况出现，我们可能会需要对单个请求的访问速率进行限制。 此时，需要用到 set 命令配置一些特殊变量来实现相关的功能。 在上述命令中，我们设置了 limit_rate 变量的值为 5k，表示单个请求的最大下载速率为 5k/s。 关于 limit_rate 的文档，可以参考文档 。 规范日志打印格式 下面，我们来看一下如何设置nginx的日志打印格式。 我们在 http 块中通过 log_format 指令来定义了一个 main 名称的 access log 的日志打印格式。 可以看到，我们在日志格式中，引用了大量的nginx内置的特殊变量，例如remote_addr等。 接下来，我们在server块中通过access_log指定设置了对于该server块的access_log存储的位置以及使用的日志打印格式。 使用nginx搭建一个具备缓存的反向代理服务 启动一个反向代理服务器 除了搭建静态资源WEB服务器之外，Nginx 最常用的一个场景应该就是通过反向代理来实现负载均衡了。 在真实的业务场景中，业务服务由于存在着相对复杂的业务逻辑，单实例的QPS往往无法满足业务的需求，这时，我们就需要部署多个实例来分担用户请求。 同时，我们还希望可以提供给用户一个统一的请求入口，而不是每个实例单独提供入口，因此，这时，我们就需要一个反向代理服务器来进行流量的接入了。 下面，我们进行一个简单的示例演示。 我们还是使用上一部分中通过nginx搭建的静态资源服务器来作为业务服务器（上游服务），然后再通过nginx启动另外一个Server用于反向代理。 通常，上游服务器是禁止公网直接访问的，因此，我们可以修改一下之前nginx的配置，将server监听的端口从8080修改为127.0.0.1:8080，即表示该端口仅允许本机访问。 此时，为了使得配置生效，需要先将nginx停止再启动才能生效: ./sbin/nginx -s stop ./sbin/nginx 再次访问时，就会发现服务已经无法正常访问了。 下面，我们来修改配置文件，增加反向代理server： 在反向代理服务器的配置中，我们首先先设置了一个 upstream 块。 upstream 块其实就是用于包含上游业务服务器的地址，此处，我们指向了刚才的静态资源WEB服务器的地址。如果有多个上游服务器实例时，只需要在 upstream 块中包含多个server记录即可。 接下来，我们定义了反向代理服务器 Server 的配置。 首先，该反向代理服务器监听的是 8092 的端口，同时将所有访问 / 目录的请求都转发给了刚才定义的 upstream 上游服务器。 此外，在这个 location 中，我们还定义了一些 set_header 的操作，即将原始访问的一些地址信息，请求信息等添加至header中并转发给上游服务。 相关的文档可以参考 文档 。 增加缓存 对于每一个请求，都通过反向代理访问业务服务器无疑是相对低效率的，那么对于一些请求响应相对固定的请求来说， 我们是否可以直接在反向代理中增加一些缓存，从而在面对相同的请求时，无需再次访问上游服务器，而是直接从缓存中读取内容并返回。 下面，我们来看一下如何和反向代理中，实现缓存的功能： 其中： proxy_cache_path: http块中，设置了缓存文件的存储位置，共享内存的大小和名称，最大缓存大小等。 proxy_cache: location块中，设置需要使用哪个共享内存。 proxy_cache_key: location块中，设置哪些条件匹配时可以使用cache。 proxy_cache_valid: location块中，设置哪些状态码下可以使用cache以及cache生效的时间。 下面，可以简单做一个试验，修改配置文件后，对nginx重新加载配置。 然后访问nginx反向代理服务器，预期可以正常访问。接下来，删除books/index.html文件，即原始静态资源服务器的文件会丢失，静态资源服务器直接访问的话预期会异常。 但是，我们再次访问nginx反向代理服务器，可以发现，嗯...竟然仍然可以正常访问，看来的确是缓存生效了。 用GoAccess实现可视化并实时监控access日志 在 nginx 中，access log 对我们而言是非常重要的，我们可以从 access log 中分析有哪些访问用户，访问请求量有多大等等。 但是 access log 毕竟是以文本的方式在 nginx 机器上存放，不利于我们快速的进行分析，此处，我们将会介绍一款工具，GoAccess。 它可以以可视化的方式，帮助我们来进行实时可视化的access log的数据分析。 GoAccess 的官方介绍网站如下: https://goaccess.io/get-started GoAccess 的安装 GoAccess 的安装相对简单，可以直接使用如下命令进行源码编译和安装: wget https://tar.goaccess.io/goaccess-1.5.1.tar.gz tar -xzvf goaccess-1.5.1.tar.gz cd goaccess-1.5.1/ apt-get install gettext autoconf gcc autopoint libmaxminddb-dev libncursesw5-dev ./configure --enable-utf8 --enable-geoip=mmdb make make install GoAccess 的启动 GoAccess 安装完成后，启动就非常简单了。示例命令如下： goaccess ./logs/access.log -o ./html/report.html --real-time-html --log-format=COMBINED --port 8890 上述命令表示： 监听的是 logs/access.log 文件。 输出结果写入到 html/report.html 文件中。 实时access log，并更新html文件。 access log的日志格式为默认是的日志格式。 设置 goaccess WebSocket 的端口为8890，保证浏览器可以正常访问端口，从而实现数据的实时更新。 下面，我们可以查看html/report.html文件，发现的确已经有了这一文件。 GoAccess 效果观察 那么，我们应该如何从浏览器访问该 HTML 页面呢？详细通过上面的学习你已经很快能想到了！ 对，就是再添加一个静态资源的WEB Location配置即可。 修改 Nginx 的配置，增加如下配置即可： 下面，我们打开浏览器进行访问： 棒，我们已经成功启动了 goaccess ，并能够从浏览器中看到相关的数据了，关于各个数据图的含义就需要你下面仔细了解了。 基于 OpenResty 用 Lua 语言实现简单服务 之前的讲解我们都还是基于原生的 Nginx 进行演示，下面，我们来看一下如何基于 OpenResty 用 Lua 语言实现简单服务。 下载安装 OpenResty OpenResty 的 官方网站 。 与 Nginx 一样，我们下载 OpenResty 的源码进行编译安装。 wget https://openresty.org/download/openresty-1.19.3.2.tar.gz tar -zxvf openresty-1.19.3.2.tar.gz cd ./openresty-1.19.3.2/ 首先来简单了解一下 OpenResty 源码的目录结构： 其中，各个模块的核心代码都在 bundle 目录下，包括 nginx 的源码目录。 bundle 目录下除了 nginx 外，其他的目录大致可以分为两类。 一类是以 ngx 开头的 c 模块，一类是以 lua 开头的 lua 编写的扩展模块。 其中，编译中会编译的其实是 c 模块，lua 相关的模块是在运行过程中动态加载执行的。 下面，我们来进行编译和安装: ./configure --prefix=/home/wangzhe/openresty make make install Lua扩展及验证 安装完成后，我们可以进入了安装的 openresty 目录。 可以看到，对于一个 openresty 的项目而言，其配置文件位于 nginx/conf/nginx.conf 文件。 修改配置文件中http块如下： http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 8210; server_name localhost; location /lua { default_type text/html; content_by_lua ' ngx.say(\"User-Agent: \", ngx.req.get_headers()[\"User-Agent\"]) '; } location / { root html; index index.html index.htm; } } } 其中，我们增加了一个 location /lua。 访问该 url 时，我们引入了一个 content_by_lua 的指令，即通过执行lua命令来生成返回结果。 下面，启动 openresty 服务来访问一下试试吧: ./bin/openresty 打开浏览器看一下~ By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/https.html":{"url":"middleware/nginx/https.html","title":"nginx与HTTPS协议","keywords":"","body":"nginx与HTTPS协议 目前，对于网络安全的重视程度越来越高，基本全部的公开服务的网站全部都是基于 HTTPS 协议的。 那么，我们将在本文中讲解一些 HTTPS 协议的基本原理，以及如何在 Nginx 中使用 HTTPS 协议。 简单的说，HTTPS 协议其实就是使用 HTTP 协议进行通讯，但是利用 SSL/TLS 协议来进行加密封包。 网络模型概述 对于 OSI 七层模型而言，SSL/TLS 协议位于表示层。 它通过握手、交换密钥、告警、对称加密等方式使得在应用层无感的情况下对数据传输过程进行了安全性保证。 对称加密与非对称加密 在加、解密的过程中，我们经常会听到对称加密、非对称加密方式。 那么，对称加密、非对称加密分别是什么含义呢？ 对称加密是指加密用到的密钥和解密用到的密钥是相同的，如下图所示： 一个典型的对称加密算法就是异或算法，对一组数字按位进行2次异或操作之后，仍然会得到原始的一组数字。 对称加密的优点的性能非常好，计算的方式简单。 那么，什么是非对称加密呢？ 非对称加密是指加密和解密用到的密钥是不同的，如下图所示： 非对称加密的密钥总是成对出现的，其中，对外公开的密钥部分称之为公钥，隐私保管的密钥称为私钥。 对于一段文本而言，可以用公钥加密、私钥解密；也可以用私钥加密、公钥解密。 SSL 证书 在目前的互联网中，我们有时会担心我们是否是访问到的一个虚假的诈骗网站等，这时，就需要一个公立的第三方机构来进行相关的认证，类似与互联网上的公安局。 而在这之中呢，最核心的就是CA证书了。 一个完整的使用流程如下： 网站的维护者（证书订阅人）首先需要在某个登记网站/机构进行证书申请，并填写相关的机构组织等信息，CA机构认证通过后，会生成一对证书，并返回给证书订阅人，同时自己也保留公钥证书。 网站的维护者拿到公私钥证书后，需要将该证书部署到Web服务器下，例如Nginx。 当用户的浏览器访问我们的WEB站点时，首先会请求获取相关证书，Nginx会将公钥证书发给浏览器。 浏览器查询CA机构提供的OCSP服务验证证书的有效性。 了解了证书的使用流程后，我们来看一下，证书具体有哪些类型呢？ 域名验证证书(DV): 该证书的验证性很弱，仅仅保证域名的正确性。 组织验证证书(OV): 该证书的验证性相对较强，会保证证书归属的组织的正确性。 扩展验证证书(EV): 该证书做了更严格的认证，大部分浏览器都对它的显示进行了一定程度的优化，例如将认证信息显示在浏览器中。 TLS 的通讯过程 在 TLS 的通讯过程中，主要包含如下四个步骤： 验证身份 达成安全套件共识 传递密钥 加密通讯 主体流程如下图所示： 用免费SSL证书实现一个HTTPS站点 首先，安装 Let's Encrypt 工具： sudo add-apt-repository ppa:certbot/certbot sudo apt-get update sudo apt-get install python3-certbot-nginx 安装完成后，我们可以找到一个 certbot 的命令，它可以帮助我们直接修改nginx的配置文件。 接下来，我们可以执行如下命令将我们的域名申请对应的证书。 certbot --nginx --nginx-server-root=/home/wangzhe/nginx/conf/ -d www.missshi.com 然后就会自动生成相关的证书并修改对应的nginx配置文件。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/architecture.html":{"url":"middleware/nginx/architecture.html","title":"浅谈nginx架构","keywords":"","body":"浅谈nginx架构 接下来，在本文中，我们将会和大家浅谈 nginx 的架构和设计。 只有了解了 Nginx 的架构和设计方案，我们才能更好的发挥出 nginx 的优势。 Nginx 的请求处理流程 首先，我们来了解一下一个请求进入 Nginx 后，整体的处理流程是什么样的。 首先nginx接收到输入流量主要是WEB、EMAIL和TCP流量。 由于 Nginx 本身的机制是非阻塞式的 epoll 进行事件驱动处理，因此，为了能够正常实现异步处理，其内部维护了传输层状态机、HTTP状态机、以及MAIL状态机。 对于一个静态资源下载的请求而言，Nginx会直接访问本地的静态资源并通过sendfile的方式进行返回，再涉及到磁盘IO相关的操作时，Nginx维护了一个线程池用于实现磁盘阻塞调用。 对于一个反向代理请求时，Nginx可以将请求转发给对应的代理服务中。 当请求处理完成后，nginx会打印access访问日志和错误日志。 Nginx 的进程结构 了解了 Nginx 请求处理的主体流程之后，我们再从进程层面了解一下 nginx 的进程结构。 Nginx 本身支持两种不同的进程结构，分别是单进程结构和多进程结构，其中，单进程结构并不适合生产结构，我们此处不再进行说明。 首先，nginx 有一个统一的父进程: master process，主要用于整体的管理。 其中，该父进程又会包含很多子进程，这些子进程大致可以分为2个大类： worker进程，负责真正的请求处理。 cache相关进程，包括 cache manager 和 cache loader，负责缓存的管理和载入。 首先，我们先来了解一下nginx为什么选择多进程而非多线程呢？ 我们都知道，对于多线程而言，它们会复用内存空间。而一旦出现内存处理异常时，多线程的服务会全部异常，而多进程则影响会小很多。因此，从可用性的 角度来看，Nginx选择了多进程这样的模式。 此外，为了更好的发挥出 nginx 的能力，我们通过会设置 worker 数量与机器的 CPU 数量一致，同时进行绑核，减少缓存失效等问题。 下面，我们通过一些具体的命令操作来观察一下Nginx中各个进程的关系。 首先，我们启动一个包含2个worker进程的nginx服务。Ps: 修改nginx配置文件中worker_processes为2。 # (base) root@wangzhe-swarm-dev:/home/wangzhe/nginx# ps -ef|grep nginx root 23382 1 0 09:15 ? 00:00:00 nginx: master process ./sbin/nginx nobody 23383 23382 0 09:15 ? 00:00:00 nginx: worker process nobody 23384 23382 0 09:15 ? 00:00:00 nginx: worker process nobody 23385 23382 0 09:15 ? 00:00:00 nginx: cache manager process nobody 23386 23382 0 09:15 ? 00:00:00 nginx: cache loader process root 23390 24374 0 09:15 pts/1 00:00:00 grep --color=auto nginx 可以看到，和我们预期的是一样的，查询到的nginx进程包括: 一个master进程。 两个worker进程。 一个cache manager进程。 一个cache loader进程。 其中，master进程是其他所有进程的父进程。 下面，我们可以执行一个 reload 的操作，然后再观察一下进程的变化情况： ./sbin/nginx -s reload ps -ef|grep nginx 得到的结果如下: # (base) root@wangzhe-swarm-dev:/home/wangzhe/nginx# ps -ef|grep nginx root 23382 1 0 09:15 ? 00:00:00 nginx: master process ./sbin/nginx nobody 23832 23382 0 09:18 ? 00:00:00 nginx: worker process nobody 23833 23382 0 09:18 ? 00:00:00 nginx: worker process nobody 23834 23382 0 09:18 ? 00:00:00 nginx: cache manager process root 23985 24374 0 09:19 pts/1 00:00:00 grep --color=auto nginx 可以看到，master进程的PID没有发生变化，而其他几个子进程的的PID发生了变化，也就是说明了 worker 和 cache进程等在reload操作时，会被master优雅退出原有进程并重新启动新的进程。 下面，我们可以试试当某个worker进程异常退出时会发生什么呢？ kill 23833 ps -ef|grep nginx 观察结果如下: # (base) root@wangzhe-swarm-dev:/home/wangzhe/nginx# ps -ef|grep nginx root 23382 1 0 09:15 ? 00:00:00 nginx: master process ./sbin/nginx nobody 23832 23382 0 09:18 ? 00:00:00 nginx: worker process nobody 23834 23382 0 09:18 ? 00:00:00 nginx: cache manager process nobody 26401 23382 0 09:23 ? 00:00:00 nginx: worker process root 26403 24374 0 09:23 pts/1 00:00:00 grep --color=auto nginx 虽然，原有的23833号进程退出了，但是nginx master很快就有创建出来了一个新的子进程，保证nginx worker的存活数量始终满足配置文件的要求。 使用信号管理 Nginx 进程 Nginx 本身是一个多进程的程序。 Nginx 进程时间的通信和管理主要也是依赖信号来实现的。 下面，我们来具体看一下是如何通过信号来管理Nginx进程的吧。 Master 进程 对于 Master 进程而言，最重要的工作之一就是管理 worker 进程了。 而 Master 管理 Worker 进程中最核心的任务就是监控 Worker 进程是否向 Master 进程发送了 CHLD 信号。 Ps: 在 Linux 系统中，如果子进程退出，则会向父进程发送 CHLD 信号。 此外，Master 进程还可以接收一些外部信号来管理 Worker 进程，例如可以接收的信号包括: TERM, INT: 立即停止Nginx进程。 QUIT: 优雅停止NGINX进程。 HUP: 重载配置文件。 USR1: 重新打开新的日志文件，进行日志文件的切割。 USR2: 启动热部署，启动一个新的NGINX Master，并自动实现无损流量切换。 WINCH: 热部署中，停止旧的NGINX Worker进程。 Nginx 命令行 在 Nginx 命令行中，我们可以实现一些基础的对 Nginx Master的信号发送。 具体来说： reload: HUP 信号 report: USR1 信号 stop: TERM 信号 quit: QUIT 信号 Nginx Reload 完整流程 Step1: 向 Nginx Master 进程发送 HUP 信号(reload命令) Step2: Master 进程检查Nginx最新的配置文件语法是否正确 Step3: Master 进程打开新的监听端口 Step4: Master 进程用新配置启动新的worker子进程 Step5: Master 进程向老的worker子进程发送QUIT信号 Step6: 老的Worker子进程关闭监听句柄，处理完当前连接后结束进程。 热升级完整流程 Step1: 将旧Nginx文件换成新的Nginx二进制文件（注意备份）。 Step2: 向Master进程发送USR2信号。 Step3: Master进程修改pid文件名，加后缀.oldbin Step4: Master进程用新的Nginx二进制文件启动新Master进程。 Step5: 向老Master进程发送QUIT信号，关闭老Master。 Step6: 回滚: 向老Master发送HUP信号，向新Master发送QUIT信号。 Worker 优雅退出的步骤 Worker 优雅退出主要针对的是HTTP请求。对于websocket或TCP/UDP等协议，优雅退出是无效的。 Step1: 设置定时器 worker_shutdown_timeout。 Step2: 关闭监听句柄。 Step3: 关闭空闲连接。 Step4: 循环中等待全部连接关闭。 Step5: 退出进程。 Nginx 网络收发相关管理 对于一个网络传输请求而言，在一个主机A访问主机B的请求中，数据流是如何传递的呢？ 上面的数据流转中，设计到了应用层、传输层、网络层和数据链路层等多个层级的共同作用，那么每一层具体是如果工作的呢？ 最终传输的报文又是什么样的？ 在TCP协议中，每一个报文其实就对应着一个网络事件。 具体来说，在网络事件的分类中，我们用可以把网络事件分为读事件和写事件。 其中， 读事件包括 Accept 建立连接以及 Read 读消息。 写事件包括 Write 写消息。 上图显示了一个事件分发的消费器。 Nginx 的事件处理机制 Nginx 整体的事件处理机制大体如下图所示: Nginx 启动后，就会建立一个连接等待接收事件。 一旦 Linux 内核接收到网络事件时，就会通过队列的形式发送给 Worker 进行执行。 worker 执行事件动作时，也可能会产生一些新的事件会继续发给到内核中，等待后续执行。 在上面的流程中，如何从内核中快速的获取到等待处理的事件其实是非常核心的关键点，那么 Nginx 具体是怎么实现的呢？ epoll是Nginx从内核中获取等待事件的核心机制。 上图表示了对几种不同的事件模型的性能的benchmark测试结果。 其中： 横轴表示文件句柄连接数。 纵轴表示了一次事件处理的耗时。 可以看出epoll随着并发连接数的不断上升，事件处理的耗时相对非常平稳，因此，可以看出 epoll 事件模型非常适合于处理大并发的任务。 在我们日常开发时，我们都知道在处理一下网络请求等相关任务中，异步请求往往比同步等待的效率要高很多。 而Nginx自身能达到很高的性能，也与它选择了非阻塞调用而非阻塞调用有关。 以下图为例: Nginx 在调用 accept 时，如果 accept 队列为空，其实有两种处理方式: 阻塞调用: 进入sleep, 等到 accept 队列收到事件后再处理，这次操作系统会对齐产生进程间切换，让CPU先来处理其他进程的任务。 非阻塞调用，直接返回某个错误，代码自主来控制是进行等待还是进行下一个任务的处理，不会被操作系统自动进行进程切换。 由此可见，非阻塞调用的最大的好处之一是可以通过代码来自主控制何时发生进程切换，不会过于频繁的进行进程切换导致性能下降。 而正式由于Nginx底层的非阻塞调用的实现，哪怕我们在OpenResty中编写的是简单的同步代码，实际底层仍然会是非阻塞的，不会导致性能下降。 Nginx 的模块 Nginx 的模块设计非常的优雅和精良，对于一些第三方开发者而言，也可以很轻松的编写 Nginx 模块并集成至 Nginx 中。 了解具体的 Nginx 模块时，往往包括如下几个内容： 将对应模块编译进入Nginx中 该模块提供了哪些配置项 如果启用该模块，该模块在何时会生效 该提供提供了哪些变量可以供我们使用 Nginx 官方模块的文档可以参考 文档 。 官方模块的支持往往都会配有相对完整的文档描述，然而对于一些第三方开发的模块而言，有可能文档就没有那么完善了。 不过不要怕，我们可以通过阅读源码的方式，按照一些技巧快速找到我们需要的内容。 首先，在我们编译 Nginx 之前，会先支持 ./configure 命令，该命令执行完成后，会生成一个 objs/ 目录。 在该目录中会包含一个 ngx_modules.c 的文件，打开这个文件，你会看到，在这个文件中有一个 ngx_modules 的数组， 这个数组中包含了所有将要编译进入 Nginx 中的模块。 而对于每个模块的源代码而言，默认路径位于 src/http/modules/ 目录下。 以 gzip 模块为例，我们可以看一下 src/http/modules/ngx_http_gzip_filter_module.c 文件。 其中，一定唯一包含一个 nginx_command_t 的数据，它的每一个成员都是它所支持的一个指令名称。 即对于每个 nginx 模块而言，都对应一个 nginx_module_t 这样的结构体，其中又包含的 commands 指定了该模块支持了哪些指令。 此外，nginx 对应不同应用场景的模块又分为了几个不同的大类，例如 core, http, event, stream, mail等， 对于一个 nginx 模块而言，首先，它应该是高内聚的，即它的功能应该是特定且直接的。 同时，它也应该能够被很好的抽象，可以按照统一的机制进行执行。 Nginx 进程间通信方式 我们已经知道 Nginx 是一个多进程的程序，它的多个 worker 进程之间，往往需要互相通信来共享数据，那么 Nginx 是如何实现多进程通信的呢？ 答案是: 共享内存。 下面，我们看一下 Nginx 的共享内存究竟是如何实现的。 即申请一个内存空间，允许多个worker进程同时进行访问和写入。 这里面有两个关键实现: 锁: 具体来说，为了避免多个进程的访问冲突，我们一定需要一个锁机制，目前的主要机制为自选锁，即while true循环。 Slab 内存管理器: 提供统一的接口对各个模块使用，底层自动实现 slab 的块切分，如按照2，4，8，16等比例切分，按需对外分配。 那么，Nginx 在哪些场景下使用了共享内存呢？ 红黑树: 如限速、流控、cache、ssl等场景。 单链表: 如upstream_zone。 http_lua_api。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/http.html":{"url":"middleware/nginx/http.html","title":"Nginx HTTP模块详解","keywords":"","body":"Nginx HTTP模块详解 在本文中，我们将会以 Nginx 请求处理流程的方式，将 HTTP 模块相关的使用方法进行分析和讲解。 Nginx 请求事件处理流程 在介绍 Nginx 的 各个 HTTP 模块功能之前，我们需要先来了解一下 Nginx 对于一个请求事件而言，其通用的处理流程是怎么样的。 首先，如果有访问Nginx的服务，首先是会与Linux内核进行一次TCP的三次握手。 当三次握手成功之后，会转给 nginx 的事件管理模块去建立一个连接，此时 nginx 需要对齐分配对应的连接内存池，同时，此时 Nginx 的 HTTP 模块会 对齐设置一个 header 读取的超时时间。 接下来，就是等待客户端继续发送请求的 header 信息了，当客户端发送 header 信息后，nginx 的HTTP模块会继续申请读缓冲区内存，用于接收 客户端发送的 header 信息。 后续的 header 接收与处理逻辑如上图所示。 其中，开启 11 个阶段的 http 请求处理之前的所有逻辑，都是 nginx 服务本身内置的 http 相关的逻辑，而用户可以开发插入的逻辑都集中在 11个阶段中。 那么，nginx HTTP 处理请求的 11 个阶段又是什么样的呢？ 我们先来看一个大致的示意图： 首先，对于一个请求而言，我们首先会读取请求的 header 信息，如上述流程所示。 接下来，会根据 header 信息来判断它属于哪一个配置块，找出对应的配置信息。 然后判断是否属于限速、限并发等流量控制策略限定域中。 接下来，会有鉴权相关的访问控制处理。 当确认该请求可以正常进行后，需要生成对应的响应体，其中，对于反向代理场景而言，需要访问上游服务获取对应的响应体。 在返回具体的响应体之前呢，还可以对响应信息再次进行处理，如gzip压缩等。 最后，当上述步骤都处理完成后，先记录access log，并将结果返回给请求客户端。 下面，我们来具体看一下，对于Nginx HTTP请求处理而言，具体包含哪些阶段: 阶段序号 阶段名称 示例模块 1 POST READ realip 2 SERVER_REWRITE rewrite 3 FIND_CONFIG 4 REWRITE rewrite 5 POST_REWRITE 6 PREACCESS limit_conn, limit_req 7 ACCESS auth_basic,access,auth_request 8 POST_ACCESS 9 PRECONTENT try_files 10 CONTENT index,auto_index,concat 11 LOG access_log 转换成一张图的话，基本如下图所示： 指令与配置块 在正式进入 http 各个模块与指令讲解之前，我们还需要先来了解一下 nginx 中关于配置块和指令的一些基本概念。 对于一个 nginx 指令而言，都有有其对应的上下文的约束，具体来说，就是限制该指令可以出现在什么位置上，例如可以出现在哪些配置块中。 这个上下文约束，我们称之为对应的 context 。 当然，对于一些指令而言，其本身可以在多个不同的配置块中出现，即其 context 可以是多种不同的配置块。 那么，对于一个指令而言，如果它同时出现在了多个不同的配置块中，且指定设置的结果不一致时，这时最终哪个指令配置的结果会生效呢？ 这时，基本可以主要分为两种类型： 对于设置配置项值的指令，例如 root, access_log 等，它们可以对配置项进行合并，合并的规则是子配置存在时，直接覆盖父配置，子配置不存在时，继承父配置。 对于设置动作行为类的指令，例如 rewrite, proxy_pass 等，通过无法对其合并，而是在生效结果直接执行。通常，对于动作类指令，主要在 server_rewrite, rewrite, content阶段生效。 正则表达式 正则表达式在 nginx 中可以说是得到了相关广泛的应用，因此在正式进入 nginx http 模块学习之前，我们还需要先来了解一下Nginx 中的正则表达式。 Nginx 中的正则表达式中支持的元字符如下表所示： 代码 说明 . 匹配除换行符之外的任意字符 \\w 匹配字母/数字/下划线/汉字 \\s 匹配任意空白符 \\d 匹配数字 \\b 匹配单词的开始和结束 ^ 匹配行开头 $ 匹配行结尾 此外，除了单个字符的匹配之外，还有用于重复的正则字符串的表达方式: 代码 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 通过正则表达式，我们可以在 location, server_name, rewrite 中取得极大的便利。 listen 指令 前面聊了这么多的基础知识，下面，我们就可以开始正式了解一些 nginx http 模块中的指令了。 listen 指令可以说是 server 块中最最基础的指令了，用于设置在本地监听哪些端口用于接收请求。 listen 指令仅允许出现在 server 块这个 context 中。 常用的基本语法如下: listen address[:port]; listen port; listen unix:path; 例如: listen 8000; # 监听所有网卡的8000端口 listen 127.0.0.1:8001; # 监听localhost的8001端口 listen unix:/var/run/nginx.sock; # 监听指定socket文件，仅限于本机通讯 server_name 指令 在 Nginx 配置中，server_name 也是一个非常重要的指令，通过 server_name 可以帮助我们找到指定请求对应生效的配置块。 说到这儿你可能就会有一些奇怪了，我们刚才已经讲到了 listen 指令，通过 listen 指令指定的端口不是已经就可以帮助我们找到对应的配置块了嘛？ 为什么还需要 server_name 这么一个东西呢？ 说起来也简单，由于 Nginx 往往是会作为我们整个网关的一个流量入口，该流量入口上常常可能会绑定多个域名，这时，我们希望多个域名对应的 服务都能够以80，或443这种常用端口来对外提供服务，而nginx可以跟进客户端请求的域名不同，来自动识别到不同的配置块上。 简单的来说，server_name 本身上就是可以根据客户端HTTP请求中header中的HOST信息与server_name进行匹配，找到对应的配置块。 server_name 可以出现的 context 为 http, server 以及 location 中。 其基本的语法格式为: server_name www.missshi.cn; # 精准匹配 server_name *.missshi.cn; # 泛域名，* 仅支持在最前或最后 server_nane ~^www\\d+\\.missshi\\.cn$; # ~开头，正则表达式 此外，在 server_name 的正则表达式中，我们还可以用小括号来创建变量，并在其余位置使用： server { server_name ~^(www\\.)?(.+)$; location / { root/sites/$2; } } 其中，我们在 location 中就使用了 $2 来表示 server_name 中匹配的域名。 或者是: server { server_name ~^(www\\.)?(?.+)$; location / { root/sites/$domain; } } 那么，在多个 Server 块都监听了相同的端口，且 server_name 设置不一致但都可能匹配的情况下，会如何进行优先匹配呢？ 精准匹配。 *在前的泛域名 *在后的泛域名 按照文件中顺序匹配正则表达式域名 全部不匹配时，如果有server块被设置为default，则匹配default块。 全部不匹配时，且没有default块时，默认匹配第一个。 realip 模块 realip 模块处于 Nginx HTTP 处理中的 POST READ 阶段，它是接收完整 header 后进行处理的第一个阶段。 realip 模块的作用是从请求的Header中找出对应的真实客户端IP，从而可以用于后续的限速等场景。 我们都知道，对于一个 TCP 连接的四元组而言，包括了 src ip, src port, dst ip, dst port 四部分，那么我们是不是只需要获取 src ip 信息即可， 为什么还需要一个单独的 realip 模块呢？ 因为在真实的网络场景下，客户端到服务端的请求往往不能直接送到，中间可能需要经过很多层代理，如下图所示： 以一个典型的用户上网场景为例，中间可能会经常CDN，反向代理等等，最终才能到达 Nginx 服务器。 这时，如果 Nginx 服务器直接获取 src ip 字段的信息时，得到的信息只能是反向代理的IP，而拿不到真实的用户 IP，这个与我们的需求往往是不符的。 那怎么能拿到真实的客户端IP呢？ 对于所有的代理服务器而言，我们有一套统一的规范，即代理服务器在转发请求时，应该在 http header 中包含 X-Forwarded-For 字段，包含 IP 连接链 X-Real-IP 字段，用于传递原始的客户端 IP 此时，Nginx 接收到客户端请求后，就可以通过解析 X-Forwarded-For 或者 X-Real-IP 字段的信息，来找到真实的客户端 IP。 那么，再获取到真实的客户端IP后，我们应该如何使用呢？例如怎么用客户端的IP进行请求限速。 答案是 变量 。 在 Nginx 中，变量在 Nginx 整个处理流程中，启动了重要的作用。 具体来说，当 realip 处理一个请求后，会重写对应的 binary_remote_add 和 remote_addr 的变量，将该变量改写为客户端的真实IP信息， 后续在限速等场景中，我们可以直接将 binary_remote_add 和 remote_addr 的变量作为限速的 key 即可。 简单对 real ip 模块做一个梳理： realip 模块可以用于查找请求的真实客户端地址。 realip 模块默认不会编译进入Nginx中，需要添加 --with-http_realip_module 来启用该功能。 realip 模块会生成 realip_remote_addr 和 real_ip_remote_port 两个新的变量，用于记录原始的请求信息（非源头）。 realip 模块会重写 binary_remote_add 和 remote_addr 变量，并设置为源头客户端来源IP。 同时，realip 模块本身提供了如下几个指令，我们来了解一下: set_real_ip_from 功能描述: 用于设置哪些来源的请求会解析realip。 语法格式: set_real_ip_from address|CIDR|unix; 默认值: 无 Context: http, server, location。 说明：只有指定的来源IP区间，我们才会对它的src ip进行解析，否则不会进行相关的src ip解析。 real_ip_header 功能描述：设置获取src ip的方式。 语法格式: real_ip_header field | X-Real-IP | X-Forwarded-For | proxy_protocol; 默认值: X-Real-IP Context: http, server, location。 说明：默认会根据请求头中的 X-Real-IP 字段来获取src ip，可以跟进自己的需求进行修改。 real_ip_recursive 功能描述：是否开启递归realip查询。 语法格式: real_ip_recursive on | off; 默认值: off Context: http, server, location。 说明：默认是关闭的，如果开启后，且 real ip 的获取方式为 X-Forwarded-For 且 X-Forwarded-For 的最后一个IP 与 set_real_ip_from 匹配时，递归向前查询，直到找出不匹配的IP作为src ip。 rewrite 模块 return 指令与 error_page 指令 rewrite 模块本身可以出现在两个不同的阶段中，即 SERVER_REWRITE 和 REWRITE 阶段，需要来说，就是在 server 块下出现或者在 location 块下出现。 它们可以使用的命令是一致的。 rewrite 模块的主要作用其实是重新请求的 url。 下面，我们先来了解一下 rewrite 模块下的 return 指令。 return 功能描述: 用于返回请求指定的返回码和URL。 语法格式: return code [text]; return code URL; return URL; Context: server, location, if 说明：停止当前的处理逻辑，指定将指定的结果返回给客户端。 其中，return 指令返回的 code 可以是： 444: Nginx 自定义 Code，用于直接关闭连接。 301: HTTP1.0 永久重定向。 302: 临时重定向。 303: 临时重定向且允许改变请求method。 307: 临时重定向且不允许改变请求method。 308: 永久重定向，且不允许改变请求method。 了解了 return 指令后，我们再来看一下 error_page 指令。 error_page 功能描述: 设置当返回指定错误码时，可以返回指定的uri或指定页面。 语法格式: error_page code ... [=[response]] uri; Context: http, server, location, if 示例代码如下: error_page 404 /404.html; error_page 500 502 503 504 /50x.html; 为什么要把 error_page 和 return 放在一起来说明呢？ 主要是 return 可以用于自主设置返回码，而 error_page 又是根据返回码的不同来设置特定的行为，那么，同时设置了 return 且匹配和 error_page 的条件后，行为会是什么样呢？ 同时试验一下的话，你会发现，return 命令结束后，会立刻进行结果返回，error_page 相关的操作其实是无法生效的。 那么，我们也知道 return 指令可以同时出现在 server 块和 location 块中，那么如果同时出现时，它们的行为又是什么样的呢？ 正如我们之前学习到的 http 处理的 11 个阶段， server_rewrite 阶段其实是早于 rewrite 阶段的，因此，在 server 块中的 return 指令执行后， 将会立即返回结果，location 下的 return 指令实际是没有机会执行的。 不知道和你想的是否是一致的呢？ rewrite 模块下的 rewrite 指令 rewrite 指令是专门针对 uri 进行处理的，具体来说，它可以通过正则匹配 uri，并将正则匹配到的 uri 提供成为一个新的 uri。 rewrite 功能描述: 正则匹配原始访问的 uri 并替换称为新的 uri 访问。 语法格式: rewrite regex replacement [flag]; Context: server, location, if 其中，当 replacement 是以 http:// 或者 https:// 开头时，则等价于返回 302 重定向。 可以看到，在 rewrite 指令中的，有一个 flag 参数，这个参数对于 rewrite 行为的影响至关重要，具体来说: last: 用 replacement 替换原始 URI 后再次进行新的 location 匹配。 break: 停止当前脚本指令的执行，直接返回对应的结果。 redirect: 适用于 http:// 或 https:// 开头，临时重定向。 permanent: 适用于 http:// 或 https:// 开头，永久重定向。 不传递时: 继续向后正常执行。 rewrite_log 功能描述: 将 rewrite 的行为接入 error 日志中。 语法格式: rewrite_log on|off; 默认值: off Context: http, server, location, if rewrite 模块下的 if 指令 rewrite 模块下提供了 if 指令，即可以使用 if 条件判断从而来进行相关行为的设置。 if 功能描述: 引入条件判断，可以根据指定的条件来设置不同的行为。 语法格式: if (condition) {...} Context: server, location Ps: 当 condition 为真时，执行大括号内的指令；遵循值指令的继承规则。 那么，if 指令中的条件表达式具体可以是哪些情况呢？ 检查变量是否为空或者值是否为0，可以直接使用。 将变量与字符串进行完整匹配，使用 = 或者 != 将变量与正则表达式进行匹配。 大小写敏感时，使用 ~ 或者 !~ 大小写不敏感时，使用 ~ 或者 !~ 检查文件是否存在，使用 —f 或者 !-f 检查目录是否存在，使用 —d 或者 !-d 检查文件、目录、软链是否存在，使用 —e 或者 !-e 检查是否为可执行文件，使用 —x 或者 !-x find_config 阶段找到对应 location 块 - location 指令 下面，我们来了解一下 FIND_CONFIG 阶段，Nginx 是如何找到对应的 location 块的。 其中，涉及到两个指令，分别是 merge_slashes 和 location。 其中， merge_slashes 相对简单，我们来简单介绍一下。 merge_slashes 功能描述: 如果 uri 中包含两个连续的 / 符号，则对齐进行 merge，合并为一个。 语法格式: merge_slashes on | off; 默认值: on Context: http, server 通常，merge_slashes 配置我们都会默认开启。 下面，我们来看一下核心的 location 指令。 location 功能描述: 设置 location 条件，从而可以让nginx判断针对指定url时，应该执行哪个语法块的逻辑。 语法格式: location [=|~|~*|^~] uri {...} location @name {...} Context: server, location 需要说明的是，在 location 的匹配中，仅会匹配 URI，而不会对参数等进行相关的匹配。 在 location 的匹配中，主要包含以下几种情况： 前缀字符串匹配 默认情况下，不加任何符号时，则表示常规的前缀字符串匹配。 如果增加了 = 符号，则表示精准匹配。 如果增加了 ^~ 符号，且最长匹配前缀，则不检查正则表达式。 正则表达式匹配 ~ 表示大小写敏感的正则匹配。 ~* 表示大小写不敏感的正则匹配。 内部跳转的命令location 那么，当一个 Server 块中包含很多 location 的时候，当一个 uri 访问时，可能会同时匹配到多个前缀匹配和正则匹配， 此时具体应该会匹配到哪一个 location 块呢？ 这就涉及到了 find_config 的相关逻辑，我们来看一下下图： 首先，最高优先级的就是 = 的精准匹配。 接下来，是 ^~ 的完整匹配。 再其次，是根据配置文件顺序的 regex 正则匹配。 最后，则是根据最长匹配的前缀字符串匹配。 了解了这个规则，你应该就知道对于任意一个 uri 的访问，它预期会进入到哪个 location 块的执行逻辑中了。 preaccess 阶段下的 limit_conn 模块 在 nginx 中，我们常常希望限制单个客户端的并发连接数目，这时，就会用到 Nginx 的 preaccess 阶段下的 limit_conn 模块。 limit_conn 模块的生效范围是全部 worker 进程，它们基于共享内存实现共享数据。 limit_conn 模块涉及到四个指令: limit_conn_zone 、 limit_conn 、limit_conn_log_level 、limit_conn_status ，下面，我们来依次进行讲解。 limit_conn_zone 功能描述: 声明一个共享内存空间，用于存放限制连接数相关的信息。 语法格式: limit_conn_zone key zone=name:size; Context: http 通过 limit_conn_zone 指令，我们可以自定义一个指定名称、指定大小的共享内存空间，同时，我们还可以设置根据哪个字段进行限制连接。 示例如下： limit_conn_zone $binary_remote_addr zone=addr:10m; 上述命令表示: 我们申请了一块10m大小的内存空间，并命名为addr。同时，在限制连接时，根据 binary_remote_addr 变量的值进行统计和限制。 limit_conn 功能描述: 设置并发连接数的规则。 语法格式: limit_conn zone number; Context: http, server, location 示例如下: limit_conn addr 5; 上式表示我们使用名称为 addr 的共享内存空间进行限制并发判断，且最大的并发数为 5 。 limit_conn_log_level 功能描述: 设置当限制并发连接拦截后，error 日志打印的级别。 语法格式: limit_conn_log_level info|notice|warn|error; 默认值: error Context: http, server, location limit_conn_status 功能描述: 设置当限制并发连接拦截后，返回的返回码。 语法格式: limit_conn_status code; 默认值: 503 Context: http, server, location limit_conn_log_level 和 limit_conn_status 相对比较简单，我们就不再举例了。 preaccess 阶段下的 limit_req 模块 在 limit_conn 模块中，我们可以限制的是单个客户端的并发连接数，然而，我们往往还有一种更加通用的需求，就是限制 QPS。 而限制 QPS 的主要方式就是 limit_req 模块了。 与 limit_conn 模块一样，limit_req 模块的生效范围也是全部 worker 进程，它们基于共享内存实现共享数据。 我们先来了解一下 limit_req 模块的实现原理： 如上图为例，假设我们有一个漏盆，它可以接收上游发送过来的请求，而上游发送过来的请求可能突快突慢，但是对于下游发送出去的数据而言，它的最大速率是固定的。 如果一个时间段请求流量非常多，过一阵请求流量很小的话，通过这个漏盆可以有效的均有下游的访问速率。 但是这里面有一个问题，如果上游的请求流量始终大于下游的最大速率时，会持续向盆内积水，这样，最终总会导致盆内的水打满，造成一些水外露，这就是这个盆所能承载的最大容量了。 而 limit_req 模块实现原理其实就是这样的。 我们可以设置一个最大的请求速率，超过这个速率的上游请求我们暂时将其夯住，直到满足速率要求后再发送给下游。但是如果夯住的请求数量超过我们设置的阈值时，将会直接提示失败。 下面，我们来看一下 limit_req 模块设置到几个指令： limit_req_zone 功能描述: 声明一个共享内存空间，用于存放限制QPS的相关信息。 语法格式: limit_req_zone key zone=name:size rate=rate; Context: http Ps：rate 的单位为 r/s 或者 r/m。 通过 limit_req_zone 指令，我们可以自定义一个指定名称、指定大小的共享内存空间，同时，我们还可以设置根据哪个字段进行限制连接以及最大的QPS限制。 示例如下： limit_req_zone $binary_remote_addr zone=addr:10m rate=10r/s; 上述命令表示: 我们申请了一块10m大小的内存空间，并命名为addr。同时，在限制QPS时，根据 binary_remote_addr 变量的值进行统计和限制，且最大QPS为10。 limit_req 功能描述: 设置QPS限速的规则。 语法格式: limit_req zone=name [brust=number] [nodelay]; 默认值: brust 默认为 0。 Context: http, server, location。 示例如下: limit_req zone=addr brust=20; 上式表示我们使用名称为 addr 的共享内存空间进行QPS速率限制，且最多waiting的请求数为20。 limit_req_log_level 功能描述: 设置QPS速率拦截后，error 日志打印的级别。 语法格式: limit_req_log_level info|notice|warn|error; 默认值: error Context: http, server, location limit_req_status 功能描述: 设置QPS速率拦截后，返回的返回码。 语法格式: limit_req_status code; 默认值: 503 Context: http, server, location limit_req_log_level 和 limit_req_status 相对比较简单，我们就不再举例了。 access 阶段下的 access 模块 preaccess 阶段说完了，现在该继续讲解 access 阶段了。 在 access 阶段，最常用的功能之一就是针对指定 IP/CIDR 增加黑白名单了。 access 模块提供的指令包括 allow 和 deny 了，两个指令的使用方式和语法完全一样，只有语义正好相反。 allow/deny 功能描述: 设置指定来源IP/CIDR为白名单或者黑名称。 语法格式: allow address|CIDR|unix:|all; Context: http, server, location, limit_except 示例如下: location / { deny 192.168.1.1; allow 192.169.1.0/24; deny all; } 其中，需要注意的是，在整个匹配的过程中，一旦匹配到某个 deny / allow 指令后，就直接生效了，不会进行后续的 deny/allow 匹配了。 access 阶段下的 auth_basic 模块 除了按照 IP 黑白名单的访问控制外，另外一种常用的访问控制就是用户名/密码控制了。即在 Nginx 请求访问中，需要用户输入用户名/密码相关的信息。 这种授权方式就对应到了 nginx 的 auth_basic 模块。 auth_basic 模块涉及到如下两个指令： auth_basic 功能描述: 设置是否开启用户名/密码认证。 语法格式: auth_basic string|off; 默认值: off Context: http, server, location, limit_except 当 auth_basic 指令设置为 off 时，表示禁用用户名/密码认证，当设置为其他字符串时，表示启用用户名/密码认证，且设置的字符串作为平台标识。 那么，具体访问的用户名和密码是什么呢？这就又涉及到了另一个指令。 auth_basic_user_file 功能描述: 用户名/密码认证配置文件。 语法格式: auth_basic_user_file file; Context: http, server, location, limit_except 那么，这个文件应该如何生成呢？ 生成这个文件需要用到一个命令行工具：htpasswd。 htpasswd -b -c ${filename} ${username} {password} 生成完成后，可以看一下生成的文件内容，格式还是比较清晰的，一行表示一个用户，密码是进行过一些简单的加密的。 当然，如果你本地没有安装 htpasswd 工具的话，也可以直接用一些在线的 htpasswd 生成器，例如 htpasswd , 它们可以帮助你无需安装命令行工具也可以快速生成对应的文件。 当我们开启了 auth_basic 的功能后，如果你再次从浏览器访问对应的地址，浏览器会自动弹出一个输入框提示输入用户名和密码。 access 阶段下的 auth_request 模块 上面讲到的 access 阶段的模块，无论是黑白名单或者是用户名/密码的鉴权，相对来说都是比较简单的鉴权方式。 在很多企业里面，我们可以已经有了专门的鉴权中心，因此，很多时候我们需要将 Nginx 的鉴权阶段与其他的内部服务进行打通，也就是说由第三方服务来进行权限控制。 这时，在 nginx 中我们就要用到了 auth_request 模块。 需要注意的是，auth_request 模块默认是没有编译进 Nginx 的，需要在编译时增加 --with-http_auth_request_module 参数。 我们先来简单的了解一下 auth_request 模块的实现原理: 首先，nginx 在接收到一个请求后，会生成一个子请求，并通过反向代理的方式把请求传递给上游的服务。 等待上游服务返回响应。 如果上游服务的返回码是2XX，表示权限认证通过，继续后续流程。 如果上游服务的返回码是401或者403，表示权限认证失败，直接将错误码返回给客户端。 了解了 auth_request 模块的实现原理后，我们来看一下如何使用 auth_request 模块。 auth_request 功能描述: 设置第三方服务地址用于权限控制。 语法格式: auth_request uri|off; 默认值: off Context: http, server, location 当 auth_request 设置为 uri 字符串时，nginx会生成一个子请求，将原始请求信息发送给对应的uri进行鉴权。 access 阶段下的逻辑控制 satisfy 指令 上面的内容中，我们已经讲解了 access 阶段下的三种访问控制手段: 黑白名单、用户名/密码以及第三方鉴权。 那么，这三种鉴权的关系是什么呢？如果同时开启了这三个access阶段的模块，部分通过，部分失败后的行为又是什么样的呢？ 这就用到了一个 satisfy 的指令了。 satisfy 的指令非常简单: satisfy 功能描述: 设置多个access相关指令的生效关系。 语法格式: satisfy all|any; 默认值: all Context: http, server, location 可以看出，satisfy 指令仅可以设置为 all 或者 any，其中: all: 所有的 access 模块全部认证通过，才能够继续访问。 any: 只要有一个 access 配置认证通过，就可以继续访问。 可以看到，通过合理的利用 satisfy 指令，我们就可以组合生成兼容多种不同的认证方式的认证策略。 precontent 阶段的 try_files 指令 了解完 access 阶段的一些常用指令后，下面我们继续来了解一些 precontent 阶段的一些指令。 首先来看一下 try_files 指令。 try_files 功能描述: 依次访问多个指定的文件，如果找到了，则直接返回，如果所有文件都不存在，则返回最后一个 url 结果或者指定返回码。 语法格式: try_files file1 file2 ... uri; try_files file1 file2 ... =code; Context: server, location try_files 指令常常可以用于一些反向代理的场景，在反向代理时，可能会有一些文件直接cache到本地，如果本地没有找到时，再转给业务服务器处理。 precontent 阶段的 mirror 模块 mirror 模块可以用于复制流量。 具体来说，nginx 在收到一个请求时，会生成一个子请求访问其他服务，但是需要注意的是，此处nginx对子请求的返回值不会进行任何处理。 mirror 模块主要包含如下两个指令： mirror 功能描述: 复制请求流量到另外一个uri中，实现请求流量多写。 语法格式: mirror uri | off 默认值: off Context: http, server, location mirror_request_body 功能描述: 设置在复制流量时，复制的请求流量是否需要传递body信息，默认是传递的。 语法格式: mirror_request_body on | off 默认值: on Context: http, server, location content 阶段的 static 模块 在 content 阶段，有一个内置的核心模块 static 。 在 static 模块中，提供了一系列的核心指令和变量。下面，我们来依次进行说明。 root/alias 指令 之前我们已经经常提到了 root/alias 指令，下面，我们来详细看一下二者的异同点。 二者在功能上是一致的，都是将 url 映射为文件路径，并返回静态文件的内容。 二者在使用上是有一些差异的，root 指令会将完整的请求url映射补充至文件路径中，而alias只会将location后url映射补充至文件路径中，不包含location匹配的前缀。 alias 功能描述: 将 url 映射为文件路径，并返回静态文件的内容。 语法格式: alias path Context: location root 功能描述: 将 url 映射为文件路径，并返回静态文件的内容。 语法格式: root path 默认值: html Context: http, server, location 此外，我们也可以看到，root 是有默认值的，默认为 html; 另外，alias 仅能用于 location Context 中，而root的使用场景则更多。 在通过 url 转化为本地文件访问时，可能会经常出现 url 映射的本地文件不存在的情况，针对这种情况，默认是会打印一条 error 日志的。 如果我们不希望这种场景下打印 error 日志，则可以通过如下指令进行禁用： log_not_found 功能描述: 设置当静态资源找不到时，是否需要打印error日志。 语法格式: log_not_found on|off 默认值: on Context: http, server, location 模块内置变量 除了上述提到了 root 和 alias 指令外，static 模块还提供了一些变量，这些变量表示了对应的文件和目录信息等，下面我们来看一下： request_filename: 表示待访问文件的完整路径 document_root: 由URI和root/alias规则生成的文件夹路径。 realpath_root: 将 document_root 中的软链接替换中真实路径。 那么，这些变量有什么用呢？ 例如，我们可以在 if 表达式中判断这些文件/目录的属性、存在性等，并针对不同的结果返回不同的内容。 nginx 的末尾补 / 机制 当我们访问一个 url 时，如果 url 的末尾不是以 / 结尾，但是 Nginx 映射到本地文件后，发现对应的内容是一个目录时，这时会自动触发一个 301 重定向操作。 在该重定向中，nginx 会在 url 的末尾中追加一个 / 。 此外，static 模块还提供了一些指令可以进一步控制重定向中的一些其他行为，例如是否需要重写 host, port 等信息。 absolute_redirect 功能描述: 设置当uri没有以/结尾时，重定向时是否需要设置完整的uri地址（包含host等信息）。 语法格式: absolute_redirect on|off 默认值: on Context: http, server, location 默认情况下，absolute_redirect 配置是开启的，即当触发301重定向追加/时，重定向响应中会返回完整的重定向地址，该地址包含访问的host信息，并会尝试读取host的信息进行Host替换。 server_name_in_redirect 功能描述: 设置当uri没有以/结尾时，重定向时是否是否配置中的server_name主域名进行替换。 语法格式: server_name_in_redirect on|off 默认值: off Context: http, server, location port_in_redirect 功能描述: 设置当uri没有以/结尾时，重定向时是否对port信息进行替换。 语法格式: port_in_redirect on|off 默认值: on Context: http, server, location content 阶段的 index 模块 在之前的试验中，我们其实已经知道了，当我们通过uri 映射到一个本地的目录时，如果该目录下有index.html文件时，会默认返回index.html文件的内容。 而这个其实就是 index 模块发挥了作用，下面，我们来了解一下 index 模块。 index 功能描述: 当访问指定目录的静态资源时，自动查找该目录下对应的index模块指定的文件。 语法格式: index file 默认值: index.html Context: http, server, location 例如，我们也可以增加index readme.md指令，此时，再次访问指定目录时，将不会再去找index.html文件了，而是会去尝试找readme.md文件。 content 阶段的 autoindex 模块 实际上，访问一个目录时，我们有时不仅仅希望访问指定名称的文件，而是希望查询该目录下包含了哪些文件。 这个就要用到了 autoindex 模块了，autoindex 模块涉及如下指令。 autoindex 功能描述: 是否开启URI以/结尾时，返回指定目录的结构。 语法格式: autoindex on|off 默认值: off Context: http, server, location autoindex_format 功能描述: 设置目录返回结构的格式。 语法格式: autoindex_format html|xml|json|jsonp 默认值: html Context: http, server, location autoindex_localtime 功能描述: 设置目录下文件的时间显示是否显示为本地时间。 语法格式: autoindex_localtime on|off 默认值: off Context: http, server, location Ps: 由于 index 模块的处理顺序早于 autoindex 模块，所以如果该目录下存在index模块指定的文件时，autoindex 模块将会失效，无法返回对应的目录。 content 阶段的 concat 模块 concat 模块是阿里巴巴贡献的第三方 Nginx 模块，专门用于在页面需要访问多个小文件时，可以将它们的文件内容合并到一次请求中完成，提升请求性能。 由于 concat 模块不是 nginx 的内置模块，需要单独安装。 具体来说，首先需要clone concat对应代码： git clone https://github.com/alibaba/nginx-http-concat 然后在编译nginx时，引入对应的模块: --add_module=../nginx-http-concat 那么，这个模块具体应该怎么使用呢？ 它可以帮助用户在访问uri的后面加上??，然后通过多个逗号来分隔多个文件。如果本身还有其他参数，可以在最后通过?追加参数。 例如url如下： https://g.alicdn.com/??kissy/k/6.2.4/seed-min.js,kg/global-util/1.0.7/indexmin.js,tb/tracker/4.3.5/index.js,kg/tb-nav/2.5.3/index-min.js,secdev/sufei_data/3.3.5/index.js 下面，我们来看一下 concat 模块相关的指令： concat 功能描述: 是否启用 concat 文件合并的功能。 语法格式: concat on|off 默认值: off Context: http, server, location concat_types 功能描述: 对哪些文件类型支持文件合并的功能。 语法格式: concat_types MIME types 默认值: text/css application/x-javascript Context: http, server, location concat_delimiter 功能描述: 当返回多个文件内容时，中间使用什么样的分隔符进行分隔。 语法格式: concat_delimiter string Context: http, server, location concat_max_files 功能描述: 当开启多文件合并请求时，最大请求的文件数量。 语法格式: concat_max_files number Context: http, server, location log 阶段 最后，我们来看一下 http 模块 11 个阶段中最后一个阶段 - log 阶段。 log 阶段的核心功能就是将 HTTP 请求相关的信息记录到日志中去，对应的就是 log 模块。 log 模块包含如下一些命令，下面，我们来依次进行说明。 首先是定义日志打印格式: log_format 功能描述: 定义日志打印的格式。 语法格式: log_format name [escape=default|json|none] string; 默认值: log_format combined '$remote_addr - $remote_user [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\"' Context: http 其中，name 是我们针对该定义的 log_format 设置的对应格式名称，在具体设置access log日志位置时，需要使用到。 access_log 功能描述: 设置指定请求的 access log的配置路径等信息。 语法格式: access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 默认值: access_log logs/access.log combined; Context: http, server, location 其中，需要说明的是： path 路径可以包含变量，但是为了避免每一行日志写入都需要打开、关闭日志文件，建议需要配置cache（见后续描述） if 可以通过条件来控制对应请求记录是否需要写入日志。 buffer 可以将批量日志进行缓存，并统一写入磁盘，可以提升性能，写入磁盘的条件包括: 缓存中的日志大小达到buffer的配置、达到flush指定时间、worker进程执行reopen命令等。 gzip 可以批量压缩内存中的日志，再写入磁盘，压缩的默认级别为1（1-9压缩率逐步增高） 上面，我们提到了当 path 中包含变量时，我们需要配置 cache 来保证nginx日志写入的性能，下面，我们来看一下具体应该如何进行配置。 open_log_file_cache 功能描述: 对log_file的句柄进行cache，避免重复打开、关闭文件。 语法格式: open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 默认值: off Context: http, server, location 其中: max 表示缓存中最大的文件句柄数，超过该总数后，使用LRU算法淘汰。 inactive: 文件访问完成后，超时关闭的时间，默认为10s。 min_uses: 在inactive时间内，使用次数至少达到 min_uses 后才会继续在内存中保留，默认为1。 valid: 超过 valid 时间后，将对缓存的日志文件进行检查是否存在，默认为60s。 off: 表示关闭缓存文件句柄的功能。 http 过滤机制 除了上面提到 HTTP 模块处理的 11 个阶段之外，在 Nginx 处理 HTTP 请求中，还有一个非常重要的机制，就是 HTTP 的过滤机制。 HTTP 过滤机制是指对 HTTP 的 content 进行一些处理和过滤，并将处理后的结果返回给客户端。 从执行时机来看，HTTP 的过滤机制通常会在 content 阶段之后，log 阶段之前执行，示例流程图如下所示: 例如上图所示中 gzip 、 image_filter 其实就都是 http 过滤机制来实现的。 HTTP 的过滤机制的实现其实包含了非常多的模块，这些模块分别实现了不同的过滤功能，例如包含的模块如下图所示: 实际在执行的过程中，模块的执行顺序正好与上图相反，即从下向上依次进行执行。 其中，有几个模块的执行时机非常重要，我们来重点关注一下: copy_filter: 读取复制包体的内容，如果想要对数据包内容进行解析，首先需要进行读取包体的信息。 postpone_filter: 处理子请求。 header_filter: 构造响应的头部信息。 writer_filter: 发送响应体信息。 sub模块 下面，我们来看看第一个用于过滤的模块 - sub 模块。 sub 模块默认没有编译进入 Nginx，需要增加 --with-http_sub_module 来启用该模块。 sub 模块的功能是可以对响应中的指定字符串进行替换，替换成新的期望字符串。 sub 模块涉及到如下4个指令，我们来依次看一下。 sub_filter 功能描述: 对指定字符串进行替换，将指定string替换成为replacement。 语法格式: sub_filter string replacement; Context: http, server, location sub_filter_last_modified 功能描述: 设置替换字符串后，是否需要在响应头部中传递last modified信息。 语法格式: sub_filter_last_modified on|off; 默认值: off Context: http, server, location sub_filter_once 功能描述: 设置替换字符串时，是否针对每个字符串最多仅替换一次。 语法格式: sub_filter_once on|off; 默认值: on Context: http, server, location sub_filter_types 功能描述: 设置针对哪些响应格式的数据才进行替换。 语法格式: sub_filter_types mime-type; 默认值: text/html Context: http, server, location addition 模块 下面，我们再来看一下 addition 模块。 addition 模块默认没有编译进入 Nginx，需要增加 --with-http_addition_module 来启用该模块。 addition 模块的功能是可以在原始的响应前后分别通过请求新的url，并将新url的响应组装到原有响应的前后，得到一个新的响应结果。 addition 模块的使用涉及到如下三个指令，下面我们来依次了解一下。 add_before_body 功能描述: 在原有响应的前面追加body信息。 语法格式: add_before_body uri; Context: http, server, location add_after_body 功能描述: 在原有响应的后面追加body信息。 语法格式: add_after_body uri; Context: http, server, location addition_types 功能描述: 设置针对哪些响应格式的数据才进行前后请求和响应组装。 语法格式: addition_types mime-type; 默认值: text/html Context: http, server, location Nginx 变量 变量是 Nginx 中最核心的功能之一，通过 nginx 变量，我们可以获取很多相关信息甚至是控制部分 Nginx 的行为。 此外在 Nginx 中，很多模块存在的唯一作用就是去生成一些特定的变量供我们使用，因此，在继续后续的模块学习之前，我们需要先来了解一下 Nginx 中变量的基本机制。 首先，Nginx的变量是有来源的，例如，各个模块甚至Nginx系统本身都会提供一些变量，而一旦这些变量被创建出来，就可以在后续nginx的其他流程中直接进行使用了。 其次，Nginx的变量不是一成不变的，在各个模块的处理流程中都可能会有一些已经存在的 nginx 变量进行修改，而 Nginx 变量在具体使用时，则是以当前阶段的变量值为准。 下面，我们来大致了解一下 Nginx 框架本身提供了哪些类型的变量: HTTP 请求相关的变量 TCP 连接相关的变量 Nginx 请求处理过程中的变量 发送 HTTP 响应时相关的变量 Nginx 系统变量 下面，我们依次来进行说明。 HTTP 请求相关的变量 变量名称 变量含义 arg_参数名 url中某个参数具体传递的值 http_头key 返回Header中指定Key对应的值 args 全部url参数 query_string 同args is_args 判断请求url中是否包含参数，包含则返回?，否则返回空 content_length HTTP请求中标识包体长度的Content-Length头部的值 content_type 标识请求包体类型的Content-Type头部的值 uri 请求的URI（不包括?后的参数） document_uri 同uri request_uri 请求的url，包括?后的请求参数 scheme 协议名称，例如http,https等 request_method 请求方法，例如GET或者POST request_length 请求体的大小，包括请求行、头部、包体等 remote_user 由HTTP Basic Auth协议传入的用户名 request_body_file 临时存放请求包体的文件 request_body 请求中的包体，当且仅当在反向代理且使用内存暂存包体时有效 request 原始请求行，包括方法，URL，协议版本等 host 优先获取Host头部，找不到的话从请求行中获取，还找不到的话，返回Nginx中匹配的server_name TCP 连接相关的变量 变量名称 变量含义 server_addr 服务器端地址（Nginx侧） server_port 服务器端端口（Nginx侧） server_protocol 服务器端协议，例如HTTP/1.1 binary_remote_addr 客户端地址的整型格式 remote_addr 客户端地址 remote_port 客户端端口 proxy_protocol_addr 从proxy_protocol协议中返回的客户端地址 proxy_protocol_port 从proxy_protocol协议中返回的客户端端口 connection 递增的连接序号 connection_requests 当前连接上执行过的请求数目，当且仅当keep-alive模式下有意义 TCP_INFO TCP内核层参数 Nginx 请求处理过程中的变量 变量名称 变量含义 request_time 请求处理到现在的耗时，单位为秒，精确到毫秒 server_name 匹配到的Server块的server_name https 是否开始了TLS/SSL协议，开启返回 on ，否则返回空 request_completion 请求处理完成，则返回 OK ，否则返回空 request_id 以16进制输出的请求标识ID，随机生成 request_filename 待访问文件的完整路径 document_root 待访问文件的所属目录 realpath_root 待访问文件的所属真实目录（软链对应的目录） limit_rate 客户端响应时的速度上限，单位为字节数/s，可以通过set 指令进行设置 发送 HTTP 响应时相关的变量 变量名称 变量含义 senthttp头部key 响应头部中某个具体key对应的取值 body_bytes_sent 响应中body包体的长度 bytes_sent 全部http响应的长度 status http响应中的返回码 Nginx 系统变量 变量名称 变量含义 time_local 以本地时间标准输出的当前时间，例如 14/Nov/2018:15:55:37 +0800 time_iso8601 使用 ISO8601 标准输出的当前时间，例如 2018-11-14T15:55:37+08:00 nginx_version Nginx 版本号 pid 所属 worker 进程的进程 id pipe 使用了管道则返回 p，否则返回 . hostname 所在服务器的主机名，与 hostname 命令输出一致 msec 1970 年 1 月 1 日到现在的时间，单位为秒，小数点后精确到毫秒 referer 模块 - 简单的防盗链方式 首先，我们来了解一下防盗链的场景是什么样的。 例如，我们的网站内部有一些比较优质的资源，我们希望这些相对优质的资源只能给我们网站的用户单独使用。 而可能有另外一些网站直接在它们的网站页面中嵌入了我们对应页面的url，从而希望可以直接从它们的网站中获取我们的资源，实现提升它们网站的流量。 那么，我们应该怎么样拒绝这种非正常的网站跳转访问我们站点的资源呢？ 此处，我们需要先提及了一个各个浏览器中默认都包含的规则，即在浏览器发送 HTTP 给后端服务器时，会将当前浏览器所在的页面 url 带上加入 header 中， 告诉服务器本地的请求是来自于哪些页面发起的。 而正是由于浏览器可以帮助我们向服务器传送请求来源的url信息，因此，我们其实可以根据浏览器传送过来的信息，进行判断是否允许该请求访问。 而这个过程中，浏览器用于传递来源信息的方式就是 header 中的 referer 字段，而 nginx 用于处理这一问题的模块名称同样是 referer 。 下面，我们先来简单看一下 referer 涉及到的相关指令： valid_referers 功能描述: 设置允许哪些referer的头部信息状态访问。 语法格式: valid_referers none | blocked | server_names | string; Context: server, location 其中: none 表示允许缺失 referer 头部的请求访问 block 表示允许 referer 头部的值为空时的请求访问 server_names 表示当 referer 头部的值与我们 server_name 中设置的域名一致时允许访问 string 表示可以是域名及URL的字符串或者正则表达式，匹配后允许访问，需要主要的是，对于域名而言，可以使用前后缀 * 做通配符。 valid_referers 指令接收的参数可以是多个，多个参数之间用空格分隔，条件之间是 或 的关系。 另外，需要注意的是，valid_referers 指令判断是否应该允许访问后，如果预期不允许访问，不是直接对请求进行拦截，而是会生成一个 invalid_referer 变量。 允许访问时，变量值为空 不允许访问时，变量值为1 需要用户自行根据 invalid_referer 变量的值，来进行条件判断编写相应的行为。 referer_hash_bucket_size 功能描述: 设置 referer Hash 缓存的 bucket 大小。 语法格式: referer_hash_bucket_size size; 默认值: 64 Context: server, location referer_hash_max_size 功能描述: 设置 referer Hash 缓存的最大值。 语法格式: referer_hash_max_size size; 默认值: 64 Context: server, location 一个关于 referer 模块使用的示例代码如下: server_name referer.missshi.cn location / { valid_referer none blocked server_names *.missshi.com www.missshi.org/nianshi ~\\.baidu\\.; if ($invalid_refer) { return 403; } return 200 'valid'; } secure_link 模块 - 更强大的防盗链工具 首先，我们来看一下上述 referer 方案有什么缺点~ 很明显，上述方案能够正常 work 的很大的一个前提是浏览器遵循了一个规则: 向后端服务器发送查询请求时，会自动添加一个 referer 的header字段。 但是，如果我们不是通过浏览器，而是通过其他客户端呢？那基本可以认为整个 referer 防盗链就完全失效了。 下面，我们来了解一种更加强大和灵活的防盗链模块 - secure_link 。 secure_link 默认是没有编译至 Nginx 中的，需要用户手动添加 --with-http_source_link_module 来启用。 下面，我来简单描述一下 secure_link 可以用于防盗链的基本原理。 服务端对对外提供的 url 进行哈希算法加工，使得它变成一个加密的字符串，并将该 url 提供给客户端。 客户端使用该 url 访问资源时，进入了 Nginx 服务器，Nginx 服务器的 secure_link 模块判断请求的url是否符合对应的哈希规则，从而来判断请求是否可以通过。 具体来看，上面主体的交互逻辑都借助了一个加密后的字符串，而这个加密字符串通常是由以下几部分有序的组成的： 资源位置，例如HTTP指定资源的URI，防止攻击者拿到某个安全URL后可以访问任意资源。 用户信息，例如用户的IP地址，限制其他用户盗用URL 时间戳，是安全URL具备过期等机制。 密钥，在服务端和Nginx端拥有，避免攻击者可以猜出来原始字符串的组成方式。 具体来看，secure_link 模块包含两种不同的使用方式，方式一更加强大，方式二使用更加便捷。 我们先来了解方式一。 在方式一中，涉及到如下两个 secure_link 模块的指令，我们先来简单了解一下: secure_link 功能描述: 设置 secure_link 的匹配方式。 语法格式: secure_link expression; Context: http, server, location secure_link_md5 功能描述: 设置 secure_link md5值的构建方式。 语法格式: secure_link_md5 expression; Context: http, server, location 在方式一中，我们可以自主设置加密字符串的构建规则，并通过 secure_link 指令计算得到 secure_link 变量，从而可以通过 secure_link 变量的值来判断请求是否可以通过。 secure_link 变量的取值可能包含如下几种： 空字符串: 验证不通过 0: 验证通过但是url已经过期 1: 验证通过 下面，我们来通过一个配置示例来了解一下具体的使用方式。 Nginx 的配置如下： secure_link $arg_md5,$arg_expires; secure_link_md5 \"$secure_link_expires$uri$remote_addr secret\"; 上述 nginx 的配置表示: 我们的加密字符串的加密规则应该是将 『时间戳 URI 客户端IP 和 密钥secret』直接拼接在一起，然后进行 md5 加密。 在url安全验证时，我们会从arg参数中获取md5 和 expires的参数，与期望结果进行匹配。 了解了第一种方式之后，我们再来了解一下第二种方式，第二种方式相对来说使用起来更简单一些，同样，直接的功能也相对局限，仅能对URI部分进行加密。 它用到了如下指令： secure_link_secret 功能描述: 设置 secure_link 的密钥。 语法格式: secure_link_secret secret; Context: http, server, location 我们先来看一下方式二的基本原理，对于方式二而言，它认为任何一个安全的请求URL应该包括三个部分，分别是 /prefix/hash/link 。 其中，中间部分的 hash 的计算方式是对 『最后一部分的url（如link）』和『提前设置到的secret』进行拼接，然后进行 md5 得到的结果。 然后，nginx 在进行 URL 处理时，会根据 Nginx 中设置的secure_link 的密钥与请求URL共同判断是否为安全URL。 此时，它的 Nginx 配置非常简单，仅需要配置 secure_link_secret 即可。 secure_link_secret secret map 模块 - 基于已有变量来生成新的变量 map 模块在 nginx 中作用是可以根据一个变量的不同条件，来创建一些新的变量，并对新的变量进行赋值。 从功能上来看，map 模块的功能非常类似于很多编程语言中的 switch {case ... default ... } 的语法结构。 其中，map 模块涉及到如下变量，我们先来简单了解一下： map 功能描述: 根据一个变量的不同条件，来创建新的变量。 语法格式: map string $var { ... }; Context: http map_hash_bucket_size 功能描述: 设置存放map的buctet块大小。 语法格式: map_hash_bucket_size size; 默认值: 32/64/128 Context: http map_hash_max_size 功能描述: 设置存放map的最大大小。 语法格式: map_hash_max_size size; 默认值: 2048 Context: http 具体来说，map 模块基于 已有变量 ，使用类似 switch {case: ... default: ...} 的语法创建新的变量。 从而，可以为其他基于变量值实现功能的模块提供更多的可能性。 下面，我们展开来对 map 模块的相关功能进行说明： 对于 map 中基于的已有变量，即语法中的 string ，它可以是字符串、也可以是一个或多个变量、还可以是字符串和变量的组合结果。 在 {} 内部的 Case 规则匹配中，存在如下多种情况： 如果是字符串时，则进行严格匹配。 如果 {} 内部使用了 hostnames 指令，则可以对域名使用前后缀泛域名匹配。 ~ 和 ~* 表示正则表达式匹配，其中，后者表示忽略大小写。 当没有匹配到任何规则时，默认是否 default 对应的值，如果没有定义 default 时，则返回空字符串给新变量。 此外，我们来可以通过 include 语法来提升可读性、使用 volatile 禁止变量值缓存。 在最后，我们来看一下示例吧： map $http_host $name { hostnames; default 0; map.missshi.com 1; map.missshi.* 2; ~map\\.miss\\w+.com 3; } 上述表达式表示从 HTTP 请求头部中找出 host 字段的值，然后与下述选项进行匹配，并且将匹配项的对应值（0，1，2，3）赋予变量 name 。 split_clients 模块 - 基于指定变量实现A/B测试（生成百分数变量） 与 map 模块非常类似，split_clients 模块也提供了一个基于已有变量生成新变量的方法，区别在于它生成的变量是可以按照一定的概率来生成变量， 因此天然适用于A/B测试的场景。 下面，我们就来了解一下 split_clients 模块的原理和功能吧。 具体来说： split_clients 模块对已有变量的值进行 MurmurHash2 算法进行处理，会得到一个 32 位的整型哈希数字。 而对于一个无符号的 32 位的整型数字而言，它的取值区间为 [0, 2^32 - 1] ，记为 max 。 那么，将得到的哈希数字 / 最大数字max，我们就可以得到一个 (0, 1) 区间的百分比数字。 而 split_clients 模块就是针对该百分比数字进行分配变量，即我们可以在配置中，设置各个赋值的百分比概率，然后 split_clients 模块 针对指定输入进行百分比计算，并将计算得到的结果分配到对应的区间中，并将对应的值赋予新的变量。 那么，对于 split_clients 模块的 Case 规则而言，需要满足如下条件: 百分比支持小数点后2位，且所有项的百分比相加不能超过100% 。 当各项之和加起来小于 100% 时，可以使用 * 来匹配剩余的百分比。 我们来看一个示例配置: split_clients \"${http_testcli}\" $varint { 10.51% one; 20% two; 50% three; * four; } 上述配置表示对于一个请求而言，我们会对它的请求 Header 中的 testcli 对应的值取 hash ，并计算其对应的百分比。 其中: 有 10.51% 的概率将 varint 变量设置为 one; 有 20% 的概率将 varint 变量设置为 two; 有 50% 的概率将 varint 变量设置为 three; 有 1 - 10.51% - 20% - 50% 的概率将 varint 变量设置为 four; geo 模块 - 基于 IP/CIDR 生成新的变量 下面，我们又要认识一下 geo 模块了， geo 模块同样是基于已有变量来创建一个新的变量，区别在于它基于的是客户端的地址，如IP地址或CIDR信息。 geo 功能描述: 基于客户端地址来设置新的变量。 语法格式: geo [$address] $variable { ... }; Context: http 下面，我们来了解一下 geo 模块的匹配规则： geo 指令后如果没有传入 address 变量时，默认使用 $remote_addr 变量作为 IP 地址。 当 {} 中使用了 proxy 指令设置了可信地址，则此时 $remote_addr 的值为 X-Forwarded-For 头部值中最后一个 IP 地址。 当 {} 中使用了 proxy_recursive 时，可以进行循环地址搜索，即从 X-Forwarded-For 头部值中排除 server_name 匹配值。 geo 指令在匹配时，可以通过 IP地址和子网掩码的方式进行匹配，多个项同时匹配时，优先匹配最大的地址。 当所有IP和子网掩码均没有匹配到时，则使用 default 的值设置为新变量的值。 为了代码的可读性，建议将 geo 指令块访问一个单独的文件中，通过 include 指令来引入即可。 一个示例代码块如下： geo $country { default XX; proxy 11.11.22.101 127.0.0.1/24 US; 127.0.0.1/32 RU; 10.1.10.0/16 RU; 192.168.1.9/24 UK; } geoip 模块 - 根据指定 IP 找出对应的地理位置信息 可以看出，在上面的例子中，我们尝试跟进不同的 IP 属于不同的 IP 来推断该客户端的来源，例如来源于哪个国家或者城市。 但是，如果所有的国家和城市如果都需要我们一个个写到配置文件中，显然是成本很大且不现实的。 那么，有没有现成的模块或者配置存储了各个国家和城市的IP段信息呢？那么，我们只要使用该模块就可以轻松的得到当前请求来源的国家和城市了。 幸运的是，Nginx 中的确已经有了这么一个模块: geoip 。 简单的说，geoip 模块基于 MaxMind 数据库，可以根据客户端地址从数据库中查询出该IP属于哪个国家和地区，并将相应信息赋予了对应的变量，从而让我们可以轻松的使用。 geoip 模块默认并没有编译进入 Nginx 中，需要使用 --with-http_geoip_module 参数。 然后，除了增加该参数外，我们还需要下载 MaxMind 里 geoip 的 C 开发库 。 同时，在 nginx 配置文件中，我们还需要指定 geoip_country 和 geoip_city 对应的文件在本地的绝对路径。 下面，我们来看一下 geoip 涉及到的指令： geoip_country/geoip_city 功能描述: 指定 geoip_country/geoip_city 文件在本机的绝对路径。 语法格式: geoip_country/geoip_city file; Context: http geoip_proxy 功能描述: 设置信任地址，来源于信任地址的请求将会从 X-Forwwarded-For 中使用最后一个 IP 作为来源 IP。 语法格式: geoip_proxy address/CIDR; Context: http 对于 geoip_country 指令而言，我们可以得到如下变量： geoip_country_code: 两个字母的国家代码，例如CN或者US geoip_country_code3: 三个字母的国家代码，例如CHN或者USA geoip_country_name: 国家名称，例如 China 或者 United States 对于 geoip_city 指令而言，还可以额外得到如下变量: geoip_city_continent_code: 属于全球哪个洲，例如EU或者AS等。 geoip_region: 洲或者省的编码，例如02 geoip_region_name: 洲或者省的名称 geoip_city: 城市名称 geoip_postal_code: 邮编号 geoip_latitude: 纬度 geoip_longitude: 经度 Nginx 对客户端 Keep-Alive 的支持 本文的最后，我们再来简单的聊一下 Nginx 如何对客户端进行 keep-alive。 我们都知道，keep-alive 机制是指多个 HTTP 请求可以复用 TCP 连接，从而可以： 减少握手次数 减少并发连接数，降低服务器的资源消耗 降低TCP拥塞控制的影响 那么，我们来看一下 HTTP 协议中对 keep-alive 机制有哪些定义。 在 HTTP 协议中，对于请求头和响应头中，都包含一个 connection 字段，取值可以是 close 或者 keepalive， 分别表示请求处理完成后立刻关闭连接、复用连接处理下一个请求。 此外，在服务端返回客户端请求时，还可以返回一个 Keep-Alive 头部，其值是 timeout=n ，其中，n的单位是s，表示告诉客户端连接至少保留 n 秒。 下面，我们来看一下 Nginx 中对于与客户端保持 keep-alive 涉及到哪些指令： keepalive_disable 功能描述: 针对指定浏览器类型禁用keep-alive机制。 语法格式: keepalive_disable none | brower; 默认值: msie6 Context: http, server, location keepalive_requests 功能描述: 设置一个keep-alive 连接最多处理的 HTTP 请求数量。 语法格式: keepalive_requests number; 默认值: 100 Context: http, server, location keepalive_timeout 功能描述: 设置 keep-alive 的超时断开时间。 语法格式: keepalive_timeout timeout [header_timeout]; 默认值: 75s Context: http, server, location By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/proxy.html":{"url":"middleware/nginx/proxy.html","title":"Nginx 反向代理详解","keywords":"","body":"Nginx 反向代理详解 在本文中，我们将会详细介绍一下在 Nginx 中，反向代理与负载均衡是如何实现和使用的。 HTTP 反向代理流程主体 首先，我们来看一下在 Nginx 中，对于一个 HTTP 反向代理的场景而言，它的完整处理流程是什么样的。 可以看到: HTTP 反向代理的工作是从 content 阶段开始的。 首先会判断是否命中了之前的 cache, 如果命中则直接返回，否则继续。 然后根据相关指令和接收到的 header 来生成发往上游的 http 头部。 读取客户端发送的包体信息。 根据负载均衡策略选择对应的上游服务器。 根据参数连接上游服务器。 向上游服务器发送请求。 接收上游服务器响应的头部。 处理上游服务器的响应头部。 接收上游服务器的响应体。 发送给客户端响应头部。 发送给客户端响应体。 如果开启了cache，则将响应信息写入cache。 关闭或复用连接，结束本次反向代理请求任务。 了解了一次 HTTP 反向代理的主体流程之后，下面，我们将根据主体流程的步骤，来依次说明每个步骤中，Nginx 的相关指令与功能。 HTTP 协议的反向代理 - proxy 模块 我们首先要来了解的第一个模块就是 proxy 模块了。 proxy 模块是 Nginx 中用于对上游服务进行 http/https 协议进行反向代理的核心模块。 指定上游服务地址 proxy 模块中，包含了一个 proxy_pass 指令，这个也是反向代理的入口指令，用于设置对应的上游服务的地址。 proxy_pass 功能描述: 指定反向代理的上游服务地址。 语法格式: proxy_pass URL; Context: location 可以看到，看起来 proxy_pass 模块仅仅接收一个 URL 参数，比较简单，但是其实 URL 参数本身有着一些规则，使用中需要非常注意，下面我们来了解一下： URL 必须以 http:// 或者 https:// 开头，后面接域名、IP、unix socket地址或者upstream名称，最后是一个可选的 URI。 URL 中是否携带 URI 会导致对上游请求转发的行为完全不同，具体来说： 当不携带 URI 时，客户端请求中的URL会直接转发给上游，里面location中使用了正则表达式，@名字时，一般采用该方式。 当携带 URI 时，客户端请求中的URL会将location参数中匹配的部分替换为 proxy_paas 中携带的 URI 内容。 URL参数中，也可以携带?+变量。 了解完反向代理的入口指令后，我们接下来继续了解一下 Nginx 在 HTTP 反向代理中是如何生成向上游服务器发送的 http 头部和包体的。 Ps: 由于 cache 部分相对独立，我们后续统一进行说明。 HTTP 反向代理中生成发往上游的请求其实主要包含三个部分： 请求行 请求头部 请求体 下面，我们来依次进行说明： 生成请求行 HTTP 反向代理中，生成发往上游服务请求行中，主要包含如下两个指令: proxy_method 功能描述: 设置/修改 HTTP 反向代理发往上游请求的请求方法。 语法格式: proxy_method method; Context: http, server, location 在生成发往上游服务请求行时，默认会使用客户端发往 nginx 的请求方法，但是你也可以通过 proxy_method 指令进行修改。 proxy_http_version 功能描述: 设置/修改 HTTP 反向代理发往上游请求的HTTP协议版本。 语法格式: proxy_http_version 1.0|1.1; 默认值: 1.0 Context: http, server, location 在生成发往上游服务请求行时，默认会使用HTTP 1.0协议与上游服务进行通信，可以手动调整为HTTP 1.1。 生成请求头部 下面，我们来看一下 HTTP 反向代理中如何生成向上游服务发送的 HTTP 请求头部。 proxy_set_header 功能描述: 设置/修改 HTTP 反向代理发往上游请求头部的指定字段。 语法格式: proxy_set_header field value; 默认值: Host: $proxy_host; Connection close; Context: http, server, location Ps: 在上述 proxy_set_header 命令中，如果指令的 value 为空字符串，那么，对应的key-value其实都不会发送。 proxy_pass_request_headers 功能描述: 设置 HTTP 反向代理发往上游请求头部时是否将客户端发送过来的头部全部带过去。 语法格式: proxy_pass_request_headers on|off; 默认值: on Context: http, server, location 默认情况下，客户端发送给 Nginx 的请求头部，Nginx 会全部直接转发给上游业务服务。 生成发往上游的包体 接下来，我们来看一下 HTTP 反向代理中如何生成向上游服务发送的 HTTP 请求体。 proxy_pass_request_body 功能描述: 设置 HTTP 反向代理发往上游请求包体时是否将客户端发送过来的包体全部带过去。 语法格式: proxy_pass_request_body on|off; 默认值: on Context: http, server, location 默认情况下，客户端发送给 Nginx 的请求包体，Nginx 会全部直接转发给上游业务服务。 proxy_set_body 功能描述: 手动设置 HTTP 反向代理发往上游的请求包体。 语法格式: proxy_set_body value; Context: http, server, location 除了直接转发客户端发送过来的请求体之外，Nginx HTTP 反向代理中，也允许自定义请求包体发送给上游业务服务。 客户端的包体接收方法 从之前的 HTTP 反向代理逻辑图中，我们其实可以看到，在 Nginx 处理客户端发送过来的包体时，有两种不同的处理方式。 方案一: 先将客户端发送过来的请求包体全部接收下来，然后在与上游服务器建立连接统一发送。 方案二: 先与上游服务器建立连接，然后在一边接收客户端的请求，一边发送给上游服务器。 这两种方式在 Nginx 的反向代理服务器中，可以说是各有优劣，下面，我们来展开说明： 对于方案一而言，比较适合于客户端网速较慢，服务端网速很快且服务端并并发连接数比较敏感的场景，在该场景下，由于 Nginx 会完整接收到客户端 的包体后再将服务端发送请求，所以可以有效的避免服务端的连接浪费，降低服务端的压力。 而对于方案二而言，可以更加及时的将请求信息发送给服务端，无需等待Nginx完全接收完客户端的请求，同时对于Nginx自身而言，可以有效降低nginx读写 磁盘的消耗（因为在方式一中，如果包体较大的话，nginx会先讲包体写入一个临时文件，然后时再从临时文件中读取）。 具体选择哪个方案，这个其实是需要从业务的角度来进行考虑的。 那么，在 nginx 中，又是如何配置该方案呢？下面，我们来讲解 proxy_request_buffering 指令： proxy_request_buffering 功能描述: 设置 HTTP 反向代理时，接收客户端包体和发送服务端包体的先后依赖关系。 语法格式: proxy_request_buffering on|off; 默认值: on Context: http, server, location 也就是说，默认情况下，Nginx 会先将客户端发送过来的包体接收完成，然后再与上游服务端建立连接并发送包体。 那么，我们下面来看一下具体Nginx是怎么接收客户端包体信息的。 首先，Nginx 在接收客户端发送头部信息的时候，可能会当头部信息传输完成后，顺带传递部分包体信息进来，此时将会出现如下一些情况： 接收头部时，顺带已经将包体全部接收了，此时，针对包体的接收，则无需再做任何操作，已经接收完成了，否则如下。 根据头部中说明的包体的大小，计算待剩余接收的包体大小，此时，如果剩余包体并不算太大时（小于client_body_buffer_size），直接分配对应内存接收body。 如果剩余的包体很大时，那么，我们会将body信息写入临时文件来进行保存，然后发送请求时，再从临时文件中读取。 通过上述的描述，我们知道在这一个过程中，有一个阈值对包体的接收非常重要，即 client_body_buffer_size 。 下面，我们来看一下如何配置 client_body_buffer_size： client_body_buffer_size 功能描述: 设置 HTTP 反向代理时，使用内存接收包体的大小限制。 语法格式: client_body_buffer_size size; 默认值: 8k|16k Context: http, server, location 此外，在接收包体的配置中，还有一个参数也比较重要，就是 client_body_in_single_buffer : client_body_in_single_buffer 功能描述: 设置 HTTP 反向代理时，接收客户端包体时，设置是否在单一buffer块中保存包体。 语法格式: client_body_in_single_buffer on|off; 默认值: off Context: http, server, location 如果我们在 nginx 的配置中，频繁使用了 request_body 变量的话，那么建议开启该配置，直接可以避免频繁的内存拷贝操作。 在接收客户端包体信息中，我们还可以设置客户端发送包体的最大长度： client_max_body_size 功能描述: 设置 HTTP 反向代理时，设置接收客户端包体的最大长度。 语法格式: client_max_body_size size; 默认值: 1m Context: http, server, location Nginx 中，会对请求头部中的 Content-Length 进行判断，如果超出我们设置的最大长度时，会直接返回 413 错误。 除了最大长度之外，我们还可以设置接收包体的超时时间: client_body_timeout 功能描述: 设置 HTTP 反向代理时，设置接收客户端接收包体时包体发送的数据间隔超时时间。 语法格式: client_body_timeout time; 默认值: 60s Context: http, server, location 之前，我们已经提到了当客户端发送的包体大小超过我们设置的阈值时，nginx 会先讲包体的内容保存在一个临时文件中，那么，具体关于临时文件保存， 有如下两个配置： client_body_temp_path 功能描述: 设置 HTTP 反向代理时，接收客户端包体后，如果需要保存临时文件时，临时文件所在的路径。 语法格式: client_body_temp_path path; 默认值: client_body_temp Context: http, server, location client_body_in_file_only 功能描述: 设置 HTTP 反向代理时，接收客户端包体后，是否需要保存在临时文件中。 语法格式: client_body_in_file_only on||clean|off; 默认值: off Context: http, server, location 其中： on: 表示针对每个请求，都创建一个临时文件保存包体，并且保留临时文件不删除，主要用于debug等场景。 clean: 表示针对每个请求，都创建一个临时文件保存包体，但请求完成后，删除对应临时文件。 off: 按需创建临时文件，临时文件用完后自动删除。 Nginx 负载均衡策略 在接收完成客户端发送来的请求并且生成需要发送给上游服务的请求信息后，下面要做的就是根据负载均衡策略选择上游服务器了。 而关于负载均衡，这是一个很大的话题，我们来展开聊一聊。 首先，来看一下负载均衡可以帮我们做一些什么。 随着现在互联网业务用户的不断扩大，单个实例提供的访问能力始终是有限的，因此，我们往往会针对一个服务部署一组实例，从而能够共同分担请求压力。 而对于用户或者下游服务而言，我们又需要一个统一的请求入口，这时，Nginx 负载均衡/反向代理就要登场了。 Nginx 负载均衡可以提供一个统一的入口，并将请求转发给一组上游的业务服务器，同时，当上游的业务服务器需要宕机、扩容等状态时，负载均衡器可以将流量 转发至其他正常运行的业务服务器上，从而不影响整体业务和用户。 那么，我们具体来看一下 Nginx 是如何来帮助我们进行负载均衡的： 从上图可以看出，Nginx 的反向代理和负载均衡主要可以分为三个方面： 首先是最简单的水平扩展，水平扩展是指上游业务服务是无状态的，且每个实例能处理也业务逻辑完全一致，此时，可以通过Round-Robin或者Least-Connected算法来将请求相对均匀的分发给上游业务服务器。 其次，有时我们期望能够将不同地域的请求发送到就近的服务器，或者将不同的用户请求发送到不同的服务时，可以根据请求的信息来进行映射到特定实例。 此外，当我们希望把一个单体应用拆分为多个微服务时，可能多个服务提供不同的url和功能，但是我们希望能有一个统一的入口对外访问，此时，就可以用到Nginx中基于URL对不同的功能请求进行分发了。 下面，我们来看一下 Nginx 都支持哪些协议吧： 可以看出，Nginx 既可以处理 4 层的 udp, tcp 协议（支持的功能比较简单），也可以处理 7 层的 HTTP 协议。 尤其是对于 7 层协议而言，Nginx 的反向代理能力非常强大，甚至可以在客户端发送过来 HTTP 请求转发成为其他各种协议并发送给上游业务服务器。 除此之外，在反向代理中，缓存也是非常重要的一环。 如上图所示，对于同一个资源请求而言，如果用用户在一段时间内请求过之后，Nginx 可以将响应内存先在本地暂存，而在暂存的时间内，如果又有请求 访问相关的资源时，那么，此时 Nginx 可以将本地暂存的结果直接返回给客户端，而不需要再次去访问上游服务了。 这样一来，一方面可以大幅度的上游服务的业务压力，另一方面，也可以有效的降低客户端请求资源的耗时。 了解了基本的原理之后，下面我们来介绍一些负载均衡与上游配置相关的一些 Nginx 指令吧，从而了解一下如何使用 Nginx 的负载均衡功能。 首先，我们需要指定上游服务的地址，这里面涉及到两个指令，分别是 upstream 和 server 指令。 upstream 功能描述: 设置上游服务的名称和对应的上游服务的配置。 语法格式: upstream name {...}; Context: http server 功能描述: 设置上游服务的具体地址和访问策略。 语法格式: server address [parameters]; Context: upstream 其中，address 可以是域名、IP地址或者unix socket地址，对于域名和IP而言，后面可以加端口，默认为80端口。 其中，常用的 parameters 参数包括： weight: 服务访问的权重，默认是1。 max_conns: Server 的并发连接数，仅作用于单个worker，默认为0，表示无限制。 max_fails: 指定时间内最大访问的失败次数，达到最大失败次数后，指定时间内不会再访问该实例。 fail_timeout: 单位为s，默认为10，表示一段时间内的最大失败次数，以及达到最大失败次数后不能访问的时间。 back: 指定对应实例为备份实例，仅当其余实例不可用时，才会转发至该server down: 标识该实例已经下线，不在服务 除了基本的上游地址配置之外，我们还可以对上游服务来建立 keep-alive 的长连接。 Ps: 在上一篇文章中，我们已经介绍过了Nginx如何与客户端建立长连接，接下来，我们就来交接一下nginx如何与上游服务建立长连接。 keepalive 功能描述: 设置与上游服务最多建立的长连接的数目。 语法格式: keepalive number; Context: upstream keepalive_requests 功能描述: 设置与上游服务建立的每个长连接最多处理的请求个数。 语法格式: keepalive_requests number; 默认值: 100 Context: upstream keepalive_timeout 功能描述: 设置与上游服务建立的长连接的超时时间。 语法格式: keepalive timeout; 默认值: 60s Context: upstream Ps: 需要重点说明的是，在 nginx 与上游连接建立连接时，默认使用的是 http 1.0 协议并且头部信息中的 connection 是 closed 。 因此，为了能够与上游服务建立长连接，我们需要在 location 块中主动设置 http_version 和头部信息中的 connection，如下所示： upstream upskeepalive { server 127.0.0.1:8011; keepalive 32; } server { server_name rrups.missshi.com; error_log myerror.log info; location /{ proxy_pass http://upskeepalive; proxy_http_version 1.1; proxy_set_header Connection \"\"; } } 上面描述的负载均衡算法非常简单，只能适用于水平扩展的场景且无法针对请求信息（如客户端来源）进行负载均衡，下面，我们来介绍一些更加高级的一些负载均衡模块。 首先介绍的第一个模块就是基于客户端IP地址的Hash算法来实现的负载均衡 - upstream_ip_hash 。 它可以以客户端的IP地址作为哈希算法的关键字映射到特定的上游服务器中，其中，它也可以基于realip来获取原始客户端的请求IP地址， 同时它还可以复用之前round-robin算法中weight的相关的配置参数。 ip_hash 功能描述: 启动根据客户端IP来进行负载均衡。 语法格式: ip_hash; Context: upstream upstream_ip_hash 只能用于针对客户端IP进行哈希算法，而如果想要根据其他请求特征来进行，那么它就无能为力了。 不过，nginx 中提供了一个更加通用的哈希负载均衡模块 - upstream_hash 。 该模块同样是通过哈希来进行负载均衡，不过它没有强制设置客户端IP作为哈希的key，而是允许用户自定义哈希的key。 hash 功能描述: 启动根据自定义Key来进行哈希，从而实现负载均衡。 语法格式: hash key [consistent]; Context: upstream 其中: key可以是变量、字符串或者是它们的组合。 consistent 表示是否使用一致性hash，一致性hash可以避免当实例数量发生变化时，大批量路由规则变化导致缓存失效的相关问题， 除了使用哈希算法来进行上游选择之外，nginx 还支持优先选择连接最少的上游服务器，这就用到了 upstream_least_conn 模块。 least_conn 功能描述: 启动根据连接数选择当前连接最小的实例进行请求转发。 语法格式: ip_hash; Context: upstream 在上面我们所有的配置中，默认配置都仅仅在单个worker中单独生效，如果想要让所有worker共同生效时，就需要用到 upstream_zone 模块了。 upstream_zone 模块可以用于分配共享内存，将其他upstream模块定义的负载均衡策略数据、运行时每个上游的状态数据存放在共享内存中， 从而生效于所有的worker进程。 zone 功能描述: 分配共享内存，使得共享内存策略在所有worker中共同生效。 语法格式: zone name [size]; Context: upstream 在负载均衡和上游实例选择的最后，我们再看看看 upstream 模块提供了哪些变量可以给我们使用，cache相关的暂时不再此处讨论，后续会有专门的内容来对cache进行说明。 upstream_addr: 上游服务器的ip地址。 upstream_connect_time: 与上游服务器建立连接的耗时，单位是s。 upstream_header_time: 接收上游服务响应头部的耗时，单位是s。 upstream_response_time: 接收完整上游服务响应所消耗的时间，单位是s。 upstreamhttp名称: 上游服务返回的响应头部信息。 upstream_bytes_received: 从上游服务接收到的响应包体长度，单位为字节。 upstream_response_length: 从上游服务返回的响应包体长度，单位为字节。 upstream_status: 上游服务返回的HTTP响应码，如果没有正常连接上，返回值为502。 upstreamcookie名称: 从上游服务返回的响应头中的Cookie中取出对应的cookie值。 upstreamtrailer名称: 从上游服务的响应尾部取到的值。 Nginx 与上游服务建立连接和收发请求 当Nginx均衡策略找到对应上上游服务实例后，接下来就可以与上游服务来建立连接并且收发请求了。 与上游建立连接并发送数据 与上游建立连接时，使用到了如下一些指令： proxy_connect_timeout 功能描述: 设置与上游服务建立连接的超时时间（三次握手时间），达到超时时间后，会返回客户端的响应码为502。 语法格式: proxy_connect_timeout time; 默认值: 60s Context: http, server, location proxy_socket_keepalive 功能描述: 设置使用与上游服务建立 TCP keep alive 机制。 语法格式: proxy_socket_keepalive on|off; 默认值: off Context: http, server, location Ps: 如上图所示，此处表示的是 TCP 协议上的 keep-alive 机制， 通过开启该 keep-alive 机制，可以定期扫描 TCP 连接对端是否已经服务停止等，从而及时释放连接。 此外，在与上游建立连接并发送 TCP 请求时，我们还可以修改 TCP 连接中的 SourceIP 地址。 proxy_bind 功能描述: 设置使用与上游服务 TCP 连接中的 SourceIP 地址。 语法格式: proxy_bind address [transparent] | off; Context: http, server, location Ps: address 可以使用 $remote_addr 来实现 SourceIP 的透传，这时也需要开启 transparent （当address非本地IP时）。 此外，如果我们一台机器上有多块网卡时，也可以通过 proxy_bind 来指定对应的 IP。 另外，当客户端与 Nginx 断开连接时，默认情况下 nginx 也会放弃与上游服务继续访问，但是，我们也可以通过如下配置强制保持与上游服务的交互： proxy_ignore_client_abort 功能描述: 设置当客户端断开连接时，是否需要与上游服务继续交互。 语法格式: proxy_ignore_client_abort on|off; 默认值: off Context: http, server, location proxy_send_timeout 功能描述: 向上游发送请求时的超时时间。 语法格式: proxy_send_timeout time; 默认值: 60s Context: http, server, location 接收上游的响应 接收上游的响应并处理过程中涉及到了如下指令，我们来依次了解一下： proxy_buffer_size 功能描述: 设置接收上游的HTTP响应头部的最大大小。 语法格式: proxy_buffer_size size; 默认值: 4k|8k Context: http, server, location proxy_buffers 功能描述: 设置接收body时可用的内存大小空间，超过该大小时会进行IO操作临时文件保存。 语法格式: proxy_buffers number size; 默认值: 8 4k|8k Context: http, server, location proxy_buffering 功能描述: 设置接收body时是否先把上游响应全部接收下来再返回客户端还是边收边返回。 语法格式: proxy_buffering on|off; 默认值: on Context: http, server, location Ps: 只有开启全部接收后再返回时，我们才能对接收到的信息进行过滤再返回，否则无法进行响应处理。 proxy_max_temp_file_size 功能描述: 设置接收body并保存到临时文件时的最大大小，即能接收上游响应的最大值。 语法格式: proxy_max_temp_file_size size; 默认值: 1024m Context: http, server, location proxy_temp_file_write_size 功能描述: 设置接收body并保存到临时文件时，每次写入的块大小。 语法格式: proxy_temp_file_write_size size; 默认值: 8k/16k Context: http, server, location proxy_temp_path 功能描述: 设置接收body并保存到临时文件时，临时文件存放的目录。 语法格式: proxy_temp_path path; 默认值: proxy_temp Context: http, server, location proxy_busy_buffers_size 功能描述: 设置接收body并达到指定大小时，就开始向客户端发送响应信息。 语法格式: proxy_busy_buffers_size size; 默认值: 8k/16k Context: http, server, location proxy_read_timeout 功能描述: 从上游服务中两次读数据的请求间隔时间。 语法格式: proxy_read_timeout time; 默认值: 60s Context: http, server, location proxy_limit_rate 功能描述: 从上游服务中读取响应中的网速限制。 语法格式: proxy_limit_rate rate; 默认值: 0 Context: http, server, location proxy_store 功能描述: 是否开启上游响应包体的持久化并保存。 语法格式: proxy_store on|off|string; 默认值: off Context: http, server, location 其中： on 表示开启上游响应包体的文件持久化，并保存在 root 目录下。 off 表示关闭上游响应包体的文件持久化。 string 表示开启上游响应包体的文件持久化，并保存在 string 指定的目录下。 proxy_store_access 功能描述: 是否开启上游响应包体的持久化的文件所属用户和权限。 语法格式: proxy_store_access users:permissions; 默认值: user:rw Context: http, server, location 加工和处理上游的响应 在上一篇 http 模块的介绍中，我们已经知道了在 Nginx 中可以使用一些 HTTP 过滤模块对 HTTP 的响应结果进行处理。 而这些过滤模块在反向代理的场景中同样也是有效的。例如： copy_filter: 复制包体内容 postpone_filter: 处理子请求 header_filter: 构造响应头部 write_filter: 发送响应等 在 HTTP 的响应头部中，有一些响应头部是有一些特殊功能的，我们可以使用 proxy_ignore_headers 指令来禁用相关的功能。 proxy_ignore_headers 功能描述: 禁用上游返回的HTTP头部中的包含一些特殊含义的header信息。 语法格式: proxy_ignore_headers field; Context: http, server, location 例如，可以被禁用的头部如下： X-Accel-Redirect: 由上游服务指定在 nginx 内部重定向，控制请求的执行。 X-Accel-Limit-Rate: 由上游服务控制发往客户端的速度限制，等价于limit_rate。 X-Accel-Buffering: 由上游控制是否缓存上游的响应。 X-Accel-Charset: 由上游控制Content-Type中的Charset。 X-Accel-Expires: 由上游控制上游响应响应在 nginx 中的缓存时间，单位为s。 Expires: 控制nginx的缓存时间，优先级低于X-Accel-Expires。 Cache-Control: 控制Nginx的缓存时间，优先级低于X-Accel-Expires。 Set-Cookie: 响应中如果出现了Set-Cookie则不会触发缓存。 Vary: 响应中出现Vary则不缓存。 除了具体特殊功能影响的header之外，还有一些header在nginx中转发过程中会没有意义，因此，nginx在转发过程中，默认会忽略掉一些header信息。 包括如下： Date: Nginx 会重写为Nginx发送给客户端响应头部的时间。 Server: Nginx 会重写为Nginx对应的版本信息。 X-Pad: 通常是Apache为避免浏览器BUG生成的头部，默认忽略。 X-Accel-: 用户控制nginx行为的响应，无需向客户端发送。 如果，我们希望强行保留如上的部分 header 时，可以使用如下指令： proxy_pass_header 功能描述: 强行把上游返回的HTTP头部中的一些header信息传递给客户端。 语法格式: proxy_pass_header field; Context: http, server, location 当然，我们也可以主动忽略掉更多的header字段。例如： proxy_hide_header 功能描述: 忽略上游返回的HTTP头部中的一些header信息。 语法格式: proxy_hide_header field; Context: http, server, location 此外，我们来可以修改上游服务返回的Cookie和Location信息，此处不再赘述了。 上游失败下的容错策略 当 Nginx 作为反向代理时，我们常常会通过负载均衡策略找到一个特定的实例进行请求转发。 然而，在请求到特定的实例时，可能会由于网络问题或者是服务稳定性问题时，请求失败。 这时，为了保证整体服务的高可用性时，我们可以设置在当请求失败时，增加一些重试的策略，例如重新选择其他的上游实例进行重试，这就要用到如下实例了。 proxy_next_upstream 功能描述: 设置当上游实例在哪些情况下访问失败时，需要进行重试。 语法格式: proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_xxx | off; 默认值: error timeout Context: http, server, location 其中: error: 表示连接建立失败。 timeout: 表示连接访问超时。 invalid_header: Header非法。 http_: http返回指定的错误码。 off: 禁用失败重试策略。 proxy_next_upstream_timeout 功能描述: 设置当上游实例访问失败重试时的超时时间。 语法格式: proxy_next_upstream_timeout time; 默认值: 0 Context: http, server, location proxy_next_upstream_tries 功能描述: 设置当上游实例访问失败重试时的最大重试次数。 语法格式: proxy_next_upstream_tries number; 默认值: 0 Context: http, server, location proxy_intercept_errors 功能描述: 当上游响应的响应码大于300时，是否需要将响应码中对应的error_page指令进行对应的处理，默认没有生效error_page指令。 语法格式: proxy_intercept_errors on|off; 默认值: off Context: http, server, location Nginx 的 HTTPS 协议 在 Nginx 中，我们既可以将其当做服务端，对外提供 https 协议，同时，我们还可以将其当做反向代理，用于客户端向上游服务器发起请求，如下图所示。 可以从上图看出，其中涉及到了如下一些指令： 指定自身使用的证书（客户端使用）: proxy_ssl_certificate proxy_ssl_certificate_key 验证服务器证书（客户端使用）: proxy_ssl_verify proxy_ssl_trusted_certificate 验证客户端证书（服务端使用）: ssl_verify_client ssl_client_certificate 指定自身使用的证书（服务端使用）: ssl_certificate ssl_certificate_key Nginx 缓存 我们都知道，在一个项目中，Nginx 一般都是用作代理层，充当客户端与服务端的代理。 因此，对于 Nginx 的缓存而言，其实也包含着两部分： 告知客户端（如浏览器）可以自行缓存相关内容，对于部分资源请求可以无需再次访问 Nginx 。 设置 Nginx 可以缓存部分服务端的响应信息，在下次请求 Nginx 时，无需再次访问上游业务服务器。 下面，我们简单的来对比一下浏览器缓存和 Nginx 缓存： 缓存方式 优点 缺点 浏览器缓存 没有网络消耗、缓存最快 仅仅针对一个电脑用户生效 客户端缓存 提升所有用户体验 用户侧依然需要一定的网络消耗 从上表中，我们可以看到，浏览器缓存和Nginx缓存各自有着它们的优缺点，不过幸运的是，这二者并不是冲突的，我们可以对它们组合使用，从而 达到最好的效果。 浏览器缓存 下面，我们先来从浏览器缓存看起。 你可能会问，我们为什么要看浏览器缓存呢？浏览器缓存不是浏览器做的工作么？和Nginx有什么关系呢？ 实际上，浏览器本身其实是不知道一个资源是否应该被缓存的，而具体的缓存策略，其实是可以在 nginx 中配置的，浏览器只是执行 nginx 响应中配置的缓存策略而已。 上图表示了在一次资源请求中，浏览器是如何来判断自身行为的。 在上图中，我们可以看到一些 Etag, If-None-Match, If-Modified-Since, Last-Modified 的相关的关键词， 下面，我们来对其中涉及的一些核心概念进行说明。 Etag ETag 是 HTTP 响应头中设置资源的特定版本的标识符。 通过 ETag，可以让缓存更加高效，例如在请求时，如果内容对应的标识符没有发生变化时，Web 服务器不需要发送完整的响应。 而如果内容发生变化，使用 Etag 有助于防止资源同时更新相互覆盖。 如果给定的 url 中资源发生更改，则一定要生成新的 Etag 的值，比较 etag 可以用于快速判断资源是否发生变化。 etag 功能描述: 是否自动为响应生成etag头部。 语法格式: etag on|off; 默认值: on Context: http, server, location 其中，Etag 的生成规则也比较简单，通常是使用 last_modified_time 与 response_content_length 拼接得到。 If-None-Match If-None-Match 是一个条件式请求首部，它是通过带着 etag 信息去服务器请求，判断是否有新的资源更新。 对于 GET 和 HEAD 请求而言，当服务器资源的 ETag 与请求中的 Headers 信息不匹配时，响应码为200并返回完整信息； 否则服务器端会返回响应码 304 （Not Modified），且不会返回响应体。 Ps: 对于Post等会引发服务器状态变化的请求，ETag 不匹配时，会发送412（前置条件失败）。 If-Modified-Since If-Modified-Since 也是一个条件式请求首部，它是带着 Last-Modified 信息去服务器请求，判断是否有新变更的内容。 只有当服务器对于所请求的资源在给定的日志时间之后，对内容有修改时，才会返回资源内容并返回码为200； 否则，会返回一个不带Body体的304响应，并在 Last-Modified 中带有上次修改时间。 Ps: 当 If-Modified-Since 与 If-None-Match 同时出现时，If-Modified-Since 会被忽略。 了解了浏览器访问的过程之后，我们再来看一下对于 Nginx 而言，具体是如何实现针对浏览器的请求设置缓存策略的吧。 对于 nginx 而言，在该场景中，最核心的就是 not_modified 过滤模块 了。 它的功能是针对客户端不确定缓存是否过期时，在请求中传入了 If-Modified-Since 或 If-None-Match 头部时， 通过将其值与响应中的Last-Modified值相互比较，决定是否通过200返回全部内容还是仅返回304响应码，让浏览器复用之前的缓存。 下面，我们来看一下其中涉及到的一些指令。 expires 功能描述: 告诉客户端该响应信息在多久之后失效。 语法格式: expires max|off|epoch|time; 默认值: off Context: http, server, location 该指令表示告知浏览器该响应的内容可以在多长时间之后失效。 其中，可选项如下： max: 返回 Expires 头部为 2037年12月31号，Cache-Control 为 10年。 off: 不添加 Expires 和 Cache-Control 头部。 epoch: Cache-Control 为 no-cache。 time: 可是设置具体时间，可以携带单位 一天内的指定时刻，例如 @18h30m 正数：设置该值为 Cache-Control 并自动计算 Expires。 负数：设置Cache-Control 为 no-cache，并自动计算 Expires。 Ps: 你可能会好奇为什么会同时有 Expires 和 Cache-Control 呢？ 最早的时候其实时候的是 Expires 字段，但是考虑到服务器时间和浏览器时间可能有差异，因此使用绝对时间会导致缓存时间异常， 因此，增加了一个相对时间的字段，Cache-Control。 目前，优先选择为 Cache-Control 。 了解了 nginx 如何给返回给客户端的响应设置缓存时间后，我们来看一下 Nginx not_modified 过滤模块的完整工作流程。 在上图中，我们又看到了两个我们之前没有接触过的 If-Unmodified-Since 和 If-Match 请求头，下面，我们先来了解一下这两个请求头吧。 If-Unmodified-Since If-Unmodified-Since 也是一个条件式请求首部，它是带着 Last-Modified 信息去服务器请求，判断是否有新变更的内容并进行操作。 只有当服务器对于所请求的资源在给定的日期时间之后，对内容没有修改时，才会返回资源内容或者接收POST之类的变更请求； 否则，就会返回412错误。 If-Unmodified-Since 常常在控制并发的场景中出现，例如避免多人同时编辑等问题中。 If-Match If-Match 是一个条件式请求首部，它是通过带着 etag 信息去服务器请求，判断是否有新的资源更新。 对于 GET 和 HEAD 请求而言，当服务器资源的 ETag 与请求中的 Headers 信息匹配时，响应码为200并返回完整信息； 对于Post等会引发服务器状态变化的请求，ETag 不匹配时，会发送412（前置条件失败）。 针对 modified_since 场景而言，nginx 还提供了一个指令可以控制相关行为： if_modified_since 功能描述: 设置修改时间与上次响应时间在不同条件下的行为。 语法格式: if_modified_since off|exact|before; 默认值: exact Context: http, server, location 其中： off: 忽略请求中的 if_modified_since 头部。 exact: 精确匹配 if_modified_since 头部与 last_modified 的值。 before: 如果 if_modified_since 大于等于 last_modified 的值，则均返回 304 。 Nginx 缓存上游响应 了解了浏览器的缓存和使用方式之后，我们再看来一下 Nginx 的缓存是怎么使用的吧。 proxy_cache_path 功能描述: 设置一个目录用于存放 nginx 缓存数据。 语法格式: proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; Context: http proxy_cache_path 是 Nginx 配置缓存中最重要的指令之一了，它指定了 Cache 在本地存放的目录以及 cache 的相关属性。 下面，我们来依次了解一下相关的参数的含义吧： path: 设置缓存文件存放的路径。 levels: 定义缓存路径的目录层级，最多3级。 use_temp_path: 支持 on|off 。 on 表示先使用 proxy_temp_path 定义的临时目录存放响应，off 表示直接使用 path 目录存放临时文件。建议 proxy_temp_path 和 path 在同一块磁盘上。 keys_zone: 定义 zone 的名称和大小，名称在 proxy_cache 中指定，size 是共享内存大小，1MB 大约存放 8000 个 key。定义一个 zone 之后可以在多个 location 中使用。 inactive: 在 inactive 中没有被访问的缓存会被淘汰，默认为 10min 。 max_size: 最大缓存文件大小，超出后会按 LRU 链表淘汰。 manager_files: cache_manager 进行在一次淘汰过程中，淘汰的最大文件数，默认为100。 manager_threshold: cache_manager 进行在一次淘汰过程中，最大的耗时时间，默认为50ms。 manager_sleep: cache_manager 进行在一次淘汰后的休眠时间，默认为200ms。 loader_files: cache_loader 进程载入磁盘缓存文件至内存时，单次最多处理的文件数，默认为100。 loader_threshold: cache_loader 进程载入磁盘缓存文件至内存时，单次最长耗时，默认为50ms。 loader_sleep:cache_loader 进程载入磁盘缓存文件至内存一次后的休眠时间，默认为50ms。 proxy_cache 功能描述: 指定缓存块名称。 语法格式: proxy_cache zone|off; 默认值: off Context: http, server, location proxy_cache_key 功能描述: 指定缓存的key。 语法格式: proxy_cache_key string; 默认值: $scheme$proxy_host$request_uri Context: http, server, location proxy_cache_valid 功能描述: 指定缓存什么样的响应。 语法格式: proxy_cache_valid [code] time; Context: http, server, location 示例如下： proxy_cache_valid 404 5min; 其中，如果不指定 code 时，默认仅对 200, 301, 302 响应码的请求进行缓存。 另外，上游服务器中返回的响应头部也会影响缓存的时长： X-Accel-Expires: 单位为s，可以设置缓存时长，为0时表示禁用缓存，可以通过@设置缓存到一天中的某一时刻。 响应头中含有 Set-Cookies 时，不会缓存。 响应头中含有 Vary: * 则不会缓存。 proxy_no_cache 功能描述: 设置什么场景下，响应不写入缓存。 语法格式: proxy_no_cache string; Context: http, server, location proxy_cache_bypass 功能描述: 设置什么场景下，不从缓存中读取数据。 语法格式: proxy_cache_bypass string; Context: http, server, location proxy_cache_convert_head 功能描述: 设置是否自动将 HEAD 请求转化为 GET 请求。 语法格式: proxy_cache_convert_head on|off; 默认值: on Context: http, server, location proxy_cache_methods 功能描述: 针对哪些方法的请求进行缓存。 语法格式: proxy_cache_methods GET|HEAD|POST; 默认值: GET HEAD Context: http, server, location 除了上述指令之外，在 Nginx 的 Cache 使用中，还可以通过 upstream_cache_status 变量查询是否命中了缓存，它有如下取值： MISS: 未命中缓存。 HIT: 命中缓存。 EXPIRED: 缓存已经过期。 STALE: 命中了陈旧的缓存。 UPDATING: 命中的缓存内容已经过期，但是正在更新。 REVALIDATED: Nginx 验证了过期的缓存仍然是有效的。 BYPASS: 缓存被主动跳过，从上游服务器请求获取了响应。 此外，我们再来介绍两个指令，它们也可以有效提升系统的响应速度。 slice 功能描述: 通过range协议将大文件分解为多个小文件，更好的用缓存为客户端的range协议服务。 语法格式: slice size; 默认值: 0 Context: http, server, location Ps: 该模块默认没有编译进入 nginx 中，需要使用 --with-http_slice_module 来启用。 open_file_cache 功能描述: 缓存文件句柄，避免每次读写都需要打开和关闭文件句柄。 语法格式: open_file_cache off|max=N [inactive=time]; 默认值: off Context: http, server, location Nginx 缓存处理流程 只了解 Nginx 缓存相关的指令，但是不了解 Nginx 在缓存中的处理流程的话，其实很难用好 Nginx 缓存的功能。 下面，我们来看一下 Nginx 接收到客户端的请求后，Nginx 是如何处理这个请求中是否可以从缓存中获取响应的流程的吧。 可以看到，Nginx 有自己的一套机制并结合配置信息判断是否读取缓存。 如果当 Nginx 如果没有查询到现成可用的缓存数据时，会继续向上游发送请求，此时，接收到上游的响应后，会尝试将其缓存下来， 其主体流程如下图所示： 需要注意的是，在上游的响应中，其中有一些响应头部是可以控制 Nginx 的缓存行为的，我们来依次了解一下。 X-Accel-Expires: 由上游服务定义缓存多长时间，单位为s，@开头时表示缓存到当天的某个时间。 Vary: *: 表明该响应不会被缓存。 Set-Cookie: 上游响应头部中包含 Set-Cookie 时，不会对响应进行缓存。 避免缓存穿透 当新增 Nginx 实例后，Nginx 初始状态是没有缓存的，此时，为了避免大量的并发请求全部打到上游服务器，导致压垮上游服务器，我们可以在 Nginx 中一些 策略，从而避免更多的请求转发至上游服务器中。 合并回源请求 合并回源请求是一种常用的避免缓存穿透的方法。 它的主要解决场景是同一时刻有多个请求请求相同资源时，可以通过加锁的状态，只放一个请求去请求上游服务，其他请求在nginx侧等待，直到上游服务返回响应后， 其他请求全部使用同样的响应结果进行返回，并 cache 响应结果。 其中涉及到的一些指令如下： proxy_cache_lock 功能描述: 是否开启合并回源请求，开启后同一时间，仅第1个请求发向上游，其他请求等待第1个响应返回或者超时后，使用缓存响应客户端。 语法格式: proxy_cache_lock on|off; 默认值: off Context: http, server, location proxy_cache_lock_timeout 功能描述: 等待第1个请求返回响应的最大时间，到达后直接向上游发送请求，但不缓存响应。 语法格式: proxy_cache_lock_timeout time; 默认值: 5s Context: http, server, location proxy_cache_lock_age 功能描述: 上一个请求反向响应的超时时间，到达后再放行一个请求发向上游。 语法格式: proxy_cache_lock_age time; 默认值: 5s Context: http, server, location 使用 stale 陈旧的缓存 除了使用回源请求之外，Nginx 还允许在缓存过期后，一定时间段内继续使用陈旧的缓存来进行响应，从而减少回源请求。 proxy_cache_use_stale 功能描述: 设置在什么情况下，暂时使用过期的缓存。 语法格式: proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | off; 默认值: off Context: http, server, location 其中，各个配置的含义如下： updating: 当缓存内容过期时，有一个请求正在访问上游试图更新缓存时，其他请求直接使用过期的内容返回客户端。此外，上游返回的响应头的也可以定制缓存行为： stale-while-revalidate: 缓存过期后，定义一段时间，在这段时间内updating设置有效，否则请求依然访问上游服务，例如 Cache-Control: max-age=600, stale-while-revalidate=30 stale-if-error: 缓存过期后，定义一段时间，在这段时间内如果上游服务出错后继续使用缓存，否则请求依然访问上游服务，例如 Cache-Control: max-age=600, stale-if-error=1200 error: 当与上游建立连接、发送请求、读取响应头部等情况出错时，使用缓存。 timeout: 当与上游建立连接、发送请求、读取响应头部等情况超时时，使用缓存。 http_${code}: 缓存指定错误码信息。 proxy_cache_background_update 功能描述: 当使用的 proxy_cache_use_stale 允许使用过期响应时，将同步生成一个子请求，通过访问上游服务更新过期的缓存。 语法格式: proxy_cache_background_update on|off; 默认值: off Context: http, server, location proxy_cache_revalidate 功能描述: 更新缓存时，是否开启If-Modified-Since和If-None-Match作为请求头部，从而可以接收304响应码减少body传输。 语法格式: proxy_cache_revalidate on|off; 默认值: off Context: http, server, location 手动立即清除缓存 除了定时删除缓存之外，Nginx 还可以通过第三方模块的方式来支持立即清除缓存。 其中，第三方模块的地址为 ngx_cache_purge 。 可以在编译 Nginx 时，使用 --add-module 的方式将对应模块加入到 nginx 中。 其功能是通过接收 HTTP 请求后立即清除缓存。 ngx_cache_purge 模块支持两种使用方式。 方式一: 在已有的 location 中，针对某些 method 请求时，可以触发释放缓存的操作。 proxy_cache_purge 功能描述: 该在指定IP通过指定方法访问对应的请求时，会触发缓存释放的操作。 语法格式: proxy_cache_purge on|off| [from all| [.. ]]; 默认值: off Context: http, server, location 方式二: 定义一个单独的 location 块，即提供一个 url ，当访问该 url 时，触发对应的缓存删除操作。 proxy_cache_purge 功能描述: 当访问对应的location块时，能够触发立即删除缓存的操作。 语法格式: proxy_cache_purge zone_name key; 默认值: none Context: location memcached 反向代理 虽然 HTTP 是 Nginx 反向代理中支持的核心协议，但其实，Nginx 远远不仅仅支持 HTTP 协议。 下面，我们就来看一下 Nginx 支持的其他协议吧，首先来看一下 memcached 反向代理。 memcached 反向代理仅处的场景是指客户端向 Nginx 发送 HTTP 协议，而 Nginx 与 memcached 进行交互，并将结果返回给 HTTP 客户端。 具体来说： 将 HTTP 请求转化为 memcached 协议中的 get 请求，转发请求至上游 memcached 服务。 get 命令: get *\\r\\n 通过 memcached_key 变量来构造 key 键。 其中涉及到的一些指令如下，并且与 http 指令进行了对比： 示例配置如下： server { server_name memcached.missshi.com; #root html/; default_type text/plain; location /get { set $memcached_key \"$arg_key\"; memcached_pass localhost:11211; } } 即将所有访问 /get 地址的请求，读取其中 key 的参数，并将该key的查询转发至memcached中。 websocket 反向代理 websocket 其实是一种基于 HTTP 1.1 的一种支持双向通信的协议。 Nginx 想要支持 websocket 协议非常简单，仅需要增加如下配置即可： proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; HTTP 2.0 协议反向代理 HTTP 2.0 是 HTTP 1.1 协议的升级版本。 它的主要特性包括： 通过二进制传输和标头压缩的方式，使得传输的数据量大幅度减少。 支持多路复用。 支持服务器消息推送。 Nginx 中 http 2.0 支持的模块默认没有编译进入 nginx 中，需要使用 --with-http_v2_module 来编译 nginx ，从而支持 http 2.0 协议。 此外，HTTP 2.0 要求必须在 TLS/SSL 协议之上工作，即必须开启 TLS/SSL 协议。 使用方法是： listen 443 ssl http2; 同时，如果想要从 Nginx 向客户端主动推送资源时，可以用到如下两个指令。 http2_push_preload 功能描述: 根据上游返回的头部信息，推送指定文件到客户端。 语法格式: http2_push_preload on|off; 默认值: off Context: http, server, location http2_push 功能描述: 根据指定uri，推送指定文件到客户端。 语法格式: http2_push uri|off; 默认值: off Context: http, server, location 示例配置如下: server { server_name http2.missshi.com; root html; location / { http2_push /mirror.txt; http2_push /video.mp4; } location /test { add_header Link \"; as=style; rel=preload\"; http2_push_preload on; } listen 4430 ssl http2; # managed by Certbot ssl_certificate /etc/letsencrypt/live/http2.missshi.com/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/http2.missshi.com/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } 此外，http 2.0 还支持各种相关配置指令，此处不再一一介绍。 GRPC 反向代理 GRPC 是 google 提出的一种基于 HTTP 2.0 的RPC通信协议。 其主要指令如上表所示，与 HTTP 协议比较类似。 stream 四层反向代理 在上面的所有内容中，都还是将对于应用层（7层）是如何进行反向代理的。 下面的内容中，我们也会简单来看一下对于传输层（4层）协议而言，Nginx 可以如何帮助我们实现反向代理。 在传输层的反向代理中，主要涉及到如下7个阶段： POST_ACCEPT: realip PREACCESS: limit_conn ACCESS: access SSL: ssl PREPEAD: ssl_preread CONTENT: return, stream_proxy LOG: access_log 关于每个模块中具体的指令，此处我们不再细讲了，大家有需要的话可以去 Nginx 官网进行查询。 其中，有一些变量在 Nginx 反向代理的配置中，我们可能会用到，我们也来大致了解一下： binary_remote_addr: 客户端地址的整型格式。 connection: 递增的连接序号。 remote_addr: 客户端地址。 remote_port: 客户端端口。 proxy_protocol_addr: proxy_protocol 协议中的地址。 proxy_protocol_port: proxy_protocol 协议中的端口。 protocol: 传输层协议，TCP/UDP。 server_addr: 服务器地址。 server_port: 服务器端口。 status: 返回码，200/400/403/500/502/503 bytes_received: 客户端收到的字节数。 bytes_sent: 发送到客户端的字节数。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/nginx/chinese.html":{"url":"middleware/nginx/chinese.html","title":"解决nginx中文乱码问题","keywords":"","body":"解决Nginx中文乱码问题 解决nginx的中文乱码问题非常简单，只需要在Server块的配置中增加如下一行即可： charset utf-8; 示例如下： upstream you.domainName.com { server 127.0.0.1:8081; } server { listen 80; server_name you.domainName.com; charset utf-8; location /examples { return 403; } } 然后，重启nginx服务即可。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/openresty/beginning.html":{"url":"middleware/openresty/beginning.html","title":"OpenResty","keywords":"","body":"OpenResty OpenResty 是通过 Lua 扩展 NGINX 实现的可伸缩的 Web 平台。 在本系列文章中，我们将会重点来讲解关于 OpenResty 相关的功能和使用。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/openresty/install.html":{"url":"middleware/openresty/install.html","title":"openresty的安装","keywords":"","body":"openresty的安装 下面，我们来了解一下 OpenResty 的安装方法。 使用包管理系统直接安装 安装 OpenResty 最简单的方式就是通过各个操作系统中自带的包管理工作来安装了。 例如，对于 MacOS，可以使用 brew 来安装，对于 CentOS，可以使用 yum 来安装，对于 Ubuntu 而言，可以使用 apt 来安装等等。 需要注意的是，在使用包管理工具来安装 OpenResty 时，我们通过用的不是操作系统内置的源，而是会使用 OpenResty 提供的仓库。 以 MacOS 系统为例，安装方式如下： brew tap openresty/brew brew install openresty 以 CentOS 系统为例，安装方式如下: # add the yum repo: wget https://openresty.org/package/centos/openresty.repo sudo mv openresty.repo /etc/yum.repos.d/ # update the yum index: sudo yum check-update # install sudo yum install openresty sudo yum install openresty-resty # query related package sudo yum --disablerepo=\"*\" --enablerepo=\"openresty\" list available 源码编译安装 我们都知道，包管理器直接安装的 OpenResty 是没有办法自主控制编译选项的。 这对我们的使用场景是非常不友好的。 下面，我们就来看一下如何通过源码的方式来编译 OpenResty 吧。 Step1: 安装 pcre wget http://www.missshi.cn:8089/pcre-8.42.tar.bz2 tar xjf pcre-8.42.tar.bz2 cd pcre-8.42 ./configure --prefix=/home/work/openresty-dependency/pcre --disable-cpp --enable-jit --enable-utf --enable-unicode-properties make -j24 V=1 make install rm -rf /home/work/openresty-dependency/pcre/bin rm -rf /home/work/openresty-dependency/pcre/share rm -f /home/work/openresty-dependency/pcre/lib/*.la rm -f /home/work/openresty-dependency/pcre/lib/*pcrecpp* rm -f /home/work/openresty-dependency/pcre/lib/*pcreposix* rm -rf /home/work/openresty-dependency/pcre/lib/pkgconfig Step2: 安装 zlib wget http://www.zlib.net/zlib-1.2.11.tar.xz tar xf zlib-1.2.11.tar.xz cd zlib-1.2.11 ./configure --prefix=/home/work/openresty-dependency/zlib make -j24 \\ CFLAGS='-O3 -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -g' \\ SFLAGS='-O3 -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -g' make install rm -rf /home/work/openresty-dependency/zlib/share/ rm -f /home/work/openresty-dependency/zlib/lib/*.la rm -rf /home/work/openresty-dependency/zlib/lib/pkgconfig/ Step3: 安装 openssl wget https://www.openssl.org/source/openssl-1.1.0j.tar.gz wget http://www.missshi.cn:8089/openssl-1.1.0d-sess_set_get_cb_yield.patch --no-check-certificate wget http://www.missshi.cn:8089/openssl-1.1.0j-parallel_build_fix.patch --no-check-certificate tar zxf openssl-1.1.0j.tar.gz cd openssl-1.1.0j patch -p1 Step4: 编译安装 OpenResty wget https://openresty.org/download/openresty-1.15.8.1.tar.gz tar zxf openresty-1.15.8.1.tar.gz cd openresty-1.15.8.1 ./configure \\ --prefix=/home/work/openresty \\ --with-cc-opt=\"-DNGX_LUA_ABORT_AT_PANIC \\ -I/home/work/openresty-dependency/zlib/include \\ -I/home/work/openresty-dependency/pcre/include \\ -I/home/work/openresty-dependency/openssl/include\" \\ --with-ld-opt=\"-L/home/work/openresty-dependency/zlib/lib \\ -L/home/work/openresty-dependency/pcre/lib \\ -L/home/work/openresty-dependency/openssl/lib \\ -Wl,-rpath,/home/work/openresty-dependency/zlib/lib:/home/work/openresty-dependency/pcre/lib:/home/work/openresty-dependency/openssl/lib\" \\ --with-pcre-jit \\ --without-http_rds_json_module \\ --without-http_rds_csv_module \\ --without-lua_rds_parser \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_ssl_preread_module \\ --with-http_v2_module \\ --without-mail_pop3_module \\ --without-mail_imap_module \\ --without-mail_smtp_module \\ --with-http_stub_status_module \\ --with-http_realip_module \\ --with-http_addition_module \\ --with-http_auth_request_module \\ --with-http_secure_link_module \\ --with-http_random_index_module \\ --with-http_gzip_static_module \\ --with-http_sub_module \\ --with-http_dav_module \\ --with-http_flv_module \\ --with-http_mp4_module \\ --with-http_gunzip_module \\ --with-threads \\ --with-luajit-xcflags='-DLUAJIT_NUMMODE=2 -DLUAJIT_ENABLE_LUA52COMPAT' \\ -j24 make -j24 make install 至此，我们的 OpenResty 就已经成功安装完成了，快来试试吧！ Ps: 上述用到源码包如果下载不下来，可以访问 package 下载。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/openresty/hello_openresty.html":{"url":"middleware/openresty/hello_openresty.html","title":"Hello OpenResty","keywords":"","body":"Hello OpenResty 在上一节中，我们已经完成了 OpenResty 的环境搭建。 下面，我们来快速体验一下 OpenResty 的使用吧！ OpenResty 目录结构说明 首先，我们进入 OpenResty 的目录来看一下： -rw-rw-r-- 1 work work 22924 Aug 2 13:53 COPYRIGHT drwxrwxr-x 6 work work 4096 Aug 2 13:53 luajit drwxrwxr-x 5 work work 4096 Aug 2 13:53 lualib -rw-rw-r-- 1 work work 226376 Aug 2 13:53 resty.index drwxrwxr-x 47 work work 4096 Aug 2 13:53 pod drwxrwxr-x 6 work work 4096 Aug 2 13:53 nginx drwxrwxr-x 5 work work 4096 Aug 2 13:53 site drwxrwxr-x 2 work work 4096 Aug 2 13:53 bin 其中，我们重点来一下如下几个目录： bin: bin目录下包含 OpenResty 中核心的可执行文件和脚本工具等。 pod: pod 是 Perl 里面的一种标记语言，用于给 Perl 的模块编写文档。pod 目录中存放的就是 OpenResty、 NGINX、lua-resty-*、LuaJIT 的文档。 nginx: Nginx 相关的目录。 luajit: LuaJIT 相关的目录。 lualib: OpenResty 中使用到的一些 Lua 库。 Hello OpenResty! 每当我们开始学习一个新的开发语言或者平台，都会从最简单的hello world开始，OpenResty 也不例外。 下面，我们就来使用 OpenResty 提供一个地址返回 Hello OpenResty! Step1: 修改 Nginx 的配置文件 /home/work/openresty/nginx/conf/nginx.conf events { worker_connections 1024; } http { server { listen 8000; location / { content_by_lua ' ngx.say(\"hello, OpenResty!\") '; } } } Step2: 启动 Nginx 然后，我们就可以启动 Nginx 服务了： ./bin/openresty -p `pwd`/nginx -c conf/nginx.conf 没有报错的话，OpenResty 的服务就已经成功启动了。你可以打开浏览器，或者使用 curl 命令，来查看结果的返回： curl -i 127.0.0.1:8000 # HTTP/1.1 200 OK # Server: openresty/1.15.8.1 # Date: Mon, 02 Aug 2021 06:28:31 GMT # Content-Type: text/plain # Transfer-Encoding: chunked # Connection: keep-alive # # hello, OpenResty! Step3: 修改配置文件并重启 Nginx 修改配置文件是 OpenResty 的使用场景中的一个高频场景，下面，我们就来看一下如何修改配置文件，并使其生效吧！ 修改 /home/work/openresty/nginx/conf/nginx.conf 文件如下: events { worker_connections 1024; } http { server { listen 8000; location / { content_by_lua ' ngx.say(\"hi, OpenResty!\") '; } } } 然后，我们可以执行如下来重启 Nginx: ./bin/openresty -p `pwd`/nginx -s reload -c conf/nginx.conf 重新调用一下接口，看看是否已经发生了变化了呢？ curl -i 127.0.0.1:8000 # HTTP/1.1 200 OK # Server: openresty/1.15.8.1 # Date: Mon, 02 Aug 2021 06:33:18 GMT # Content-Type: text/plain # Transfer-Encoding: chunked # Connection: keep-alive # # hi, OpenResty! Step4: 当我们 OpenResty 程序使用完成后，可以通过如下命令来停止 OpenResty 服务: ./bin/openresty -p `pwd`/nginx -s quit -c conf/nginx.conf By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/zookeeper/beginning.html":{"url":"middleware/zookeeper/beginning.html","title":"zookeeper","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"middleware/sentry/beginning.html":{"url":"middleware/sentry/beginning.html","title":"sentry","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/beginning.html":{"url":"linux/basic/beginning.html","title":"Linux基础","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/ssh.html":{"url":"linux/basic/ssh.html","title":"Ubuntu系统开启远程ssh访问","keywords":"","body":"Linux系统开启远程ssh访问 什么是SSH？ SSH通过在网络中创建安全隧道来实现SSH客户端与服务器之间的连接。 SSH最常见的用途是远程登录系统，人们通常利用SSH来传输命令行界面和远程执行命令。 开启步骤 Linux系统开启远程ssh访问的方法非常简单，仅需要安装ssh服务端并启动即可。 下面，我们以Ubuntu系统为例。 Step1: 安装ssh服务端 sudo apt-get install openssh-server Step2: 检查ssh服务端是否正常启动 ps -ef|grep sshd 在上图中，我们可以看到 /usr/sbin/sshd 进程，那么就说明我们的ssh服务端已经正常启动了。 Step3: 如果没有找到ssh服务端进程，则可以使用如下命令重启ssh服务端 service ssh restart 接下来，你就可以在一台网络相互联通的机器上通过 ssh 命令进行尝试远程登录了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/ftp.html":{"url":"linux/basic/ftp.html","title":"Ubuntu系统下搭建FTP服务器","keywords":"","body":"Ubuntu系统下搭建与使用FTP服务器 环境准备 在本文中，我们将会以 Ubuntu 20.04 版本的操作系统为例，演示如何快速搭建一个FTP服务器。 Step By Step Step1: 安装FTP服务器 sudo apt-get install vsftpd 简单一条命令，其实我们就已经完成了FTP服务的安装，接下来我们需要创建对应的用户并修改相关配置文件使其生效。 Step2：创建FTP用户 # 创建用户 sudo useradd -m ftpuser # 设置用户密码 sudo passwd ftpuser 至此，FTP用户已经成功创建好了，下面，我们来修改FTP服务的相关配置文件 Step3：修改FTP配置文件 sudo vim /etc/vsftpd.conf 此时，为了能够让我们的FTP服务器能够正常运行，我们仅仅只需要修改开启write_enable即可： # Uncomment this to enable any form of FTP write command. write_enable=YES 其他配置可以保持不变。 Step4：重启FTP服务使配置生效 service vsftpd restart 此时，FTP服务已经正常启动了，接下来我们就可以正常使用FTP服务了。 其他配置说明 关于 vsftpd 服务的相关配置都位于 /etc/vsftpd.conf 配置文件中。 下面，我们来依次讲解一些常用的配置。 自定义端口 对于FTP服务器，其默认端口为21。 有时，我们希望能够修改FTP服务监听的端口，此时，则使用到了如下配置： listen_port=8021 除了修改 /etc/vsftpd.conf 配置文件外，我们还需要修改 /etc/services 文件，其中有系统Service相关的端口设置： ftp 8021/tcp ftp 8021/udp fsp fspd pasv_promiscuous参数 pasv_promiscuous=YES 该参数可以是YES / NO。默认值为NO。 当该参数设置为NO时，会进行被动模式安全检查，这一检查可以保证数据连接源于同一个IP地址。 当该参数设置为YES时，则会忽略该检查。 FTP服务文件上传下载 客户端工具 我们以Mac为例，可以选择使用 ForkLift 客户端软件来与FTP服务器进行交互。 命令行工具 除了客户端外，我们最常用的命令行工具就是 wget 工具了。 wget ftp://${username}:${password}@{hostname}:${port}/{filepath} 其中，FTP协议的默认端口是21，如果没有修改端口的话，可以不用传入端口信息。 除了 wget 命令行工具外，一个更加强大的命令行工具就是telnet了。 telnet是一个基于TCP协议的强大的命令行工具。使用telnet可以与FTP Server进行正常交互。 下面，我们以一个示例来演示如何使用telnet命令行工具与FTP Server进行交互。 Ps: 假设FTP Server的IP为192.168.1.22，端口为21。用户名和密码都是ftpuser。 Step1: 连接FTP服务器： telnet 192.168.1.22 21 # 220 (vsFTPd 3.0.3) Step2：输入用户名和密码： USER ftpuser # 331 Please specify the password. PASS ftpuser # 230 Login successful. Step3：切换目录 与 查询当前目录 # cd / CDUP # cd ./test CWD test # pwd PWD Step4：删除文件 DELE hello.txt Step5：上传文件 上传文件时，相对过程比较复杂，我们需要开启两个终端来进行操作。 首先，使用终端1 连接FTP服务器的21端口，并进行用户名和密码登录。 telnet 192.168.1.22 21 # Trying 192.168.1.22... # Connected to 192.168.1.22. # Escape character is '^]'. # 220 (vsFTPd 3.0.3) USER ftpuser # 331 Please specify the password. PASS ftpuser # 230 Login successful 接下来，需要在终端1中 通过 PASV 命令请求FTP 服务器开启另外一个端口等待数据传输。 PASV # 227 Entering Passive Mode (192,168,1,22,165,92). 可以看到，PASV命令执行后会返回一个包含6个元素的元组。其中前四位表示FTP服务器的IP，后两位组成的时临时端口。 临时端口的计算方式如下： 165 * 256 + 92 = 42332 然后，我们需要使用终端2中使用 telnet 命令连接FTP服务器临时申请的端口用于数据传输。 telnet 192.168.1.22 42332 # Trying 192.168.1.22... # Connected to 192.168.1.22. # Escape character is '^]'. 在终端1中启动文件写入命令： STOR test.txt # 150 Ok to send data. 此时，就可以在终端2中输入响应需要写入的数据了。 this is test data missshi 当数据写入完成后，在终端1中退出即可。 附录：FTP常用命令 命令 描述 USER \\ 系统登录的用户名 PASS \\ 系统登录密码 CDUP \\ 改变服务器上的父目录 CWD \\ 改变服务器上的工作目录 PWD 显示当前工作目录 HELP \\ 返回指定命令信息 QUIT 从 FTP 服务器上退出登录 LIST \\ 如果是文件名列出文件信息，如果是目录则列出文件列表 DELE \\ 删除服务器上的指定文件 RMD \\ 在服务器上删除指定目录 MKD \\ 在服务器上建立指定目录 STOR \\ 储存（复制）文件到服务器上 STOU \\ 储存文件到服务器名称上 SYST 返回服务器使用的操作系统 PASV 请求服务器等待数据连接 ABOR 中断数据连接程序 ACCT \\ 系统特权帐号 ALLO \\ 为服务器上的文件存储器分配字节 APPE \\ 添加文件到服务器同名文件 MODE \\ 传输模式（S=流模式，B=块模式，C=压缩模式） NLST \\ 列出指定目录内容 NOOP 无动作，除了来自服务器上的承认 REIN 重新初始化登录状态连接 REST \\ 由特定偏移量重启文件传递 RETR \\ 从服务器上找回（复制）文件 RNFR \\ 对旧路径重命名 RNTO \\ 对新路径重命名 SITE \\ 由服务器提供的站点特殊参数 SMNT \\ 挂载指定文件结构 STAT \\ 在当前程序或目录上返回信息 STRU \\ 数据结构（F=文件，R=记录，P=页面） TYPE \\ 数据类型（A=ASCII，E=EBCDIC，I=binary） By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/file_server.html":{"url":"linux/basic/file_server.html","title":"使用Python搭建简单的文件服务器","keywords":"","body":"使用Python搭建简单的文件服务器 依赖准备 本文主要依赖Python2.7，提前安装Python2.7即可。 文件下载服务器 Python2内置了一个SimpleHTTPServer的模块，通过命令行工具，我们就可以快速启动一个HTTP服务器用于文件下载。 python2 -m SimpleHTTPServer 8000 其中，上述命令中的8000表示启动HTTP服务的端口，可以根据你的需要进行修改。 Ps：对于Python3而言，启动命令变为如下： python3 -m http.server 8000 文件上传服务器 对于文件上传，我们推荐一个Droopy的第三方工具。 Droopy是一个简单的用于文件上传的Web服务器。 droopy本身是一个命令行脚本，下载地址如下：droopy 你可以将它下载下来后保存至~/bin/目录下，从而可以直接使用。 启动方式如下： mkdir ~/uploads cd ~/uploads python ~/bin/droopy -m \"Hi, it's me Bob. You can send me a file.\" -p ~/avatar.png 上述命令会启动droopy服务器并占用8000端口。 其中，droopy命令行的使用方式如下： Usage: droopy [options] [PORT] Options: -h, --help 帮助信息 -d DIRECTORY, --directory DIRECTORY 上传文件的保存目录 -m MESSAGE, --message MESSAGE 提示消息 -p PICTURE, --picture PICTURE 提示图片 --dl 提供下载链接 --save-config 将参数保存到配置文件 --delete-config 删除配置文件并退出 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/expect.html":{"url":"linux/basic/expect.html","title":"通过expect实现无交互式的远程命令执行与远程文件传输","keywords":"","body":"通过expect实现无交互式的远程命令执行与远程文件传输 背景 在很多自动化场景中，都需要解决一个交互式输入密码的问题。例如当我们需要远程执行命令、远程传输文件等场景。 expect其实就是专门用于解决交互式命令输入的工具。 expect详解 expect是一个自动化交互套件，主要应用于执行命令和程序时，系统以交互形式要求输入指定字符串，实现交互通信。 它的自动交互流程如下： spawn启动指定进程 expect获取指定关键字 send向指定程序发送指定字符 执行完成退出 expect的常用命令总结如下： 命令 介绍 spawn | 交互程序开始后面跟命令或者指定程序 expect | 获取匹配信息匹配成功则执行expect后面的程序动作 send exp_send | 用于发送指定的字符串信息 exp_continue | 在expect中多次匹配就需要用到 send_user | 用来打印输出 相当于shell中的echo exit | 退出expect脚本 eof | expect执行结束 退出 set | 定义变量 puts | 输出变量 set timeout | 设置超时时间 interact 　　　　|　　 允许用户交互 demo示例 下面，我们通过一些非常简单的demo来演示expect相关的使用: #!/usr/bin/expect spawn ssh wangzhe@192.168.1.22 df -Th expect \"*password\" send \"123456\\n\" expect eof 在上面的例子中，我们将会通过用户名wangzhe，密码123456登录192.168.1.22机器，然后执行df -Th命令并返回执行结果。 expect的安装 以Ubuntu系统为例，我们可以直接使用包管理工具进行安装: sudo apt-get install tcl tk expect 常用模板工具 从本地到远程机器远程文件传输 #!/usr/bin/expect set timeout 10 set host [lindex $argv 0] set username [lindex $argv 1] set password [lindex $argv 2] set src_file [lindex $argv 3] set dest_file [lindex $argv 4] spawn scp $src_file $username@$host:$dest_file expect { \"(yes/no)?\" { send \"yes\\n\" expect \"*assword:\" { send \"$password\\n\"} } \"*assword:\" { send \"$password\\n\" } } expect \"100%\" expect eof 使用方式: ./expect_scp ${remote_host_ip} ${remote_host_user} ${remote_host_password} ${local_file} ${remote_des_file} # example # ./expect_scp 192.168.1.22 wangzhe 123456 mock.tar /home/wangzhe/桌面/mock.$tag.tar By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/supervisor.html":{"url":"linux/basic/supervisor.html","title":"Supervisor实现程序管理与保活","keywords":"","body":"supervisor 进程托管系统 Supervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。 它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。 也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。 supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程。 安装 Supervisor是一个用Python开发的进程管理程序。因此，可以使用Python自带的包管理工具pip进行安装。 pip install supervisor 安装完成后，我们可以测试一下是否已经安装完成： supervisord --help 正常情况下我们可以看到如下内容： 配置解析 在命令行中执行如下命令 echo_supervisord_conf 可以看到在标准输出中输出了一份标准的配置文件模板。 我们可以将其重定向到某个文件中，从而生成一个配置文件: echo_supervisord_conf > /home/work/supervisor/conf/supervisord.conf 此时，我们将会得到一个文件 /home/work/supervisor/conf/supervisord.conf。 下面我们来浅谈一下配置文件的内容，从上至下，依次包括如下Section： unix_http_server，其中，file指定了socket file的位置。 inet_http_server，用于启动一个含有前端的服务，可以从Web页面中管理服务。其中，port用于设置访问地址，username和password用于设置授权认证。 supervisord是对管理服务本身的配置。包含日志文件相关、进程文件、启动方式等等。 rpcinterface:supervisor中包含了rpc相关的接口。 supervisorctl是对supervisorctl服务相关的配置。 program是真正配置需要管理的任务。 eventlistener是对事件进行的管理。 group可以实现对任务组的管理。 include中可以引用其他的配置文件。 推荐使用方式： 将系统相关配置文件写在一个配置文件中，而在这个配置文件中的include Section中引入一个文件夹。具体的服务管理机制则针对每个任务单独编写文件。 下面，我们可以给出一个demo的配置文件： [unix_http_server] file=/tmp/supervisor.sock [inet_http_server] port=*:9001 username=user password=123 [supervisord] logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.log logfile_maxbytes=50MB ; max main logfile bytes b4 rotation; default 50MB logfile_backups=10 ; # of main logfile backups; 0 means none, default 10 loglevel=info ; log level; default info; others: debug,warn,trace pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pid nodaemon=false ; start in foreground if true; default false minfds=1024 ; min. avail startup file descriptors; default 1024 minprocs=200 ; min. avail process descriptors;default 200 [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket [include] files = /etc/supervisord.d/*.ini 具体的进程托管命令如下，/etc/supervisord.d/logstash.ini文件： [program:nianshi_logstash] command=/root/logstash/logstash-6.2.2/bin/logstash -f /root/logstash/conf/logstash.conf startsecs=3 user=root stdout_logfile=/root/logstash/log/stdout.log stderr_logfile=/root/logstash/log/stderr.log environment=PYTHONPATH=$PYTHONPATH:/home/wangzhe/bcm-onlinecheck/alarm-online-check directory=/home/wangzhe/bcm-onlinecheck/alarm-online-check Web管理界面 可以看到在之前的配置中，我们增加了如下内容： [inet_http_server] port=*:9001 username=user password=123 该配置表示我们开启了9001端口提供一个Web服务，登录的用户名、密码分别是user, 123。 supervisor服务启动后，访问对应的URL并登录后，可以看到如下页面： 在该页面中，我们可以查询托管进程的状态，也能够启动、停止、重启对应的托管进程。 常见使用方式 启动 当我们完成配置文件的准备后，就可以启动supervisord服务了。 supervisord -c /home/nianshi/supervisor/conf/supervisord.conf 其中，-c用于指定配置文件。 当发生错误时，我们可以使用-n参数运行从而可以在前端运行，方便定位原因。 服务管理 除了使用supervisord进行服务启动外，针对单独的服务，我们还可以使用supervisorctl进行服务管理。 一、启动指定的服务 supervisorctl start test123 二、停止指定的服务 supervisorctl stop test123 三、更新配置文件变化并重启变化的服务 supervisorctl update 四、重启相关服务 supervisorctl reload By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/crontab.html":{"url":"linux/basic/crontab.html","title":"Linux 下添加定时任务","keywords":"","body":"Linux 下添加定时任务 很多时候，我们需要在 Linux 系统中添加各种各样的定时任务。 比如定时数据备份等一系列操作。 那么，本文将会讲解如何在 Linux 系统中添加定时任务。 一次性定时任务 一次性定时任务是指希望在一个指定的时间点执行一个某个任务/命令。 一次性定时任务的投放比较简单，主要用到了 at 命令。 首先，在终端输入 at ${time} 表示将在指定时间投放命令。 例如: at 18:45。 接下来，会进入一个交互式的命令行中可以输入想要执行的命令，例如: echo \"123\" > /tmp/task 然后，按 Control + D 提交对应的任务。 此时，我们可以通过 atq 命令查询当前等待执行的定时任务。 等到了我们具体设定的时间后，之前提交的定时命令则会按时执行。 周期性定时任务 除了一次性定时任务外，我们其实更常用的是一个周期性的定时任务。 比如每天临晨3点进行一次数据备份，每周一上午10点清理一次日志等等，这些都要用到定时任务。 对于周期性定时任务而言，我们需要用到的命令则是 crontab。 例如，配置定时任务: crontab -e，查看现有的定时任务: crontab -l 等。 周期性定时任务中，配置文件的格式如下： 分钟 小时 日期 月份 星期 执行的命令 也就是说，每个周期性定时任务都对应上述六个字段。 例如: * * * * * /usr/bin/date >> /tmp/date.txt 上述配置表示在每分钟都执行一次 date 命令，并将标准输出追加到 /tmp/date.txt 文件中。 Ps: 在指定 分钟 小时 日期 月份 星期 时，可以用 * 表示通配。 想要看到周期性定时任务的执行详情，可以查询 /var/log/cron 文件进行查询。 此外，在指定 分钟 小时 日期 月份 星期 时，还可以用 , 或 - 来进行一些更通用的表示。 例如: * * * * 1,3 /usr/bin/date >> /tmp/date.txt 上述配置表示在每周一和周三每分钟都执行一次 date 命令，并将标准输出追加到 /tmp/date.txt 文件中。 * * * * 1-5 /usr/bin/date >> /tmp/date.txt 上述配置表示在每周一到周五每分钟都执行一次 date 命令，并将标准输出追加到 /tmp/date.txt 文件中。 Ps: 定时任务的配置文件其实是存储在 /var/spool/cron/ 目录下，文件名为定时任务创建的用户的用户名。 任务加锁 flock 很多时候，我们不希望一个命令再上一次运行还没有退出的时候，下一次运行就被启动了起来。 这个时候，一种常用的处理方法是用一个 \"锁\" 机制。 而在 Linux 中， flock 就是一个可以直接使用的锁工具。 我们可以准备一个脚本 sleep.sh: #!/usr/bin/env bash sleep 1000 使用如下命令执行: flock -xn \"/tmp/sleep.lock\" -c \"bash sleep.sh\" 此时，该命令会一直前台执行并始终等待。 这时，我们再打开一个新的终端，执行相同的命令: flock -xn \"/tmp/sleep.lock\" -c \"bash sleep.sh\" 你会发现这个命令立马就退出了，这是因为之前的进程已经对文件进行了加锁，新的命令获取不到文件锁，直接退出了。 此时，如果停止掉之前启动的命令，再次再新窗口中启动该命令时，你会发现命令已经可以正常运行了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/find.html":{"url":"linux/basic/find.html","title":"Linux文本搜索","keywords":"","body":"Linux文本搜索 在 Linux 系统中，我们最常用的文本操作之一就是去进行指定文本操作了。 例如，我们经常需要从日志中查询某些关键词等等。 Linux 文本搜索支持完整匹配和正则匹配多种方式。 完整匹配相对比较简单，此处不做过多的赘述，我们主要来讨论一下 Linux 下的正则匹配。 元字符 在正则匹配中，首先需要了解的就是 元字符 。 元字符指的是具备一定特殊含义的特殊字符，例如包括： . 匹配除换行符外的任意单个字符。 * 匹配任意一个跟在它前面的字符，常用 .* 组合匹配任意字符串。 [] 匹配方括号中字符类中的任意一个。 ^ 匹配开头。 $ 匹配结尾。 \\ 用于转义后面的特殊字符。 + 匹配前面的正则表达式且至少出现一次。 ? 匹配前面的正则表达式出现零次或一次。 | 匹配它前面或后面的正则表达式。 接下来，我们可以用 grep 命令与元字符组合来实现相关的文本搜索。 # 完整匹配 grep password /root/anaconda-ks.cfg # . 匹配 grep pass.... /root/anaconda-ks.cfg # 元字符组合使用 grep pass....$ /root/anaconda-ks.cfg grep pass.* /root/anaconda-ks.cfg grep pa[a-Z]* /root/anaconda-ks.cfg # 转义字符的使用 grep \"\\*\" /root/anaconda-ks.cfg find 文件查找命令 find 命令是一个用于文件查找的常用命令。 其基本的语法格式如下: find 路径 查找条件 [补充条件] 示例： # 在/etc目录下找出文件名为passwd的文件 find /etc -name passwd # 使用通配符查询 find /etc -name pass* # 使用正则表达式查询 find /etc -regex pass.* # 使用正则表达式查询指定的文件夹/文件 find /etc -type d -regex pass.* find /etc -type f -regex pass.* # 8小时以内更新的文件 find /etc -type f -mtime 8 -regex pass.* # 查询 root 用户的文件 find /etc -type f -user root -regex pass.* # 找到需要的文件并删除 find /etc -type f -user root -regex pass.* -exec rm -v {} \\; # 找到需要的文件并删除(需要交互式确认) find /etc -type f -user root -regex pass.* -ok rm -v {} \\; grep 命令的高级使用 使用 grep 加管道命令，我们可以将找到的内容进行切分并提取出我们想要的内容。 例如: grep pass /root/anaconda-ks.cfg | cut -d \" \" -f 1 上述命令表示将找到的行用空格进行切分，并取出其中第一段。 此外，我们还可以使用 uniq -c 对提取到的信息进行统计，例如: cut -d \":\" -f 7 /etc/passwd | sort | uniq -c Ps: 可以看到，我们中间加入了 sort 命令，原因是在用 uniq 进行统计时，只会对连续的内容进行重复统计，因此如果不提前排序，则会导致统计错误。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/sed.html":{"url":"linux/basic/sed.html","title":"Linux文本处理之sed","keywords":"","body":"Linux文本处理之sed sed 是 Linux 中的一个常用的行编辑器，主要用于文本替换等操作。 sed 工作原理概述 sed 的基本工作方式如下： 将文件以行为单位读取到内存（模式空间）中。 使用 sed 的每个脚本对该行进行操作。 处理完成后输出该行。 sed 替换命令s 上面，我们已经提到了，sed 最常用的使用场景就是文本替换了。 一个最简单的sed命令如下: sed 's/old/new/' filename 上式表示对filename文件的逐行进行处理，只要找到old匹配的字符串，就全部替换为new。 如果我们想要进行多个替换操作时，上述命令需要改写如下: sed -e 's/old/new/' -e 's/old1/new1/' filename1 filename2 即在每个替换命令前都加上一个 -e 即可。 或者可以修改如下： sed 's/old/new/;s/old1/new1/' filename1 filename2 即多个替换命令可以拼接在一起，中间使用;进行间隔。 在上述 sed 命令中，我们按行进行了处理，并将处理的结果打印到了终端上，实际上对原始文件并没有进行任何改动。 如果我们想要直接对原始文件进行修改应该怎么办呢？非常简单，只需要加上 -i 参数即可，例如： sed -i -e 's/old/new/' -e 's/old1/new1/' filename1 filename2 此外，我们在使用扩展正则表达式进行匹配替换时，还需要增加-r参数，例如: sed -r 's/扩展正则表达式/new/' filename 有时，我们希望将匹配的内容在新的行中出现多次，那么应该怎么实现呢？ sed -r 's/(a.*b)/\\1:\\1/' filename 下面，我们来解读一下上述命令的含义： 首先，匹配的内容是一个aXXXXb的一个字符串。 接下来，将这个aXXXXb的一个字符串用()包围表示一个整体。 新字符串中，用\\1表示()包围的这个整体。 也就是说，上述替换会把aXXXXb字符串替换为aXXXXb:aXXXXb字符串。 全量替换 之前的 sed 命令的使用中，我们可以发现，如果在一行中，匹配到了多次 old 字符串时，默认仅仅会将第一个匹配到的字段串进行替换。 如果我们希望将全部出现的old字符串都替换成new字符串时应该怎么做呢？ s/old/new/g Ps: 可以看到，我们在替换操作的最后，增加了一个g，这个g就表示替换所有出现的old字符串。 有时，我们既不希望全部替换，也不希望替换第一个匹配项，而是希望替换第二个或者第n个匹配项时，那么可以修改如下: s/old/new/2 即将最后的g改为期望替换的匹配项序号。 此外，如果带替换的字符串中包含/时，分割字符串也可以修改为其他符号，例如: s@old@new@g 其功能效果与上述是一样的。 寻址范围 默认情况下，sed命令在文本处理时，会依次处理中文本中的每一行。 有时候，我们会希望让 sed 命令仅仅处理文本中的满足特定条件的行，例如正则匹配的行，指定区间的行等等。 场景1: 只用sed命令处理正则表达式匹配的行 /正则表达式/s/old/new/g 场景2: 只用sed命令处理指定行数的行 行号s/old/new/g # 在第五行到第十行进行替换 5,10s/old/new/g # 在第五行以后进行替换 5,$s/old/new/g 场景3: 寻址且多条sed命令组合 /正则表达式/{s/old/new/g;s/old1/new1/g} 需要注意的是，刚寻址和多条sed命令组合时，多条sed命令除了之间需要用分号分隔之外，还需要用{}进行包围。 sed 脚本文件 当 sed 命令希望反复使用时，可以将其接入一个文件中，并直接使用该脚本文件即可。 sed -f sedscript filename sed 其他指令 删除 基本格式如下: [寻址]d 或 /正则表达式/d 示例如下： 1,2d Ps: 一旦匹配后，匹配的内容之后的内容会全部被删除。d命令之后其他的命令后不会生效。 追加a、插入i、更改c sed '/ab/i hello' bfile 上式表示在 bfile 文件中匹配 ab，一旦匹配，则该匹配行之前插入一个hello。 sed '/ab/a hello' bfile 上式表示在 bfile 文件中匹配 ab，一旦匹配，则该匹配行之后插入一个hello。 sed '/ab/c hello' bfile 上式表示在 bfile 文件中匹配 ab，一旦匹配，则该匹配行修改为hello。 退出命令 退出命令表示当满足匹配条件后，直接退出，不再处理后续的行。 例如: sed 10q filenmae sed 多行模式空间 默认情况下，sed命令是以单行模式进行处理的。但是，sed其实也支持了多行模式的处理。 sed 在多行处理时有如下关键命令: N: 将下一行加入到模式空间。 D: 删除模式空间中的第一个字符到第一个换行符。 P: 打印模式空间的的第一个字符到第一个换行符。 示例代码如下: sed 'N;s/he.*lo/!!!/g' a.txt 上式表示先将行合并，然后再进行替换。 一个结合 N、D、P的复杂sed脚本如下: sed 'N;s/\\n//;s/hello bash/hello sed\\n/;P;D' a.txt sed 保持空间 sed 保持空间也是sed多行处理的一种操作方式，即将内容暂存在保持空间，便于多行处理。 涉及到的指令包括: h 和 H 将模式空间内容存放到保持空间 g 和 G 将保持空间内容取出到模式空间 x 交换模式空间和保存空间的内容 Ps: 小写表示覆盖模式，大写表示追加模式。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/basic/awk.html":{"url":"linux/basic/awk.html","title":"Linux文本处理之awk","keywords":"","body":"Linux文本处理之awk awk 和 sed 的区别 awk 更像是脚本语言。适用于比较规范的文本处理，常用于统计数量并输出指定字段。 与之对比，sed 则常用于将不规范的文本转换为比较规范的文件。 因此，在 Linux 中，我们常常将 awk 和 sed 搭建使用。 awk 脚本的流程控制 awk 脚本的控制流程包含如下: 输入数据前例程 BEGIN{} 主输入循环{} 所有文件读取完成例程 END{} awk 的字段引用和分离 在 awk 中每一行称之为 awk 的一条记录。 使用空格、制表符分隔的单词在 awk 中称之为一个字段。当然，也可以自己指定分隔字段的符号。 在 awk 中，我们可以使用 $1, $2 等表示第一个字段、第二个字段等。 Ps: $0 表示整行。 一个简单的 awk 命令如下： awk '{ print $1,$2,$3 }' filename 上式表示打印每一行的第一、第二、第三的三个字段。 如果字段分隔符不是空格和换行符时，也可以使用 -F 来改变字段分隔符。例如： awk -F ',' '{ print $1,$2,$3 }' filename Ps: 在 awk 中，字符分隔符还可以是正则表达式。 此外，在 awk 中，我们还可以在 awk 命令中增加正则表达式过滤，只有正则匹配的行才进行处理。 格式如下： awk '/正则表达式/{ print $1,$2,$3 }' filename 如果，我们在 awk 打印中，增加打印的序号时，可以增加内容如下: awk '/正则表达式/{ print x++,$1,$2,$3 }' filename 其中，x++ 表示我们要显示的序号，每打印一行则序号自增1。 awk 表达式 从本质上来看，awk 其实非常类似于一门编程语言，它有着自己的表达式，分支和循环语句，数组，甚至是函数。 下面，我们先来看一下 awk 的表达式是什么样的吧~ 赋值操作符 = 是 awk 中最常用的赋值操作符。 例如： var1 = \"name\" var2 = \"hello\" \"world\" # 会自动拼接 var3 = $1 其他的赋值操作符还有++，--，+=，-=，*=，/=，%=，^=等。 算术运算符 算术运算符比较简单，包括+,-,*,/,%,^等。 系统变量 awk 内部包含一些特殊的系统变量，包括： FS 和 OFS 字段分隔符，其中，OFS 表示输出的字段分隔符。 RS 记录分隔符 NR 和 FNR 表示行数，其中NR不区分文件，数字持续累加，FNR序号针对每个文件进行重新排序。 NF 表示字段数量，最后一个字段的内容可以使用 $NF 来获取。 之前，我们用 -F 指定分隔符时，本质上就是在设置 FS 系统变量。 下面，我们来换一种编写方式: head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print NR,$1,$NF}' 关系操作符 关系操作符包括: , =, ==, !=, ~, !~ 等。 布尔操作符 逻辑操作符包括: &&, ||, ! 关系操作符和布尔操作符主要用于 awk 判断等场景中，我们后面会重点说明，此处不多做赘述。 awk 条件和循环语句 条件语句 awk 的条件语句使用 if 开头，根据表达式的结果来判断执行哪条语句。 基本格式如下： if (表达式) awk 语句1 [else if(表达式) awk 语句2 ] [else awk 语句2 ] Ps: 条件语句内部，如果有多个语句需要执行，可以使用 {} 来将多个语句包围起来。 示例代码如下: awk '{if($2>=80) print $1}' kpi.txt 循环语句 在 awk 中，支持 while、 do-while 循环和 for 循环。 while 循环的基本格式如下： while(表达式) awk语句 do-while 循环的基本格式如下： do { awk语句 }while(表达式) for 循环的基本格式如下： for (初始值; 循环判断条件; 累加) awk语句 此外，在循环语句中，和其他编程语言一样，也支持 break 和 continue 语句。 一个简单的示例代码如下: head -1 kpi.txt|awk '{sum=0;for(c=2;c awk 数组 awk 数据和其他编程语言中的数据类似，是一组有某种关联的数组，可以通过下标来访问。 赋值方法：数组名称[下标] = 值 需要注意的是：下标可以使用数字，也可以使用字符串。Ps: 本质上类似于 Python 的 dict 。 数组的遍历也非常简单，可以使用如下形式的 for 循环: for (变量 in 数组名) print 数组名[变量] 删除数组：delete 数组名。 删除数组中指定元素: delete 数组名[下标]。 示例代码如下: head -1 kpi.txt|awk '{sum=0;for(c=2;c 命令行参数数组 在使用 awk 时，有时我们会从命令行中传入一些参数，而在 awk 命令中可以对这些参数进行解析。 其中，涉及到了两个内部变量，分别是: ARGC: 传入的参数的格式。 ARGV: 传入的参数数组。 一个常用的示例如下： BEGIN{ for(x=0;x awk 函数 算术函数 awk 支持的算术函数比较多，一些常用的算术函数包括: sin() cos() int() rand() 示例代码如下： BEGIN{ pi=3.14 print int(pi) srand() # 重新获取随机种子 print rand() } 字符串函数 awk 中常用的字符串函数包括: gsub(r, s, t): 字符串切分 index(s, t): 找出字符串子串 length(s): 计算字符串长度 match(s, r): 字符串匹配 split(s, a, sep): 字符串分隔 sub(r, s, t): 字符串切分 substr(s, p, n): 字符串切分 自定义函数 awk 中也支持自定义函数，自定义函数的格式如下: function 函数名 (参数) { awk语句 return awk变量 } Ps: awk 自定义函数需要编写在 BEGIN，主循环和END 的外侧。 示例如下： awk 'function a() {return 0} BEGIN{ print a() }' By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/beginning.html":{"url":"linux/network/beginning.html","title":"网络协议相关","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/ports.html":{"url":"linux/network/ports.html","title":"端口存活查询与验证","keywords":"","body":"Linux系统中的端口存活查询与验证 前言 在Linux系统中，我们常常需要查询某个端口是否存在，例如: 验证某个服务/进程是否正常启动，最简单的方法就是验证该端口是否存在。 服务启动失败时，判断是否端口已经被其他进行占用时，也需要验证该端口是否已经被绑定。 对于很多同学来说，可能都知道一些常见的命令，例如 lsof、 telnet 等命令，但是对相关命令往往并不是很了解，因此在使用过程中经常会遇到各种问题。 为此，我们将在本文中针对Linux中端口的检查和存活性验证进行详细的说明。 端口查询 查询端口占用情况最常用的工具就是 netstat 以及 lsof 了，下面，我们来依次讲解两个命令: netstat netstat用来查看系统当前系统网络状态信息，包括端口，连接情况等，常用方式如下: netstat -atunlp 其中，各个参数的含义如下： -t : 指明显示TCP端口 -u : 指明显示UDP端口 -l : 仅显示监听套接字(LISTEN状态的套接字) -p : 显示进程标识符和程序名称，每一个套接字/端口都属于一个程序 -n : 不进行DNS解析 -a : 显示所有连接的端口 当前，在上面的输出中，我们会直接得到所有的端口绑定信息，查询起来比较复杂，因此，我们常常会搭配 grep 命令来使用，查询对应的进程或指定的端口。 lsof lsof的作用是列出当前系统打开文件(list open files)。 通过-i参数也能查看端口的连接情况，-i后跟冒号端口可以查看指定端口信息，直接-i是系统当前所有打开的端口。 最简单的使用方式如下： lsof -i:${ports} 端口存活性验证 为了验证某一端口是否能够正常访问，我们常常会使用的命令就是 telnet 和 nc 了，下面来进行具体的说明： telnet telnet是一个用于验证TCP端口连接情况的命令行工具，常用使用方式如下： telnet ${ip} ${port} 连接成功时，示例如下： 连接失败时，示例如下： nc telnet命令仅适用于tcp协议的端口验证，对于udp协议的端口而言，则需要使用 nc 来进行验证。 Ubuntu下的安装方式: apt-get install netcat UDP端口检测方式： nc -vuz ${ip} ${port} 其中: -v 表示打印详细模式 -u 表示UDP协议，默认为TCP协议 -z 表示仅检测端口，不发送数据 连接成功时，示例如下： 连接失败时，示例如下： By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/dhcp.html":{"url":"linux/network/dhcp.html","title":"DHCP服务搭建","keywords":"","body":"在Ubuntu中搭建DHCP服务 什么是DHCP？ 动态主机设置协议（Dynamic Host Configuration Protocol，缩写：DHCP），又称动态主机组态协定。 是一个用于IP网络的网络协议，位于OSI模型的应用层，使用DHCP协议工作，主要有两个用途： 用于内部网或网络服务供应商自动分配IP地址给用户。 用于内部网管理员对所有电脑作中央管理。 安装DHCP服务 下面，我们以 Ubuntu 20.04 系统为例，来讲解如何安装DHCP服务。 1. 安装DHCP服务器 sudo apt-get installdhcp3-server 接下来，我们需要设置DHCP相关的配置文件。 与DHCP服务器相关的配置文件共有2个，分别是 /etc/dhcp/dhcpd.conf 和 /etc/default/isc-dhcp-server。 2. 修改 /etc/default/isc-dhcp-server 配置 首先我们首先来修改 /etc/default/isc-dhcp-server 配置文件。 在该配置文件中，我们仅仅只需要设置监听DHCP服务的网卡即可，首先，我们需要使用 ip addr 命令查询机器上可用的网卡名称： $ ip addr 1: lo: mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp0s31f6: mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 54:e1:ad:28:cb:aa brd ff:ff:ff:ff:ff:ff inet 192.168.1.22/24 brd 192.168.1.255 scope global noprefixroute enp0s31f6 valid_lft forever preferred_lft forever inet6 fe80::56e1:adff:fe28:cbaa/64 scope link valid_lft forever preferred_lft forever 从上面输出中，我们可以看到机器上有一个名为 enp0s31f6 网卡。 接下来就是编辑 /etc/default/isc-dhcp-server 配置文件，找到下面这行进行修改即可： INTERFACESv4=\"enp0s31f6\" Ps：根据不同的操作系统版本，由于名词也不太一样，例如，有时会叫做 INTERFACES 可以根据默认配置文件进行查看。 3. 修改 /etc/dhcp/dhcpd.conf 配置 该文件中，需要修改两部分。 首先是注释第一部分中的 option domain-name-servers 行，如下所示： # option definitions common to all supported networks... option domain-name \"example.org\"; # option domain-name-servers ns1.example.org, ns2.example.org; # 注释该行 default-lease-time 600; max-lease-time 7200; 第二部分则是修改 subnet 块： # A slightly different configuration for an internal subnet. subnet 192.168.1.0 netmask 255.255.255.0 { range 192.168.1.150 192.168.1.253; option domain-name-servers 192.168.1.1; option subnet-mask 255.255.255.0; option routers 192.168.1.1; option broadcast-address 192.168.1.255; default-lease-time 600; max-lease-time 7200; } 4. 重启DHCP服务 sudo service isc-dhcp-server restart 5. 验证DHCP服务是否正常启动 sudo netstat -uap # ... # udp 0 0 0.0.0.0:bootps 0.0.0.0:* 1084/dhcpd # ... Ps: 如果能够看到上述输出中包含dhcp任务，那就说明DHCP服务器已经正常启动了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/nfs.html":{"url":"linux/network/nfs.html","title":"NFS网络文件系统搭建","keywords":"","body":"NFS网络文件系统搭建 概述 NFS或网络文件系统是一种分布式文件系统协议，最初是由Sun Microsystems构建的。 通过NFS，您可以允许系统通过网络与其他人共享目录和文件。 在NFS文件共享中，用户甚至程序可以访问远程系统上的信息，就像它们驻留在本地计算机上一样。 NFS 以客户端 - 服务器方式运行，其中服务器负责管理客户端的身份验证，授权和管理，以及特定文件系统内共享的所有数据。 授权后，任意数量的客户端都可以访问共享数据，就好像它们存在于其内部存储中一样。 在 Ubuntu 系统上设置 NFS 服务器非常简单。 在本文中，我们将逐步说明如何设置NFS服务器和客户端，使您能够将文件从一个Ubuntu系统共享到另一个Ubuntu系统。 服务端搭建 Step1: 安装 NFS 服务器 sudo apt-get update sudo apt install nfs-kernel-server Step2: 创建共享目录 sudo mkdir -p /home/wangzhe/Desktop/sync_data_executor_dir sudo chown nobody:nogroup /home/wangzhe/Desktop/sync_data_executor_dir sudo chmod 777 /home/wangzhe/Desktop/sync_data_executor_dir Step3: 设置目录访问权限 修改 /etc/exports 文件，增加如下内容: /home/wangzhe/Desktop/sync_data_executor_dir 192.168.1.0/24(rw,sync,no_subtree_check) 上述内容的含义表示: 允许 192.168.1.0/24 网段的机器读写 /home/wangzhe/Desktop/sync_data_executor_dir 共享目录。 Step4: 重启NFS服务端使得配置生效 sudo exportfs -a sudo service nfs-kernel-server restart 此时，NFS 服务端就已经搭建完成了。 客户端搭建 Step1: 安装 NFS Common （包含 NFS 客户端） sudo apt-get update sudo apt-get install nfs-common Step2: 在客户端机器上创建一个目录用于挂载共享目录 sudo mkdir -p /home/wangzhe/Desktop/sync_data_executor_dir sudo mount 192.168.1.102:/home/wangzhe/Desktop/sync_data_executor_dir /home/wangzhe/Desktop/sync_data_executor_dir Step3: 测试一下吧 此时，其实我们的 NFS 服务端和客户端就都已经搭建完成了，下面我们可以来验证一下。 在客户端机器的目录上创建一个文件，然后在服务端对应的共享目录上看一下，是不是已经可以看到该文件了呢。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/ntp.html":{"url":"linux/network/ntp.html","title":"NTP服务搭建","keywords":"","body":"Ubuntu系统中安装NTP服务器 什么是NTP服务 为了避免Linux系统的主机，在长时间运行下所导致的时间偏差，因此需要对时间进行时间同步(synchronize)。 我们一般使用ntp服务来同步不同机器的时间，NTP 是网络时间协议（Network Time Protocol）的简称，它是通过UDP协议，对时间进行同步的。 NTP服务器安装与配置 下面，我们以 Ubuntu 20.04 操作系统为例，讲解如下安装与配置NTP服务器。 NTP服务器的安装 在Ubuntu系统中，NTP服务器的安装非常的检查，仅需要执行如下命令即可： sudo apt-get install ntp NTP服务器的配置 NTP服务器的配置文件为: /etc/ntp.conf。 在国内的场景下，我们可以直接修改 /etc/ntp.conf 文件如下： driftfile /var/lib/ntp/ntp.drift statistics loopstats peerstats clockstats filegen loopstats file loopstats type day enable filegen peerstats file peerstats type day enable filegen clockstats file clockstats type day enable server s1a.time.edu.cn prefer server s2a.time.edu.cn server s2b.time.edu.cn server s2e.time.edu.cn server 127.127.1.0 fudge 127.127.1.0 stratum 5 restrict -4 default kod notrap nomodify nopeer noquery restrict -6 default kod notrap nomodify nopeer noquery restrict 192.168.1.0 mask 255.255.255.0 nomodify 其中需要注意最后一行： restrict 192.168.1.0 mask 255.255.255.0 nomodify restrict 用于权限相关控制，其基本语法为： restrict ${IP地址} mask ${子网掩码} ${参数} 其中: IP地址也可以是default ，default 就是指所有的IP。 参数支持如下选项： ignore ：关闭所有的 NTP 联机服务。 nomodify：客户端不能更改服务端的时间参数，但是客户端可以通过服务端进行网络校时。 notrust ：客户端除非通过认证，否则该客户端来源将被视为不信任子网。NTP4.2 版本以后使用会出错。 noquery ：不提供客户端的时间查询：用户端不能使用ntpq，ntpc等命令来查询ntp服务器。 notrap ：不提供trap远端登陆：拒绝为匹配的主机提供模式 6 控制消息陷阱服务。PS：陷阱服务是 ntpdq 控制消息协议的子系统，用于远程事件日志记录程序。 nopeer ：用于阻止主机尝试与服务器对等，并允许欺诈性服务器控制时钟。 kod ： 访问违规时发送 KoD 包。 restrict -6 表示IPV6地址的权限设置。 修改完成配置文件后，我们需要使用如下命令重启NTP服务： service ntp restart NTP服务器功能验证 NTP服务器配置文件修改完成并重启服务后，我们可以执行如下命令进行服务可用性与上级联通性验证： ntpq -p By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/rtsp.html":{"url":"linux/network/rtsp.html","title":"rtsp协议与实战","keywords":"","body":"rtsp协议概述与实战 协议概述 RTSP（Real Time Streaming Protocol），RFC2326，中文名称为实时流传输协议，是TCP/IP协议体系中的一个应用层协议。 它由哥伦比亚大学、网景和RealNetworks公司提交的IETF RFC标准。 该协议定义了一对多应用程序如何有效地通过IP网络传送多媒体数据。 RTSP在体系结构上位于RTP和RTCP之上，它使用TCP或UDP完成数据传输。 HTTP与RTSP相比，HTTP请求由客户机发出，服务器作出响应；使用RTSP时，客户机和服务器都可以发出请求，即RTSP可以是双向的。 RTSP是用来控制声音或影像的多媒体串流协议，并允许同时多个串流需求控制，传输时所用的网络通讯协定并不在其定义的范围内，服务器端可以自行选择使用TCP或UDP来传送串流内容，它的语法和运作跟HTTP 1.1类似，但并不特别强调时间同步，所以比较能容忍网络延迟。 而前面提到的允许同时多个串流需求控制（Multicast），除了可以降低服务器端的网络用量，更进而支持多方视讯会议（Video Conference）。 因为与HTTP1.1的运作方式相似，所以代理服务器〈Proxy〉的快取功能〈Cache〉也同样适用于RTSP，并因RTSP具有重新导向功能，可视实际负载情况来转换提供服务的服务器，以避免过大的负载集中于同一服务器而造成延迟。 Python rtsp协议实战 在下面的实战中，我们使用Python及Python的第三方库rtsp来拉取RTSP的视频流以及相关操作。 Ps：在本实验中，我们使用的Python的版本是Python 3.8。 首先，需要安装Python的第三方库rtsp。 pip install rtsp==1.1.8 接下来，我们来了解几种rtsp最常用的方式： 一、抓取RTSP瞬时截图 import rtsp client = rtsp.Client(rtsp_server_uri = 'rtsp://192.168.1.202/1') client.read().show() client.close() 二、抓取RTSP视频流 import rtsp with rtsp.Client(rtsp_server_uri = 'rtsp://192.168.1.202/1') as client: client.preview() 三、持续抓取视频帧并处理 import rtsp def process_image(image): \"\"\" # 处理每一帧图像的逻辑 \"\"\" pass with rtsp.Client(rtsp_server_uri = 'rtsp://192.168.1.202/1') as client: _image = client.read() while True: process_image(_image) _image = client.read(raw=True) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/snmp.html":{"url":"linux/network/snmp.html","title":"Linux上如何扫描同一网段内的所有设备","keywords":"","body":"Linux上如何扫描同一网段内的所有设备 有时，我们希望内知道当前交换机/局域网内连接了哪些设备，这是就会用到一个 snmp 的命令了。 snmp 快速入门 具体命令如下: nmap –nsP 192.168.1.0/24 # 扫描从192.168.1.0到192.168.1.255所有IP By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/network_priority.html":{"url":"linux/network/network_priority.html","title":"Linux多网卡优先级配置","keywords":"","body":"Linux系统中多网卡优先级配置 前言 在一台Linux服务器中，可能同时有多块网卡，一块用于连接内网，一块用于连接外网。或者一个是有线网络、另一个是无线网络等场景。 此时，我们需要对网卡的优先级进行有效的配置，否则可能会导致网络异常，无法正常访问的一系列问题。 什么是网卡路由优先级 网卡路由优先级只是在路由表里的多个路由中选择与转发包中的目标地址最为匹配的路由时的顺序。 其中，每个路由都会设置一个跃点数，跃点越低则表示优先级越高。 通常，跃点可以根据网络速度、可靠性、吞吐量、管理属性等进行指定。 查询路由信息的方式如下： route -n # 内核 IP 路由表 # 目标 网关 子网掩码 标志 跃点 引用 使用 接口 # 0.0.0.0 192.168.1.1 0.0.0.0 UG 20100 0 0 enp0s31f6 # 169.254.0.0 0.0.0.0 255.255.0.0 U 1000 0 0 enp0s31f6 # 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 # 172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker_gwbridge # 192.168.1.0 0.0.0.0 255.255.255.0 U 100 0 0 enp0s31f6 此时，需要注意的是，如果有两块网卡的跃点值相同，泽辉出现抢占优先级，从而导致的网卡冲突，可能导致一块网卡无法连接。 如何修改网卡优先级 那么，怎么修改网卡的优先级呢？ 修改网卡优先级的方式就是修改网卡的配置文件，并添加或修改其中的IPV4_ROUTE_METRIC参数。 网卡的配置文件所在的目录为/etc/sysconfig/network-script/。 通常，配置文件的名称为ifcfg-xxx。其中，xxx表示网卡名称或无线Wifi名称。 配置文件格式如下： NAME=“eth1” TYPE=“Ethernet” BOOTPROTO=“none” DEVICE=“eth1” ONBOOT=“yes” IPADDR=**** NETMASK=255.255.255.224 GATEWAY=**** IPV4_ROUTE_METRIC=100 其中，上述最后一行的IPV4_ROUTE_METRIC就是用于设置网卡跃点数的配置，如果之前没有改行，可以主动添加并设置。 修改完配置文件后需要重启网络服务才能生效: systemctl restart network 服务重启完成后，可以route -n命令查询配置的跃点数是否生效。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/network/https.html":{"url":"linux/network/https.html","title":"HTTPS 协议实战","keywords":"","body":"HTTPS 协议实战 为什么需要 HTTPS ？ HTTP 中存在如下一些缺点，例如: 通信使用明文（不加密），内容可能会被窃听。 不验证通信方的身份，因此有可能遭遇伪装。 无法证明报文的完整性，所以内容有可能遭到篡改。 这其实不仅仅是 HTTP 的问题，而是所有未加密的协议中都有可能出现的问题。 窃听风险 在 TCP/IP 协议族中的工作机制中，通信内容在所有通信线路上都有可能遭到窥视。如下图所示: 那么，怎么才能加密处理才能防止被窃听呢？加密的方式通常有如下两种: 通信的加密 HTTP 协议本身没有加密机制，可以通过和 SSL 或 TLS 的组合使用，加密 HTTP 通信内容，这就是典型的通信的加密。 具体来说，用 SSL 建立安全通信线路之后，就可以在这条线路上进行 HTTP 通信了。 与 SSL 组合使用的 HTTP 被称为 HTTPS 或 HTTP over SSL 。 内容的加密 除了直接对通信的加密，还可以直接对传输的内容本身进行加密，即把 HTTP 报文里包含的内容进行加密处理。 这个的前提是客户端和服务端同时具备加密和解密的能力。 通信方伪装风险 HTTP 协议中的请求和响应不会对通信方进行确认，也就说存在『服务器是否就是发送请求中 URI 真正指定的主机』、 『返回的响应是否真的返回到实际提出请求的客户端』等类似问题。 在 HTTP 通信协议中，不存在确认通信方的处理步骤，任何人都可以发起请求， 服务器也不会关心是谁发起的请求，都会返回对应的响应。 虽然使用 HTTP 协议无法确定通信方，但使用 SSL 协议则可以具备相应能力。 SSL 不仅仅可以用于数据加密处理，还使用了一种被称为『证书』的手段，可以用于确认通信方。 证书由值得信任的第三方机构颁发，用于证明服务器和客户端是实际存在的。 而伪造证书从技术角度来说是一件异常困难的事，因此只要能确认通信方（服务器/客户端）持有的证书，就可以判断出对应的来源。 内容遭遇风险 由于 HTTP 协议无法证明通信的报文完整性，因此无法确认发出的请求/响应和接收到的请求/响应是前后相同的。 像上图所示，在请求或响应的传输途中，遭到攻击者拦截并篡改内容的攻击称为中间人攻击。 在 SSL 中，提供的摘要等相关的功能，可以有效的保证 HTTP 消息的完整性。 HTTPS (HTTP + 加密 + 认证 + 完整性保护) 原理 HTTPS 就是指在 HTTP 协议的基础上，提供了通信加密、证书认证和完整性保护相关的功能。 在对 SSL 进行讲解时，我们先来讲解一下加密方法。 例如 SSL 采用的是 公开密钥加密 的加密处理方式。 目前，加密的算法其实都是公开的，只有密钥才是保密的，正式通过密钥的保密来实现的加密方案的安全性。 加密和解密都会用到密钥。没有密钥就无法对密码进行解密，反过来说，任何人只要持有密钥就能解密了。 对称加密(共享密钥) 加密和解密同用一个密钥的方式称为对称加密。 以共享密钥方式加密时必须将密钥也发给对方。可怎么才能把密钥安全的传输呢？ 非对称加密(公开密钥) 公开密钥加密方式很好地解决了共享密钥加密的困难。 公开密钥加密使用一对非对称的密钥。 一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。 顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。 而由于公开密钥和私有密钥的内容其实是不一样的，这就是所谓的『非对称加密』。 使用公开密钥加密方式，发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后， 再使用自己的私有密钥进行解密。 利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。 HTTPS 加密 HTTPS 采用共享密钥加密和公开密钥加密两者并用的混合加密机制。 公开密钥加密与共享密钥加密相比，其处理速度要慢，但无法保证密钥的安全传输。 所以应充分利用两者各自的优势，将多种方法组合起来用于通信。 在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。 身份认证机制 通过共享密钥加密和公开密钥加密两者的结合，HTTPS 有效的实现了数据传输过程中的加密机制。 下面，我们来看一下 HTTPS 是如何解决身份认证机制的吧。 HTTPS 中的身份认证机制是由数字证书认证机构（CA）和其相关机关颁发的公开密钥证书实现的。 具体来说，数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。 首先，服务器的运营人员向数字证书认证机构提出公开密钥的申请。 然后，数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名。 接下来，分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起。 服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。 公钥证书也可叫做数字证书或直接称为证书。 接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证， 一旦验证通过，客户端便可明确两件事： 一. 认证服务器的公开密钥的是真实有效的数字证书认证机构。 二. 服务器的公开密钥是值得信赖的。 此处认证机关的公开密钥必须安全地转交给客户端。 使用通信方式时，如何安全转交是一件很困难的事。 因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。 上图展示了对于一个WEB服务器而言，是如何使用 HTTPS 进行加密和身份认证的完整流程。 除了直接对服务端进行认证，HTTPS 其实也支持对客户端进行认证。 以客户端证书进行客户端认证，证明服务器正在通信的对方始终是预料之内的客户端，其作用跟服务器证书如出一辙。 不过对于客户端证书而言，通常存在如下两个问题： 是证书的获取及发布。客户端证书需要用户自行购买和安装，对用户充满挑战。 客户端证书毕竟只能用来证明客户端实际存在，而不能用来证明用户本人的真实有效性。 因此，目前的客户端证书其实仅仅在部分的领域中应用而已。 自签名证书 我们之前提到了 CA 机构，也就是说通过 CA 机构可以颁发认证的数字签名。 而其实我们自己也可以使用 OpenSSL 这套开源程序，自己搭建一套属于自己的认证机构， 从而可以自己给自己颁发服务器证书。 Ps: 不过这套颁发的证书在互联网上（各个浏览器）并没有内置公开密钥信息，因此浏览器在判断证书的可靠性时，默认会不信任。 独立构建的认证机构叫做自认证机构，由自认证机构颁发的证书也被戏称为自签名证书。 客户端与服务器进行 HTTPS 协议通信的流程如上图所示。 HTTPS 实战 了解了 HTTPS 相关的原理之后，我们来进行一些相关的 HTTPS 实战吧！ 创建相关证书 首先，我们需要使用 OpenSSL 二进制程序来制作相关程序用到的公钥证书、私钥等。 Step1: 生成 CA 的证书和私钥 openssl req -nodes -new -x509 -days 3650 -keyout ca.key -out ca.crt -subj \"/CN=Virtual Environment Admission Controller Webhook CA\" 其中：ca.key 表示 CA 私钥，ca.crt 表示 CA 证书。 Step2: 生成服务器私钥 openssl genrsa -out webhook-server-tls.key 2048 其中: webhook-server-tls.key 表示服务器私钥 Step3: 为私钥生成证书签名请求 (CSR)，并使用 CA 的私钥对其进行签名。 openssl req -new -key webhook-server-tls.key -subj \"/CN=webhook-server.kt-virtual-environment.svc\" \\ | openssl x509 -req -days 3650 -CA ca.crt -CAkey ca.key -CAcreateserial -out webhook-server-tls.crt 其中: webhook-server-tls.crt 表示服务器公钥证书（包含公钥和CA私钥签名）。 webhook-server.kt-virtual-environment.svc 表示了服务器的访问地址，客户端验证证书时，会验证访问地址是否与证书中的地址一致。 搭建 HTTPS 服务 下面，我们编写一个简单的 Flask WEB 服务来实现一个 HTTPS 服务的搭建： from flask import Flask app = Flask(__name__) @app.route(\"/\") def hello(): return \"Hello World!\" if __name__ == \"__main__\": app.run(ssl_context=('webhook-server-tls.crt', 'webhook-server-tls.key')) 编写 HTTPS 客户端 下面，我们还是使用 python requests 客户端来发送 HTTPS 请求。 import requests url = \"https://webhook-server.kt-virtual-environment.svc:5000/\" response = requests.get(url, verify=\"ca.crt\") print(response.content) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/git/beginning.html":{"url":"linux/git/beginning.html","title":"git杂谈","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/git/gitignore.html":{"url":"linux/git/gitignore.html","title":"Git忽略已加入版本控制系统中的文件","keywords":"","body":"Git忽略已加入版本控制系统中的文件 背景描述 众所周知，对于git项目，可以在.gitignore中添加一些文件/文件夹，以此来进行文件忽略。 然而，对于一些已经被track的文件，再添加至.gitignore中是没有效果的。 在本文中，我们将会主要讲解针对已经被track的文件如何通过.gitignore文件进行忽略。 实现方式 具体来说，为了实现通过.gitignore文件进行忽略已经被track的文件，需要通过如下两步： 清除本地缓存。 重新提交commit信息。 git rm -r --cached . git add . git commit -m 'update .gitignore' By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"linux/git/mirror.html":{"url":"linux/git/mirror.html","title":"Git mirror实现飞速上传/下载","keywords":"","body":"Github mirror实现飞速上传/下载 我们在用git的向github拉取代码的时候，一定体会过10+kb下载的绝望吧~ 辛苦等待几小时，结果又fail了。 本文主要是讲解一个小技巧，让你能够实现飞速的对github拉取/上传代码。 常用mirror推荐 https://github.com.cnpmjs.org/ https://hub.fastgit.org/ https://gitclone.com/github.com/ Git Clone加速示例 #原地址 git clone https://github.com/kubernetes/kubernetes.git #改为 git clone https://github.com.cnpmjs.org/kubernetes/kubernetes.git #或者 git clone https://hub.fastgit.org/kubernetes/kubernetes.git #或者 git clone https://gitclone.com/github.com/kubernetes/kubernetes.git release下载加速 #原地址 wget https://github.com/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgz #改为 wget https://hub.fastgit.org/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgz 全局替换方法 git config --global url.\"https://github.com.cnpmjs.org\".insteadOf https://github.com # 测试 git clone https://github.com/kubernetes/kubernetes.git # 查看git配置信息 git config --global --list # 取消git配置 git config --global --unset url.https://github.com.cnpmjs.org.insteadof By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/tensorflow/beginning.html":{"url":"ai/tensorflow/beginning.html","title":"tensorflow快速入门","keywords":"","body":"tensorflow快速入门 简述 tensorflow 是由 Google 开源的一款深度学习框架，也是目前最流行的深度学习框架。 早在2012年，Google 内部就使用了一个名为 Google DistBelief 的第一代 深度学习平台用于公司内部的深度学习算法相关开发与应用。 而在2015年，Google 推出了它的第二代深度学习框架 - Tensorflow ，并将其开源， 从而也逐步变成了社区最流行的深度学习框架。 对于Tensorflow框架而言，其具备如下优点: 包含灵活通用的深度学习库 兼容端云结合的运行场景 是一款高性能的基础平台软件 具备跨平台运行的能力 Tensorflow 典型应用场景 深度学习近些年来突然大火，不得不提及的就是 Alpha Go 大胜人类围棋高手的事件了。 而 Alpha Go 就是 Google 基于 tensorflow 编写的众多AI算法模型之一了。 但是，其实除了 Alpha Go 之外，深度学习近些年来其实已经深入到了我们生活的方方面面。 常见的包括基于人脸识别算法的人脸签到和门禁；基于OCR识别的身份证信息识别与核对等等一系列场景。 而目前使用 Tensorflow 的公司也是不胜枚举，除了 Google 自家公司之外，国外的 NVIDIA, Intel、 国内的小米、腾讯、网易等等都在使用着 Tensorflow 框架来开发自己的 AI 应用。 Tensorflow 发展现状 目前，Github 中的 tensorflow 代码库已经有了超过 154K 的Star，同时也被 Fork 了超过 84.2k 次。 这一数据在 Github 中已经进入了前10名的范围。 同时，最新的 tensorflow 也已经进入 2.0+ 版本，相比 1.0+ 版本而言， 2.0版本有了更加友好的体验和更加强大的功能。 Tensorflow 也支持各种编程语言的接口，例如 Python, c++, Java, Go, JS等等，基本可以满足任何开发场景的需求。 怎么样？听了我们的描述，是不是对 Tensorflow 已经充满了求知的欲望，下面，来跟着我们一起进入 tensorflow 的学习吧。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/tensorflow/install.html":{"url":"ai/tensorflow/install.html","title":"tensorflow环境搭建","keywords":"","body":"tensorflow 环境搭建 了解了 tensorflow 的各种优点、应用场景后，接下来，我们就需要去快速体验一下 tensorflow 的功能了。 那么，实战 tensorflow 的第一步永远都是环境搭建，下面，我们来分别用几种不同的方式来进行 tensorflow 的环境搭建。 基础环境说明 首先，Tensorflow 支持各种各样的硬件平台，例如： CPU GPU Cloud TPU Android IOS 嵌入式系统 浏览器等 而支持 Tensorflow 的操作系统也多种多样，例如: Ubuntu, Windows, macOS, Raspbian 等等。 下面，我们将以 macOS 为例来演示如何通过多种方式搭建 tensorflow 基础环境。 Ps: 在本文中，我们将会搭建 tensorflow 1.15.5 （tensorflow 1.0版本中的最新版本）环境，在后续的文章中，我们以后搭建 tensorflow 2.0+ 的 版本。 物理机 / 虚拟机上搭建 tensorflow 我们在本系列文章中，主要会以 Python 代码为例，来演示 tensorflow 相关的功能使用，因此，我们搭建的 tensorflow 也是基于 Python 语言的。 而搭建 Python 的 Tensorflow 环境首先就需要安装 Python 和 Python 的包管理工作 pip 。 而 Anaconda 是一个集成了 Python + Python 部分依赖的一个软件包，我们可以直接使用 Anaconda 进行相关环境搭建。 安装完成 Anaconda 后，我们可以使用 conda 来创建一个 Python 的虚拟环境。 conda create -n tensorflow115 python=3.6 其中： -n 表示创建新创建的虚拟环境的名称 python=3.6 表示当前创建的虚拟环境使用的Python版本是3.6 Ps: Python虚拟环境可以在同一台机器上管理多个不同版本的 Python 解释器，同时，可以给每个 Python 解析器安装不同的版本的第三方库依赖。 这样，我们就可以在同一台机器上同时体会 Python 2.7 和 Python 3.6，也可以同时使用 Tensorflow 1.X 和 Tensorflow 2.X。 接下来，我们可以切换到新创建的虚拟环境中: conda activate tensorflow115 此时，我们使用 pip 进行安装的依赖都会安装到该虚拟环境下，同时使用的 python 以及其他第三方库二进制可执行文件都会使用该虚拟环境下的文件。 切换到对应的虚拟环境后，我们就可以安装 Python 的 tensorflow 依赖库了: pip3 install tensorflow==1.15.5 我们使用了 1.15.5 版本的tensorflow进行安装，如果依赖包下载速率太慢的话，也可以指定国内的一些 pip 源: pip3 install tensorflow==1.15.5 -i https://pypi.tuna.tsinghua.edu.cn/simple 安装完成后，我们就可以使用 python 解析器来验证一下 tensorflow 是否已经正常安装了: python3 -c \"import tensorflow as tf\" 如果没有看到什么报错的话，那么恭喜你，你的 tensorflow 环境已经基本搭建好了。 下面，我们来体验一下 tensorflow 的 hello world ! 编写 hello_tensorflow.py 文件如下： # -*- coding: UTF-8 -*- import tensorflow as tf # 定义一个hello 的常量 hello = tf.constant(\"Hello Tensorflow\") # 创建一个会话 session = tf.Session() # 执行常量操作并打印到标准输出 print(session.run(hello)) 运行 hello_tensorflow.py 文件，你就可以看到命令行中打印的标准输出了。 jupyter notebook 中使用 tensorflow 但是，通过编写一个完整的 Python 文件并执行在调试或者学习过程中，往往是非常低效的。 而 Python 虽然也提供了交互式命令行工具，但是对于画图等场景并不友好，因此，我们接下来，需要使用一个 Python 开发利器: Jupyter Notebook。 Jupyter Notebook 是一个 Python的交互式开发环境，也属于 Python 的第三方扩展工具，同样可以使用 pip 包管理工具进行安装。 同样是需要先进入之前创建的虚拟环境，然后执行如下命令可以安装 Jupyter Notebook : pip3 install jupyter 安装完成后，只需要执行 jupyter-notebook 即可启动对应的 Jupyter Notebook 服务。 此时，jupyter-notebook 会自动打开浏览器，并访问对应 jupyter-notebook 页面，你可以在该页面中创建 notebook 文件并执行。 在 Docker 容器中使用 tensorflow 最后，我们来了解一下在云原生时代，我们是如何使用 tensorflow 的。 云原生时代最大的成果之一就是 Docker 了。 通过 Docker 镜像，我们可以将运行某个程序的所有依赖环境全部都打包的镜像中去，真正运行容器时，只需要拉取镜像并启动镜像即可。 不再需要因为环境搭建、依赖复杂等问题影响我们的工作效率了。 当然，想要使用 Docker 容器首先需要安装 Docker 软件，这一步骤 官网 已经有了详细的说明，我们就不再赘述了。 安装完成后，我们可以直接拉取对应的 Docker 镜像： docker pull tensorflow/tensorflow:nightly-jupyter 其中: tensorflow/tensorflow 是对应的镜像名称。 nightly-jupyter 是我们要拉取的镜像tag，其中: nightly-jupyter 表示轻量级 tensorflow 且安装有 jupyter notebook 镜像拉取可能需要一段时间，当镜像拉取完成后，我们可以启动该 Docker 镜像: docker run -it -p 8888:8888 -v ${local_path}:/tf/notebooks tensorflow/tensorflow:nightly-jupyter 其中: -it 表示以交互式命令行的方式前台启动该镜像。 -p 表示需要镜像端口映射，即将容器内的8888端口映射到本地的8888端口，从而可以在本地浏览器进行访问。 -v 表示进行目录映射，即将本地的指定目录（需手动修改）挂载到容器内部的 /tf/notebooks 目录下，这样，我们就可以在容器内部看到并修改本地的文件了。 启动该容器后，我们就可以打开浏览器并访问 http://127.0.0.1:8888/tree 进行相关的操作了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/tensorflow/artitecture.html":{"url":"ai/tensorflow/artitecture.html","title":"tensorflow架构介绍","keywords":"","body":"tensorflow 架构介绍 看上去， tensorflow 仅仅是一个 Python 的第三方库而已，你可能还在想，一个第三方库也需要介绍架构？ 如果你这么想的话，那你实在是太小瞧了 tensorflow 。 模块和API 首先，我们先从大的模块分类了解 tensorflow 包含哪些模块: 从面向用户的分层结构上来看， tensorflow 可以大致分为 4 层。 其中，用户往往仅关心前两层到三层。 下面，我们依次来讲解每一层的功能和使用场景。我们从上向下进行分析： High-Level Tensorflow APIs: Estimators 和 Keras 其实都是针对 tensorflow 高度封装 的API，通过 Estimators 和 Keras，我们甚至可以使用不到10行代码就能够实现一个相当复杂的模型。因此， High-Level Tensorflow APIs 非常适用于相当直接使用 Tensorflow 来完成某项任务的工程师。 Mid-Level Tensorflow APIs: 包括了很多常用的深度学习网络层的函数、数据集的操作管理函数以及相关各种指标管理的函数。 因此，当现有的Estimators 和 Keras模型无法满足你的需求时（如需要自定义网络模型），那Mid-Level Tensorflow APIs可能 就是一个不错的选择了。 Low-Level Tensorflow APIs 则是更加底层的 tensorflow 操作 API，它甚至可以提供基于tensorflow的算法操作等。 因此，当你需要完全自定义相关计算逻辑时，至少也可以直接调用Low-Level Tensorflow APIs。同时，Low-Level Tensorflow APIs 提供了各个语言的版本，你可以将训练好的模型通过各个语言进行调用并在不同的场景下进行执行。 Tensorflow Kernel 是 Tensorflow 真正的精华所在，负责整体的任务计算、执行、调度等一系列操作，各个 Level 的 API 最终 都是通过与 Tensorflow Kernel 进行交互实现对应的计算任务。 Tensorflow 架构 上面，我们从用户视角了解了 Tensorflow 的基本分层思想，下面，我们要从系统架构的角度来了解 Tensorflow 的架构。 上图是 Tensorflow 的系统架构图。 Tensorflow的系统结构以C API为界，将整个系统分为前端和后端两个子系统： 前端负责设计数据流图 后端执行数据流图，可再细分为： 运行时：提供本地模式和分布式模式 计算层：由 kernel 函数组成 通信层：基于 gRPC 实现组件间的数据交换，并能够在支持 IB 网络的节点间实现RDMA通信 设备层：计算设备是 OP 执行的主要载体，TensorFlow 支持多种异构的计算设备类型 从图管理的角度来看，tensorflow 包括： 设计数据流图: 仅仅设计数据流图的组织关系，但是不执行，由前端 API 实现。 编排数据流图: 将计算图的节点以最佳的执行方案部署在集群中各个计算设备上，有运行时来负责相关的功能。 运行数据流图: 按照拓扑排序执行图中的节点，并启动每个OP的Kernel计算(计算层、通信层、设备层) 而从系统组成部分来看，还可以分成: client: 毫无疑问，client 是 tensorflow 的使用入口，负责设计数据流图并与 master 交互发送任务。 master: master 负责接收数据流图并进行处理和任务分配 client 在执行 Session.run 时，传递整个计算图(Full Graph)给后端的 Master。 master 通过 Session.run 中的 fetches、feeds 参数根据依赖关系将 Full Graph 剪枝为小的依赖子图(Client Graph)。 master 根据任务名称将 Client Graph 分为多个 Graph Partition(SplitByTask)，每个 Graph Partition 被注册到相应的 Worker 上(任务和 Worker 一一对应)。 master 通知所有 worker 启动相应 Graph Partition 并发执行。 worker: worker 是最终的数据流图的计算执行者 接收来自 master 下发的执行任务。 对注册的 Graph Partition 根据本地设备集二次分裂(SplitByDevice)，其中每个计算设备对应一个 Graph Partition (是注册的Graph Partition中更小的Partition)，并通知各个计算设备并发执行这个更小的 Graph Partition (计算根据图中节点之间的依赖关系执行拓扑排序算法)。 按照拓扑排序算法在某个计算设备上执行本地子图，并调度OP的Kernel实现。 协同任务之间的数据通信(交换OP运算的结果) 本地CPU与GPU之间，使用 cudaMemcpyAsync 实现异步拷贝。 本地GPU之间，使用端到端的 DMA 操作，避免主机端CPU的拷贝。 分布式运行时，通过 gRPC 协议完成跨节点的数据通信。 kernel: Kernel 是 OP 在某种硬件设备的特定实现，它负责执行 OP 的具体运算，大多数 Kernel 基于 Eigen::Tensor 实现。 数据流图概述 在上述 tensorflow 的架构中，我们不止一次的提到了 数据流图 这一核心概念。 那么，我们接下来需要学习一下在 tensorflow 中的数据流图究竟是什么。 如上图所示，这就是一个典型的可视化的 tensorflow 的数据流图。 在这一数据流图中，可以看到两个类型的元素，分别是: 节点：在 tensorflow 中，节点通常表示的就是数据流图中的数学操作（Operation），此外，除操作外，我们还用节点来表示一些数据输入。 有向边：在 tensorflow 中，有向边指的是在各个数学操作之间流动的数据，由于在深度学习中的计算通常的高维数据，因此，有向边也就是对应着张量数据。 那数据流图有什么作用呢？ TensorFlow 程序通常被组织成一个构建图阶段和一个执行图阶段。 在构建阶段, op 的执行步骤被描述成一个图。 在执行阶段, 使用会话执行执行图中的 op。 通过这个步骤的拆分，在构建阶段，本质上只是在设计操作流程，并不会真正触发计算操作。而是统一在执行阶段执行相关的操作。 这样一来，Tesorflow 在执行阶段，可以有效的将计算任务进行拆分和分配，从而能够充分发挥出计算资源的能力，尽可能快速的完成计算任务。 具体体现在，在多块GPU卡并行计算中： n 块 GPU 卡能处理的图片数目几乎等于 1 块 GPU 卡能处理的图片数目 * n。 在多台服务器分布式计算中： n 块 GPU 卡能处理的图片数目几乎等于 1 块 GPU 卡能处理的图片数目 * n。 参考资源 极客时间-tensorflow入门 知乎-《TensorFlow 内核剖析》笔记——系统架构 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/tensorflow/concept.html":{"url":"ai/tensorflow/concept.html","title":"tensorflow核心概念","keywords":"","body":"tensorflow 核心概念 在进一步学习 tensorflow 的使用之前，我们非常有必要来了解一些 tensorflow 的一些核心概念。 张量（tensor） 在数学定义中， 张量 是一种几何实体，从广义上来讲，张量可以表示任意形式的数据。 其中： 标量可以认为是0阶张量。 向量可以认为是1阶张量。 矩阵可以认为是2阶张量。 数据立方体可以认为是3阶向量。 超过3维的数据可以认为是n阶张量。 可以看出，张量的 阶数 描述它表示数据的最大维度。 而具体到 Tensorflow 中， Tensor 表示的是某种相同数据类型的多维数组。 因此，对于张量而言，它有两个重要属性: 数据的类型：如浮点型、整型、字符串型等等。 数组的形状：如各个维度的大小。 那么，在 Tensorflow 中，张量是用来做什么的呢，又具备哪些特点呢？ 首先，张量是用来表示 Tensorflow 计算过程中的多维数据的。 对于 Tensorflow 中的每次执行操作而言，它的输入和输出数据其实都是张量。 而张量本身也是有 Tensorflow 的执行操作来创建和计算的。 同时，张量的形状在编译时可能不会完全确定，而是在运行的过程中通过输入内容进行推断计算得到的。 而 Tensorflow 中有几个相对特别的张量，我们来此处进行简单说明： tf.constant: Tensorflow 中定义的常量，一旦设置后不能进行修改。 tf.placeholder: Tensorflow 中定义的占位符，往往用于接收输入数据。 tf.Variable: Tensorflow 中定义的变量，在数据流图的计算过程中进行计算和赋值等操作。 针对上述提及的 constant 而言，相对来说比较简单，我们在后续应用到时直接讲解就行。 而针对 Variable 和 placeholder ，我们需要多提几句。 变量（Variable） Tensorflow 中的 Variable 的主要作用是维护特定节点的状态，如深度学习或机器学习的模型参数。 其中： tf.Variable 方法是一个 Operation。 而 tf.Variable 方法的返回值是一个变量（一种张量）。 通过 tf.Variable 方法创建的变量与张量一样，也可以作为 Operation 的输入和输出，但是需要注意的是： 普通张量的生命周期通常随着依赖的计算完成而结束，内存也就随之能够正常释放。 而 Variable 变量则是常驻内存，在每一步训练时不断更新其值，从而实现模型参数的不断迭代优化。 此外，考虑到 tensorflow 在大型模型的训练过程中往往不是一蹴而就的，可能需要分多个阶段进行训练，甚至训练的过程中还会出现人工介入 进行参数调优等现象，因此，我们需要能够将 tensorflow 训练的模型参数能够持久化保存和恢复。 为此，tensorflow 提供了一个能够将 Variable 持久化到文件中的方法: tf.train.Saver 。 如上图所示，Variable 在持久化保存时，会保存至 checkpoint 文件，同时，我们也可以在任意阶段重新进行持久化或者从持久化文件中恢复参数。 占位符（placeholder） Tensorflow 使用占位符操作表示图外输入的数据，如训练数据和测试数据。 Tensorflow 数据流图描述了算法模型的计算拓扑，其中的各个操作（节点）都是抽象的函数映射和数学表达式。 换句话说，数据流图本身是一个具有计算拓扑和内部结构的『壳』，在用户向数据流图填充数据之前，图中并没有执行任何的计算。 # 定义placeholder x = tf.placeholder(tf.int16, shape=(), name=\"x\") y = tf.placeholder(tf.int16, shape=(), name=\"y\") # 建立session with tf.Session() as session: # 填充数据后真正执行操作 print(session.run(add, feed_dict={x: 2, y: 3})) # 其中add和mul都是提前定义好的数据流图的操作 print(session.run(mul, feed_dict={x: 2, y: 3})) 操作（operation） 在 Tensorflow 中用 数据流图 来表示算法模型。而数据流图是由节点和有向边组成的，每一个节点都对应了一个具体的操作。 因此，数据流图中，本身上就是定义了如何通过一组操作来依次处理数据的过程。 现在，我们就来学习一些 tensorflow 中的 操作（operation）具体的含义。 tensorflow 中的节点按照功能可以分为 3 种： 存储节点：有状态的变量操作，通常用来存储模型参数。 计算节点：无状态的计算或者控制操作，主要负责算法的逻辑表达式或者流程控制。 数据节点：数据的占位符操作，用于描述图外的输入数据的属性。 下面，我们来看一下 tensorflow 中支持了哪些典型的计算和控制操作： 操作类型 典型操作 基础算术 add / multiply / mod / sqrt / sin / trace / fft / argmin 数组运算 size / rank / split / reverse / cast / one_hot / quantize 梯度裁剪 clip_by_value / clip_by_norm / clip_by_global_norm 逻辑控制和调试 identity / logical_and / equal / less / is_finite / is_nan 数据流控制 enqueue / dequeue / size / take_grad / apply_grad 初始化操作 zeros_initializer / random_normal_initializer / orthogonal_initializer 神经网络运算 convolution / pool / bias_add / softmax / dropout / erosion2d 随机运算 random_normal / random_shuffle / multinomial / random_gamma 字符串运算 string_to_hash_bucket / reduce_join / substr / encode_base64 图像处理运算 encode_png / resize_images / rot90 / hsv_to_rgb / adjust_gamma 会话（session） 会话提供了计算张量和执行操作的运行环境。 具体来说，它本质上是一个发送计算任务的客户端，通过客户端将所有的计算任务下发给它连接的执行引擎来完成计算。 一个典型的Session流程包含如下步骤： # 1. 创建会话 session = tf.Session(target=..., graph=..., config=...) # 2. 执行操作计算张量 session.run(...) # 3. 关闭会话 session.close() 其中，可以看到，在创建 Session 对象时，用到了三个参数，它们的含义如下： 参数名称 功能说明 target 会话连接时的执行引擎 graph 会话加载时的数据流图 config 会话启动时的配置项 关于上述参数的具体使用方式和详细介绍，在后续的文章中我们都会一一进行讲解。 下面，我们来看一个完整的示例： import tensorflow as tf # 定义数据流图： z = x * y x = tf.placeholder(tf.int16, shape=(), name=\"x\") y = tf.placeholder(tf.int16, shape=(), name=\"y\") z = tf.multiply(x, y, name=\"z\") # 创建会话 session = tf.Session() # 执行操作计算张量 print(session.run(z, feed_dict={x: 3.0, z: 2.0})) # 关闭会话 session.close() 除了上述示例中获取张量值用到的 session.run 外，其他还有两种方法来计算张量值： Tensor.eval() Operation.run() 我们以下面的代码为例进行说明： import tensorflow as tf # 创建数据流图: y = W * x + b, 其中，W 和 b 为存储节点， x 为数据节点 x = tf.placehold(tf.float32) W = tf.Variable(1.0) b = tf.Variable(1.0) y = W * x + b # 创建会话 with tf.Session() as session: tf.global_variables_initializer().run() # 初始化全部变量 fetch = y.eval(feed_dict={x: 3.0}) # 等价于 fetch = session.run(y, feed_dict={x: 3.0}) print(fetch) 那么，Tensorflow 的会话究竟是怎么执行的呢？下面，我们来简单看一下其执行原理。 当我们调用 session.run(train_op) 语句执行训练操作时: 首先，程序内部提取操作依赖的所有前置操作。这些操作的节点会共同构成一副子图。 然后，程序会将子图中的计算节点、存储节点、数据节点按照鸽子的执行设备进行分类，相同设备上的节点组成了一副局部图。 最后，每个设备上的局部图在实际执行时，根据节点间的依赖关系将各个节点有序的加载到设备上执行。 对于一个单机程序而言，相同机器上不同编号的 GPU 或者 CPU 其实就是不同的设备，我们在创建节点的的时候其实就可以指定执行该节点的设备： # 在0号CPU执行的存储节点 with tf.device(\"/cpu:0\"): v = tf.Variable(...) # 在0号GPU执行计算的计算 with tf.device(\"/gpu:0\"): z = tf.matmul(x, y) 以上图为例，整体的运行流程如下： Client 端负责数据流图的结构设计，并将设计完成的数据流图发送Server端。 Server 端对数据流图中的任务进行拆分，并下发给对应执行的设备Worker。 Worker 负责对应的OP执行相关操作。 优化器（optimizer） 在学习优化器之前，我们首先需要学习一下什么是 损失函数 、 经验风险 、 结构风险 。 损失函数是指在评估特定模型参数和指定的输入下，表达模型输出的的推理值和真实值之前的不一致程度。 一个广义的损失函数 L 的形式化定义如下： loss=L(f(xi;θ),yi) loss = L(f(x_i; \\theta), y_i) loss=L(f(x​i​​;θ),y​i​​) 其中： xix_ix​i​​ 表示指定的输入 θ\\thetaθ 表示指定的模型参数 f(xi;θ)f(x_i; \\theta)f(x​i​​;θ) 表示将将指定输入传给模型后得到的模型推理值输出。 yiy_iy​i​​ 表示真实值 常见的损失函数有： 平方损失函数 loss=(yi−f(xi;θ))2 loss = (y_i - f(x_i; \\theta))^2 loss=(y​i​​−f(x​i​​;θ))​2​​ 交叉熵损失函数 loss=yi∗log(f(xi;θ)) loss = y_i * \\log(f(x_i; \\theta)) loss=y​i​​∗log(f(x​i​​;θ)) 指数损失函数 loss=exp(−yi∗f(xi;θ)) loss = exp(-y_i * f(x_i; \\theta)) loss=exp(−y​i​​∗f(x​i​​;θ)) 了解了什么是损失函数，下面我们需要再继续看一下什么是经验风险。 使用损失函数对所有的训练样本求损失值，再累加求平均就可以得到模型的经验风险。转换为数学表达式的定义如下： Remp(f)=1N∑i=1NL(f(xi;θ),yi) R_{emp}(f) = \\frac{1}{N} \\sum_{i=1}^{N} L(f(x_i; \\theta), y_i) R​emp​​(f)=​N​​1​​​i=1​∑​N​​L(f(x​i​​;θ),y​i​​) 理想情况下，我们希望能找到一组参数使得模型的经验风险最小。 但实际上，由于我们的测试数据不能包含全部数据，因此，如果过度追求训练数据的低损失值，就会造成过拟合问题。 简单来说，过拟合是指模型参数过分适配当前的训练集，导致在面对一些新的样本集就会无所适从，这次模型的泛化能力就会变差。 造成过拟合最常见的原因往往是模型复杂度过高导致，因此，为了降低训练过度导致的过拟合问题，可以引入一个 用于衡量模型复杂度的正则化项(regularizer)/惩罚项(penalty term)，我们称为 J(f)J(f)J(f)。 常用的正则化项有: L0 范数、L1 范数、L2 范数。 因此，我们将模型最优化的目标可以优化为泛化能力更好的 结构风险最小化（structural risk minimization, SRM）。 如下式所示，它由经验风险项和正则项两部分组成： Rsrm(f)=min1N∑i=1NL(f(xi;θ),yi)+λJ(θ) R_{srm}(f) = \\min\\frac{1}{N} \\sum_{i=1}^{N} L(f(x_i; \\theta), y_i) + \\lambda J(\\theta) R​srm​​(f)=min​N​​1​​​i=1​∑​N​​L(f(x​i​​;θ),y​i​​)+λJ(θ) 在模型训练的过程中，结构风险不断的降低。当小于我们设置的阈值损失值时，我们就可以认为此时的模型已经满足需求。 因此，模型训练的本质就是在最小化结构风险的同时取得最优的模型参数。 最优模型参数的表达式定义如下： θ∗=argminθRsrm(f)=argmin1N∑i=1NL(f(xi;θ),yi)+λJ(θ) \\theta^* = arg \\min_\\theta R_{srm}(f) = arg \\min\\frac{1}{N} \\sum_{i=1}^{N} L(f(x_i; \\theta), y_i) + \\lambda J(\\theta) θ​∗​​=arg​θ​min​​R​srm​​(f)=argmin​N​​1​​​i=1​∑​N​​L(f(x​i​​;θ),y​i​​)+λJ(θ) 了解了 损失函数 、 经验风险 、 结构风险 的相关概念之后，我们知道其实深度学习本质上就是求解一个最优化的问题。 求解最优化问题的方法我们称之为 优化算法 ，通常采用迭代的方式来实现: 首先设置一个初试的可行解，然后基于特定函数反复重新计算可行解，直到找到一个最优解或者达到预设的收敛条件。 不同的优化算法采用的迭代策略各有不同，常见的迭代算法包括： 使用目标函数的一阶导数，如梯度下降法。 使用目标函数的二阶导数，如牛顿法。 使用前几轮的迭代信息，如Adam。 基于梯度下降法的迭代策略相对最简单，它表示直接沿着梯度的负方向，即 目标函数下降最快 的方向进行直线迭代，其计算表达式如下： xk+1=xk−α∗grad(xk) x_{k+1} = x_k - \\alpha * grad(x_k) x​k+1​​=x​k​​−α∗grad(x​k​​) 其中，α\\alphaα 表示每次迭代的步长。 因此，对于一个典型的深度学习问题而言，包含以下三部分： 模型：y=f(x)=wx+by = f(x) = wx + by=f(x)=wx+b，其中 x 是输入数据， y 是模型输出的推理值，f 是模型的定义，其中可能包含若干个需要用户训练的模型参数。 损失函数：loss=L(y,y′)loss = L(y, y')loss=L(y,y​′​​)，其中，y' 对应x的真实值（标签），loss为损失函数输出的损失值。 优化算法：w−w+α∗grad(w)w w−w+α∗grad(w)、b−b+α∗grad(b)b b−b+α∗grad(b) 其中， grad(w) 和 grad(b) 分别表示当损失值为loss时，模型参数 w 和 b 各自的梯度值。 而具体到优化算法时，一次典型的迭代优化可以分为以下 3 个步骤： 计算梯度: 调用 compute_gradients 方法。 处理梯度: 用户按照自己的需求处理梯度值，例如梯度裁剪和梯度加权。 应用梯度: 调用 apply_gradients 方法，将处理后的梯度值应用到模型参数的迭代中。 最后，我们来看一下 tensorflow 中已经内置了哪些优化器吧： 优化器名称 文件路径 Adadelta tensorflow/python/training/adadelta.py Adagrad tensorflow/python/training/adagrad.py Adagrad Dual Averaging tensorflow/python/training/adagrad_da.py Adam tensorflow/python/training/adam.py Ftrl tensorflow/python/training/ftrl.py Gradient Descent tensorflow/python/training/gradent_descent.py Momentum tensorflow/python/training/momentum.py Proximal Adagrad tensorflow/python/training/proximal_adagrad.py Proximal Gradient Descent tensorflow/python/training/proximal_gradent_descent.py Rmsprop tensorflow/python/training/rmsprop.py Synchronize Replicas tensorflow/python/training/sync_replicas_optimizer.py By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/tensorflow/predict_house_price.html":{"url":"ai/tensorflow/predict_house_price.html","title":"tensorflow初体验之房价预测","keywords":"","body":"tensorflow初体验之房价预测 了解了 tensorflow 的基本概念后，接下来，我们将以一个 房价预测 的案例为例，演示 tensorflow 的基本功能使用。 背景知识说明 开始正式进入 Tensorflow 实战之前，我们还需要了解一些机器学习相关的背景知识。 监督学习（supervised learning） 监督学习是机器学习的方法之一，它是指从训练数据（输入和预期输出）中学到的一个模型（函数），并且可以根据模型推断出新实例的方法。 其中，函数的输出既可以是一个连续值（如回归分析）或一个离散值/类别标签（如分类问题）。 上图表示了一个监督学习的基本流程。 典型的监督学习算法非常多，例如： 线性回归（Linear Regression） 逻辑回归（Logistic Regression） 决策树（Decision Tree） 随机森林（Random Forest） 最近邻算法（k-NN） 朴素贝叶斯（Naive Bayes） 支持向量机（SVM） 感知器（Perceptron） 深度神经网络（DNN） 线性回归与梯度下降法 线性回归可以说是监督学习中最简单的算法了，下面我们来对线性回归进行分析。 在统计学中，线性回归是指 利用线性回归方程的最小二乘函数对一个或多个自变量和因变量之间的关系进行建模的一种回归分析 。 这种函数是一个或多个称为回归系数的模型参数的线性组合。 以 单变量线性回归 为例，如果一个模型是线性关系的，那么它可以表示如下： y=wx+b y = wx + b y=wx+b 那么，我们也就可以假设函数如下： hθ(x)=θ(x)0+θ(x)1x1=θ(x)0x0+θ(x)1x1=θ(x)Tx(x0=1) h_\\theta(x) = \\theta(x)_0 + \\theta(x)_{1}x_1 = \\theta(x)_{0}x_0 + \\theta(x)_{1}x_1 = \\theta(x)^Tx (x_0=1) h​θ​​(x)=θ(x)​0​​+θ(x)​1​​x​1​​=θ(x)​0​​x​0​​+θ(x)​1​​x​1​​=θ(x)​T​​x(x​0​​=1) 其中，θ\\thetaθ 就是我们假设的函数参数。 而假设函数和理想模型的损失值（误差）就是： loss=y−hθ(x) loss = y - h_{\\theta}(x) loss=y−h​θ​​(x) 因此，我们想要做的就是从一组样本 (xi,yi)(x_i, y_i)(x​i​​,y​i​​) 中找出误差最小的 θ\\thetaθ 值。 此时，我们可以使用最小二乘法，即它的优化目标为最小化残差平方和： J(θ)=1n∑i=1n(hθ(xi)−yi)2 J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} (h_{\\theta}(x_i) - y_i)^2 J(θ)=​n​​1​​​i=1​∑​n​​(h​θ​​(x​i​​)−y​i​​)​2​​ 而梯度迭代法就是指在优化目标函数的每一轮迭代中，都按照模型参数 θ\\thetaθ 的梯度方向进行变更，即表达式如下： θj:=θj−α∂∂θjJ(θ) \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial\\theta_j} J(\\theta) θ​j​​:=θ​j​​−α​∂θ​j​​​​∂​​J(θ) 代入 J(θ)J(\\theta)J(θ) 进行求导，得到的结果如下： θj:=θj−2α1n∑i=1n(hθ(xi)−yi)(xi) \\theta_j := \\theta_j - 2\\alpha \\frac{1}{n} \\sum_{i=1}^{n} (h_{\\theta}(x_i) - y_i) (x_i) θ​j​​:=θ​j​​−2α​n​​1​​​i=1​∑​n​​(h​θ​​(x​i​​)−y​i​​)(x​i​​) 下面，我们来看一下 多变量 线性回归的场景： 多变量线性回归可以表示如下： y=w0+w1x1+w2x2=WTX y = w_{0} + w_{1}x_{1} + w_{2}x_{2} = W^{T}X y=w​0​​+w​1​​x​1​​+w​2​​x​2​​=W​T​​X 那么，我们也就可以假设函数如下： hθ(X)=θ0x0+θ1x1+θ2x2=θ(x)TX(x0=1) h_\\theta(X) = \\theta_{0}x_0 + \\theta_{1}x_1 + \\theta_{2}x_2 = \\theta(x)^{T}X (x_0=1) h​θ​​(X)=θ​0​​x​0​​+θ​1​​x​1​​+θ​2​​x​2​​=θ(x)​T​​X(x​0​​=1) 其中，θ\\thetaθ 就是我们假设的函数参数。 而假设函数和理想模型的损失值（误差）就是： loss=y−hθ(X) loss = y - h_{\\theta}(X) loss=y−h​θ​​(X) 同样可以使用最小二乘法，即它的优化目标为最小化残差平方和： J(θ)=(hθ(X)−y)T(hθ(X)−y) J(\\theta) = (h_\\theta(X) - y)^T(h_\\theta(X) - y) J(θ)=(h​θ​​(X)−y)​T​​(h​θ​​(X)−y) 问题描述 下面，我们来以单变量房价预测问题为例，即根据房屋面试 xxx 来预测销售价格 yyy 。 示例的训练数据如下： 面积（平方英尺） 价格（美元） 2104 399900 1600 329900 2400 369000 1416 232000 3000 539900 1985 299900 1534 314900 1427 198999 1380 212000 1494 242500 1940 239999 2000 347000 1890 329999 4478 699900 1268 259900 .... ...... 此外，我们来考虑一下当房价预测问题为多变量预测问题时，输入的数据会是什么样？ 假设给定的输入数据中包含房屋面积 x1x_1x​1​​ 和 卧室数量 x2x_2x​2​​，来预测其房屋价格： 示例的训练数据如下： 面积（平方英尺） 卧室数量（个） 价格（美元） 2104 3 399900 1600 3 329900 2400 3 369000 1416 2 232000 3000 4 539900 1985 4 299900 1534 3 314900 1427 3 198999 1380 3 212000 1494 3 242500 1940 4 239999 2000 3 347000 1890 3 329999 4478 5 699900 1268 3 259900 .... ...... ...... 了解了想要解决的问题之后，我们就要看如何一步步的解决问题了。 使用 Tensorflow 训练模型的整体工作流如下图所示： 数据读入 数据分析 数据预处理（数据规范化） 创建模型（数据流图） 创建会话（运行环境） 训练模型 下面，我们来依次学习如下步骤。 数据读入 首先是数据读入，对于机器学习中的数据，常常是使用 csv 文件的方式进行存储，而我们想要做的其实就是从 csv 中读取文件。 在 Python 的大量第三方库中，其实有很多库都可以操作 csv 文件，而在此处，我们将会使用的是一个 pandas 的库。 熟悉机器学习的同学应该对 pandas 库并不会太陌生。它是一个基于 BSD 开源协议许可的软件库， 面向 Python 用户的高性能和易于上手的数据结构化和数据分析的工具。 在 pandas 中， DataFrame 是其最核心的数据存储对象。 具体来说，DataFrame 是一个二维带标记的数据结构，每一列的数据类型可以不同，我们常常可以用它来当做电子表格或数据库表。 而使用 pandas 来读取 csv 文件的内容非常简单，简单到只需要一行代码就能将 excel 数据转换为 dataframe 对象： import pandas as pd # 读取指定 csv 文件，并为每一列设置列名 df0 = pd.read_csv('data0.csv', names=['square', 'price']) # 打印 dataframe 的前五行 df0.head() 数据预处理与可视化 当我们将 csv 数据读入后，常常会简单的对数据进行一定的分析，如数据分布情况等。而数据分析的最佳方式之一就是数据可视化了。 接下来，我们来看一下如何进行数据的可视化。 Python 中关于数据可视化提供了如下相关的第三方库： matplotlib: 它是一个 Python 的 2D 绘图库，可以生成高质量的图片并支持各种存储格式，同时能够广泛支持多个运行平台， 如 Python 脚本、 IPython Shell 和 Jupyter Notebook. seaborn: 它是一个基于 matplotlib 的 High Level 的 Python 数据可视化库，提供了更加易用的高级接口，用于绘制 精美且信息丰富的统计图形。 mpl_toolkits.mplot3d: 它是一个基础的 3D 绘图工具集，也是 matplotlib 的一部分。 下面，我们分别来将刚才的读入的数据进行数据可视化。 对于单变量数据而言，其数据可视化数据如下，横轴表示房屋面积，纵轴表示房屋价格： import pandas as pd import seaborn as sns # 设置 seaborn 的基本配置 sns.set(context=\"notebook\", style=\"whitegrid\", palette=\"dark\") # 读取指定 csv 文件，并为每一列设置列名 df0 = pd.read_csv('data0.csv', names=['square', 'price']) # 数据可视化图 sns.lmplot('square', 'price', df0, height=4, fit_reg=False) # fit_reg 设置为 True 时，可以自动生成拟合线 对于多变量数据而言，其数据可视化数据如下，x轴表示房屋面积，y轴表示房间数量，z轴表示房屋价格： import pandas as pd import matplotlib.pyplot as plt from mpl_toolkits import mplot3d # 读取多变量数据 df1 = pd.read_csv('data1.csv', names=['square', 'bedrooms', 'price']) # 创建一个 Axes3D object fig = plt.figure() ax = plt.axes(projection='3d') # 设置 3 个坐标轴的名称 ax.set_xlabel('square') ax.set_ylabel('bedrooms') ax.set_zlabel('price') # 绘制 3D 散点图, c表示散点深度的取决对象，cmap表示散点的颜色 ax.scatter3D(df1['square'], df1['bedrooms'], df1['price'], c=df1['price'], cmap='Greens') 观察上述三维散点图，你会发现它的 x 轴、 y 轴 和 z 轴的分布太不均匀了。 例如： x 轴的区间是 1-5 y 轴的区间是 0- 5000 z 轴的区间甚至是 0 - 7000000 如此不均匀的分布对于模型训练等场景都会带来一定的弊端，因此，在模型训练还是之前，我们通常需要将其进行数据归一化。 常用的数据归一化的方式如下： x′=x−x¯σ x' = \\frac{x - \\bar{x}}{\\sigma} x​′​​=​σ​​x−​x​¯​​​​ 那么，我们再来看看如何用代码实现呢？这是就要体现出 pandas 强大的功能了。 def normalize_feature(df): \"\"\" 归一化函数 \"\"\" return df.apply(lambda column: (column - column.mean()) / column.std()) df1 = pd.read_csv('data1.csv', names=['square', 'bedrooms', 'price']) df = normalize_feature(df1) 我们定义了一个归一化函数 normalize_feature ，在该函数内，我们针对每一列，计算的列内元素的均值和方差，并从而进行了数据的归一化。 # 创建一个 Axes3D object fig = plt.figure() ax = plt.axes(projection='3d') # 设置 3 个坐标轴的名称 ax.set_xlabel('square') ax.set_ylabel('bedrooms') ax.set_zlabel('price') # 绘制 3D 散点图, c表示散点深度的取决对象，cmap表示散点的颜色 ax.scatter3D(df['square'], df['bedrooms'], df['price'], c=df['price'], cmap='Reds') 归一化后的数据可视化图如下所示： 设计数据流图 下面，我们就要正式进入到数据流图的设计中了。 而设计数据流图的第一步就是要确定输入、输出数据了。 我们以 多变量预测问题 为例，我们其实就是想要估计下式中的 \\theta : hθ(X)=θ0x0+θ1x1+θ2x2=θ(x)TX(x0=1) h_\\theta(X) = \\theta_{0}x_0 + \\theta_{1}x_1 + \\theta_{2}x_2 = \\theta(x)^{T}X (x_0=1) h​θ​​(X)=θ​0​​x​0​​+θ​1​​x​1​​+θ​2​​x​2​​=θ(x)​T​​X(x​0​​=1) 为了能够方便的进行矩阵乘法，我们需要对输入参数中进行 x0=1x_0 = 1x​0​​=1 的填充，即增加一列全为1的列。 此时，我们就需要用到另外一个 Python 的第三方库 numpy 了。 numpy 可以说是 Python 机器学习中的基础了，几乎所有的深度学习框架底层的数据结构存储都是基于 numpy 的。 同时 numpy 也是一个基础科学计算库，在多维数组上实现了线性袋鼠、傅立叶变换和其他丰富的函数计算。 下面，我们就来看看如何将读取的数据进行转换，得到模型的输入和输出数据吧： import numpy as np ones = pd.DataFrame({'ones': np.ones(len(df))}) # 生成一列全为1的列 df = pd.concat([ones, df], axis=1) # 将全为1的列插入到原有的 dataframe 中 X_data = np.array(df[df.columns[0:3]]) # 前三列为模型的输入数据 y_data = np.array(df[df.columns[-1]]).reshape(len(df), 1) # 最后一列为标记结果，用于与模型的输出结果计算偏差 完成了输入和输出数据，接下来，就是要完整的定义模型的数据流图了： import tensorflow as tf alpha = 0.01 # 学习率 alpha epoch = 500 # 训练全量数据集的轮数 # 输入 X，形状[47, 3] X = tf.placeholder(tf.float32, X_data.shape) # 输出 y，形状[47, 1] y = tf.placeholder(tf.float32, y_data.shape) # 权重变量 W，形状[3,1] W = tf.get_variable(\"weights\", (X_data.shape[1], 1), initializer=tf.constant_initializer()) # 假设函数 h(x) = w0*x0+w1*x1+w2*x2, 其中x0恒为1 # 推理值 y_pred 形状[47,1] y_pred = tf.matmul(X, W) # 损失函数采用最小二乘法，y_pred - y 是形如[47, 1]的向量。 # tf.matmul(a,b,transpose_a=True) 表示：矩阵a的转置乘矩阵b，即 [1,47] X [47,1] # 损失函数操作 loss loss_op = 1 / (2 * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True) # 随机梯度下降优化器 opt opt = tf.train.GradientDescentOptimizer(learning_rate=alpha) # 单轮训练操作 train_op train_op = opt.minimize(loss_op) 在上述的代码中，我们完整的定义了整个模型的结构（即数据流图），其中包含了节点关系、损失函数以及优化器等。 模型训练 当数据流图定义完成，此时我们就可以直接建立一个会话进行模型的训练了： with tf.Session() as sess: # 初始化全局变量 sess.run(tf.global_variables_initializer()) # 开始训练模型， # 因为训练集较小，所以每轮都使用全量数据训练 for e in range(1, epoch + 1): sess.run(train_op, feed_dict={X: X_data, y: y_data}) if e % 10 == 0: loss, w = sess.run([loss_op, W], feed_dict={X: X_data, y: y_data}) log_str = \"Epoch %d \\t Loss=%.4g \\t Model: y = %.4gx1 + %.4gx2 + %.4g\" print(log_str % (e, loss, w[1], w[2], w[0])) 此时，模型才会正式进入计算的过程中，并在不断迭代的过程中打印相关的loss值及训练过程中的模型参数值等信息。 可视化损失值 为了能够更加直观、有效的分析模型的训练状态和效果，我们常常会在训练过程中将损失值记录下来并进行可视化显示。 修改上述代码如下： with tf.Session() as sess: # 初始化全局变量 sess.run(tf.global_variables_initializer()) # 记录所有损失值 loss_data = [] # 开始训练模型 # 因为训练集较小，所以采用批梯度下降优化算法，每次都使用全量数据训练 for e in range(1, epoch + 1): _, loss, w = sess.run([train_op, loss_op, W], feed_dict={X: X_data, y: y_data}) # 记录每一轮损失值变化情况 loss_data.append(float(loss)) if e % 100 == 0: log_str = \"Epoch %d \\t Loss=%.4g \\t Model: y = %.4gx1 + %.4gx2 + %.4g\" print(log_str % (e, loss, w[1], w[2], w[0])) 可以看出，我们在上述代码中定义了一个 loss_data 的列表用于记录迭代过程中损失值的变化趋势。 Ps: session.run() 函数对针对每个 OP 操作的结果进行返回。 最后，我们可以使用 matplotlib 库来可视化 loss 曲线。 import matplotlib.pyplot as plt import seaborn as sns sns.set(context=\"notebook\", style=\"whitegrid\", palette=\"dark\") ax = sns.lineplot(x='epoch', y='loss', data=pd.DataFrame({'loss': loss_data, 'epoch': np.arange(epoch)})) ax.set_xlabel('epoch') ax.set_ylabel('loss') plt.show() By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/tensorflow/tensorboard.html":{"url":"ai/tensorflow/tensorboard.html","title":"TensorBoard快速入门","keywords":"","body":"TensorBoard 快速入门 为了能够在 Tensorflow 的使用过程中有更好的体验，Tensorflow 还提供了一个重要的可视化工具: TensorBoard 。 TensorBoard 的使用场景 TensorBoard 的使用场景非常广泛： 在数据处理的过程中，可视化地直观的查看数据集分布情况。 在模型设计的过程中，分析和检查数据流图的实现是否正确。 在模型训练的过程中，关注模型参数和超参数的变化趋势。 在模型测试的过程中，查看准确率和召回率等评估指标。 而 TensorBoard 正是这样一个可以通过图形的可视化展示来有效辅助机器学习程序的开发者和使用者理解算法模型及 工作流程，提升模型开发工具的一大利器。 模型训练过程中的可视化 统计数据的可视化 数据集的可视化 数据流图的可视化 TensorBoard 使用流程 TensorBoard 本质上可视化的内容实际是数据流图和张量，它们需要在会话中加载或者执行操作后才能获取。 然后，用户需要利用 FileWriter 实例将这些数据写入事件文件中。 此时，我们就可以启动 TensorBoard 程序，来加载事件文件中的序列化数据，从而在各个面板中展示对应的可视化对象。 其整体使用流程图如下所示： 上述内容中提到的 FileWriter 实例和汇总操作（Summary Ops）均属于 tf.summary 模块。 其主要功能是获取和输出模型相关的序列化数据，它是 TensorBoard 整个使用流程的中核心内容。 tf.summary 模块的核心部分由一组操作以及 FileWriter 、 Summary 和 Event 三个类组成。 TensorBoard 数据流图的可视化 接下来，我们先来看一下如何进行数据流图的可视化。 我们仍然基于房价预测一节中的代码为例，在 Session 计算中增加如下两行代码： with tf.Session() as sess: # 初始化全局变量 sess.run(tf.global_variables_initializer()) # 创建FileWriter实例，并传入当前会话加载的数据流图 writer = tf.summary.FileWriter('./summary/linear-regression-1', sess.graph) # 开始训练模型 # 因为训练集较小，所以每轮都使用全量数据训练 for e in range(1, epoch + 1): sess.run(train_op, feed_dict={X: X_data, y: y_data}) if e % 10 == 0: loss, w = sess.run([loss_op, W], feed_dict={X: X_data, y: y_data}) log_str = \"Epoch %d \\t Loss=%.4g \\t Model: y = %.4gx1 + %.4gx2 + %.4g\" print(log_str % (e, loss, w[1], w[2], w[0])) # 关闭FileWriter的输出流 writer.close() 即我们在 session 内部，创建了一个 FileWriter 对象，并进行了保存。 此时，我们就已经将对应的数据流图保存到了一组events文件中了。 接下来，我们再次进入 summary 目录下，启动 TensorBoard : tensorboard --logdir=./ --host=localhost 此时，使用浏览器打开 http://localhost:6006/ ，你就可以看到刚才保存的数据流图了。 但是你应该会发现，这个数据流图实在是有点儿乱，并不方便我们理解和分析。 接下来，我们来看看如何能够让数据流图更加的有条理。 为了使得数据流图能够更加条理，我们需要为变量进行分组并设置抽象作用域，修改数据流图的定义代码如下： import tensorflow as tf alpha = 0.01 # 学习率 alpha epoch = 500 # 训练全量数据集的轮数 with tf.name_scope('input'): # 输入 X，形状[47, 3] X = tf.placeholder(tf.float32, X_data.shape, name='X') # 输出 y，形状[47, 1] y = tf.placeholder(tf.float32, y_data.shape, name='y') with tf.name_scope('hypothesis'): # 权重变量 W，形状[3,1] W = tf.get_variable(\"weights\", (X_data.shape[1], 1), initializer=tf.constant_initializer()) # 假设函数 h(x) = w0*x0+w1*x1+w2*x2, 其中x0恒为1 # 推理值 y_pred 形状[47,1] y_pred = tf.matmul(X, W, name='y_pred') with tf.name_scope('loss'): # 损失函数采用最小二乘法，y_pred - y 是形如[47, 1]的向量。 # tf.matmul(a,b,transpose_a=True) 表示：矩阵a的转置乘矩阵b，即 [1,47] X [47,1] # 损失函数操作 loss loss_op = 1 / (2 * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True) with tf.name_scope('train'): # 随机梯度下降优化器 opt train_op = tf.train.GradientDescentOptimizer(learning_rate=alpha).minimize(loss_op) 重新运行并生成新的 events 文件后，再次打开 tensorboard。 这次你将会看到一个如下的数据流图： 嗯，果然，此时的数据流图已经变的清晰了很多。此外，如果想要分析每个组件内部的具体细节逻辑，双击节点即可展开其内部细节， 快来体验吧~ By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/tensorflow/mnist_practice.html":{"url":"ai/tensorflow/mnist_practice.html","title":"Keras实战之手写数字识别","keywords":"","body":"Keras实战之手写数字识别 在之前的实战章节中，我们学会了如何使用 tensorflow 自身提供的 API 去实现一个房价预测的模型。 但是，这个模型是一个非常简单的线性回归，并不能算作深度学习。 而在本节中，我们将以一个类似于深度学习的 hello world 示例来演示如何使用 Tensorflow 的 High Level API Keras 来实现一个 用于自动识别手写数字的模型。 MNIST 数据集简介 MNIST 是一套手写体数字的图像数据集，包含 60000 个训练样本和 10000 个测试样本，由纽约大学的 Yann LeCun 等人维护。 MNIST 图像数据集使用形如［28，28］的二阶数组来表示每个手写体数字，数组中的每个元素对应一个像素点， 即每张图像大小固定为 28x28 像素。 MNIST 数据集中的图像都是256阶灰度图，即灰度值 0 表示白色（背景），255 表示 黑色（前景）， 使用取值为［0，255］的uint8数据类型表示图像。 下载 mnist 数据集 Keras 提供了一个 datasets 的模块，其中包括了各个常用的开放数据集。因此，我们可以直接使用 keras.datasets 来下载 mnist 数据集。 from keras.datasets import mnist (x_train, y_train), (x_test, y_test) = mnist.load_data('mnist/mnist.npz') print(x_train.shape, y_train.shape) print(x_test.shape, y_test.shape) # (60000, 28, 28) (60000,) # (10000, 28, 28) (10000,) 其中， load_data 函数接收一个参数 path 表示数据集下载后存放的地址。 需要注意的是，该地址是一个相对目录，实际存放数据集的绝对目录为: ~/.keras/datasets/$path 。 我们可以将下载的部分数据进行可视化显示: import matplotlib.pyplot as plt fig = plt.figure() for i in range(15): plt.subplot(3,5,i+1) # 绘制前15个手写体数字，以3行5列子图形式展示 plt.tight_layout() # 自动适配子图尺寸 plt.imshow(x_train[i], cmap='Greys') # 使用灰色显示像素灰度值 plt.title(\"Label: {}\".format(y_train[i])) # 设置标签为子图标题 plt.xticks([]) # 删除x轴标记 plt.yticks([]) # 删除y轴标记 Softmax 网络介绍 Perceptron 1957 年，Frank Rosenblatt 发明了神经感知机模型 Perceptron 。 其模型结构如下所示： 可以看到，在该模型中，在对输入参数加权求和之后，加入了一个激活函数，即 当加权求和值大于某个阈值时，输出为1，否则，输出为0。 这一模型常常用于解决一些二分类的问题。 而随着时代的发展，人们发现 Perceptron 中由于仅有权重参数，能够解决的问题非常有限。 ANN 因此，人们又提出了 人工神经网络（ANN）。 人工神经网络是多层神经元之间的连接，上一层的神经元输出可以作为下一层的神经元输出，从输入数据到输出数据之间，中间可能会包含多层神经元，如下所示： 激活函数 但是，尽管神经网络的层数不断变高，但是，由于每一层都是线性关系，因此最终组合后的结果仍然只能完成线性分割的任务。 而为了解决一些线性不可分的问题，人们又提出了 激活函数 的概念，通过激活函数来实现非线性问题的分割。 激活函数都采用非线性函数，常用的有Sigmoid、tanh、ReLU等。 其中，最常用的应该就是 ReLU 激活函数了，再后续的示例中我们也会用到相关内容。 全连接层 全连接层是一种对输入数据直接做线性变换的线性计算层。 它是神经网络中最常用的一种层，用于学习输出数据和输入数据之间的变换关系。 全连接层可作为特征提取层使用，在学习特征的同时实现特征融合； 全连接层也可作为最终的分类层使用，其输出神经元的值代表了每个输出类别的概率。 前向传播 在多层神经网络的评估过程中，首先会进行前向传播来计算输出。 以下图为例: 其中: LLL 表示网络层数，www 和 bbb 为模型参数，XXX 为输入数据。 xix_ix​i​​ 表示第 iii 个神经元的输入。 ai(l)a_{i}^{(l)}a​i​(l)​​ 表示第 lll 层的第 iii 个神经元的输出。 wij(l)w_{ij}^{(l)}w​ij​(l)​​ 表示第 lll 层的第 jjj 个神经元 到 第 l+1l+1l+1 层的第 iii 个神经元的权重。 bi(l)b_{i}^{(l)}b​i​(l)​​ 表示第 lll 层的第 iii 个神经元的偏置。 hw,b(X)h_{w,b}(X)h​w,b​​(X) 表示神经网络的输出数据。 根据上述的符号表示，前向传播的计算公式如下： ai(l)=f(∑j=1nwj(l−1)a(l−1)+b(l−1)) a_{i}^{(l)} = f( \\sum_{j=1}^{n} w_{j}^{(l-1)}a^{(l-1)} + b^{(l-1)}) a​i​(l)​​=f(​j=1​∑​n​​w​j​(l−1)​​a​(l−1)​​+b​(l−1)​​) 其中: fff 表示激活函数。 反向传播 BP 算法的基本思想就是通过损失函数对模型中的各个参数进行求导， 并据复合函数求导常用的“链式法则”将不同层的模型参数的梯度联系起来，使得计算所有模型参数的梯度更简单。 BP算法的思想早在 1960 年就被提出来了。 直到1986年， David Rumelhart 和 Geoffrey Hinton 等人发表了一篇后来成为经典的论文，清晰地描述了BP算法的框架，才使得BP算法真正流行起来，并带来了神经网络在80年代的辉煌。 Softmax 网络 softmax 也是一种激活函数，非常适合用于多分类问题的输出层。 softmax 将多个神经元的输出，映射到（0,1）区间内，可以看成是当前输出是属于各个分类的概率。 其中，所有分类的概率之和为1，而 softmax 会找出所有分类概率中概率值最大的结果作为输出结果，从而来解决多分类问题。 假设有一个数组 vvv ， viv_iv​i​​ 为数据中的第 iii 个元素。那么，viv_iv​i​​ 元素进行 softmax 激活函数后得到的结果如下： Si=evi∑jevj S_i = \\frac{e^{v_i}}{\\sum_j e^{v_j}} S​i​​=​∑​j​​e​v​j​​​​​​e​v​i​​​​​​ 因此，我们可以通过两层全连接层 + 最终的 Softmax 激活函数得到一个如下的神经网络模型: 可以看到，输入的数据是将 28 * 28 的图像展开后为 784 长度的输入，接着加入了两层全连接层，最后通过 softmax 层进行输出。 利用 Softmax 实现手写数字识别的模型 上述内容讲述了通过全连接层 + softmax 激活函数实现的多分类模型的基础知识，接下来，我们来看看如何用代码来实现它。 下面，我们用以 tensorflow 的 High Level API 为例进行示范: # 加载 MNIST 数据集 from keras.datasets import mnist from keras.utils import np_utils from keras.models import Sequential from keras.layers.core import Dense, Activation (x_train, y_train), (x_test, y_test) = mnist.load_data('mnist/mnist.npz') # 数据预处理 与 归一化 # 数据展开 X_train = x_train.reshape(60000, 784) X_test = x_test.reshape(10000, 784) # 将数据类型转换为float32 X_train = X_train.astype('float32') X_test = X_test.astype('float32') # 数据归一化 X_train /= 255 X_test /= 255 # one-hot 转化 n_classes = 10 print(\"Shape before one-hot encoding: \", y_train.shape) Y_train = np_utils.to_categorical(y_train, n_classes) # 对标记数据进行 one-hot 转化 print(\"Shape after one-hot encoding: \", Y_train.shape) Y_test = np_utils.to_categorical(y_test, n_classes) # 定义神经网络 model = Sequential() model.add(Dense(512, input_shape=(784,))) model.add(Activation('relu')) model.add(Dense(512)) model.add(Activation('relu')) model.add(Dense(10)) model.add(Activation('softmax')) # 编译模型 model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') # 训练模型 history = model.fit(X_train, Y_train, batch_size=128, epochs=5, verbose=2, validation_data=(X_test, Y_test)) 感受一下？ Keras API 是不是非常的便捷？仅仅数十行代码就可以实现一个完整的神经网络的模型训练。 经过训练，可以看到，我们的模型在训练集上的准确率大约可以到 99% ，在测试集上的准确率也能够达到 97% 以上。 CNN 网络介绍 CNN模型是一种以卷积为核心的前馈神经网络模型。 20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性， 继而提出了卷积神经网络（Convolutional Neural Networks，简称CNN）。 利用 CNN 实现手写数字识别的模型 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/paddle/beginning.html":{"url":"ai/paddle/beginning.html","title":"paddle快速入门","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"ai/paddle/tensor.html":{"url":"ai/paddle/tensor.html","title":"Paddle 核心概念 Tensor 详解","keywords":"","body":"Paddle 核心概念 Tensor 详解 作为 Paddle 学习的第一课，我们将首先从 Paddle 中最核心的的 Tensor 对象来进行讲解。 Paddle 和其他深度学习框架一样，使用 Tensor 来表示数据，在神经网络中传递的数据均为 Tensor 对象。 Tensor可以将其理解为多维数组，其可以具有任意多的维度，不同Tensor可以有不同的数据类型 (dtype) 和形状 (shape)。 同一Tensor的中所有元素的dtype均相同。如果你对 Numpy 熟悉，Tensor是类似于 Numpy Array 的概念。 Tensor 的基本操作 创建 Tensor 创建 Tensor 有多种方式。 最常用的方式之一就是使用 paddle.to_tensor() 函数来将 list, np.array 等对象转化为 Tensor 对象。 # 一维 Tensor ndim_1_tensor = paddle.to_tensor([2.0, 3.0, 4.0], dtype='float64', stop_gradient=False) # 二维 Tensor ndim_2_tensor = paddle.to_tensor(numpy.random.rand(3, 2)) # 三维 Tensor ndim_3_tensor = paddle.to_tensor([[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]], [[11, 12, 13, 14, 15], [16, 17, 18, 19, 20]]]) Ps: Tensor 对象可以非常方便的转化为 numpy.array 对象，只需要调用 Tensor.numpy() 方法即可。 Tensor 对象中要求所有元素的 dtype 类型必须是一致的。 除了根据 list, np.array 转化为 Tensor 对象外，还可以使用一些 Paddle 的 API 来快速生成 Paddle 对象： paddle.zeros([m, n]) # 创建数据全为0，shape为[m, n]的Tensor paddle.ones([m, n]) # 创建数据全为1，shape为[m, n]的Tensor paddle.full([m, n], 10) # 创建数据全为10，shape为[m, n]的Tensor paddle.arange(start, end, step) # 创建从start到end，步长为step的Tensor paddle.linspace(start, end, num) # 创建从start到end，元素个数固定为num的Tensor Tensor 的属性 一. shape 查看一个Tensor的形状可以通过 Tensor.shape 属性查询，shape 属性可以显示 tensor 对象在每个维度上的元素数量。 与 shape 强关联的属性还有： ndim: 显示 tensor 的维度数量，等价于 len(shape) size: 显示 tensor 中的元素数量，等价于 shape 各个维度元素数量的乘积。 二. dtype dtype 属性表示了 Tensor 元素中的数据类型，可以通过 Tensor.dtype 来查看。 dtype支持：'bool'，'float16'，'float32'，'float64'，'uint8'，'int8'，'int16'，'int32'，'int64'。 通过Python元素创建的Tensor，可以通过dtype来进行指定，如果未指定： 对于python整型数据，则会创建int64型Tensor 对于python浮点型数据，默认会创建float32型Tensor，并且可以通过set_default_type来调整浮点型数据的默认类型。 通过Numpy array创建的Tensor，则与其原来的dtype保持相同。 三. place 初始化 Tensor 时可以通过 place 参数来指定其分配的设备位置，可支持的设备位置有三种： CPU GPU 固定内存 其中固定内存也称为不可分页内存或锁页内存，其与GPU之间具有更高的读写效率，并且支持异步传输，这对网络整体性能会有进一步提升， 但其缺点是分配空间过多时可能会降低主机系统的性能，因为其减少了用于存储虚拟内存数据的可分页内存。 示例如下： # CPU cpu_tensor = paddle.to_tensor(1, place=paddle.CPUPlace()) # GPU gpu_tensor = paddle.to_tensor(1, place=paddle.CUDAPlace(0)) # 固定内存 pin_memory_tensor = paddle.to_tensor(1, place=paddle.CUDAPinnedPlace()) 四. name Tensor 的 name 是其唯一的标识符，为 python 字符串类型，查看一个Tensor的name可以通过Tensor.name属性。 默认地，在每个Tensor创建时，Paddle会自定义一个独一无二的name。 五. stop_gradient stop_gradient 用于表示对于一个 Tensor 对象而言，是否需要累积计算对应的梯度信息。 默认为 True ，即不保留梯度信息。 对于模型中需要训练的参数而言，stop_gradient 为 false，即会保留梯度信息并用于迭代。 Tensor 的操作 一. resize 在 Paddle 中，我们可能会经常需要重新定义 tensor 的 shape。 为此，Paddle 提供了 reshape 接口来改变 Tensor 的 shape : ndim_3_tensor = paddle.to_tensor(numpy.random.rand(3, 2, 5)) new_ndim_3_tensor = paddle.reshape(ndim_3_tensor, [2, 5, 3]) print(\"After reshape:\", new_ndim_3_tensor.shape) 其中，在 resize 操作中，是有一些特殊的使用技巧的： 指定维度设置为 -1 时，表示这个维度的值是从Tensor的元素总数和剩余维度推断出来的。因此，有且只有一个维度可以被设置为-1。 指定维度设置为 0 时，表示实际的维数是从 原Tensor对象的对应维数中复制出来的，与原 Tesnor 对象保持一致。 paddle.reshape(ndim_3_tensor, [-1]) 可以将任意 Tensor 平铺展开为 1-D Tensor。 二. cast 在 Paddle 中，使用 cast 函数可以修改指定的 Tensor 对象的 dtype： float32_tensor = paddle.to_tensor(1.0) float64_tensor = paddle.cast(float32_tensor, dtype='float64') print(\"Tensor after cast to float64:\", float64_tensor.dtype) int64_tensor = paddle.cast(float32_tensor, dtype='int64') print(\"Tensor after cast to int64:\", int64_tensor.dtype) 三. 索引和切片 我们可以通过索引或切片方便地访问或修改 Tensor。 Paddle 使用标准的 Python 索引规则，即与 Numpy 索引规则类似。 具体来说： 基于 0-n 的下标进行索引，如果下标为负数，则从尾部开始计算。 通过冒号 : 分隔切片参数 start:stop:step 来进行切片操作，其中 start、stop、step 均可缺省。 二维数据检索示例： ndim_2_tensor = paddle.to_tensor([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]) print(\"Origin Tensor:\", ndim_2_tensor.numpy()) print(\"First row:\", ndim_2_tensor[0].numpy()) print(\"First row:\", ndim_2_tensor[0, :].numpy()) print(\"First column:\", ndim_2_tensor[:, 0].numpy()) print(\"Last column:\", ndim_2_tensor[:, -1].numpy()) print(\"All element:\", ndim_2_tensor[:].numpy()) print(\"First row and second column:\", ndim_2_tensor[0, 1].numpy()) 四. 数学运算符 在 Paddle 中，可以对多个 Tesnor 对象进行数学运算。 同时，在对 Paddle 进行数学运算的时候，还支持多种方式: Paddle API 方式与 Tensor 类成员方法，下面我们以具体的示例进行说明： x = paddle.to_tensor([[1.1, 2.2], [3.3, 4.4]], dtype=\"float64\") y = paddle.to_tensor([[5.5, 6.6], [7.7, 8.8]], dtype=\"float64\") # Paddle API 函数 print(paddle.add(x, y), \"\\n\") # Tensor 类成员方法 print(x.add(y), \"\\n\") 两种方法的功能是相同的，因此，我们后续将仅以类成员方法为例进行说明。 目前，Paddle 支持的数学运算符包括如下： x.abs() #逐元素取绝对值 x.ceil() #逐元素向上取整 x.floor() #逐元素向下取整 x.round() #逐元素四舍五入 x.exp() #逐元素计算自然常数为底的指数 x.log() #逐元素计算x的自然对数 x.reciprocal() #逐元素求倒数 x.square() #逐元素计算平方 x.sqrt() #逐元素计算平方根 x.sin() #逐元素计算正弦 x.cos() #逐元素计算余弦 x.add(y) #逐元素相加 x.subtract(y) #逐元素相减 x.multiply(y) #逐元素相乘 x.divide(y) #逐元素相除 x.mod(y) #逐元素相除并取余 x.pow(y) #逐元素幂运算 x.max() #指定维度上元素最大值，默认为全部维度 x.min() #指定维度上元素最小值，默认为全部维度 x.prod() #指定维度上元素累乘，默认为全部维度 x.sum() #指定维度上元素的和，默认为全部维度 Paddle对python数学运算相关的魔法函数进行了重写，以下操作与上述结果相同: x + y -> x.add(y) #逐元素相加 x - y -> x.subtract(y) #逐元素相减 x * y -> x.multiply(y) #逐元素相乘 x / y -> x.divide(y) #逐元素相除 x % y -> x.mod(y) #逐元素相除并取余 x ** y -> x.pow(y) #逐元素幂运算 五. 逻辑运算符 目前，Paddle 支持的逻辑运算符包括如下： x.isfinite() #判断tensor中元素是否是有限的数字，即不包括inf与nan x.equal_all(y) #判断两个tensor的全部元素是否相等，并返回shape为[1]的bool Tensor x.equal(y) #判断两个tensor的每个元素是否相等，并返回shape相同的bool Tensor x.not_equal(y) #判断两个tensor的每个元素是否不相等 x.less_than(y) #判断tensor x的元素是否小于tensor y的对应元素 x.less_equal(y) #判断tensor x的元素是否小于或等于tensor y的对应元素 x.greater_than(y) #判断tensor x的元素是否大于tensor y的对应元素 x.greater_equal(y) #判断tensor x的元素是否大于或等于tensor y的对应元素 x.allclose(y) #判断tensor x的全部元素是否与tensor y的全部元素接近，并返回shape为[1]的bool Tensor 以下操作仅针对bool型Tensor: x.logical_and(y) #对两个bool型tensor逐元素进行逻辑与操作 x.logical_or(y) #对两个bool型tensor逐元素进行逻辑或操作 x.logical_xor(y) #对两个bool型tensor逐元素进行逻辑亦或操作 x.logical_not(y) #对两个bool型tensor逐元素进行逻辑非操作 同样地，Paddle对python逻辑比较相关的魔法函数进行了重写，以下操作与上述结果相同: x == y -> x.equal(y) #判断两个tensor的每个元素是否相等 x != y -> x.not_equal(y) #判断两个tensor的每个元素是否不相等 x x.less_than(y) #判断tensor x的元素是否小于tensor y的对应元素 x x.less_equal(y) #判断tensor x的元素是否小于或等于tensor y的对应元素 x > y -> x.greater_than(y) #判断tensor x的元素是否大于tensor y的对应元素 x >= y -> x.greater_equal(y) #判断tensor x的元素是否大于或等于tensor y的对应元素 六. 线性代数运算 目前，Paddle 支持的线性代数操作如下： x.cholesky() #矩阵的cholesky分解 x.t() #矩阵转置 x.transpose([1, 0]) #交换axis 0 与axis 1的顺序 x.norm('fro') #矩阵的 Frobenius 范数 x.dist(y, p=2) #矩阵（x-y）的2范数 x.matmul(y) #矩阵乘法 需要注意，Paddle中Tensor的操作符均为非inplace操作，即 x.add(y) 不会在tensor x上直接进行操作，而会返回一个新的Tensor来表示运算结果。 Tensor 的广播机制 飞桨（PaddlePaddle，以下简称Paddle）和其他框架一样，提供的一些API支持广播(broadcasting)机制，允许在一些运算时使用不同形状的张量。 通常来讲，如果有一个形状较小和一个形状较大的张量，会希望多次使用较小的张量来对较大的张量执行一些操作， 看起来像是较小形状的张量的形状首先被扩展到和较大形状的张量一致，然后做运算。 值得注意的是，这期间并没有对较小形状张量的数据拷贝操作。 飞桨的广播机制主要遵循如下规则: 每个张量至少为一维张量。 从后往前依次比较张量的形状，当前维度的大小要么相等，要么其中一个等于一，要么其中一个不存在。 示例如下： import paddle x = paddle.ones((2, 3, 4)) y = paddle.ones((2, 3, 4)) # 两个张量 形状一致，可以广播 z = x + y print(z.shape) # [2, 3, 4] x = paddle.ones((2, 3, 1, 5)) y = paddle.ones( (3, 4, 1)) # 从后向前依次比较： # 第一次：y的维度大小是1 # 第二次：x的维度大小是1 # 第三次：x和y的维度大小相等 # 第四次：y的维度不存在 # 所以 x和y是可以广播的 z = x + y print(z.shape) # [2, 3, 4, 5] # 相反 x = paddle.ones((2, 3, 4)) y = paddle.ones((2, 3, 6)) # 此时x和y是不可广播的，因为第一次比较 4不等于6 # z = x + y # InvalidArgumentError: Broadcast dimension mismatch. Tensor 的自动微分机制 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"auvideo/stream_practice/beginning.html":{"url":"auvideo/stream_practice/beginning.html","title":"流媒体协议实战","keywords":"","body":"流媒体协议实战 近些年来，音视频技术不断发展。 一方面，视频压缩技术从 H261 到 H264，再到现在的 H265 及未来不久将出现的 AV1，视频压缩率越来越高；音频压缩技术也从电话使用的 G.711、G.722 等窄带音频压缩技术，发展到现代的 AAC、OPUS 等宽带音频压缩技术。 另一方面，从中国 3G 网络正式商用开始，移动网络也发生了翻天覆地的变化。从 3G 到 4G ，再到马上要落地的 5G，移动网络的带宽和质量越来越高，为音视频数据传输打下了坚实的基础。 因此，音视频技术在未来一段时间，相信仍然会有飞速的发展。 而作为音视频技术学习的开始，我们首先将要在本章学习 音视频协议 相关的内容。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"auvideo/stream_practice/rtsp.html":{"url":"auvideo/stream_practice/rtsp.html","title":"rtsp协议杂谈与实战","keywords":"","body":"rtsp协议杂谈与实战 rtsp协议概述 RTSP（Real Time Streaming Protocol），RFC2326，实时流传输协议，是TCP/IP协议体系中的一个 应用层协议 ，由哥伦比亚大学、网景和RealNetworks公司提交的IETF RFC标准。 该协议定义了一对多应用程序如何有效地通过IP网络传送多媒体数据。 RTSP在体系结构上位于RTP和RTCP之上，它使用TCP或UDP完成数据传输。 HTTP与RTSP相比，HTTP请求由客户机发出，服务器作出响应；使用RTSP时，客户机和服务器都可以发出请求，即RTSP可以是双向的。 RTSP是用来控制声音或影像的多媒体串流协议，并允许同时多个串流需求控制，传输时所用的网络通讯协定并不在其定义的范围内，服务器端可以自行选择使用TCP或UDP来传送串流内容，它的语法和运作跟HTTP 1.1类似，但并不特别强调时间同步，所以比较能容忍网络延迟。 而前面提到的允许同时多个串流需求控制（Multicast），除了可以降低服务器端的网络用量，更进而支持多方视讯会议（Video Conference）。 因为与HTTP1.1的运作方式相似，所以代理服务器〈Proxy〉的快取功能〈Cache〉也同样适用于RTSP，并因RTSP具有重新导向功能，可视实际负载情况来转换提供服务的服务器，以避免过大的负载集中于同一服务器而造成延迟。 rtsp服务器搭建（live555） live555是一个为流媒体提供解决方案的跨平台的C++开源项目，它实现了标准流媒体传输，是一个为流媒体提供解决方案的跨平台的C++开源项目，它实现了对标准流媒体传输协议如RTP/RTCP、RTSP、SIP等的支持。 Live555实现了对多种音视频编码格式的音视频数据的流化、接收和处理等支持，包括MPEG、H.263+ 、DV、JPEG视频和多种音频编码。 同时由于良好的设计，Live555非常容易扩展对其他格式的支持。 Live555已经被用于多款播放器的流媒体播放功能的实现，如VLC(VideoLan)、MPlayer。 因此，通过live555，我们就可以搭建一个rtsp的服务器。 live555可以在 此处 进行下载。 下载完成后，我们需要给 live555MediaServer 增加可执行权限。 chmod a+x live555MediaServer rtsp初体验之播放rtsp流 环境准备 除了上述通过 live555 搭建的rtsp server之外，我们还需要做如下准备： 准备一个mp4的视频文件用于验证 下载 VLC media player 用于播放rtsp视频流。 把mp4文件转化为ts文件 mp4是一种常见的视频格式，但是无法直接被live555MediaServer使用，因此，我们需要将mp4文件转化为ts文件。 我们可以通过 convertio 网站进行视频文件在线转换。 我们将转换后的ts文件放在live555MediaServer的同级目录下。 启动live555MediaServer ./live555MediaServer 此时，我们可以看到rtsp中打印出服务启动的rstp的地址: rtsp://192.168.18.139/。 使用VLC media player播放rtsp视频流 打开 VLC media player 软件，选择 File -> Open Network... 。 在地址栏中输入刚才得到的rtsp地址 + 文件名称，Open即可。 此时，VLC media player预期就可以正常的播放视频喽~ rtsp初体验之推送rtsp流 环境准备 准备一个mp4的视频文件用于验证 安装ffmpeg命令行工具。 安装VLC media player软件。 其中，ffmpeg命令行工具可以去 官方网站 下载。 拉取rtsp服务镜像 docker pull gemfield/zlmediakit:20.04-runtime-ubuntu18.04 启动rtsp镜像容器： docker run -id -p 1935:1935 -p 554:554 -p 8080:80 gemfield/zlmediakit:20.04-runtime-ubuntu18.04 使用 ffmpeg 推送rtsp视频流 先来看一下ffmpeg的一个基本命令： ./ffmpeg -i ${input_video} -f flv rtmp://${server}/live/${streamName} 其中： -i：表示输入视频文件，后跟视频文件路径/URL。 -f：强制ffmpeg采用某种格式，后跟对应的格式。 最后输入的表示推送到 rtmps服务器的地址。 例如： ./ffmpeg -re -i SampleVideo_1280x720_20mb.mp4 -vcodec h264 -acodec aac -strict -2 -f rtsp -rtsp_transport tcp rtsp://127.0.0.1/live/test1 其中: SampleVideo_1280x720_20mb.mp4 是我们提前准备好的mp4文件 -re 表示以本地帧频读数据，主要用于模拟捕获设备 -i SampleVideo_1280x720_20mb.mp4 表示指定本地文件 -vcodec h264 设置视频编码为h264编码 -acodec aac 设置音频编码为aac -strict -2 设置strictness跟标准的严格性 -f rtsp 强制ffmpeg输出为rtsp流。 -rtsp_transport tcp 设置rtsp底层协议为tcp协议 rtsp://127.0.0.1/live/test1 是rtsp服务器推流的地址，其中 /live/test1 为自定义地址。 最后，我们再次使用 VLC media player 播放rtsp视频流，同样还是Open Network，只需要在地址兰总输入刚才的推流地址即可。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"embedded-system/micro-python/beginning.html":{"url":"embedded-system/micro-python/beginning.html","title":"micro-python快速入门","keywords":"","body":"micro-python快速入门 从本节开始，我们将会以micro-python为基本，带你快速了解如何用micro-python来进行相关的嵌入式软件的开发。 你可能会觉得奇怪：嗯？嵌入式开发为什么不用 C 语言？ 主要原因是，我不希望开发语言成为实战项目的障碍。先不说 C 语言本身的难度，光是它需要交叉编译的特性和不够便捷的调试方式，就已经很影响效率了。 相比之下，使用比较简单的 Python 语言，开发和调试都会非常方便。当然，选择 Python 还有别的好处，你在后面的实战过程中可以逐渐感受到。 不过，你可能还是不放心：嵌入式硬件的计算资源都非常有限，在开发板上面运行 Python 代码可行吗？ 这确实是一个挑战，好在 MicroPython 项目已经提供了解决方案。 MicroPython 是专门为嵌入式系统打造的 Python 实现。它完整实现了 Python3.4 的语言特性，部分支持 Python3.5 的特性。在标准库方面，MicroPython 实现了 Python 语言的一个子集，另外还增加了与底层硬件交互的库模块。 参考资源： MicroPython 官方文档。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"embedded-system/micro-python/environment.html":{"url":"embedded-system/micro-python/environment.html","title":"micro-python环境搭建","keywords":"","body":"micro-python环境搭建 学习嵌入式开发的第一步就是要搭建嵌入式的开发环境。 首先，我们需要选择一块合适的开发板。 我们推荐选择开源硬件的开发板，有两个原因。第一，硬件、软件的各种技术实现是公开的，方便分析问题，也方便后期转化为量产的产品；第二，有社区氛围，使用的人比较多，大家可以针对具体的问题进行交流。 比如说 NodeMCU 就是一个不错的选择。基于 ESP32S 芯片的版本，Flash 空间有 4MB，自带 Wi-Fi 功能，而且价格便宜，在国内外都非常流行。 搭建 MicroPython 开发环境 接下来，我们需要吧MicroPython部署到NodeMCU开发板上，准备好开发环境。 准备固件文件 首先，我们需要为 NodeMCU 准备好 MicroPython 固件文件。MicroPython 官方已经为 ESP32 准备了现成的固件 ，省去了交叉编译的工作。 我们需要选择“Firmware with ESP-IDF v3.x”下面的“GENERIC”类别，直接下载最新版本的固件文件到电脑中。 安装烧录工具 然后，我们使用一根 USB 数据线，将 NodeMCU 开发板和电脑连接起来。USB 数据线选择一头是 USB-A 接口、另一头是 Micro-USB 接口，并且支持数据传输的完整线缆。 接着，我们在电脑终端运行下面的命令，安装用来烧录的工具 esptool ： pip3 install esptool esptool 安装完成后，你可以运行 esptool.py read_mac 命令，确认 NodeMCU 板子是否连接成功。连接成功后的屏幕显示是这样的： 如果连接不成功应该怎么办呢？ 如果是Mac系统，可以在电脑的terminal中输入 ls -l /dev/cu.* 查看是否有/dev/cu.usbserial-***相关的名字的设备文件。 如果没有，那应该是板子或者usb线有问题，建议更换重试。 烧录固件 接下来我们需要烧录固件。 在这之前，我们需要先输入下面命令，擦除 Flash 芯片： esptool.py --chip esp32 --port /dev/cu.usbserial-xxxx erase_flash Ps: 需要将上述命令中的cu.usbserial-xxxx修改为你自己的设备名称。后续的命令同理。 擦除成功后，我们进入存储前面下载固件的目录中，运行下面的命令，将固件文件烧录到开发板的 Flash 中： esptool.py --chip esp32 --port /dev/cu.usbserial-xxxx --baud 460800 write_flash -z 0x1000 esp32-idf3-20200902-v1.13.bin 烧录成功后，MicroPython 预期已经在你的开发板上运行起来了。 确认运行状态 但是开发板跟电脑不一样，是没有显示屏的，我们要怎么确认它的运行状态呢？ 接下来，我们就要使用串口连接开发板来验证 MicroPython 环境是否已经搭建完成了。 同样还是用USB线将开发版和电脑连接起来。 通过查询ls /dev/cu.*查询到对应的设备名称后，下载终端连接软件，例如SecureCRT ，通过串口协议与开发板进行交互。 需要注意的是，波特率（Baud rate）设置为 115200，这与前面烧录时选择的值不同。 成功连接后，SecureCRT 的窗口会输出类似下面的结果： 看到熟悉的 >>> 引导符，我们就直接引入进入了Python的交互式命令行了。 Ps: SecureCRT串口连接后，如果无法看到 >>> 引导符，可能是有如下原因 开发板上已经在运行一些阻塞运行的程序，导致阻塞串口交互。解决方案是删除开发板根目录下的main.py文件。 开发板之前的连接没有断开。解决方案，断开其他终端的连接方式，并按复位键。 体验交互 先用“Hello World”来个经典的打招呼吧。 print(\"Hello World from MicroPython!\") 可以看到，和普通的Python并没有什么区别，在开发板上，同样打印出了相关的语句。 下面，我们来尝试点亮一个LED灯吧。 首先导入machine 模块，machine模块几乎包含了整个ESP32的硬件资源的接口. NodeMCU32-S开发板上有一个蓝色的LED， 由P2引脚的输出来控制，高电平亮，低电平灭，因此我们可以控制P2引脚的输出来点亮该LED： 声明一个管脚，GPIO编号为2，在板子的引脚上标记为P2, 模式为输出模式，即设置为machine.PIN.OUT，并将管脚写入高电平。 import machine pin2 = machine.Pin(2, machine.Pin.OUT) pin2.value(1) 这时你应该可以看到该led灯被点亮，散发出宝石般的蓝色光芒。 部署代码到开发板 上面的例子中，我们已经使用交互式命令行运行了Python的命令。 但是交互式命令行只是在调试场景比较适用，对于生产环境而言，我们希望的是它能够直接运行一个/组Python文件。 比如，我们有一段如下代码： import machine import time # 指明 GPIO2 管脚 pin = machine.Pin(2, machine.Pin.OUT) # 循环执行 while True: time.sleep(2) # 等待 2 秒 pin.on() # 控制 LED 状态 time.sleep(2) # 等待 2 秒 pin.off() # 切换 LED 状 这段代码实现的功能是，控制 LED 灯以 2 秒的间隔，不断点亮、熄灭。 为了在电路板上运行这个 Python 代码，我们需要做两件事情： 将代码段保存到一个文件中，这个文件的名字必须是 main.py。 将代码文件 main.py 放到开发板的文件系统中，而且是根目录。 这样，当开发板启动或者重启的时候，就会自动执行 main.py 文件中的代码。 第一点我们可以很容易做到。但是，怎么把代码文件上传到开发板上呢？ 推荐的一个工具是 ampy . 一般情况下，你可以用下面的命令完成安装： pip3 install adafruit-ampy 所以在使用的时候，我们需要先设置一个环境变量 —— AMPY_DELAY。延时的推荐值是 0.5。 export AMPY_DELAY=0.5 建议可以将它加入到 .bashrc 或 .zshrc 等配置文件中，避免每次都需要重复输入。 使用 ampy 的过程中，常用的环境变量还有下面两个，可以根据具体情况设置： #设备名称请根据你的情况修改 export AMPY_PORT=/dev/cu.wchusbserialxxxx #串口通信的波特率 export AMPY_BAUD=115200 然后，输入下面的命令，就把代码部署到开发板上了。 ampy put main.py 其实，ampy还有很多实用的功能，你可以在下面自己进行探索。 参考资料： ESP32S 引脚说明书 SecureCRT 下载地址 ampy 安装文档 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"embedded-system/micro-python/network.html":{"url":"embedded-system/micro-python/network.html","title":"micro-python环境联网与HTTP请求","keywords":"","body":"micro-python环境联网与HTTP请求 我们已经了解了micro-python在ESP32S开发板上的一些基本使用了。 下面，我们要做的是对ESP32S开发版联网，并尝试发送http请求。 micro-python联网 import network wifi = network.WLAN(network.STA_IF) wifi.active(True) # 启用wifi模块 wifi.scan() # 扫描当前可用的wifi网络 wifi.isconnected() # 判断当前wifi是否连接 wifi.connect('你家中Wi-Fi的SSID', '你家中Wi-Fi密码') # 连接wifi wifi.isconnected() # 判断当前wifi是否连接 需要说明的是： wifi.connect('你家中Wi-Fi的SSID', '你家中Wi-Fi密码') 是一个异步连接Wifi的任务，可能该命令执行完成后，wifi仍然处于连接中，此时查询connect状态仍然是False，需要等待一阵查询才能成为True。 Ps：重要说明，wifi的开启与连接仅限于本次运行中，对开发板断电重连后，需要重新开启WIfi。 micro-python中的HTTP请求 在micro-python中，内置了一个urequests库。 它与Python中的requests库非常类似，使用方式几乎一致。 例如： import urequests as requests res = requests.get(url='http://www.baidu.com/') print(res.content) By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"embedded-system/raspberry/beginning.html":{"url":"embedded-system/raspberry/beginning.html","title":"树莓派快速入门","keywords":"","body":"树莓派快速入门 树莓派（英语：Raspberry Pi）是基于Linux的单片机电脑，由英国树莓派基金会开发，目的是以低价硬件及自由软件促进学校的基本计算机科学教育。 树莓派每一代均使用博通（Broadcom）出产的ARM架构处理器，如今生产的机型内存在2GB和8GB之间，主要使用SD卡或者TF卡作为存储媒体，配备USB接口、HDMI的视频输出（支持声音输出）和RCA端子输出，内置Ethernet/WLAN/Bluetooth网络链接的方式（依据型号决定），并且可使用多种操作系统。产品线型号分为A型、B型、Zero型和ComputeModule计算卡。 Raspberry Pi OS是所有型号树莓派的官方操作系统，树莓派基金会网站也提供了Ubuntu MATE、Ubuntu Core、Ubuntu Server、OSMC等第三方系统供大众下载。 从本文开始，我们将会搭配实践来讲解树莓派的相关使用介绍等。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"embedded-system/raspberry/gladys_assistant.html":{"url":"embedded-system/raspberry/gladys_assistant.html","title":"树莓派Gladys Assistant环境搭建","keywords":"","body":"树莓派Gladys Assistant环境搭建 Gladys Assistant概述 Gladys Assistant是一个开源的智能家居平台。 它是一个刚刚重新设计和开发的智能家居平台。 原生支持 Z-Wave、MQTT 和小米等设备接口，并且在平台中嵌入了自己的 NLP（自然语言处理）对话引擎。 你可以在平台上定义复杂的场景模式。 Gladys Assistant 的主要交互界面是 Web 页面。 不过这些 Web 界面在手机上的体验也非常好，因为它是基于 PWA（Progressive Web App）实现的。 PWA 技术使 Web 应用在手机的体验基本和原生 App 一致。 Gladys Assistant 使用 JavaScript 语言实现的。 它对于树莓派的支持非常不错，提供了基于 Raspbian 的系统镜像。 另外，通过 Docker 的方式对 MacOS 和 Windows 系统也提供了支持。 Gladys Assistant 代码采用的是 Apache License 2.0开源协议。 Gladys Assistant环境搭建 现在，我们就开始动手，在树莓派上安装Gladys Assistant， 体验一下通过智能家居系统监测设备数值的过程。 准备器材 首先我介绍一下需要准备的器材有哪些： 树莓派 Raspberry Pi 4B，要求内存 2GB 以上，但是 8GB 内存版本要谨慎选择，因为有些开源平台软件对 Arm 64bit 芯片支持不够好。 供电电源，要求支持 3A 以上电流。 Micro SD 卡，也叫 TF 卡，存储容量最好在 16GB 以上。在选择的时候，你要关注读写速度等级，比如 U3 表示最低写入速度是 30MB/s。同时你也要关注应用性能等级，它定义了 Micro SD 卡进行随机读写的性能，最好是选择 Application Performance Class 2（卡面上标识 A2 图标）。在卡上存储应用程序和应用程序数据时，这个性能指标非常重要。 Micro SD 卡读卡器。有些电脑自带这个接口，如果没有的话，你可以买一个便宜的使用。 普通网线。如果你希望以有线的方式使用树莓派，需要准备一根。同时，我也会介绍树莓派接入 Wi-Fi 的方式。 烧录系统镜像 树莓派板子在启动的时候，会从 SD 卡读取操作系统镜像文件，完成操作系统的引导启动工作。 所以我们接下来要在 SD 卡上烧录系统镜像。 具体怎么烧录呢？我们可以使用一个免费的烧录工具，Etcher。 它支持 MacOS、Windows 和 Linux 三种主流的电脑系统， 你可以从官方网站 上下载和安装。 也可以点击这个链接 下载最新版。 下载完成后，正常安装Etcher烧录软件即可。 然后，我们需要下载树莓派的系统镜像文件。 树莓派有官方的操作系统镜像 Raspbian 可以选择，但是为了避免手动在 Raspbian 系统中安装 Gladys Assistant 软件的麻烦，我们直接选择官方提供的已经配置好 Gladys Assistant 的 Raspbian 镜像文件。 从这个链接 中下载好镜像文件，并且解压缩得到\"img\"扩展名的文件。 然后把 Micro SD 卡插入读卡器，或者直接插入你的电脑接口中，运行 Etcher 软件，按照步骤把镜像文件烧录到存储卡中。 树莓派支持网线接口，不过，如果你希望树莓派接入家里的 Wi-Fi 热点，而不是使用网线访问网络，那么就需要在 Micro SD 卡中增加一个配置文件。 这个配置文件的文件名必须是 wpa_supplicant.conf。 你可以在电脑上使用自己熟悉的文本编辑器创建这个文件，并且在文件中输入下面的内容： ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 country=CN network={ ssid=\"你的Wi-Fi热点SSID名称\" psk=\"你的Wi-Fi热点密码\" key_mgmt=WPA-PSK } Ps: 注意，将 Wi-Fi 热点的 SSID 和密码替换为你家里的 Wi-Fi 路由器的真实情况。 然后将这个文件拷贝到 Micro SD 卡的根目录。 这时，你就可以把 Micro SD 卡插入树莓派开发板了。 启动系统 烧录好镜像文件，准备好 Micro SD 卡后，你可以把 Micro SD 卡从读卡器取出，插入树莓派的对应接口中。 接着，接上电源线（如果你使用网线方式，记得也将网线接入树莓派板的网口上）。 这时树莓派将自动启动运行，需要等待一段时间。 过一会儿之后，在你的电脑上，打开浏览器，输入 http://gladys.local 来访问树莓派上的 Gladys Assistant 系统，如下图所示。 在 Gladys Assistant 上添加设备 因为我们是第一次配置 Gladys Assistant，所以要在上面的页面中选择“Create local account with your Email”，来创建一个本地账号。 创建完账号后，其他的步骤不是必填项，你根据喜好填写就行了。 房屋配置部分，你可以创建一个名称为 bedroom 的房间，后面会用到。 最后，你应该可以看到这个 Dashboard 页面。 接下来，我们来添加一个设备，来体验一下 Gladys Assistant 的功能。 首先，我们在 Gladys Assistant 上准备 MQTT Broker。 选择 Dashboard 上部的标签页“Integrations”，点击 MQTT 标签。 进入 MQTT 设置界面后，你现在需要点击左边的 Setup，开始安装 MQTT Broker。 我们通过默认选项，即使用 Docker 的方式来完成。 这个过程需要几分钟时间。 完成后，你就可以看到 MQTT Broker 的用户名和密码。 你也可以修改为你自己需要的密码，这个密码需要记下来，后面模拟MQTT中需要用到。 接着，我们点击左边的 Device，切换到 MQTT 设备页面。 点击右上角的 New 打开创建页面。 设备名称我们可以选择 Temperature Sensor，External ID 填写 mqtt:bedroom:temperature-sensor。 字符串中 bedroom 是和下一项房间填写的信息一致的。 然后，我们为设备添加特性（Features）。这里，我们选择 Temperature 类型。 选择完类型后，我们点击 Add feature，开始设置具体的特性参数。 你可以按照下图的内容来设置自己的参数。 其中，external ID 填写 mqtt:bedroom:temperature-sensor:temperature 字符串。 最下面的 MQTT Topic，你需要记录下来，后面发送消息时需要用到。 点击下部的保存（Save）和返回（Back），然后我们可以看到创建完成的 MQTT 设备。 在模拟发送 MQTT 消息之前，我们还需要编辑一下 Dashboard 界面。 你需要点击左上角切换回 Home 标签页，然后点击右上角的 Edit 按键。 在编辑界面的 Column 1 选择 Devices in room 类别。 然后依次选择 bedroom 和我们刚创建的设备 Temperature Sensor 传感器。 点击页面右下角的 Save，保存 Dashboard 的编辑界面。 模拟 MQTT 设备 由于，我们在树莓派上通过Docker部署的MQTT仅限于localhost访问，远程其他设备无法正常访问到MQTT。 因此，我们为了能够模拟MQTT设备远程连接到树莓派上面的MQTT服务，我们需要搭建一个nginx来代理MTQQ的端口，并允许远程访问。 Nginx的安装方式参考如下 Nginx的配置文件如下： worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 8002; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } stream { server { listen 1884; proxy_pass mqtt; } upstream mqtt { server 127.0.0.1:1883; } } 其核心是最下面的stream块，它表示监听本地1884端口，并将请求转发至本地的1883端口。 最后，我们在本地打开一个终端窗口，输入下面的命令： hbmqtt_pub -d --url mqtt://wangzhe:wangzhe@gladys.local:1884 -t gladys/master/device/mqtt:bedroom:temperature-sensor/feature/mqtt:bedroom:temperature-sensor:temperature/state -m 25.2 其中: wangzhe:wangzhe 是用户名和密码，它们以分号相连。 gladys.local 是树莓派的域名。 -t 后面的消息主题就是你刚才记录的 MQTT Topic 字符串。 -m 后面是温度数值。 执行这个命令后，你再打开 Gladys Assistant 的 Dashboard 界面，这时你就可以看到设备卡片显示出来了刚才发送的温度数值。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"embedded-system/raspberry/speech.html":{"url":"embedded-system/raspberry/speech.html","title":"树莓派语音处理实战","keywords":"","body":"树莓派语音处理实战 设备依赖组件 在本文中，我们将会针对上一节中搭建的树莓派环境进行进一步实战，了解如何使用树莓派来支持语音的录音和播放。 为了完成本节内容，我们需要准备以下组件： 树莓派开发板 麦克风阵列（ReSpeaker 2-Mics Pi HAT） 耳机/扬声器 环境搭建 下面，我们来安装相关的驱动程序。 首先，你最好切换一下树莓派的软件安装源，将它切换到国内的腾讯云安装源，这样下载安装的速度比较快。 运行下面的命令修改配置文件： vim /etc/apt/sources.list 注释掉原有的内容，修改如下： deb https://mirrors.cloud.tencent.com/raspbian/raspbian/ buster main contrib non-free rpi # Uncomment line below then 'apt-get update' to enable 'apt-get source' deb-src https://mirrors.cloud.tencent.com/raspbian/raspbian/ buster main contrib non-free rpi 修改另一个软件安装源的配置文件，命令如下所示： vim /etc/apt/sources.list.d/raspi.list 修改后的文件内容如下： deb https://mirrors.cloud.tencent.com/raspberrypi/ buster main # Uncomment line below then 'apt-get update' to enable 'apt-get source' deb-src https://mirrors.cloud.tencent.com/raspberrypi/ buster main 然后，你需要运行下面的命令更新安装源： sudo apt-get clean all sudo apt-get update 现在，你可以运行下面命令安装麦克风阵列的驱动程序。 因为这个驱动依赖的 wm8960 编解码器没有包含在树莓派系统的内核里面，需要重新加载内核，编译驱动，所以整个过程比较久。 sudo apt-get install git git clone --depth=1 https://github.com/respeaker/seeed-voicecard cd seeed-voicecard sudo ./install.sh --compat-kernel sudo reboot 驱动程序安装完成后，我们就需要开始完成整个物理环境的连接。 把 ReSpeaker 2-Mics Pi HAT 直接插入到树莓派板子上。如图所示： 把耳机通过耳机孔插入到树莓派的3.5mm的耳机孔中。 录音与声音播放实战 连线完成后，检查音频的输入和输出设备是否正常工作。 arecord -l aplay -l 如果一切正常，我们就可以测试录音和播放功能了。 在 ReSpeaker 2-Mics Pi HAT 的耳机插口上插入耳机或者扬声器，运行下面的命令，并说几句话。 arecord -d 5 test.wav aplay test.wav 另外，你也可以通过软件 AlsaMixer（命令 alsamixer）来配置声音设置和调整音量，左、右箭头键用于选择通道或设备，向上、向下箭头控制当前所选设备的音量。 退出程序使用 ALT + Q，或者按 Esc 键。 alsamixer 使用方式如上图所示。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/beginning.html":{"url":"cloud-native/kubernetes/beginning.html","title":"Kubernetes","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/concept.html":{"url":"cloud-native/kubernetes/concept.html","title":"Kubernetes基本概述","keywords":"","body":"Kubernetes 基本概念 Kubernetes 是一个开源的容器编排引擎，用来对容器化应用进行自动化部署、扩缩容和管理。 接下来，在本文中，我们将会讲解 Kubernetes 的一些基本概念。 Kubernetes 是什么？ Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态 系统。Kubernetes 的服务、支持和工具非常广泛，适用于各个领域。 历史追溯 让我们回顾一下历史，从而看看为什么 kubernetes 如此的有用。 传统部署时代 早期，各个组织机构都是在物理服务器上运行应用程序。而在物理机直接部署服务时，用户无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。 例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况，结果可能导致其他应用程序的性能下降。 一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展， 并且维护许多物理服务器的成本很高。 虚拟化时代 为了解决物理机部署时代的资源隔离问题，人们引入了虚拟化的解决方案。 虚拟化技术是指允许用户在单个物理服务器的CPU上运行多个虚拟机（ VM ）。虚拟化的作用能够使用应用程序在 VM 之间隔离，并且提供了一定的安全保证。 因为一个应用程序的信息不能被另一应用程序随意访问。 虚拟化技术能够更好地利用物理服务器上的资源，并且因为可轻松地添加或更新应用程序 而可以实现更好的可伸缩性，降低硬件成本等等。 每个 VM 都是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。 容器部署时代 容器与虚拟机类似，但是相比虚拟机而言，容器的隔离性并没有虚拟机那么强，它们可以在应用程序之间共享操作系统。 因此，容器可以被认为是一种轻量级的隔离方式。 容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。由于它们与基础架构分离，因此可以跨云、 OS 版本进行移植。 容器因为具备如下的许多优势而变得非常流行，下面是一些容器的优点： 敏捷应用程序的创建和部署: 与使用 VM 镜像相比，容器的镜像创建的便捷性和效率更高。 持续开发、集成和部署: 通过快速简单的回滚 (由于镜像的不可变性) ，支持可靠且频繁的容器镜像构建和部署。 开发与运维的分离: 在构建/发布时创建应用程序容器镜像 (而不是在部署时)，从而将应用程序与基础架构分离。 可观察性: 不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标。 跨开发、测试和生产的环境一致性: 在个人计算机上甚至与与在云中运行的行为相同。 跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松耦合、分布式、弹性、解放的微服务：应用程序可以被分解成较小的独立部分，并且可以动态部署和管理，而不是在一台大型单机上整体运行。 资源隔离：通过有效的资源隔离可以预测和保证容器内部署的应用程序的性能。 资源利用：通过充分利用资源达到高效率和高密度。 为什么需要 Kubernetes，它能做什么? 容器是打包和运行应用程序的绝佳方式。 在生产环境中，你需要管理运行应用程序的容器，并确保不会停机。例如，如果一个容器发生故障，则需要启动另一个容器。那么，如果系统可以自动处理此行为， 你的工作量是不是会大大的减少？ Kubernetes 就是解决这些问题的方法！ Kubernetes 为你提供了一个可弹性运行分布式系统的框架。Kubernetes 会满足你的扩展要求、故障转移、部署模式等。例如， Kubernetes 可以轻松管理系统的 Canary 部署。 详细来说， Kubernetes 为你提供了如下功能： 服务发现和负载均衡: Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。 存储编排: Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。 自动部署和回滚: 你可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态 更改为期望状态。 例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。 自动完成装箱计算: Kubernetes 允许你指定每个容器所需 CPU 和内存（RAM）。 当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。 容器保活: Kubernetes 能够重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。 密钥与配置管理: Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。 Kubernetes 不是什么? Kubernetes 不是传统的、包罗万象的 PaaS（平台即服务）系统。 由于 Kubernetes 在容器级别而不是在硬件级别运行，它提供了 PaaS 产品共有的一些普遍适用的功能， 例如部署、扩展、负载均衡、日志记录和监视。 但是，Kubernetes 不是单体系统，默认解决方案都是可选和可插拔的。 Kubernetes 提供了构建开发人员平台的基础，但是在重要的地方保留了用户的选择和灵活性。 具体来说， Kubernetes： 不限制支持的应用程序类型。 Kubernetes 旨在支持极其多种多样的工作负载，包括无状态、有状态和数据处理工作负载。 如果应用程序可以在容器中运行，那么它应该可以在 Kubernetes 上很好地运行。 不部署源代码，也不构建你的应用程序。持续集成(CI)、交付和部署（CI/CD）工作流取决于组织的文化和偏好以及技术要求。 不提供应用程序级别的服务作为内置服务，例如中间件（例如，消息中间件）、 数据处理框架（例如，Spark）、 数据库（例如，mysql）、缓存、集群存储系统 （例如，Ceph）。 这样的组件可以在 Kubernetes 上运行，并且/或者可以由运行在 Kubernetes 上的应用程序通过可移植机制（例如， 开放服务代理）来访问。 不要求日志记录、监视或警报解决方案。 它提供了一些集成作为概念证明，并提供了收集和导出指标的机制。 不提供或不要求配置语言/系统（例如 jsonnet），它提供了声明性 API， 该声明性 API 可以由任意形式的声明性规范所构成。 不提供也不采用任何全面的机器配置、维护、管理或自我修复系统。 此外，Kubernetes 不仅仅是一个编排系统，实际上它消除了编排的需要。 编排的技术定义是执行已定义的工作流程：首先执行 A，然后执行 B，再执行 C。 相比之下，Kubernetes 包含一组独立的、可组合的控制过程， 这些过程连续地将当前状态驱动到所提供的所需状态。 如何从 A 到 C 的方式无关紧要，也不需要集中控制，这使得系统更易于使用 且功能更强大、系统更健壮、更为弹性和可扩展。 Kubernetes 组件 一个 Kubernetes 集群由一组被称作节点的机器组成。这些节点上运行 Kubernetes 所管理的容器化应用。每个集群具有至少一个工作节点。 工作节点托管作为应用负载的组件的 Pod 。 控制平面管理集群中的工作节点和 Pod 。 为集群提供故障转移和高可用性，这些控制平面一般跨多主机运行，集群跨多个节点运行。 接下来，我们来讲解正常运行的 Kubernetes 集群所需的各种组件。 下图展示了包含所有相互关联组件的 Kubernetes 集群。 控制平面组件 （Control Plane Components） 控制平面的组件对集群做出全局决策(比如调度) 以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。 控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件，并且不会在此计算机上运行用户容器。 kube-apiserver API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。 Kubernetes API 服务器的主要实现是 kube-apiserver。 kube-apiserver 设计上考虑了水平伸缩，也就是说，它可通过部署多个实例进行伸缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。 etcd etcd 是兼具一致性和高可用性的键值数据库，作为保存 Kubernetes 所有集群数据的后台数据库。 您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。 要了解 etcd 更深层次的信息，请参考 etcd 文档 。 kube-scheduler kube-scheduler 是控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。 调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。 kube-controller-manager kube-controller-manager 是在主节点上运行 控制器 的组件。它通过 api-server 监控集群的公共状态，并致力于将当前状态转变为期望状态。 从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。 这些控制器包括: 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应。 副本控制器（Replication Controller）: 负责为系统中的每个副本控制器对象维护正确数量的 Pod。 端点控制器（Endpoints Controller）: 填充端点 (Endpoints) 对象(即加入 Service 与 Pod)。 服务帐户和令牌控制器（Service Account & Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌。 cloud-controller-manager 云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器允许您链接聚合到云提供商的应用编程接口中， 并分离出相互作用的组件与您的集群交互的组件。 cloud-controller-manager 仅运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。 与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。 下面的控制器都包含对云平台驱动的依赖： 节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除 路由控制器（Route Controller）: 用于在底层云基础架构中设置路由 服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器 Node组件 节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。 kubelet 一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。 kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。 kube-proxy kube-proxy 是集群中每个节点上运行的网络代理，实现 Kubernetes 服务（Service） 概念的一部分。 kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。 如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。 容器运行时 (Container Runtime) 容器运行环境是负责运行容器的软件。 Kubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。 插件 （Addons） 插件使用 Kubernetes 资源（DaemonSet、 Deployment等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 kube-system 命名空间。 下面是最常用的几个插件。有关可用插件的完整列表，请参见 插件（Addons） 。 DNS 尽管其他插件都并非严格意义上的必需组件，但几乎所有 Kubernetes 集群都应该 有集群 DNS， 因为很多示例都需要 DNS 服务。 集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。 Kubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。 Web界面（仪表盘） Dashboard 是Kubernetes 集群的通用的、基于 Web 的用户界面。 它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。 容器资源监控 容器资源监控 将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。 集群层面日志 集群层面日志 机制负责将容器的日志数据 保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。 Kubernetes API Kubernetes 控制面 的核心是 API 服务器。 API 服务器负责提供 HTTP API，以供用户、集群中的不同部分和集群外部组件相互通信。 Kubernetes API 使你可以查询和操纵 Kubernetes API 中对象（例如：Pod、Namespace、ConfigMap 和 Event）的状态。 大部分操作都可以通过 kubectl 命令行接口 或 类似 kubeadm 这类命令行工具来执行， 这些工具在背后也是调用 API。不过，你也可以使用 REST 调用来访问这些 API。 如果你正在编写程序来访问 Kubernetes API，可以考虑使用 客户端库 。 OpenAPI 规范 完整的 API 细节是用 OpenAPI 来表述的。 Kubernetes API 服务器通过 /openapi/v2 提供 OpenAPI 规范。 你可以按照下表所给的请求头部，指定响应的格式： 头部 可选值 说明 Accept-Encoding gzip 不指定此头部也是可以的 Accept application/com.github.proto-openapi.spec.v2@v1.0+protobuf 主要用于集群内部 Accept * 提供application/json Accept application/json 默认值 Kubernetes 为 API 实现了一种基于 Protobuf 的序列化格式，主要用于集群内部通信。 关于此格式的详细信息，可参考 Kubernetes Protobuf 序列化 设计提案。 每种模式对应的接口描述语言（IDL）位于定义 API 对象的 Go 包中。 API变更 任何成功的系统都要随着新的使用案例的出现和现有案例的变化来成长和变化。 为此，Kubernetes 的功能特性设计考虑了让 Kubernetes API 能够持续变更和成长的因素。 Kubernetes 项目的目标是不要引发现有客户端的兼容性问题，并在一定的时期内维持这种兼容性，以便其他项目有机会作出适应性变更。 一般而言，新的 API 资源和新的资源字段可以被频繁地添加进来。删除资源或者字段则要遵从 API 废弃策略 。 关于什么是兼容性的变更、如何变更 API 等详细信息，可参考 API 变更 。 API 组和版本 为了简化删除字段或者重构资源表示等工作，Kubernetes 支持多个 API 版本， 每一个版本都在不同 API 路径下，例如 /api/v1 或 /apis/rbac.authorization.k8s.io/v1alpha1。 版本化是在 API 级别而不是在资源或字段级别进行的，目的是为了 确保 API 为系统资源和行为提供清晰、一致的视图，并能够控制对已废止的和/或实验性 API 的访问。 为了便于演化和扩展其 API，Kubernetes 实现了 可被 启用或禁用 的 API 组 。 API 资源之间靠 API 组、资源类型、名字空间（对于名字空间作用域的资源而言）和 名字来相互区分。 API 服务器可能通过多个 API 版本来向外提供相同的下层数据， 并透明地完成不同 API 版本之间的转换。 所有这些不同的版本实际上都是同一资源 的（不同）表现形式。 例如，假定同一资源有 v1 和 v1beta1 版本， 使用 v1beta1 创建的对象则可以使用 v1beta1 或者 v1 版本来读取、更改 或者删除。 关于 API 版本级别的详细定义，请参阅 API 版本参考 。 API 扩展 有两种途径来扩展 Kubernetes API： 你可以使用 自定义资源 来以声明式方式定义 API 服务器如何提供你所选择的资源 API。 你也可以选择实现自己的 聚合层 来扩展 Kubernetes API。 使用 Kubernetes 对象 Kubernetes 对象概述 在 Kubernetes 系统中，Kubernetes对象 是持久化的实体。 Kubernetes 使用这些实体去表示整个集群的状态。 具体来说，Kubernetes对象描述了如下信息： 哪些容器化应用在运行（以及在哪些节点上） 可以被应用使用的资源 关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略 Kubernetes 对象是 “目标性记录” —— 一旦创建对象，Kubernetes 系统将持续工作以确保对象存在。 通过创建对象，本质上是在告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的，这就是 Kubernetes 集群的 期望状态（Desired State）。 操作 Kubernetes 对象(无论是创建、修改，或者删除)都需要使用 Kubernetes API 。 比如，当使用 kubectl 命令行接口时，CLI 会执行必要的 Kubernetes API 调用， 也可以在程序中使用 客户端库直接调用 Kubernetes API。 对象规约（Spec）与状态（Status） 几乎每个 Kubernetes 对象包含两个嵌套的对象字段，它们负责管理对象的配置： 对象 spec（规约） 和 对象 status（状态） 。 对于具有 spec 的对象，你必须在创建对象时设置其内容，描述你希望对象所具有的特征： 期望状态（Desired State） 。 status 描述了对象的 当前状态（Current State），它是由 Kubernetes 系统和组件 设置并更新的。 在任何时刻，Kubernetes 控制平面 都一直积极地管理着对象的实际状态，以使之与期望状态相匹配。 例如，Kubernetes 中的 Deployment 对象能够表示运行在集群中的应用。 当创建 Deployment 时，可能需要设置 Deployment 的 spec，以指定该应用需要有 3 个副本运行。 Kubernetes 系统读取 Deployment 规约，并启动我们所期望的应用的 3 个实例 —— 更新状态以与规约相匹配。 如果这些实例中有的失败了（一种状态变更），Kubernetes 系统通过执行修正操作来响应规约和状态间的不一致，在这里意味着它会启动一个新的实例来替换。 关于对象 spec、status 和 metadata 的更多信息，可参阅 Kubernetes API 约定 。 描述 Kubernetes 对象 创建 Kubernetes 对象时，必须提供对象的规约，用来描述该对象的期望状态以及关于对象的一些基本信息（例如名称）。 当使用 Kubernetes API 创建对象时（或者直接创建，或者基于kubectl）， API 请求必须在请求体中包含 JSON 格式的信息。 大多数情况下，需要在 .yaml 文件中为 kubectl 提供这些信息。kubectl 在发起 API 请求时，将这些信息转换成 JSON 格式。 这里有一个 .yaml 示例文件，展示了 Kubernetes Deployment 的必需字段和对象规约： apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 使用类似于上面的 .yaml 文件来创建 Deployment的一种方式是使用 kubectl 命令行接口（CLI）中的 kubectl apply 命令， 将 .yaml 文件作为参数。 下面是一个示例： kubectl apply -f https://k8s.io/examples/application/deployment.yaml --record 输出类似如下这样： deployment.apps/nginx-deployment created 必需字段 在想要创建的 Kubernetes 对象对应的 .yaml 文件中，需要配置如下的字段： apiVersion - 创建该对象所使用的 Kubernetes API 的版本。 kind - 想要创建的对象的类别。 metadata - 帮助唯一性标识对象的一些数据，包括一个 name 字符串、UID 和可选的 namespace。 你也需要提供对象的 spec 字段。 对象 spec 的精确格式对每个 Kubernetes 对象来说是不同的，包含了特定于该对象的嵌套字段。 Kubernetes API 参考 能够帮助我们找到任何我们想创建的对象的 spec 格式。 例如，可以从 core/v1 PodSpec 查看 Pod 的 spec 格式， 并且可以从 apps/v1 DeploymentSpec 查看 Deployment 的 spec 格式。 Kubernetes 对象管理 kubectl 命令行工具支持多种不同的方式来创建和管理 Kubernetes 对象。 本文档概述了不同的方法。阅读 Kubectl book 来了解 kubectl 管理对象的详细信息。 管理技巧 管理方式 操作对象 推荐场景 支持写入来源数量 学习难道 命令式命令 活动对象 开发环境下 1+ 简单 命令式对象配置 独立文件 生产环境下 1 中等 声明式对象配置 一组文件/目录 开发环境下 1+ 难 Ps: 应该只使用一种技术来管理 Kubernetes 对象。混合和匹配技术作用在同一对象上将导致未定义行为。 命令式命令 使用命令式命令时，用户可以在集群中的活动对象上进行操作。用户将操作传给 kubectl 命令作为参数或标志。 这是开始或者在集群中运行一次性任务的最简单方法。 因为这个技术直接在活动对象上操作，所以它不提供以前配置的历史记录。 示例如下： 通过创建 Deployment 对象来运行 nginx 容器的实例： kubectl run nginx --image nginx 使用不同的语法来达到同样的上面的效果： kubectl create deployment nginx --image nginx 与对象配置相比的优点： 命令简单，易学且易于记忆。 命令仅需一步即可对集群进行更改。 与对象配置相比的缺点： 命令不与变更审查流程集成。 命令不提供与更改关联的审核跟踪。 除了实时内容外，命令不提供记录源。 命令不提供用于创建新对象的模板。 命令式对象配置 在命令式对象配置中，kubectl 命令指定操作（创建，替换等），可选标志和至少一个文件名。 指定的文件必须包含 YAML 或 JSON 格式的对象的完整定义。 有关对象定义的详细信息，请查看 API 参考 。 Ps: replace 命令式命令将现有规范替换为新提供的规范，并删除对配置文件中缺少的对象的所有更改。 此方法不应与规范独立于配置文件进行更新的资源类型一起使用。 比如类型为 LoadBalancer 的服务，它的 externalIPs 字段就是独立于集群配置进行更新。 示例如下： 创建配置文件中定义的对象： kubectl create -f nginx.yaml 删除两个配置文件中定义的对象： kubectl delete -f nginx.yaml -f redis.yaml 通过覆盖活动配置来更新配置文件中定义的对象： kubectl replace -f nginx.yaml 与命令式命令相比的优点： 对象配置可以存储在源控制系统中，比如 Git。 对象配置可以与流程集成，例如在推送和审计之前检查更新。 对象配置提供了用于创建新对象的模板。 与命令式命令相比的缺点： 对象配置需要对对象架构有基本的了解。 对象配置需要额外的步骤来编写 YAML 文件。 与声明式对象配置相比的优点： 命令式对象配置行为更加简单易懂。 从 Kubernetes 1.5 版本开始，命令式对象配置更加成熟。 与声明式对象配置相比的缺点： 命令式对象配置更适合文件，而非目录。 对活动对象的更新必须反映在配置文件中，否则会在下一次替换时丢失。 声明式对象配置 使用声明式对象配置时，用户对本地存储的对象配置文件进行操作，但是用户未定义要对该文件执行的操作。 kubectl 会自动检测每个文件的创建、更新和删除操作。这使得配置可以在目录上工作，根据目录中配置文件对不同的对象执行不同的操作。 Ps: 声明式对象配置保留其他编写者所做的修改，即使这些更改并未合并到对象配置文件中。 可以通过使用 patch API 操作仅写入观察到的差异，而不是使用 replace API 操作来替换整个对象配置来实现。 示例如下： 处理 configs 目录中的所有对象配置文件，创建并更新活动对象。 可以首先使用 diff 子命令查看将要进行的更改，然后在进行应用： kubectl diff -f configs/ kubectl apply -f configs/ 递归处理目录： kubectl diff -R -f configs/ kubectl apply -R -f configs/ 与命令式对象配置相比的优点： 对活动对象所做的更改即使未合并到配置文件中，也会被保留下来。 声明性对象配置更好地支持对目录进行操作并自动检测每个文件的操作类型（创建，修补，删除）。 与命令式对象配置相比的缺点： 声明式对象配置难于调试并且出现异常时结果难以理解。 使用 diff 产生的部分更新会创建复杂的合并和补丁操作。 对象名称和 IDs 集群中的每一个对象都有一个名称来标识在同类资源中的唯一性。 每个 Kubernetes 对象也有一个 UID 来标识在整个集群中的唯一性。 比如，在同一个名字空间中有一个名为 myapp-1234 的 Pod, 但是可以命名一个 Pod 和一个 Deployment 同为 myapp-1234. 对于用户提供的非唯一性的属性，Kubernetes 提供了 标签（Labels） 和 注解（Annotation） 机制。 名称 客户端提供的字符串，引用资源 url 中的对象，如 /api/v1/pods/some name。 某一时刻，只能有一个给定类型的对象具有给定的名称。但是，如果删除该对象，则可以创建同名的新对象。 以下是比较常见的三种资源命名约束。 DNS 子域名 很多资源类型需要可以用作 DNS 子域名的名称。 DNS 子域名的定义可参见 RFC 1123 。 这一要求意味着名称必须满足如下规则： 不能超过253个字符 只能包含字母数字，以及'-' 和 '.' 须以字母数字开头 须以字母数字结尾 DNS 标签名 某些资源类型需要其名称遵循 RFC 1123 所定义的 DNS 标签标准。也就是命名必须满足如下规则： 最多63个字符 只能包含字母数字，以及'-' 须以字母数字开头 须以字母数字结尾 路径分段名称 某些资源类型要求名称能被安全地用作路径中的片段。 换句话说，其名称不能是 .、..，也不可以包含 / 或 % 这些字符。 下面是一个名为nginx-demo的 Pod 的配置清单： apiVersion: v1 kind: Pod metadata: name: nginx-demo spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 Ps: 某些资源类型可能具有额外的命名约束。 UIDs UIDs 是 Kubernetes 系统生成的字符串，唯一标识对象。 在 Kubernetes 集群的整个生命周期中创建的每个对象都有一个不同的 uid，它旨在区分类似实体的历史事件。 Kubernetes UIDs 是全局唯一标识符（也叫 UUIDs）。 UUIDs 是标准化的，见 ISO/IEC 9834-8 和 ITU-T X.667. 名字空间 Kubernetes 支持多个虚拟集群，它们底层依赖于同一个物理集群。 这些虚拟集群被称为名字空间。 何时使用多个名字空间 名字空间适用于存在很多跨多个团队或项目的用户的场景。 对于只有几到几十个用户的集群，根本不需要创建或考虑名字空间。当需要名称空间提供的功能时，请开始使用它们。 名字空间为名称提供了一个范围。资源的名称需要在名字空间内是唯一的，但不能跨名字空间。 名字空间不能相互嵌套，每个 Kubernetes 资源只能在一个名字空间中。 名字空间是在多个用户之间划分集群资源的一种方法（通过 资源配额 ）。 不需要使用多个名字空间来分隔轻微不同的资源，例如同一软件的不同版本，使用标签来区分同一名字空间中的不同资源即可。 使用名字空间 名字空间的创建和删除在 名字空间的管理指南文档 描述。 Ps: 避免使用前缀 kube- 创建名字空间，因为它是为 Kubernetes 系统名字空间保留的。 查看名字空间 你可以使用以下命令列出集群中现存的名字空间： kubectl get namespace 输出如下: NAME STATUS AGE default Active 1d kube-node-lease Active 1d kube-system Active 1d kube-public Active 1d Kubernetes 会创建四个初始名字空间： default 没有指明使用其它名字空间的对象所使用的默认名字空间。 kube-system Kubernetes 系统创建对象所使用的名字空间。 kube-public 这个名字空间是自动创建的，所有用户（包括未经过身份验证的用户）都可以读取它。 这个名字空间主要用于集群使用，以防某些资源在整个集群中应该是可见和可读的。 这个名字空间的公共方面只是一种约定，而不是要求。 kube-node-lease 此名字空间用于与各个节点相关的租期（Lease）对象；此对象的设计使得集群规模很大时节点心跳检测性能得到提升。 为请求设置名字空间 要为当前请求设置名字空间，请使用 --namespace 参数。 例如: kubectl run nginx --image=nginx --namespace= kubectl get pods --namespace= 设置名字空间偏好 你可以永久保存名字空间，以用于对应上下文中所有后续 kubectl 命令。 kubectl config set-context --current --namespace= # 验证之 kubectl config view | grep namespace: 名字空间和 DNS 当你创建一个 服务 时， Kubernetes 会创建一个相应的 DNS 条目 。 该条目的形式是 ..svc.cluster.local，这意味着如果容器只使用 ，它将被解析到本地名字空间的服务。 这对于跨多个名字空间（如开发、分级和生产） 使用相同的配置非常有用。 如果你希望跨名字空间访问，则需要使用完全限定域名（FQDN）。 并非所有对象都在名字空间中 大多数 kubernetes 资源（例如 Pod、Service、副本控制器等）都位于某些名字空间中。 但是名字空间资源本身并不在名字空间中。而且底层资源，例如 节点 和持久化卷不属于任何名字空间。 查看哪些 Kubernetes 资源在名字空间中，哪些不在名字空间中： # 位于名字空间中的资源 kubectl api-resources --namespaced=true # 不在名字空间中的资源 kubectl api-resources --namespaced=false 标签和选择算符 标签（Labels） 是附加到 Kubernetes 对象（比如 Pods）上的键值对。 标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接对核心系统有语义含义。 标签可以用于组织和选择对象的子集。标签可以在创建时附加到对象，随后可以随时添加和修改。 每个对象都可以定义一组键/值标签。每个键对于给定对象必须是唯一的。 \"metadata\": { \"labels\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } } 标签能够支持高效的查询和监听操作，对于用户界面和命令行是很理想的。 应使用 注解 记录非识别信息。 动机 标签使用户能够以松耦合的方式将他们自己的组织结构映射到系统对象，而无需客户端存储这些映射。 服务部署和批处理流水线通常是多维实体（例如，多个分区或部署、多个发行序列、多个层，每层多个微服务）。 管理通常需要交叉操作，这打破了严格的层次表示的封装，特别是由基础设施而不是用户确定的严格的层次结构。 示例标签： \"release\" : \"stable\", \"release\" : \"canary\" \"environment\" : \"dev\", \"environment\" : \"qa\", \"environment\" : \"production\" \"tier\" : \"frontend\", \"tier\" : \"backend\", \"tier\" : \"cache\" \"partition\" : \"customerA\", \"partition\" : \"customerB\" \"track\" : \"daily\", \"track\" : \"weekly\" 这些只是常用标签的例子; 你可以任意制定自己的约定。请记住，对于给定对象标签的键必须是唯一的。 语法和字符集 标签 是键值对。 有效的标签键有两个段：可选的前缀和名称，用斜杠（/）分隔。 名称 段是必需的，必须小于等于63个字符，以字母数字字符（[a-z0-9A-Z]）开头和结尾， 带有破折号（-），下划线（_），点（ .）和之间的字母数字。 前缀是可选的，如果指定，前缀必须是 DNS 子域：由点（.）分隔的一系列 DNS 标签，总共不超过 253 个字符， 后跟斜杠（/）。 如果省略前缀，则假定标签键对用户是私有的。 向最终用户对象添加标签的自动系统组件 （例如 kube-scheduler、kube-controller-manager、 kube-apiserver、kubectl 或其他第三方自动化工具）必须指定前缀。 kubernetes.io/ 前缀是为 Kubernetes 核心组件保留的。 有效标签值必须为 63 个字符或更少，并且必须为空或以字母数字字符（[a-z0-9A-Z]）开头和结尾， 中间可以包含破折号（-）、下划线（_）、点（.）和字母或数字。 标签选择算符 与名称和 UID 不同， 标签不支持唯一性。通常，我们希望许多对象携带相同的标签。 通过 标签选择算符，客户端/用户可以识别一组对象。标签选择算符是 Kubernetes 中的核心分组原语。 API 目前支持两种类型的选择算符：基于等值的 和 基于集合的 。 标签选择算符可以由 逗号分隔 的多个需求组成。在多个需求的情况下，必须满足所有要求，因此逗号分隔符充当 逻辑与（&&） 运算符。 空标签选择算符或者未指定的选择算符的语义取决于上下文，支持使用选择算符的 API 类别应该将算符的合法性和含义用文档记录下来。 Ps: 对于某些 API 类别（例如 ReplicaSet）而言，两个实例的标签选择算符不得在命名空间内重叠， 否则它们的控制器将互相冲突，无法确定应该存在的副本个数。 对于基于等值的和基于集合的条件而言，不存在逻辑或（||）操作符。你要确保你的过滤语句按合适的方式组织。 基于等值的需求 基于等值 或 基于不等值 的需求允许按标签键和值进行过滤。 匹配对象必须满足所有指定的标签约束，尽管它们也可能具有其他标签。 可接受的运算符有=、== 和 != 三种。 前两个表示 相等（并且只是同义词），而后者表示 不相等。例如： environment = production tier != frontend 前者表示其键名等于 environment，值等于 production 的所有资源。 后者表示其键名等于 tier，值不同于 frontend 的所有资源 以及 所有都没有带有 tier 键标签的资源。 可以使用逗号运算符来过滤 production 环境中的非 frontend 层资源：environment=production,tier!=frontend。 基于等值的标签要求的一种使用场景是 Pod 要指定节点选择标准。 例如，下面的示例 Pod 选择带有标签 \"accelerator=nvidia-tesla-p100\"。 apiVersion: v1 kind: Pod metadata: name: cuda-test spec: containers: - name: cuda-test image: \"k8s.gcr.io/cuda-vector-add:v0.1\" resources: limits: nvidia.com/gpu: 1 nodeSelector: accelerator: nvidia-tesla-p100 基于集合的需求 基于集合的标签需求允许你通过一组值来过滤键。 支持三种操作符：in、notin 和 exists (只可以用在键标识符上)。例如： environment in (production, qa) tier notin (frontend, backend) partition !partition 第一个示例选择了所有键等于 environment 并且值等于 production 或者 qa 的资源。 第二个示例选择了所有键等于 tier 并且值不等于 frontend 或者 backend 的资源，以及所有没有 tier 键标签的资源。 第三个示例选择了所有包含了有 partition 标签的资源；没有校验它的值。 第四个示例选择了所有没有 partition 标签的资源；没有校验它的值。 类似地，逗号分隔符充当 与 运算符。 因此，使用 partition 键（无论为何值）和 environment 不同于 qa 来过滤资源可以使用 partition, environment notin（qa) 来实现。 基于集合的标签选择算符是相等标签选择算符的一般形式， 因为 environment=production 等同于 environment in（production）；!= 和 notin 也是类似的。 基于集合 的要求可以与基于 相等 的要求混合使用。例如：partition in (customerA, customerB),environment!=qa 。 API LIST 和 WATCH 过滤 LIST 和 WATCH 操作可以使用查询参数指定标签选择算符过滤一组对象。 两种需求都是允许的。（这里显示的是它们出现在 URL 查询字符串中）: 基于等值 的需求: ?labelSelector=environment%3Dproduction,tier%3Dfrontend 基于集合 的需求: ?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29 两种标签选择算符都可以通过 REST 客户端用于 list 或者 watch 资源。 例如，使用 kubectl 定位 apiserver，可以使用 基于等值 的标签选择算符可以这么写： kubectl get pods -l environment=production,tier=frontend 或者使用 基于集合的 需求： kubectl get pods -l 'environment in (production),tier in (frontend)' 正如刚才提到的，基于集合 的需求更具有表达力。例如，它们可以实现值的 或 操作： kubectl get pods -l 'environment in (production, qa)' 或者通过 exists 运算符限制不匹配： kubectl get pods -l 'environment,environment notin (frontend)' 在 API 对象中设置引用 一些 Kubernetes 对象，例如 services 和 replicationcontrollers ， 也使用了标签选择算符去指定了其他资源的集合，例如 pods。 一个 Service 指向的一组 Pods 是由标签选择算符定义的。同样，一个 ReplicationController 应该管理的 pods 的数量也是由标签选择算符定义的。 两个对象的标签选择算符都是在 json 或者 yaml 文件中使用映射定义的，并且只支持 基于等值 需求的选择算符： \"selector\": { \"component\" : \"redis\", } 或者： selector: component: redis 这个选择算符(分别在 json 或者 yaml 格式中) 等价于 component=redis 或 component in (redis) 。 此外，对于比较新的资源，例如 Job、 Deployment、 Replica Set 和 DaemonSet ， 也支持基于集合的需求。 selector: matchLabels: component: redis matchExpressions: - {key: tier, operator: In, values: [cache]} - {key: environment, operator: NotIn, values: [dev]} matchLabels 是由 {key,value} 对组成的映射。 matchLabels 映射中的单个 {key,value} 等同于 matchExpressions 的元素， 其 key 字段为 \"key\"，operator 为 \"In\"，而 values 数组仅包含 \"value\"。 matchExpressions 是 Pod 选择算符需求的列表。 有效的运算符包括 In、NotIn、Exists 和 DoesNotExist。 在 In 和 NotIn 的情况下，设置的值必须是非空的。 Ps: 来自 matchLabels 和 matchExpressions 的所有要求都按逻辑与的关系组合到一起，它们必须都满足才能匹配。 此外，通过标签进行选择的一个用例是确定节点集，方便 Pod 调度。 有关更多信息，请参阅选择 节点文档 。 注解 你可以使用 Kubernetes 注解为对象附加任意的非标识的元数据。客户端程序（例如工具和库）能够获取这些元数据信息。 为对象附加元数据 你可以使用标签或注解将元数据附加到 Kubernetes 对象。 标签可以用来选择对象和查找满足某些条件的对象集合。 相反，注解不用于标识和选择对象。 注解中的元数据，可以很小，也可以很大，可以是结构化的，也可以是非结构化的，能够包含标签不允许的字符。 注解和标签一样，是键/值对: \"metadata\": { \"annotations\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } } 以下是一些例子，用来说明哪些信息可以使用注解来记录: 由声明性配置所管理的字段。将这些字段附加为注解，能够将它们与客户端或服务端设置的默认值、 自动生成的字段以及通过自动调整大小或自动伸缩系统设置的字段区分开来。 构建、发布或镜像信息（如时间戳、发布 ID、Git 分支、PR 数量、镜像哈希、仓库地址）。 指向日志记录、监控、分析或审计仓库的指针。 可用于调试目的的客户端库或工具信息：例如，名称、版本和构建信息。 用户或者工具/系统的来源信息，例如来自其他生态系统组件的相关对象的 URL。 轻量级上线工具的元数据信息：例如，配置或检查点。 负责人员的电话或呼机号码，或指定在何处可以找到该信息的目录条目，如团队网站。 从用户到最终运行的指令，以修改行为或使用非标准功能。 你可以将这类信息存储在外部数据库或目录中而不使用注解，但这样做就使得开发人员很难生成用于部署、管理、自检的客户端共享库和工具。 语法和字符集 注解（Annotations） 存储的形式是键/值对。 有效的注解键分为两部分： 可选的前缀和名称，以斜杠（/）分隔。 名称 段是必需项，并且必须在63个字符以内，以字母数字字符（[a-z0-9A-Z]）开头和结尾， 并允许使用破折号（-），下划线（_），点（.）和字母数字。 前缀 是可选的。如果指定，则前缀必须是DNS子域：一系列由点（.）分隔的DNS标签， 总计不超过253个字符，后跟斜杠（/）。 如果省略前缀，则假定注解键对用户是私有的。 由系统组件添加的注解 （例如，kube-scheduler，kube-controller-manager，kube-apiserver，kubectl 或其他第三方组件）， 必须为终端用户添加注解前缀。 kubernetes.io/ 和 k8s.io/ 前缀是为Kubernetes核心组件保留的。 例如，下面是一个 Pod 的配置文件，其注解中包含 imageregistry: https://hub.docker.com/： apiVersion: v1 kind: Pod metadata: name: annotations-demo annotations: imageregistry: \"https://hub.docker.com/\" spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 字段选择器 字段选择器（Field selectors）允许你根据一个或多个资源字段的值 筛选 Kubernetes 资源。 下面是一些使用字段选择器查询的例子： metadata.name=my-service metadata.namespace!=default status.phase=Pending 下面这个 kubectl 命令将筛选出 status.phase 字段值为 Running 的所有 Pod： kubectl get pods --field-selector status.phase=Running 字段选择器本质上是资源过滤器（Filters）。默认情况下，字段选择器/过滤器是未被应用的，这意味着指定类型的所有资源都会被筛选出来。 这使得以下的两个 kubectl 查询是等价的： kubectl get pods kubectl get pods --field-selector \"\" 支持的字段 不同的 Kubernetes 资源类型支持不同的字段选择器。 所有资源类型都支持 metadata.name 和 metadata.namespace 字段。 使用不被支持的字段选择器会产生错误。例如： kubectl get ingress --field-selector foo.bar=baz 错误输出如下： Error from server (BadRequest): Unable to find \"ingresses\" that match label selector \"\", field selector \"foo.bar=baz\": \"foo.bar\" is not a known field selector: only \"metadata.name\", \"metadata.namespace\" 支持的操作符 你可在字段选择器中使用 =、==和 != （= 和 == 的意义是相同的）操作符。 例如，下面这个 kubectl 命令将筛选所有不属于 default 命名空间的 Kubernetes 服务： kubectl get services --all-namespaces --field-selector metadata.namespace!=default 链式选择器 同标签和其他选择器一样， 字段选择器可以通过使用逗号分隔的列表组成一个选择链。 下面这个 kubectl 命令将筛选 status.phase 字段不等于 Running 同时 spec.restartPolicy 字段等于 Always 的所有 Pod： kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always 多种资源类型 你能够跨多种资源类型来使用字段选择器。 下面这个 kubectl 命令将筛选出所有不在 default 命名空间中的 StatefulSet 和 Service： kubectl get statefulsets,services --all-namespaces --field-selector metadata.namespace!=default 推荐使用的标签 除了 kubectl 和 dashboard 之外，您可以使用其他工具来可视化和管理 Kubernetes 对象。 一组通用的标签可以让多个工具之间相互操作，用所有工具都能理解的通用方式描述对象。 除了支持工具外，推荐的标签还以一种可以查询的方式描述了应用程序。 元数据围绕 应用（application） 的概念进行组织。Kubernetes 不是 平台即服务（PaaS），没有或强制执行正式的应用程序概念。 相反，应用程序是非正式的，并使用元数据进行描述。应用程序包含的定义是宽松的。 下文中，我们将会讲解一些推荐的标签。它们使管理应用程序变得更容易但不是任何核心工具所必需的。 共享标签和注解都使用同一个前缀：app.kubernetes.io。没有前缀的标签是用户私有的。共享前缀可以确保共享标签不会干扰用户自定义的标签。 标签 为了充分利用这些标签，应该在每个资源对象上都使用它们。 键 描述 示例 app.kubernetes.io/name 应用程序的名称 mysql app.kubernetes.io/instance 用于唯一确定应用实例的名称 mysql-abcxzy app.kubernetes.io/version 应用程序的当前版本（例如，语义版本，修订版哈希等） 5.7.21 app.kubernetes.io/component 架构中的组件 database app.kubernetes.io/part-of 此级别的更高级别应用程序的名称 wordpress app.kubernetes.io/managed-by 用于管理应用程序的工具 helm 为说明这些标签的实际使用情况，请看下面的 StatefulSet 对象： apiVersion: apps/v1 kind: StatefulSet metadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: mysql-abcxzy app.kubernetes.io/version: \"5.7.21\" app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/managed-by: helm 应用和应用实例 应用可以在 Kubernetes 集群中安装一次或多次。 在某些情况下，可以安装在同一命名空间中。 例如，可以不止一次地为不同的站点安装不同的 WordPress。 应用的名称和实例的名称是分别记录的。 例如，某 WordPress 实例的 app.kubernetes.io/name 为 wordpress， 而其实例名称表现为 app.kubernetes.io/instance 的属性值 wordpress-abcxzy。 这使应用程序和应用程序的实例成为可能是可识别的。 应用程序的每个实例都必须具有唯一的名称。 示例 为了说明使用这些标签的不同方式，以下示例具有不同的复杂性。 一个简单的无状态服务 考虑使用 Deployment 和 Service 对象部署的简单无状态服务的情况。 以下两个代码段表示如何以最简单的形式使用标签。 下面的 Deployment 用于监督运行应用本身的 pods: apiVersion: apps/v1 kind: Deployment metadata: labels: app.kubernetes.io/name: myservice app.kubernetes.io/instance: myservice-abcxzy 下面的 Service 用于暴露应用: apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/name: myservice app.kubernetes.io/instance: myservice-abcxzy 带有一个数据库的 Web 应用程序 考虑一个稍微复杂的应用：一个使用 Helm 安装的 Web 应用（WordPress），其中 使用了数据库（MySQL）。 以下代码片段说明用于部署此应用程序的对象的开始。 以下 Deployment 的开头用于 WordPress： apiVersion: apps/v1 kind: Deployment metadata: labels: app.kubernetes.io/name: wordpress app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: \"4.9.4\" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: server app.kubernetes.io/part-of: wordpress ... 这个 Service 用于暴露 WordPress： apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/name: wordpress app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: \"4.9.4\" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: server app.kubernetes.io/part-of: wordpress MySQL 作为一个 StatefulSet 暴露，包含它和它所属的较大应用程序的元数据： apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: mysql-abcxzy app.kubernetes.io/version: \"5.7.21\" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress Service 用于将 MySQL 作为 WordPress 的一部分暴露： apiVersion: v1 kind: Service metadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: mysql-abcxzy app.kubernetes.io/version: \"5.7.21\" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress ... 使用 MySQL StatefulSet 和 Service，您会注意到有关 MySQL 和 Wordpress 的信息，包括更广泛的应用程序。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/artitecture.html":{"url":"cloud-native/kubernetes/artitecture.html","title":"Kubernetes架构","keywords":"","body":"Kubernetes架构 节点 Kubernetes 通过将容器放入在节点（Node）上运行的 Pod 中来执行你的工作负载。 节点可以是一个虚拟机或者物理机器，取决于所在的集群配置。每个节点包含运行 Pods 所需的服务， 这些 Pods 由控制面负责管理。 通常集群中会有若干个节点；而在一个学习用或者资源受限的环境中，你的集群中也可能 只有一个节点。 节点上的组件包括 kubelet、 容器运行时以及 kube-proxy。 管理 向 API 服务器添加节点的方式主要有两种： 节点上的 kubelet 向控制面执行自注册； 你，或者别的什么人，手动添加一个 Node 对象。 在你创建了 Node 对象或者节点上的 kubelet 执行了自注册操作之后， 控制面会检查新的 Node 对象是否合法。 例如，如果你使用下面的 JSON 对象来创建 Node 对象： { \"kind\": \"Node\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"10.240.79.157\", \"labels\": { \"name\": \"my-first-k8s-node\" } } } Kubernetes 会在内部创建一个 Node 对象作为节点的表示。 Kubernetes 检查 kubelet 向 API 服务器注册节点时使用的 metadata.name 字段是否匹配。 如果节点是健康的（即所有必要的服务都在运行中），则该节点可以用来运行 Pod。 否则，直到该节点变为健康之前，所有的集群活动都会忽略该节点。 Ps: Kubernetes 会一直保存着非法节点对应的对象，并持续检查该节点是否已经变得健康。 你，或者某个控制器必需显式地 删除该 Node 对象以停止健康检查操作。 Node 对象的名称必须是合法的 DNS 子域名。 节点自注册 当 kubelet 标志 --register-node 为 true（默认）时，它会尝试向 API 服务注册自己。 这是首选模式，被绝大多数发行版选用。 对于自注册模式，kubelet 使用下列参数启动： --kubeconfig - 用于向 API 服务器表明身份的凭据路径。 --cloud-provider - 与某云驱动 进行通信以读取与自身相关的元数据的方式。 --register-node - 自动向 API 服务注册。 --register-with-taints - 使用所给的污点列表（逗号分隔的 =:）注册节点。 当 register-node 为 false 时无效。 --node-ip - 节点 IP 地址。 --node-labels - 在集群中注册节点时要添加的标签。 （参见 NodeRestriction 准入控制插件 所实施的标签限制）。 --node-status-update-frequency - 指定 kubelet 向控制面发送状态的频率。 启用 节点授权模式 和 NodeRestriction准入插件 时，仅授权 kubelet 创建或修改其自己的节点资源。 手动节点管理 你可以使用 kubectl 来创建和修改 Node 对象。 如果你希望手动创建节点对象时，请设置 kubelet 标志 --register-node=false。 你可以修改 Node 对象（忽略 --register-node 设置）。 例如，修改节点上的标签或标记其为不可调度。 你可以结合使用节点上的标签和 Pod 上的选择算符来控制调度。 例如，你可以限制某 Pod 只能在符合要求的节点子集上运行。 如果标记节点为不可调度（unschedulable），将阻止新 Pod 调度到该节点之上，但不会影响任何已经在其上的 Pod。 这是重启节点或者执行其他维护操作之前的一个有用的准备步骤。 要标记一个节点为不可调度，执行以下命令： kubectl cordon $NODENAME Ps: 被 DaemonSet 控制器创建的 Pod 能够容忍节点的不可调度属性。 DaemonSet 通常提供节点本地的服务，即使节点上的负载应用已经被腾空，这些服务也仍需运行在节点之上。 节点状态 一个节点的状态包含以下信息: 地址 状态 容量与可分配 信息 你可以使用 kubectl 来查看节点状态和其他细节信息： kubectl describe node 下面对每个部分进行详细描述。 地址 这些字段的用法取决于你的云服务商或者物理机配置: HostName：由节点的内核设置。可以通过 kubelet 的 --hostname-override 参数覆盖。 ExternalIP：通常是节点的可外部路由（从集群外可访问）的 IP 地址。 InternalIP：通常是节点的仅可在集群内部路由的 IP 地址。 状态 conditions 字段描述了所有 Running 节点的状态。状态的示例包括： 节点状态 描述 Ready 如节点是健康的并已经准备好接收 Pod 则为 True；False 表示节点不健康而且不能接收 Pod；Unknown 表示节点控制器在最近 node-monitor-grace-period 期间（默认 40 秒）没有收到节点的消息 DiskPressure True 表示节点的空闲空间不足以用于添加新 Pod, 否则为 False MemoryPressure True 表示节点存在内存压力，即节点内存可用量低，否则为 False PIDPressure True 表示节点存在进程压力，即节点上进程过多；否则为 False NetworkUnavailable True 表示节点网络配置不正确；否则为 False Ps: 如果使用命令行工具来查询已保护（Cordoned）节点的细节，其中的 Condition 字段可能 包括 SchedulingDisabled。 SchedulingDisabled 不是 Kubernetes API 中定义的 Condition，被保护起来的节点在其规约中被标记为不可调度（Unschedulable）。 节点条件使用 JSON 对象表示。例如，下面的响应描述了一个健康的节点。 \"conditions\": [ { \"type\": \"Ready\", \"status\": \"True\", \"reason\": \"KubeletReady\", \"message\": \"kubelet is posting ready status\", \"lastHeartbeatTime\": \"2019-06-05T18:38:35Z\", \"lastTransitionTime\": \"2019-06-05T11:41:27Z\" } ] 如果 Ready 条件处于 Unknown 或者 False 状态的时间超过了 pod-eviction-timeout 值， （一个传递给 kube-controller-manager 的参数）， 节点上的所有 Pod 都会被节点控制器计划删除。 默认的逐出超时时长为 5 分钟。 某些情况下，当节点不可达时，API 服务器不能和其上的 kubelet 通信， 此时，删除 Pod 的决定不能传达给 kubelet，直到它重新建立和 API 服务器的连接为止。 与此同时，被计划删除的 Pod 可能会继续在游离的节点上运行。 节点控制器在确认 Pod 在集群中已经停止运行前，不会强制删除它们。 你可以看到这些可能在无法访问的节点上运行的 Pod 处于 Terminating 或者 Unknown 状态。 如果 kubernetes 不能基于下层基础设施推断出某节点是否已经永久离开了集群， 集群管理员可能需要手动删除该节点对象。 从 Kubernetes 删除节点对象将导致 API 服务器删除节点上所有运行的 Pod 对象并释放它们的名字。 节点生命周期控制器会自动创建代表状况的 污点 。 当调度器将 Pod 指派给某节点时，会考虑节点上的污点。 Pod 则可以通过容忍度（Toleration）表达所能容忍的污点。 容量与可分配 描述节点上的可用资源：CPU、内存和可以调度到节点上的 Pod 的个数上限。 capacity 块中的字段标示节点拥有的资源总量。 allocatable 块指示节点上可供普通 Pod 消耗的资源量。 可以在学习如何在节点上 预留计算资源 的时候了解有关容量和可分配资源的更多信息。 信息 关于节点的一般性信息，例如内核版本、Kubernetes 版本（kubelet 和 kube-proxy 版本）、 Docker 版本（如果使用了）和操作系统名称。这些信息由 kubelet 从节点上搜集而来。 节点控制器 节点控制器是 Kubernetes 控制面组件，管理节点的方方面面。 节点控制器在节点的生命周期中扮演多个角色。 第一个是当节点注册时为它 分配一个 CIDR 区段 （如果启用了 CIDR 分配）。 第二个是保持节点控制器内的节点列表与云服务商所提供的可用机器列表同步。 如果在云环境下运行，只要某节点不健康，节点控制器就会询问云服务是否节点的虚拟机仍可用。 如果不可用，节点控制器会将该节点从它的节点列表删除。 第三个是监控节点的健康情况。 节点控制器负责在节点不可达（即，节点控制器因为某些原因没有收到心跳，例如节点宕机）时， 将节点状态的 NodeReady 状况更新为 \"Unknown\"。 如果节点接下来持续处于不可达状态，节点控制器将逐出节点上的所有 Pod（使用体面终止）。 默认情况下 40 秒后开始报告 \"Unknown\"，在那之后 5 分钟开始逐出 Pod。 节点控制器每隔 --node-monitor-period 秒检查每个节点的状态。 心跳机制 Kubernetes 节点发送的心跳（Heartbeats）用于确定节点的可用性。 心跳有两种形式：NodeStatus 和 Lease 对象。 每个节点在 kube-node-lease 名字空间 中都有一个与之关联的 Lease 对象。 Lease 是一种轻量级的资源，可在集群规模扩大时提高节点心跳机制的性能。 kubelet 负责创建和更新 NodeStatus 和 Lease 对象。 当状态发生变化时，或者在配置的时间间隔内没有更新事件时，kubelet 会更新 NodeStatus。 NodeStatus 更新的默认间隔为 5 分钟（比不可达节点的 40 秒默认超时时间长很多）。 kubelet 会每 10 秒（默认更新间隔时间）创建并更新其 Lease 对象。 Lease 更新独立于 NodeStatus 更新而发生。 如果 Lease 的更新操作失败，kubelet 会采用指数回退机制，从 200 毫秒开始重试，最长重试间隔为 7 秒钟。 可靠性 大部分情况下，节点控制器把逐出速率限制在每秒 --node-eviction-rate 个（默认为 0.1）。 这表示它每 10 秒钟内至多从一个节点驱逐 Pod。 当一个可用区域（Availability Zone）中的大量节点变为不健康时，节点的驱逐行为将发生改变。 节点控制器会同时检查可用区域中不健康（NodeReady 状况为 Unknown 或 False） 的节点的百分比。 如果不健康节点的比例超过 --unhealthy-zone-threshold （默认为 0.55）， 驱逐速率将会降低： 如果集群较小（意即小于等于 --large-cluster-size-threshold 个节点 - 默认为 50）， 驱逐操作将会停止， 否则驱逐速率将降为每秒 --secondary-node-eviction-rate 个（默认为 0.01）。 在单个可用区域实施这些策略的原因是当一个可用区域可能从控制面脱离时其它可用区域可能仍然保持连接。 如果你的集群没有跨越云服务商的多个可用区域，那（整个集群）就只有一个可用区域。 跨多个可用区域部署你的节点的一个关键原因是当某个可用区域整体出现故障时，工作负载可以转移到健康的可用区域。 因此，如果一个可用区域中的所有节点都不健康时，节点控制器会以正常的速率 --node-eviction-rate 进行驱逐操作。 在所有的可用区域都不健康（也即集群中没有健康节点）的极端情况下， 节点控制器将假设控制面节点的连接出了某些问题，它将停止所有驱逐动作直到一些连接恢复。 节点控制器还负责 驱逐运行在拥有 NoExecute 污点的节点上的 Pod， 除非这些 Pod 能够容忍此污点。 此外，节点控制器还负责 根据节点故障（例如节点不可访问或没有就绪）为其添加污点 。这意味着调度器不会将 Pod 调度到不健康的节点上。 Ps: kubectl cordon 会将节点标记为“不可调度（Unschedulable）”。 此操作的副作用是，服务控制器会将该节点从负载均衡器中之前的目标节点列表中移除， 从而使得来自负载均衡器的网络请求不会到达被保护起来的节点。 节点容量 Node 对象会记录节点上资源的容量（例如可用内存和 CPU 数量）。 通过 自注册 机制生成的 Node 对象会在注册期间报告自身容量。 如果你手动添加了 Node，你就需要在添加节点时 手动设置节点容量。 Kubernetes 调度器保证节点上有足够的资源供其上的所有 Pod 使用。它会检查节点上所有容器的请求的总和不会超过节点的容量。 总的请求包括由 kubelet 启动的所有容器，但不包括由容器运行时直接启动的容器， 也不包括不受 kubelet 控制的其他进程。 Ps: 如果要为非 Pod 进程显式保留资源。请参考 为系统守护进程预留资源 。 节点拓扑 支持版本: Kubernetes v1.16 [alpha] 如果启用了TopologyManager 特性门控 ，kubelet 可以在作出资源分配决策时使用拓扑提示。 参考 控制节点上拓扑管理策略 了解详细信息。 节点优雅退出 支持版本: Kubernetes v1.20 [alpha] 如果你启用了 GracefulNodeShutdown 特性门控 ， 那么 kubelet 尝试检测节点的系统关闭事件并终止在节点上运行的 Pod。 在节点终止期间，kubelet 保证 Pod 遵从常规的 Pod 终止流程 。 当启用了 GracefulNodeShutdown 特性门控时， kubelet 使用 systemd 抑制器锁 在给定的期限内延迟节点关闭。在关闭过程中，kubelet 分两个阶段终止 Pod： 终止在节点上运行的常规 Pod。 终止在节点上运行的关键 Pod 。 节点优雅退出的特性对应两个 KubeletConfiguration 选项： ShutdownGracePeriod: 指定节点应延迟关闭的总持续时间。此时间是 Pod 体面终止的时间总和，不区分常规 Pod 还是 关键 Pod。 ShutdownGracePeriodCriticalPods: 在节点关闭期间指定用于终止关键Pod的持续时间。该值应小于 ShutdownGracePeriod。 例如，如果设置了 ShutdownGracePeriod=30s 和 ShutdownGracePeriodCriticalPods=10s，则 kubelet 将延迟 30 秒关闭节点。 在关闭期间，将保留前 20（30 - 10）秒用于体面终止常规 Pod，而保留最后 10 秒用于终止 关键 Pod。 控制面到节点通信 Kubernetes 采用的是中心辐射型（Hub-and-Spoke）API 模式。 所有从集群（或所运行的 Pods）发出的 API 调用都终止于 apiserver（其它控制面组件都没有被设计为可暴露远程服务）。 apiserver 被配置为在一个安全的 HTTPS 端口（443）上监听远程连接请求，并启用一种或多种形式的客户端 身份认证 机制。 一种或多种客户端身份认证应该被启用， 特别是在允许使用 匿名请求 或 服务账号 令牌的时候。 应该使用集群的公共根证书开通节点，这样它们就能够基于有效的客户端凭据安全地连接 apiserver。 一种好的方法是以客户端证书的形式将客户端凭据提供给 kubelet。 请查看 kubelet TLS 启动引导 以了解如何自动提供 kubelet 客户端证书。 想要连接到 apiserver 的 Pod 可以使用服务账号安全地进行连接。 控制器 云控制器管理器的基础概念 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/setup_env.html":{"url":"cloud-native/kubernetes/setup_env.html","title":"Kubernetes环境搭建","keywords":"","body":"Kubernetes环境搭建 在本文中，我们将会分别讲解在不同的平台下如何搭建 Kubernetes 环境。 Mac 下 kubernetes 环境搭建 在 Mac 下，Docker Desktop 可以自带 Kubernetes 部署。 但是，由于国内的网络无法访问 kubernetes 镜像仓库，因此，我们需要从其他镜像仓库拉取镜像后重新修改镜像名称。 针对这一需求，Github 代码库可以很好的帮助我们： git clone https://github.com/maguowei/k8s-docker-for-mac cd ./k8s-docker-for-mac sh ./load_images.sh load_images.sh 脚本的作用就是从其他镜像仓库拉取 kubernetes 组件的镜像，并修改镜像名称为原始镜像名称。 接下来，我们只需要在 Docker Desktop 中开启 Kubernetes 服务即可： By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/configmap.html":{"url":"cloud-native/kubernetes/configmap.html","title":"Kubernetes ConfigMap 杂谈","keywords":"","body":"Kubernetes ConfigMap 杂谈 ConfigMap 是一种 Kubernetes API 对象，用来将非机密性的数据保存到键值对中。 使用时， Pods 可以将其用作环境变量、命令行参数或者存储卷中的配置文件。 ConfigMap 可以将您的环境配置信息和 容器镜像 解耦，便于应用配置的修改。 Ps: ConfigMap 并不提供保密或者加密功能。 如果你想存储的数据是机密的，请使用 Secret， 或者使用其他第三方工具来保证你的数据的私密性。 为什么需要 ConfigMap ？ 使用 ConfigMap 可以将你的配置数据和应用程序代码分开。 比如，假设你正在开发一个应用，它可以在你自己的电脑上（用于开发）和在云上 （用于实际流量）运行。 你的代码里有一段是用于查看环境变量 DATABASE_HOST，在本地运行时， 你将这个变量设置为 localhost; 在云上，你将其设置为引用 Kubernetes 集群中的公开数据库组件的服务名称。 这让你可以获取在云中运行的容器镜像，并且如果有需要的话，在本地调试完全相同的代码。 ConfigMap 在设计上不是用来保存大量数据的。 在 ConfigMap 中保存的数据不可超过 1 MiB。 如果你需要保存超出此尺寸限制的数据，你可能希望考虑挂载存储卷 或者使用独立的数据库或者文件服务。 ConfigMap 对象 ConfigMap 是一个 API 对象， 让你可以存储其他对象所需要使用的配置。 和其他 Kubernetes 对象都有一个 spec 不同的是，ConfigMap 使用 data 和 binaryData 字段。 这些字段能够接收键-值对作为其取值。 data 和 binaryData 字段都是可选的。 data 字段设计用来保存 UTF-8 字节序列，而 binaryData 则 被设计用来保存二进制数据作为 base64 编码的字串。 ConfigMap 的名字必须是一个合法的 DNS 子域名，即满足如下规则： 最多63个字符 只能包含小写字母、数字，以及'-' 须以字母数字开头 须以字母数字结尾 data 或 binaryData 字段下面的每个键的名称都必须由字母数字字符或者 -、_ 或 . 组成。 data 下保存的键名不可以与 binaryData 下出现的键名有重叠。 ConfigMaps 和 Pods 你可以写一个引用 ConfigMap 的 Pod 的 spec，并根据 ConfigMap 中的数据在该 Pod 中配置容器。 其中，这个 Pod 和 ConfigMap 必须要在同一个名字空间中。 下面是一个 ConfigMap 的示例，它的一些键只对应一个值，其他键的值看起来像是对应一个配置文件。 apiVersion: v1 kind: ConfigMap metadata: name: game-demo data: # 类属性键；每一个键都映射到一个简单的值 player_initial_lives: \"3\" ui_properties_file_name: \"user-interface.properties\" # 类文件键 game.properties: | enemy.types=aliens,monsters player.maximum-lives=5 user-interface.properties: | color.good=purple color.bad=yellow allow.textmode=true 你可以使用四种方式来使用 ConfigMap 配置 Pod 中的容器： 在容器命令和参数内 容器的环境变量 在只读卷里面添加一个文件，让应用来读取 编写代码在 Pod 中运行，使用 Kubernetes API 来读取 ConfigMap 这些不同的方法适用于不同的数据使用方式。 对前三个方法，kubelet 使用 ConfigMap 中的数据在 Pod 中启动容器。 第四种方法意味着你必须编写代码才能读取 ConfigMap 和它的数据。 然而， 由于你是直接使用 Kubernetes API，因此只要 ConfigMap 发生更改，你的应用就能够通过订阅来获取更新，并且在这样的情况发生的时候做出反应。 通过直接访问 Kubernetes API，这个技术也可以让你能够获取到不同的名字空间里的 ConfigMap。 下面是一个 Pod 的示例，它通过使用 game-demo 中的值来配置一个 Pod： apiVersion: v1 kind: Pod metadata: name: configmap-demo-pod spec: containers: - name: demo image: alpine command: [\"sleep\", \"3600\"] env: # 定义环境变量 - name: PLAYER_INITIAL_LIVES # 请注意这里和 ConfigMap 中的键名是不一样的 valueFrom: configMapKeyRef: name: game-demo # 这个值来自 ConfigMap key: player_initial_lives # 需要取值的键 - name: UI_PROPERTIES_FILE_NAME valueFrom: configMapKeyRef: name: game-demo key: ui_properties_file_name volumeMounts: - name: config mountPath: \"/config\" readOnly: true volumes: # 你可以在 Pod 级别设置卷，然后将其挂载到 Pod 内的容器中 - name: config configMap: # 提供你想要挂载的 ConfigMap 的名字 name: game-demo # 来自 ConfigMap 的一组键，将被创建为文件 items: - key: \"game.properties\" path: \"game.properties\" - key: \"user-interface.properties\" path: \"user-interface.properties\" ConfigMap 不会区分单行属性值和多行类似文件的值，重要的是 Pods 和其他对象如何使用这些值。 上面的例子定义了一个卷并将它作为 /config 文件夹挂载到 demo 容器内。 创建两个文件，/config/game.properties 和 /config/user-interface.properties。 因为 Pod 定义中在 volumes 节指定了一个 items 数组。 如果你完全省略 items 数组，则 ConfigMap 中的每个键都会变成一个与该键同名的文件，因此你会得到四个文件。 使用 ConfigMap ConfigMap 可以作为数据卷挂载。 ConfigMap 也可被系统的其他组件使用，而不一定直接暴露给 Pod。 例如，ConfigMap 可以保存系统中其他组件要使用的配置数据。 ConfigMap 最常见的用法是为同一命名空间里某 Pod 中运行的容器执行配置。你也可以单独使用 ConfigMap。 比如，你可能会遇到基于 ConfigMap 来调整其行为的插件或者 operator。 下面，我们来看一下如何在 Pod 中将 ConfigMap 访问文件来使用： 创建一个 ConfigMap 对象或者使用现有的 ConfigMap 对象，多个 Pod 可以引用同一个 ConfigMap。 修改 Pod 定义，在 spec.volumes[] 下添加一个卷。 为该卷设置任意名称，之后将 spec.volumes[].configMap.name 字段设置为对 你的 ConfigMap 对象的引用。 为每个需要该 ConfigMap 的容器添加一个 .spec.containers[].volumeMounts[]。 设置 .spec.containers[].volumeMounts[].readOnly=true 并将 .spec.containers[].volumeMounts[].mountPath 设置为一个未使用的目录名，ConfigMap 的内容将出现在该目录中。 更改你的镜像或者命令行，以便程序能够从该目录中查找文件，ConfigMap 中的每个 data 键会变成 mountPath 下面的一个文件名。 下面是一个将 ConfigMap 以卷的形式进行挂载的 Pod 示例： apiVersion: v1 kind: Pod metadata: name: mypod spec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: \"/etc/foo\" readOnly: true volumes: - name: foo configMap: name: myconfigmap 其中，你希望使用的每个 ConfigMap 都需要在 spec.volumes 中被引用到。 如果 Pod 中有多个容器，则每个容器都需要自己的 volumeMounts 块， 但针对每个 ConfigMap，你只需要设置一个 spec.volumes 块。 当卷中使用的 ConfigMap 被更新时，所投射的键最终也会被更新。 kubelet 组件会在每次周期性同步时检查所挂载的 ConfigMap 是否为最新。 kubelet 使用的是其本地的高速缓存来获得 ConfigMap 的当前值。 高速缓存的类型可以通过 KubeletConfiguration 结构 的 ConfigMapAndSecretChangeDetectionStrategy 字段来配置。 ConfigMap 既可以通过 watch 操作实现内容传播（默认形式），也可实现基于 TTL 的缓存，还可以直接经过所有请求重定向到 API 服务器。 因此，从 ConfigMap 被更新的那一刻算起，到新的主键被投射到 Pod 中去，这一时间跨度可能与 kubelet 的同步周期加上高速缓存的传播延迟相等。 这里的传播延迟取决于所选的高速缓存类型 （分别对应 watch 操作的传播延迟、高速缓存的 TTL 时长或者 0）。 Ps: 以环境变量方式使用的 ConfigMap 数据不会被自动更新。 更新这些数据需要重新启动 Pod。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/storage.html":{"url":"cloud-native/kubernetes/storage.html","title":"Kubernetes PV/PVC/StorageClass 杂谈","keywords":"","body":"Kubernetes PV/PVC/StorageClass 杂谈 在本文中，我们将会对 PV、PVC 以及 StorageClass 相关的概念与使用依次进行讲解与说明。 卷 Volume 在了解 PV、PVC 等概念之前，我们首先要了解的一个基础概念就是 Volume 。 在 K8s 中，Container 中的文件在磁盘上是临时存放的，这给 Container 中运行的较重要的应用程序带来一些问题。 问题之一是当容器崩溃时文件丢失，即当容器崩溃时 kubelet 会重新启动容器， 但容器会以干净的状态重启。 第二个问题会在同一 Pod 中运行多个容器时，希望多个容器之间可以共享文件。 Kubernetes 卷（Volume） 这一抽象概念能够解决这两个问题。 Kubernetes 支持很多类型的卷。 一个 Pod 可以同时使用任意数目的卷类型。 其中，临时卷类型的生命周期与 Pod 相同，但持久卷可以比 Pod 的存活期长。 即当 Pod 不再存在时，Kubernetes 也会销毁临时卷；不过 Kubernetes 不会销毁持久卷。 对于给定 Pod 中任何类型的卷，在容器重启期间数据都不会丢失。 卷的核心是一个目录，其中可能存有数据，Pod 中的容器可以访问该目录中的数据。 所采用的特定的卷类型将决定该目录如何形成的、使用何种介质保存数据以及目录中存放的内容。 使用卷时, 在 .spec.volumes 字段中设置为 Pod 提供的卷，并在 .spec.containers[*].volumeMounts 字段中声明卷在容器中的挂载位置。 容器中的进程看到的是由它们的 Docker 镜像和卷组成的文件系统视图。 Docker 镜像 位于文件系统层次结构的根部。各个卷则挂载在镜像内的指定路径上。 卷不能挂载到其他卷之上，也不能与其他卷有硬链接。 同时，Pod 配置中的每个容器必须独立指定各个卷的挂载位置。 下面，我们来针对一些简单的卷类型进行示例讲解。 emptyDir 卷 emptyDir 卷是一种最简单的卷了，它本身没有其他任何的外部依赖，可以在 K8s 集群中直接使用。 当 Pod 分派到某个 Node 上时，emptyDir 卷会被创建，并且在 Pod 在该节点上运行期间，卷一直存在。 就像其名称表示的那样，卷最初是空的。 尽管 Pod 中的容器挂载 emptyDir 卷的路径可能相同也可能不同，但这些容器都可以读写 emptyDir 卷中相同的文件。 当 Pod 因为某些原因被从节点上删除时，emptyDir 卷中的数据也会被永久删除。 emptyDir 卷看起来非常简单，那它有什么用呢？ 缓存空间，例如基于磁盘的归并排序。 为耗时较长的计算任务提供检查点，以便任务能方便地从崩溃前状态恢复执行。 在 Web 服务器容器服务数据时，保存内容管理器容器获取的文件。 取决于你的环境，emptyDir 卷存储在该节点所使用的介质上；这里的介质可以是磁盘或 SSD 或网络存储。 此外，你可以将 emptyDir.medium 字段设置为 \"Memory\"，以告诉 Kubernetes 为你挂载 tmpfs（基于 RAM 的文件系统）。 虽然 tmpfs 速度非常快，但是要注意它与磁盘不同。 tmpfs 在节点重启时会被清除，并且你所写入的所有文件都会计入容器的内存消耗，受容器内存限制约束。 一个使用 emptyDir 的示例 Pod 如下: apiVersion: v1 kind: Pod metadata: name: test-pd spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: {} NFS 卷 nfs 卷能将 NFS (网络文件系统) 挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，nfs 卷的内容在删除 Pod 时会被保存，卷只是被卸载。 这意味着 nfs 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。 Ps: 与 emptyDir 卷不同，在正式使用 NFS 卷之前，你必须运行自己的 NFS 服务器并将目标 share 导出备用。 Persistent Volume 介绍 了解了 Volume 的概念后，我们来继续了解一下什么是 Persistent Volume 。 存储的管理是一个与计算实例的管理完全不同的问题。 PersistentVolume 子系统为用户 和管理员提供了一组 API，将存储如何供应的细节从其如何被使用中抽象出来。 为了实现这点，我们引入了两个新的 API 资源：PersistentVolume 和 PersistentVolumeClaim。 持久卷（PersistentVolume，PV）是集群中的一块存储，可以由管理员事先供应，或者使用存储类（Storage Class）来动态供应。 持久卷是集群资源，就像节点也是集群资源一样。 PV 持久卷和普通的 Volume 一样，也是使用卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。 持久卷申领（PersistentVolumeClaim，PVC）表达的是用户对存储的请求。概念上与 Pod 类似。 Pod 会耗用节点资源，而 PVC 申领会耗用 PV 资源。 Pod 可以请求特定数量的资源（CPU 和内存）；同样 PVC 申领也可以请求特定的大小和访问模式 （例如，可以要求 PV 卷能够以 ReadWriteOnce、ReadOnlyMany 或 ReadWriteMany 模式之一来挂载，参见访问模式）。 尽管 PersistentVolumeClaim 允许用户消耗抽象的存储资源， 常见的情况是针对不同的需求用户需要的是具有不同属性（如，性能）的 PersistentVolume 卷。 集群管理员需要能够提供不同性质的 PersistentVolume，并且这些 PV 卷之间的差别不仅限于卷大小和访问模式， 同时又不能将卷是如何实现的这些细节暴露给用户。 为了满足这类需求，就有了存储类（StorageClass）资源。 PV 和 PVC 的生命周期 PV 卷是集群中的资源，PVC 申领是对这些资源的请求，也被用来执行对资源的申领检查。 PV 卷和 PVC 申领之间的互动遵循如下生命周期： 供应 PV 卷的供应有两种方式：静态供应或动态供应。 静态供应是指集群管理员创建若干 PV 卷。 这些卷对象带有真实存储的细节信息，并且对集群用户可用（可见）。 PV 卷对象存在于 Kubernetes API 中，可供用户消费（使用）。 动态供应是指如果管理员所创建的所有静态 PV 卷都无法与用户的 PersistentVolumeClaim 匹配， 集群可以尝试为该 PVC 申领动态供应一个存储卷。 这一供应操作是基于 StorageClass 来实现的：PVC 申领必须请求某个存储类，同时集群管理员必须已经创建并配置了该类，这样动态供应卷的动作才会发生。 如果 PVC 申领指定存储类为 \"\"，则相当于为自身禁止使用动态供应的卷。 绑定 用户创建一个带有特定存储容量和特定访问模式需求的 PersistentVolumeClaim 对象； 在动态供应场景下，这个 PVC 对象可能已经创建完毕。 主控节点中的控制回路监测新的 PVC 对象，寻找与之匹配的 PV 卷（如果可能的话）， 并将二者绑定到一起。 如果为了新的 PVC 申领动态供应了 PV 卷，则控制回路总是将该 PV 卷绑定到这一 PVC 申领。 否则，用户总是能够获得他们所请求的资源，只是所获得的 PV 卷可能会超出所请求的配置。 一旦绑定关系建立，则 PersistentVolumeClaim 绑定就是排他性的，无论该 PVC 申领是如何与 PV 卷建立的绑定关系。 PVC 申领与 PV 卷之间的绑定是一种一对一的映射，实现上使用 ClaimRef 来记述 PV 卷 与 PVC 申领间的双向绑定关系。 如果找不到匹配的 PV 卷，PVC 申领会无限期地处于未绑定状态。当与之匹配的 PV 卷可用时，PVC 申领会被绑定。 例如，即使某集群上供应了很多 50 Gi 大小的 PV 卷，也无法与请求 100 Gi 大小的存储的 PVC 匹配。 当新的 100 Gi PV 卷被加入到集群时，该 PVC 才有可能被绑定。 使用 Pod 将 PVC 申领当做存储卷来使用。集群会检视 PVC 申领，找到所绑定的卷，并为 Pod 挂载该卷。 对于支持多种访问模式的卷，用户要在 Pod 中以卷的形式使用申领时指定期望的访问模式。 一旦用户有了申领对象并且该申领已经被绑定，则所绑定的 PV 卷在用户仍然需要它期间一直属于该用户。 用户通过在 Pod 的 volumes 块中包含 persistentVolumeClaim 节区来指定 Pod 访问所申领的 PV 卷。 保护使用中的存储对象 保护使用中的存储对象（Storage Object in Use Protection）这一功能特性的目的是确保 仍被 Pod 使用的 PersistentVolumeClaim（PVC）对象及其所绑定的 PersistentVolume（PV）对象在系统中不会被删除， 因为这样做可能会引起数据丢失。 Ps: 当使用某 PVC 的 Pod 对象仍然存在时，认为该 PVC 仍被此 Pod 使用。 如果用户删除被某 Pod 使用的 PVC 对象，该 PVC 申领不会被立即移除。 PVC 对象的移除会被推迟，直至其不再被任何 Pod 使用。 此外，如果管理员删除已绑定到某 PVC 申领的 PV 卷，该 PV 卷也不会被立即移除。 PV 对象的移除也要推迟到该 PV 不再绑定到 PVC。 你可以看到当 PVC 的状态为 Terminating 且其 Finalizers 列表中包含 kubernetes.io/pvc-protection 时，PVC 对象是处于被保护状态的。 kubectl describe pvc hostpath # Name: hostpath # Namespace: default # StorageClass: example-hostpath # Status: Terminating # Volume: # Labels: # Annotations: volume.beta.kubernetes.io/storage-class=example-hostpath # volume.beta.kubernetes.io/storage-provisioner=example.com/hostpath # Finalizers: [kubernetes.io/pvc-protection] # ... 回收 当用户不再使用其存储卷时，他们可以从 API 中将 PVC 对象删除，从而允许该资源被回收再利用。 PersistentVolume 对象的回收策略告诉集群，当其被从申领中释放时如何处理该数据卷。 目前，数据卷可以被 Retained（保留）、 Deleted（删除） 或 Retain（保留，即将废弃，建议用动态供应替换）。 回收策略 Retain 使得用户可以手动回收资源。 当 PersistentVolumeClaim 对象被删除时，PersistentVolume 卷仍然存在，对应的数据卷被视为\"已释放（released）\"。 由于卷上仍然存在这前一申领人的数据，该卷还不能用于其他申领。 管理员可以通过下面的步骤来手动回收该卷： 删除 PersistentVolume 对象。此时，与之相关的、位于外部基础设施中的存储资产 （例如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）在 PV 删除之后仍然存在。 根据情况，手动清除所关联的存储资产上的数据。 手动删除所关联的存储资产；如果你希望重用该存储资产，可以基于存储资产的定义创建新的 PersistentVolume 卷对象。 删除策略 Delete 会将 PersistentVolume 对象从 Kubernetes 中移除， 同时也会从外部基础设施（如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）中移除所关联的存储资产。 动态供应的卷会继承其 StorageClass 中设置的回收策略，该策略默认为 Delete。 预留PV 通过在 PersistentVolumeClaim 中指定 PersistentVolume，你可以声明该特定 PV 与 PVC 之间的绑定关系。 如果该 PersistentVolume 存在且未被通过其 claimRef 字段预留给 PersistentVolumeClaim， 则该 PersistentVolume 会和该 PersistentVolumeClaim 绑定到一起。 此时，绑定操作不会考虑某些卷匹配条件是否满足，包括节点亲和性等等。 但是，控制面仍然会检查存储类、访问模式和所请求的存储尺寸都是合法的。 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: foo-pvc namespace: foo spec: storageClassName: \"\" # 此处须显式设置空字符串，否则会被设置为默认的 StorageClass volumeName: foo-pv ... 此方法无法对 PersistentVolume 的绑定特权做出任何形式的保证。 如果有其他 PersistentVolumeClaim 可以使用你所指定的 PV，则你应该首先预留该存储卷。 你可以将 PV 的 claimRef 字段设置为相关的 PersistentVolumeClaim 以确保其他 PVC 不会绑定到该 PV 卷。 apiVersion: v1 kind: PersistentVolume metadata: name: foo-pv spec: storageClassName: \"\" claimRef: name: foo-pvc namespace: foo ... 如果你想要使用 claimPolicy 属性设置为 Retain 的 PersistentVolume 卷时，包括你希望复用现有的 PV 卷时，这点是很有用的。 扩充PVC申领 当我们 PVC 已经申请下来后，如果发现卷的大小不足时，还可以对 PVC 申请进行扩容。 目前支持 PVC 的卷类型包括： gcePersistentDisk awsElasticBlockStore Cinder 等等。 只有当 PVC 的存储类中将 allowVolumeExpansion 设置为 true 时，你才可以扩充该 PVC 申领。例如： apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: gluster-vol-default provisioner: kubernetes.io/glusterfs parameters: resturl: \"http://192.168.10.100:8080\" restuser: \"\" secretNamespace: \"\" secretName: \"\" allowVolumeExpansion: true 如果要为某 PVC 请求较大的存储卷，可以编辑 PVC 对象，设置一个更大的尺寸值。 这一编辑操作会触发为下层 PersistentVolume 提供存储的卷的扩充。 Ps: Kubernetes 不会创建新的 PV 卷来满足此申领的请求，而是将现有的卷调整大小。 持久卷类型 PV 持久卷是用插件的形式来实现的。Kubernetes 目前支持以下插件： local - 节点上挂载的本地存储设备 csi - 容器存储接口 (CSI) glusterfs - Glusterfs 卷 cephfs - CephFS volume 等等。 持久卷属性 每个 PV 对象都包含 spec 部分和 status 部分，分别对应卷的规约和状态。 PersistentVolume 对象的名称必须是合法的 DNS 子域名. 示例如下： apiVersion: v1 kind: PersistentVolume metadata: name: pv0003 spec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp server: 172.17.0.2 Ps: 在集群中使用持久卷存储通常需要一些特定于具体卷类型的辅助程序。 在这个例子中，PersistentVolume 是 NFS 类型的，因此需要辅助程序 /sbin/mount.nfs 来支持挂载 NFS 文件系统。 capacity 一般而言，每个 PV 卷都有确定的存储容量。 容量属性是使用 PV 对象的 capacity 属性来设置的。 目前，存储大小是可以设置和请求的唯一资源。 未来可能会包含 IOPS、吞吐量等属性。 volumeMode 针对 PV 持久卷，Kubernetes 支持两种 volumeMode : Filesystem Block 其中，volumeMode 是一个可选的 API 参数，默认为 Filesystem 。 volumeMode 属性设置为 Filesystem 的卷会被 Pod 挂载（Mount） 到某个目录。 如果卷的存储来自某块设备而该设备目前为空，Kuberneretes 会在第一次挂载卷之前 在设备上创建文件系统。 accessModes PersistentVolume 卷可以用资源提供者所支持的任何方式挂载到宿主系统上。 提供者（驱动）的能力不同，每个 PV 卷的访问模式都会设置为对应卷所支持的模式值。 例如，NFS 可以支持多个读写客户，但是某个特定的 NFS PV 卷可能在服务器上以只读的方式导出。 每个 PV 卷都会获得自身的访问模式集合，描述的是特定 PV 卷的能力。 其中，访问模式包括： ReadWriteOnce -- 卷可以被一个节点以读写方式挂载； ReadOnlyMany -- 卷可以被多个节点以只读方式挂载； ReadWriteMany -- 卷可以被多个节点以读写方式挂载。 persistentVolumeReclaimPolicy 目前的回收策略有： Retain -- 手动回收 Recycle -- 基本擦除 (rm -rf /thevolume/*) Delete -- 诸如 AWS EBS、GCE PD、Azure Disk 或 OpenStack Cinder 卷这类关联存储资产也被删除 目前，仅 NFS 和 HostPath 支持回收（Recycle）。 AWS EBS、GCE PD、Azure Disk 和 Cinder 卷都支持删除（Delete）。 storageClassName 每个 PV 可以属于某个类（Class），通过将其 storageClassName 属性设置为某个 StorageClass 的名称来指定。 特定类的 PV 卷只能绑定到请求该类存储卷的 PVC 申领。 未设置 storageClassName 的 PV 卷没有类设定，只能绑定到那些没有指定特定存储类的 PVC 申领。 mountOptions Kubernetes 管理员可以指定持久卷被挂载到节点上时使用的附加挂载选项。 Ps: 并非所有持久卷类型都支持挂载选项。 Kubernetes 不对挂载选项执行合法性检查。如果挂载选项是非法的，挂载就会失败。 nodeAffinity 对于 local 类型的挂载，我们还可以指定 nodeAffinity 。 Kubernetes 调度器使用 PersistentVolume 的 nodeAffinity 信息来将使用 local 卷的 Pod 调度到正确的节点。 示例如下： apiVersion: v1 kind: PersistentVolume metadata: name: example-pv spec: capacity: storage: 100Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/disks/ssd1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - example-node Phase 每个卷会处于以下阶段（Phase）之一： Available（可用）-- 卷是一个空闲资源，尚未绑定到任何申领； Bound（已绑定）-- 该卷已经绑定到某申领； Released（已释放）-- 所绑定的申领已被删除，但是资源尚未被集群回收； Failed（失败）-- 卷的自动回收操作失败。 其中，命令行接口能够显示绑定到某 PV 卷的 PVC 对象。 PVC 介绍 每个 PVC 对象都有 spec 和 status 部分，分别对应申领的规约和状态。 PersistentVolumeClaim 对象的名称必须是合法的 DNS 子域名. 一个示例 PVC 如下： apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim spec: accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 8Gi storageClassName: slow selector: matchLabels: release: \"stable\" matchExpressions: - {key: environment, operator: In, values: [dev]} PVC 用于 Volume Pod 可以将 PVC 作为卷来使用，并藉此访问存储资源。 申领必须位于使用它的 Pod 所在的同一名字空间内。 集群在 Pod 的名字空间中查找申领，并使用它来获得申领所使用的 PV 卷。 之后，卷会被挂载到宿主上并挂载到 Pod 中。 示例如下： apiVersion: v1 kind: Pod metadata: name: mypod spec: containers: - name: myfrontend image: nginx volumeMounts: - mountPath: \"/var/www/html\" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim StorageClass 介绍 StorageClass 为管理员提供了描述存储 \"类\" 的方法。 不同的类型可能会映射到不同的服务质量等级或备份策略，或是由集群管理员制定的任意策略。 Kubernetes 本身并不清楚各种类代表的什么。这个类的概念在其他存储系统中有时被称为 \"配置文件\"。 StorageClass 说明 每个 StorageClass 都包含 provisioner、parameters 和 reclaimPolicy 字段， 这些字段会在 StorageClass 需要动态分配 PersistentVolume 时会使用到。 StorageClass 对象的命名很重要，用户使用这个命名来请求生成一个特定的类。 当创建 StorageClass 对象时，管理员设置 StorageClass 对象的命名和其他参数，一旦创建了对象就不能再对其更新。 管理员可以为没有申请绑定到特定 StorageClass 的 PVC 指定一个存储类，例如: apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: standard provisioner: kubernetes.io/aws-ebs parameters: type: gp2 reclaimPolicy: Retain allowVolumeExpansion: true mountOptions: - debug volumeBindingMode: Immediate provisioner 每个 StorageClass 都有一个 Provisioner ，它用来决定使用哪个卷插件制备 PV ，该字段必须指定。 kubernetes 内置了一系列 Provisioner ，但是如果内置的 Provisioner 如果无法满足你的使用场景， 你还可以运行和指定外部制备器，这些独立的程序遵循由 Kubernetes 定义的规范。 reclaimPolicy 由 StorageClass 动态创建的 PersistentVolume 会在类的 reclaimPolicy 字段中指定回收策略，可以是 Delete 或者 Retain。 如果 StorageClass 对象被创建时没有指定 reclaimPolicy，它将默认为 Delete。 通过 StorageClass 手动创建并管理的 PersistentVolume 会使用它们被创建时指定的回收政策。 allowVolumeExpansion PersistentVolume 可以配置为可扩展。将此功能设置为 true 时，允许用户通过编辑相应的 PVC 对象来调整卷大小。 当下层 StorageClass 的 allowVolumeExpansion 字段设置为 true 时，部分类型的卷支持卷扩展。 mountOptions 由 StorageClass 动态创建的 PersistentVolume 将使用类中 mountOptions 字段指定的挂载选项。 如果卷插件不支持挂载选项，却指定了挂载选项，则 provisioner 操作会失败。 挂载选项在 StorageClass 和 PV 上都不会做验证，如果其中一个挂载选项无效，那么这个 PV 挂载操作就会失败。 volumeBindingMode volumeBindingMode 字段控制了卷绑定和动态提供 PV 应该发生在什么时候。 默认情况下，Immediate 模式表示一旦创建了 PersistentVolumeClaim 也就完成了卷绑定和动态制备。 对于由于拓扑限制而非集群所有节点可达的存储后端，PersistentVolume 会在不知道 Pod 调度要求的情况下绑定或者制备。 集群管理员可以通过指定 WaitForFirstConsumer 模式来解决此问题。 该模式将延迟 PersistentVolume 的绑定和制备，直到使用该 PersistentVolumeClaim 的 Pod 被创建。 PersistentVolume 会根据 Pod 调度约束指定的拓扑来选择或制备。 动态卷供应 动态卷供应允许按需创建 PV 。 如果没有动态供应，集群管理员必须手动地联系他们的云或存储提供商来创建新的存储卷， 然后在 Kubernetes 集群创建 PersistentVolume 对象来表示这些卷。 动态供应功能消除了集群管理员预先配置存储的需要。 相反，它在用户请求时自动供应存储。 动态卷供应的实现基于 storage.k8s.io API 组中的 StorageClass API 对象。 集群管理员可以根据需要定义多个 StorageClass 对象，每个对象指定一个 provisioner， provisioner 向卷供应商提供在创建卷时需要的数据卷信息及相关参数。 要启用动态供应功能，集群管理员需要为用户预先创建一个或多个 StorageClass 对象。 StorageClass 对象定义当动态供应被调用时，哪一个驱动将被使用和哪些参数将被传递给驱动。 示例如下： apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: slow provisioner: kubernetes.io/gce-pd parameters: type: pd-standard 用户通过在 PersistentVolumeClaim 中包含存储类来请求动态供应的存储。 用户现在能够而且应该使用 PersistentVolumeClaim 对象的 storageClassName 字段。 这个字段的值必须能够匹配到集群管理员配置的 StorageClass 名称，示例如下： apiVersion: v1 kind: PersistentVolumeClaim metadata: name: claim1 spec: accessModes: - ReadWriteOnce storageClassName: slow resources: requests: storage: 30Gi 该声明会自动供应一块类似 SSD 的永久磁盘。 在删除该声明后，这个卷也会被销毁。 此外，可以在群集上启用动态卷供应，以便在未指定存储类的情况下动态设置所有声明。 集群管理员可以通过以下方式启用此行为： 标记一个 StorageClass 为默认； 确保 DefaultStorageClass 准入控制器在 API 服务端被启用。 管理员可以通过向其添加 storageclass.kubernetes.io/is-default-class 注解来将特定的 StorageClass 标记为默认。 当集群中存在默认的 StorageClass 并且用户创建了一个未指定 storageClassName 的 PersistentVolumeClaim 时， DefaultStorageClass 准入控制器会自动向其中添加指向默认存储类的 storageClassName 字段。 Ps: 群集上最多只能有一个 默认存储类，否则无法创建没有明确指定 storageClassName 的 PersistentVolumeClaim。 实战演示 下面，我们通过一个示例来演示 PV、PVC 以及 StorageClass 的相关功能与使用。 local-path-provisioner 部署 为了能够正常使用 PV 相关的功能，我们首先需要搭建一个 Provisioner 服务来给我们提供持久卷。 此处，我们使用 local-path-provisioner 来提供持久卷，官方文档请参考 local-path-provisioner 。 kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml 在该 yaml 中，定义了 local-path-provisioner 的 Namespace, ServiceAccount, ClusterRole, ClusterRoleBinding, Deployment, ConfigMap 以及 StorageClass 。 其中，我们重点关注一下 StorageClass 对象的配置信息： apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: local-path provisioner: rancher.io/local-path volumeBindingMode: WaitForFirstConsumer reclaimPolicy: Delete 根据之前的学习内容，我们可以知道，在这个 yaml 中，我们定义了一个 StorageClass ，名称是 local-path ， reclaimPolicy 为 Delete，volumeBindingMode为 PVC 被声明使用时才创建。 接下来，我们可以查询 Pod 的状态，直到 Pod 成功运行： kubectl -n local-path-storage get pod 此时，我们依赖的 provisioner 已经部署完成，同时 StorageClass 也已经创建好了，下面，我们就具体来演示一下如何使用吧！ 使用 StorageClass 自动创建 PV 并绑定 第一步，我们首先需要创建一个 PVC 用于申请一块磁盘资源，示例 yaml 文件如下： apiVersion: v1 kind: PersistentVolumeClaim metadata: name: wangzhe-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi storageClassName: local-path volumeMode: Filesystem 接下来，我们可以 apply 该 yaml 文件使其生效: kubectl apply -f pvc.yaml 此时，查询该对应的 pvc 的状态，可以发现该状态其实是 unbound 的。 kubectl get pvc 这时由于在安装 provisioner 时，对应创建的 StorageClass 中 volumeBindingMode 配置是 WaitForFirstConsumer 而不是 Immediate 导致的。 下面，我们来创建一个 Deployment ，其中该 Pod 使用了刚刚创建的 PVC，yaml 文件内容如下: apiVersion: apps/v1 kind: Deployment metadata: name: flaskapp-pvc spec: selector: matchLabels: app: flaskapp-pvc replicas: 1 template: metadata: labels: app: flaskapp-pvc spec: containers: - name: flaskapp image: dustise/flaskapp imagePullPolicy: IfNotPresent env: - name: version valueFrom: configMapKeyRef: name: game-demo key: player_initial_lives volumeMounts: - name: config mountPath: \"/config\" readOnly: true volumes: - name: config persistentVolumeClaim: claimName: wangzhe-pvc 可以看到，在该 yaml 文件的 Pod spec 配置中，我们定义了一个 volumes，并关联到了我们刚才创建的 PVC 上。 同时，我们还将该 Volume 挂载到了Container的指定目录下。 下面，我们 apply 该 yaml 文件: kubectl apply -f flask_deployments.yaml 此时，再次查询对应的 PVC 的状态，就可以发现对应的 PVC 的状态已经是 Bound 了，同样，进入容器后，你也可以看到对应的卷。 Ps: 删除 Pod / Deployment 时，不会自动删除对应的 PV 和 PVC 。如果希望删除指定的 PV / PVC ，需要主动来指定并删除它们。 手动创建 PV 并绑定和使用 除了通过 StorageClass 来自动动态生成 PV 之外，我们来可以主动申请 PV 并绑定 PVC 和使用。 首先，创建 pv.yaml 文件如下： apiVersion: v1 kind: PersistentVolume metadata: name: wangzhe-pv spec: accessModes: - ReadWriteOnce capacity: storage: 10Gi claimRef: apiVersion: v1 kind: PersistentVolumeClaim name: wangzhe-pvc-2 namespace: books nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - hostname1 persistentVolumeReclaimPolicy: Delete storageClassName: \"\" volumeMode: Filesystem local: path: /home/data/wangzhe-pv Ps: 此时，我们需要在对应的机器上创建该目录 /home/data/wangzhe-pv 。 接下来，查询对应的 PV 状态，预期状态应该会变为 Available 。 下面，我们来创建一个 pvc 来绑定对应的 PV。 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: wangzhe-pvc-2 spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi storageClassName: \"\" volumeMode: Filesystem 此时，再次查询对应的 PV 、 PVC 状态，可以看到二者的状态都已经是 Bound 了。 下面，我们来创建对应的 Deployment 来使用对应的 PVC: apiVersion: apps/v1 kind: Deployment metadata: name: flaskapp-pvc-3 spec: selector: matchLabels: app: flaskapp-pvc-3 replicas: 1 template: metadata: labels: app: flaskapp-pvc-3 spec: containers: - name: flaskapp image: dustise/flaskapp imagePullPolicy: IfNotPresent volumeMounts: - name: config mountPath: \"/config\" readOnly: true volumes: - name: config persistentVolumeClaim: claimName: wangzhe-pvc-2 下面，我们就可以进入该容器，并在目录中进行相关的操作啦~ By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/rbac.html":{"url":"cloud-native/kubernetes/rbac.html","title":"Kubernetes RBAC 杂谈","keywords":"","body":"Kubernetes RBAC 杂谈 RBAC 背景概述 了解 K8s 的同学都知道，Kubernetes 中所有的 API 对象都保存在 etcd 里。 而在 K8s 中，我们想要通过自己的插件来实现对 API 对象进行操作时，一定需要通过访问 kube-apiserver 来实现。 在 kube-apiserver 的调用中，首先需要来完成授权相关的工作。 而在 Kubernetes 项目中，负责完成授权（Authorization）工作的机制，就是 RBAC: 基于角色的访问控制（Role-Based Access Control）。 RBAC 基本概念 在 RBAC 中，有三个最核心的概念： Role: 角色，它其实是一组规则，定义了一组对 Kubernetes API 对象的操作权限。 Subject: 被作用者，既可以是『人』，也可以是『机器』，也可以是你在 Kubernetes 里面定义的『用户』。 RoleBinding: 定义了『被作用者』和『角色』的绑定关系。 Role Role 本身就是一个 Kubernetes 的 API 对象，定义如下所示： kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: mynamespace name: example-role rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] 首先，这个 Role 对象指定了它能产生作用的 Namespace: mynamespace 。 Ps: Namespace 是 Kubernetes 项目里的一个逻辑管理单位。不同 Namespace 的 API 对象，在通过 kubectl 命令进行操作的时候，是互相隔离开的。 当然，这仅限于逻辑上的“隔离”，Namespace 并不会提供任何实际的隔离或者多租户能力。 然后，这个 Role 对象的 rules 字段就是它所定义的权限规则。 以上面的示例为例，这条规则的含义就是：允许“被作用者”，对 mynamespace 下面的 Pod 对象，进行 GET、WATCH 和 LIST 操作。 在 Role 中，verbs 的全集包括: get, list, watch, create, update, patch, delete。 类似地，Role 对象的 rules 字段也可以进一步细化。比如，你可以只针对某一个具体的对象进行权限设置，如下所示： rules: - apiGroups: [\"\"] resources: [\"configmaps\"] resourceNames: [\"my-config\"] verbs: [\"get\"] 这个例子就表示，这条规则的“被作用者”，只对名叫“my-config”的 ConfigMap 对象，有进行 GET 操作的权限。 RoleBinding 那么，这个具体的“被作用者”又是如何指定的呢？这就需要通过 RoleBinding 来实现了。 RoleBinding 本身也是一个 Kubernetes 的 API 对象。它的定义如下所示： kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-rolebinding namespace: mynamespace roleRef: kind: Role name: example-role apiGroup: rbac.authorization.k8s.io subjects: - kind: User name: example-user apiGroup: rbac.authorization.k8s.io 其中，包含了一个 roleRef 字段。 通过这个字段，RoleBinding 对象就可以直接通过名字，来引用我们前面定义的 Role 对象（example-role）， 从而定义了“被作用者（Subject）”和“角色（Role）”之间的绑定关系。 需要注意的是： Role 和 RoleBinding 对象都是 Namespaced 对象（Namespaced Object）， 它们对权限的限制规则仅在它们自己的 Namespace 内有效， roleRef 也只能引用当前 Namespace 里的 Role 对象。 那么，对于非 Namespaced（Non-namespaced）对象（比如：Node）， 或者，某一个 Role 想要作用于所有的 Namespace 的时候，我们又该如何去做授权呢？ 我们就必须要使用 ClusterRole 和 ClusterRoleBinding 这两个组合了。 这两个 API 对象的用法跟 Role 和 RoleBinding 完全一样。 只不过，它们的定义里，没有了 Namespace 字段。 示例如下： kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-clusterrole rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-clusterrolebinding subjects: - kind: User name: example-user apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: example-clusterrole apiGroup: rbac.authorization.k8s.io 可以看到，这个 RoleBinding 对象里还包含了一个 subjects 字段，即“被作用者”。 它的类型是 User，即 Kubernetes 里的用户。这个用户的名字是 example-user。 ServiceAccount 可是，在 Kubernetes 中，其实并没有一个叫作“User”的 API 对象。 而且，我们在前面和部署使用 Kubernetes 的流程里，既不需要 User，也没有创建过 User。 这个 User 到底是从哪里来的呢？ 实际上，Kubernetes 里的“User”，也就是“用户”，只是一个授权系统里的逻辑概念。 它需要通过外部认证服务，比如 Keystone 来提供。 或者，你也可以直接给 APIServer 指定一个用户名、密码文件。 那么 Kubernetes 的授权系统，就能够从这个文件里找到对应的“用户”了。 当然，在大多数私有的使用环境中，我们只要使用 Kubernetes 提供的“内置用户”，就足够了。 而这个内置用户，其实就是: ServiceAccount 。 首先，我们要定义一个 ServiceAccount。它的 API 对象非常简单，如下所示： apiVersion: v1 kind: ServiceAccount metadata: namespace: mynamespace name: example-sa 可以看到，一个最简单的 ServiceAccount 对象只需要 Name 和 Namespace 这两个最基本的字段。 我们可以应用一下上述的 yaml 文件: kubectl create -f svc-account.yaml 然后，我们来查看一下这个 ServiceAccount 的详细信息： - apiVersion: v1 kind: ServiceAccount metadata: creationTimestamp: 2018-09-08T12:59:17Z name: example-sa namespace: mynamespace resourceVersion: \"409327\" ... secrets: - name: example-sa-token-vmfg6 可以看到，Kubernetes 会为一个 ServiceAccount 自动创建并分配一个 Secret 对象， 即：上述 ServiceAcount 定义里最下面的 secrets 字段。 这个 Secret，就是这个 ServiceAccount 对应的，用来跟 APIServer 进行交互的授权文件，我们一般称它为：Token。 Token 文件的内容一般是证书或者密码，它以一个 Secret 对象的方式保存在 Etcd 当中。 这时候，用户的 Pod，就可以声明使用这个 ServiceAccount 了，比如下面这个例子： apiVersion: v1 kind: Pod metadata: namespace: mynamespace name: sa-token-test spec: containers: - name: nginx image: nginx:1.7.9 serviceAccountName: example-sa 可以看到，在 Pod 的 Spec 中，可以增加一个 serviceAccountName 字段来指定对应的 serviceAccount 名称。 等这个 Pod 运行起来之后，我们就可以看到，该 ServiceAccount 的 token， 也就是一个 Secret 对象被 Kubernetes 自动挂载到了容器的 /var/run/secrets/kubernetes.io/serviceaccount 目录下，如下所示: kubectl describe pod sa-token-test -n mynamespace 输出如下: Name: sa-token-test Namespace: mynamespace ... Containers: nginx: ... Mounts: /var/run/secrets/kubernetes.io/serviceaccount from example-sa-token-vmfg6 (ro) 这时候，我们可以通过 kubectl exec 查看到这个目录里的文件： kubectl exec -it sa-token-test -n mynamespace -- /bin/bash # root@sa-token-test:/# ls /var/run/secrets/kubernetes.io/serviceaccount # ca.crt namespace token 如上所示，容器里的应用，就可以使用这个 ca.crt 来访问 APIServer 了。 更重要的是，此时它只能够做 GET、WATCH 和 LIST 操作。 因为 example-sa 这个 ServiceAccount 的权限，已经被我们绑定了 Role 做了限制。 如果一个 Pod 没有声明 serviceAccountName， Kubernetes 会自动在它的 Namespace 下创建一个名叫 default 的默认 ServiceAccount，然后分配给这个 Pod。 但是这个 default 的 ServiceAccount 实际没有关联任何的 Role，具体的权限是有 Kubernetes 默认的。 所以，在生产环境中，我强烈建议你为所有 Namespace 下的默认 ServiceAccount，绑定一个只读权限的 Role。 而上述的 RoleBinding 的 yaml 文件可以转化为如下格式: kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-rolebinding namespace: mynamespace subjects: - kind: ServiceAccount name: example-sa namespace: mynamespace roleRef: kind: Role name: example-role apiGroup: rbac.authorization.k8s.io 可以看到，在这个 RoleBinding 对象里，subjects 字段的类型（kind），不再是一个 User，而是一个名叫 example-sa 的 ServiceAccount。 Kubernetes 还拥有“用户组”（Group）的概念，也就是一组“用户”的意思。 如果你为 Kubernetes 配置了外部认证服务的话，这个“用户组”的概念就会由外部认证服务提供。 而对于 Kubernetes 的内置“用户”ServiceAccount 来说，上述“用户组”的概念也同样适用。 实际上，一个 ServiceAccount，在 Kubernetes 里对应的“用户”的名字是： system:serviceaccount:: 而它对应的内置“用户组”的名字，就是： system:serviceaccounts: 比如，现在我们可以在 RoleBinding 里定义如下的 subjects： subjects: - kind: Group name: system:serviceaccounts:mynamespace apiGroup: rbac.authorization.k8s.io 这就意味着这个 Role 的权限规则，作用于 mynamespace 里的所有 ServiceAccount。这就用到了“用户组”的概念。 而下面这个例子： subjects: - kind: Group name: system:serviceaccounts apiGroup: rbac.authorization.k8s.io 就意味着这个 Role 的权限规则，作用于整个系统里的所有 ServiceAccount。 在 Kubernetes 中已经内置了很多个为系统保留的 ClusterRole，它们的名字都以 system: 开头。 你可以通过 kubectl get clusterroles 查看到它们。 一般来说，这些系统 ClusterRole，是绑定给 Kubernetes 系统组件对应的 ServiceAccount 使用的。 比如，其中一个名叫 system:kube-scheduler 的 ClusterRole， 定义的权限规则是 kube-scheduler（Kubernetes 的调度器组件）运行所需要的必要权限。 你可以通过如下指令查看这些权限的列表： kubectl describe clusterrole system:kube-scheduler Name: system:kube-scheduler ... PolicyRule: Resources Non-Resource URLs Resource Names Verbs --------- ----------------- -------------- ----- ... services [] [] [get list watch] replicasets.apps [] [] [get list watch] statefulsets.apps [] [] [get list watch] replicasets.extensions [] [] [get list watch] poddisruptionbudgets.policy [] [] [get list watch] pods/status [] [] [patch update] 这个 system:kube-scheduler 的 ClusterRole，就会被绑定给 kube-system Namesapce 下名叫 kube-scheduler 的 ServiceAccount， 它正是 Kube-Scheduler 的 Pod 声明使用的 ServiceAccount。 除此之外，Kubernetes 还提供了四个预先定义好的 ClusterRole 来供用户直接使用： cluster-admin admin edit view 通过它们的名字，你应该能大致猜出它们都定义了哪些权限。比如，这个名叫 view 的 ClusterRole，就规定了被作用者只有 Kubernetes API 的只读权限。 上面这个 cluster-admin 角色，对应的是整个 Kubernetes 项目中的最高权限（verbs=*），因此，cluster-admin 的使用要非常慎用。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kubernetes/admission_controller.html":{"url":"cloud-native/kubernetes/admission_controller.html","title":"Kubernetes 准入控制","keywords":"","body":"Kubernetes 准入控制机制 准入控制器概述 准入控制器是指当用户请求通过认证和授权之后，对象被持久化之前拦截 apiserver 的请求。 准入控制器可以可以执行\"验证\"和\"变更\"操作。 其中，\"变更\"操作是指可以修改被接收的对象的meta信息。 默认的控制器代码是编译进入 kube-apiserver 二进制文件的，只能由集群管理员配置。 准入控制过程分为两个阶段。 第一阶段，运行\"变更\"准入控制器。 第二阶段，运行\"验证\"准入控制器。 Ps: 某些控制器既是变更准入控制器又是验证准入控制器。 如果任何一个阶段的任何控制器拒绝了该请求，则整个请求将立即被拒绝，并向终端用户返回一个错误。 启用/关闭一个准入控制器 kube-apiserver 的 enable-admission-plugins 参数接受一个以逗号分隔的准入控制插件顺序列表。 kube-apiserver --enable-admission-plugins=NamespaceLifecycle,LimitRanger 上述命令中启用了 NamespaceLifecycle 和 LimitRanger 准入控制插件。 同样，disable-admission-plugins 参数也可以将传入的（以逗号分隔的） 准入控制插件列表禁用，即使是默认启用的插件也会被禁用。 kube-apiserver --disable-admission-plugins=PodNodeSelector,AlwaysDeny 我们可以查询哪些准入控制插件是默认启用的: kube-apiserver -h | grep enable-admission-plugins 这些准入控制器都是 kubernetes 内置推荐的准入控制器。 内置准入控制器功能概述 自定义准入控制器 除了上述我们提到的 Kubernetes 中内置的准入控制器插件外，Kubernetes 还提供了一种可以自定义开发的准入控制插件， 它是通过在运行时所配置的 webhook 的形式来运行的。 准入 Webhook 是一种用于接收准入请求并对其进行处理的 HTTP 回调机制。 我们可以定义两种类型的准入 webhook: \"验证\"性质的准入 Webhook: ValidatingWebhookConfiguration \"修改\"性质的准入 Webhook: MutatingWebhookConfiguration 修改性质的准入 Webhook 会先被调用。 它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作。 在完成了所有对象修改并且 API 服务器也验证了所传入的对象之后， 验证性质的 Webhook 会被调用，并通过拒绝请求的方式来强制实施自定义的策略。 准入 Webhook 实战 准入 Webhook 本质上是集群控制平面的一部分。 因此，对于准入 Webhook 的编写，应该非常是谨慎的编写和部署。 下面，我们来看看如何快速编写一个 Webhook 。 准入 Webhook 生效需要具备如下条件: Kubernetes 集群版本至少为 v1.16 确保启用 MutatingAdmissionWebhook 和 ValidatingAdmissionWebhook 控制器。 示例准入 webhook 应用 对于一个准入 webhook 而言，需要包含如下三个步骤: 编写一个准入 webhook 应用。 部署 webhook 应用。 配置对应的 WebhookConfiguration 。 在如下代码中，包含了 admission webhook 服务器 的示例实现。 具体来说，webhook 处理由 apiserver 发送的 AdmissionReview 请求，并且将其决定作为 AdmissionResponse 对象以相同版本发送回去。 下面，我们来一个示例的 ValidatingWebhookConfiguration 的配置: apiVersion: admissionregistration.k8s.io/v1 kind: ValidatingWebhookConfiguration metadata: name: \"pod-policy.example.com\" webhooks: - name: \"pod-policy.example.com\" rules: # webhook 生效范围 - apiGroups: [\"\"] # \"\" 表示核心组，*匹配所有组 apiVersions: [\"v1\"] # * 匹配所有组 operations: [\"CREATE\"] # 支持 CREATE, UPDATE, DELETE, CONNECT, * resources: [\"pods\"] # \"*\" 匹配所有资源，但不包括子资源。\"*/*\" 匹配所有资源，包括子资源。\"pods/*\" 匹配 pod 的所有子资源。\"*/status\" 匹配所有 status 子资源。 scope: \"Namespaced\" # 表示 namespace 级别生效, Cluster表示集群有效, * 表示全局生效 clientConfig: # Webhook 的地址 service: namespace: \"example-namespace\" name: \"example-service\" caBundle: \"Ci0tLS0tQk......tLS0K\" admissionReviewVersions: [\"v1\", \"v1beta1\"] sideEffects: None timeoutSeconds: 5 # 超时时间默认为 10s 当 apiserver 收到与 rules 相匹配的请求时，apiserver 按照 clientConfig 中指定的方式向 webhook 发送一个 admissionReview 请求。 创建 webhook 配置后，系统将花费几秒钟使新配置生效。 那么，apiserver 发送给 webhook 服务器的请求的格式是什么样的呢？一个示例如下： { \"apiVersion\": \"admission.k8s.io/v1\", \"kind\": \"AdmissionReview\", \"request\": { # 唯一标识此准入回调的随机 uid \"uid\": \"705ab4f5-6393-11e8-b7cc-42010a800002\", # 传入完全正确的 group/version/kind 对象 \"kind\": {\"group\":\"autoscaling\",\"version\":\"v1\",\"kind\":\"Scale\"}, # 修改 resource 的完全正确的的 group/version/kind \"resource\": {\"group\":\"apps\",\"version\":\"v1\",\"resource\":\"deployments\"}, # subResource（如果请求是针对 subResource 的） \"subResource\": \"scale\", # 在对 API 服务器的原始请求中，传入对象的标准 group/version/kind # 仅当 webhook 指定 `matchPolicy: Equivalent` 且将对 API 服务器的原始请求转换为 webhook 注册的版本时，这才与 `kind` 不同。 \"requestKind\": {\"group\":\"autoscaling\",\"version\":\"v1\",\"kind\":\"Scale\"}, # 在对 API 服务器的原始请求中正在修改的资源的标准 group/version/kind # 仅当 webhook 指定了 `matchPolicy：Equivalent` 并且将对 API 服务器的原始请求转换为 webhook 注册的版本时，这才与 `resource` 不同。 \"requestResource\": {\"group\":\"apps\",\"version\":\"v1\",\"resource\":\"deployments\"}, # subResource（如果请求是针对 subResource 的） # 仅当 webhook 指定了 `matchPolicy：Equivalent` 并且将对 API 服务器的原始请求转换为该 webhook 注册的版本时，这才与 `subResource` 不同。 \"requestSubResource\": \"scale\", # 被修改资源的名称 \"name\": \"my-deployment\", # 如果资源是属于名字空间（或者是名字空间对象），则这是被修改的资源的名字空间 \"namespace\": \"my-namespace\", # 操作可以是 CREATE、UPDATE、DELETE 或 CONNECT \"operation\": \"UPDATE\", \"userInfo\": { # 向 API 服务器发出请求的经过身份验证的用户的用户名 \"username\": \"admin\", # 向 API 服务器发出请求的经过身份验证的用户的 UID \"uid\": \"014fbff9a07c\", # 向 API 服务器发出请求的经过身份验证的用户的组成员身份 \"groups\": [\"system:authenticated\",\"my-admin-group\"], # 向 API 服务器发出请求的用户相关的任意附加信息 # 该字段由 API 服务器身份验证层填充，并且如果 webhook 执行了任何 SubjectAccessReview 检查，则应将其包括在内。 \"extra\": { \"some-key\":[\"some-value1\", \"some-value2\"] } }, # object 是被接纳的新对象。 # 对于 DELETE 操作，它为 null。 \"object\": {\"apiVersion\":\"autoscaling/v1\",\"kind\":\"Scale\",...}, # oldObject 是现有对象。 # 对于 CREATE 和 CONNECT 操作，它为 null。 \"oldObject\": {\"apiVersion\":\"autoscaling/v1\",\"kind\":\"Scale\",...}, # options 包含要接受的操作的选项，例如 meta.k8s.io/v CreateOptions、UpdateOptions 或 DeleteOptions。 # 对于 CONNECT 操作，它为 null。 \"options\": {\"apiVersion\":\"meta.k8s.io/v1\",\"kind\":\"UpdateOptions\",...}, # dryRun 表示 API 请求正在以 `dryrun` 模式运行，并且将不会保留。 # 带有副作用的 Webhook 应该避免在 dryRun 为 true 时激活这些副作用。 # 有关更多详细信息，请参见 http://k8s.io/docs/reference/using-api/api-concepts/#make-a-dry-run-request \"dryRun\": false } } Webhook 使用 HTTP 200 状态码、Content-Type: application/json 和一个包含 AdmissionReview 对象的 JSON 序列化格式来发送响应。 该 AdmissionReview 对象与发送的版本相同，且其中包含的 response 字段已被有效填充。 response 至少必须包含以下字段： uid，从发送到 webhook 的 request.uid 中复制而来 allowed，设置为 true 或 false 一个最简单允许请求的示例如下: { \"apiVersion\": \"admission.k8s.io/v1\", \"kind\": \"AdmissionReview\", \"response\": { \"uid\": \"\", \"allowed\": true } } Webhook 禁止请求的最简单响应示例： { \"apiVersion\": \"admission.k8s.io/v1\", \"kind\": \"AdmissionReview\", \"response\": { \"uid\": \"\", \"allowed\": false } } 当拒绝请求时，Webhook 可以使用 status 字段自定义 http 响应码和返回给用户的消息。示例如下： { \"apiVersion\": \"admission.k8s.io/v1\", \"kind\": \"AdmissionReview\", \"response\": { \"uid\": \"\", \"allowed\": false, \"status\": { \"code\": 403, \"message\": \"You cannot do this because it is Tuesday and your name starts with A\" } } } 当允许请求时，mutating准入 Webhook 也可以选择修改传入的对象。 这是通过在响应中使用 patch 和 patchType 字段来完成的。 当前唯一支持的 patchType 是 JSONPatch，其中的 patch 字段包含一个以 base64 编码的 JSON patch 操作数组。 例如，设置 spec.replicas 的单个补丁操作将是: [{\"op\": \"add\", \"path\": \"/spec/replicas\", \"value\": 3}] 如果以 Base64 形式编码，结果将是 W3sib3AiOiAiYWRkIiwgInBhdGgiOiAiL3NwZWMvcmVwbGljYXMiLCAidmFsdWUiOiAzfV0= 。 因此，添加该标签的 webhook 响应为： { \"apiVersion\": \"admission.k8s.io/v1\", \"kind\": \"AdmissionReview\", \"response\": { \"uid\": \"\", \"allowed\": true, \"patchType\": \"JSONPatch\", \"patch\": \"W3sib3AiOiAiYWRkIiwgInBhdGgiOiAiL3NwZWMvcmVwbGljYXMiLCAidmFsdWUiOiAzfV0=\" } } By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kt-env/beginning.html":{"url":"cloud-native/kt-env/beginning.html","title":"KT-env实战","keywords":"","body":"KT-env实战 KtEnv 是一种基于ServiceMesh的微服务环境复用工具，源于阿里内部的“项目环境”实践。 通过识别Pod上的虚拟环境标签，KtEnv能够自动将测试环境网络动态隔离成多个虚拟隔离域， 同时以简单规则在隔离域间局部复用Pod实例， 从而达到只需很少资源成本即可创建大量不同微服务版本组合的独立测试环境的目的。 在本系列文章中，我们将会详细介绍 KT-env 的原理，使用，源码实现等等。 希望通过本系列的文章，可以让你熟练掌握 KT-env 相关的使用。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kt-env/request_routing.html":{"url":"cloud-native/kt-env/request_routing.html","title":"Mesh基础知识及请求路由","keywords":"","body":"Mesh基础知识及请求路由 想要了解 KT-env 相关的功能和使用，首先需要了解一下什么是 mesh 以及请求路由相关的功能。 ServiceMesh 相关介绍 首先，我们来了解一下大家对 ServiceMesh 的定义： 服务网格（Service Mesh）是处理服务间通信的基础设施层。 它负责构成现代云原生应用程序的复杂服务拓扑来可靠地交付请求。 在实践中，Service Mesh 通常以轻量级网络代理阵列的形式实现， 这些代理与应用程序代码部署在一起，对应用程序来说无需感知代理的存在。 ServiceMesh 通常有如下特点： 它是应用程序间通信的中间层。 轻量级网络代理。 应用程序无感知。 解耦应用程序的重试/超时、监控、追踪和服务发现。 ServiceMesh 仅仅是一种定义和概念，而关于 ServiceMesh 的具体实现，则有多种不同的服务实现方式，例如 Istio, Linkerd。 其中，Istio 是目前最流行 ServiceMesh 服务了，我们也将会继续对 Istio 来进行详细的说明。 Istio 概述 Istio 是 ServiceMesh 的一种实现。 Istio 服务网格从逻辑上分为数据平面和控制平面。 数据平面: 由一组智能代理（Envoy）组成，被部署为 Sidecar。这些代理负责协调和控制微服务之间的所有网络通信。它们还收集和报告所有网格流量的遥测数据。 控制平面: 管理并配置代理来进行流量路由。 下图展示了组成每个平面的不同组件： Envoy Istio 使用 Envoy 代理的扩展版本。Envoy 是用 C++ 开发的高性能代理，用于协调服务网格中所有服务的入站和出站流量。 Envoy 代理是唯一与数据平面流量交互的 Istio 组件。 Envoy 代理被部署为服务的 Sidecar，在逻辑上为服务增加了 Envoy 的许多内置特性，例如： 动态服务发现 负载均衡 TLS HTTP/2 与 grpc 代理 熔断器 健康检查 基于百分比流量分割的分阶段发布 故障注入 丰富的监控指标 这种 Sidecar 部署允许 Istio 可以执行策略决策，并提取丰富的遥测数据，接着将这些数据发送到监视系统以提供有关整个网格行为的信息。 Sidecar 代理模型还允许您向现有的部署添加 Istio 功能，而不需要重新设计架构或重写代码。 由 Envoy 代理启用的一些 Istio 的功能和任务包括： 流量控制功能：通过丰富的 HTTP、gRPC、WebSocket 和 TCP 流量路由规则来执行细粒度的流量控制。 网络弹性特性：重试设置、故障转移、熔断器和故障注入。 安全性和身份认证特性：执行安全性策略，并强制实行通过配置 API 定义的访问控制和速率限制。 基于 WebAssembly 的可插拔扩展模型，允许通过自定义策略执行和生成网格流量的遥测。 Istiod Istiod 提供服务发现、配置和证书管理。 Istiod 将控制流量行为的高级路由规则转换为 Envoy 特定的配置，并在运行时将其传播给 Sidecar。 Pilot 提取了特定平台的服务发现机制，并将其综合为一种标准格式，任何符合 Envoy API 的 Sidecar 都可以使用。 Istio 可以支持发现多种环境，如 Kubernetes 或 VM。 您可以使用 Istio 流量管理 API 让 Istiod 重新构造 Envoy 的配置，以便对服务网格中的流量进行更精细的控制。 Istiod 安全通过内置的身份和凭证管理，实现了强大的服务对服务和终端用户认证。 您可以使用 Istio 来升级服务网格中未加密的流量。 使用 Istio，运营商可以基于服务身份而不是相对不稳定的第 3 层或第 4 层网络标识符来执行策略。 此外，您可以使用 Istio 的授权功能控制谁可以访问您的服务。 Istiod 还充当证书授权（CA），并生成证书以允许在数据平面中进行安全的 mTLS 通信。 Istio 请求路由控制 Istio 提供的核心功能之一就是 服务发现 。 Istio 简单的规则配置和流量路由允许您控制服务之间的流量和 API 调用过程。 Istio 简化了服务级属性（如熔断器、超时和重试）的配置，并且让它轻而易举的执行重要的任务（如 A/B 测试、金丝雀发布和按流量百分比划分的分阶段发布）。 例如，在 Istio 中，有两个非常重要的概念，VirtualService 和 DestinationRule。 通过合理的 VirtualService 和 DestinationRule 的配置，可以实现根据指定 uri, 指定的 headers 信息等等来配置对应的下游地址。 可以参考如下示例: Istio 请求路由 Service 、 VirtualService 、 DestinationRule 关系介绍 Service 是 K8s 中的核心概念之一，它是 K8s 中默认的服务发现机制。 具体来说，K8s 中的 Service 对应于一组指定标签的 Pod 实例，发向该 Service 的请求会被自动转发到对应的 Pod 实例上。 虽然，K8s 中的 Service 已经具备了基本的服务发现的能力，但实际上这种基本的服务发现能力远远无法满足业务对流量治理相关能力， 例如，特定的路由策略、网络重试等功能。 因此，Istio 的出现就是为了进一步提升流量治理的能力，而在 Istio 中，最核心的两个概念就是 VirtualService 和 DestinationRule 了。 其中: VirtualService 的目的是定义一组要在访问 host 时应用的流量路由规则，每个路由规则定义了特定协议流量的匹配规则。如果流量的匹配规则满足的话，则将其发送到配置中定义的目标服务（或其子集/版本）中，此外，还包括了HTTP超时控制、重试、镜像、修改headers等。 DestinationRule 的目的定义在路由发生后应用于服务流量的策略。 这些规则指定负载均衡的配置、来自 sidecar 的连接池大小和异常检测设置，以检测和从负载均衡池中驱逐不健康的实例。 VirtualService 故名思义就是虚拟服务，VirtualService 中定义了一系列针对指定服务的流量路由规则。 每个路由规则都是针对特定协议的匹配规则。 如果流量符合这些特征，就会根据规则发送到服务注册表中的目标服务（或者目标服务的子集或版本）。 DestinationRule 是基于已有的 K8s Service 进行 Pod 下的细粒度的分组。 例如，可以将一个 Service 下的 Pod 根据 label 等信息再次分为多个 subset，从而可以在 VirtualService 对流量进行 subset 级别的细粒度分发。 也就是说：VirtualService 和 DestinationRule 都是基于已有的 K8s Service 的条件下进行的功能扩展，必须保证 K8s Service 已经存在。 而在消息具体发送的过程中，envoy 会默认劫持流量并发送给对应的 Pod 实例，而非依赖 kube-proxy 进行请求下发。 示例的 DestinationRule 配置文件如下： apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: flaskapp spec: host: flaskapp.books.svc.cluster.local subsets: - name: subset-v1 labels: version: v1 - name: subset-v2 labels: version: v2 它可以将 books namespace 下的 flaskapp 的 service 下关联的 Pod 进行细粒度的分组， 其中 subset-v1 中包含所有 labels 中 version 为 v1 的 Pod，subset-v2 中包含所有 labels 中 version 为 v2 的 Pod。 VirtualService 的配置文件如下： apiVersion: networking.istio.io/v1beta1 kind: VirtualService metadata: name: flaskapp-policy spec: hosts: - flaskapp.books.svc.cluster.local http: - route: - destination: host: flaskapp.books.svc.cluster.local subset: subset-v2 match: - headers: end-user: exact: jason - route: - destination: host: flaskapp.books.svc.cluster.local subset: subset-v1 我们来看一下这个 VirtualService 的配置做了什么事情： 它扩展了 books namespace 下原有 K8s Service flaskapp 的路由策略，当请求的 headers 中包括 end-user 且值为 jason 的话， 则将对应请求发送给 subset-v2 分组的 Pod 实例，否则的话，则将对应请求发送给 subset-v1 分组的 Pod 实例。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kt-env/basic.html":{"url":"cloud-native/kt-env/basic.html","title":"KT-env目标及功能","keywords":"","body":"KT-env目标及功能 对于微服务的开发者而言，拥有一套干净、独占的完整测试环境无疑能够提高软件研发过程中的功能调试和异常排查效率。 然而在中大型团队里，为每位开发者维护一整套专用测试服务集群，从经济成本和管理成本上考虑都并不现实。为此阿里巴巴的研发团队采用了基于路由隔离的\"虚拟环境\"方法。 “虚拟环境”的本质是基于服务实例（即Kubernetes的Pod实例）上的“环境标”（在Kubernetes表现为Label）属性，结合约定的路由复用规则，形成一个个开发者视角的专属测试环境。这些虚拟的专属环境从集群管理者的视角来看，称为“隔离域”，它具有如下特点： “隔离域”是由路由规则形成的虚拟边界 每个“环境标”都会形成一个独立的“隔离域” “隔离域”之间可以存在部分或完全重合 “隔离域”的成员会随集群中服务实例所带“环境标”动态变化 路由规则 虚拟环境的路由规则很简单：如果请求是来自一个带有环境标的服务实例， 它会优先寻找跟它具有相同环境标的实例，如果没有，则会寻找它上一级的环境标，直至到达顶级的默认服务实例。 假设A、B、C、D四个微服务组成了一个完整的测试环境。 此时若为集群中的服务实例全部赋予环境标dev，就形成了一个隔离域，如下图蓝色部分所示。结合虚拟环境的实践，我们称这个隔离域为“公共基础环境”（也称默认环境）。 当进行特定项目开发的时候，开发者不需要重新部署整套微服务系统，而是单独部署需要修改的部分服务（如服务C和服务D），为它们赋予一个子级环境标，比如dev.proj，然后加入到测试环境中。 根据路由规则，当请求来自带有dev.proj环境标的实例C，需要调用服务B，但是发现没有带环境标dev.proj的服务B实例，于是会寻找带有上一级环境标dev的服务B实例。同理当链路到达服务C时，会由dev环境标的实例响应，而由于服务D存在dev.proj环境标的实例，所以这部分实例会接管到达服务D的请求。 因此dev.proj环境标所形成的隔离域边界下图红色区域所示，这便是dev.proj虚拟环境的服务实例集合。 不难看出，dev.proj虚拟环境复用了部分公共基础环境的资源（服务A和服务B）。这样做的好处是，第一不会占用大量的计算资源；第二，不会影响公共基础环境的稳定性。 开发者还可以将本地开发机加入虚拟环境。比如小明在本地启动了一个服务C的实例，他给这个服务实例打上环境标dev.proj.local，基于前面介绍的路由规则，带环境标的服务发出的请求会优先寻找带相同环境标的服务实例，如果找不到则会逐级寻找带有上一级环境标的实例。于是环境标为dev.proj.local的服务C、环境标为dev.proj服务D和公共基础环境dev中的服务A、服务B就组成了一个新的的虚拟环境，如下图红色部分所示。 这时小明的同事在本地启动了一个服务A，如果他没有对这个服务打环境标，则他的所有调用请求会默认使用“公共基础环境”进行测试。因此小明在自己的虚拟环境中的任何调试都不会影响到他的同事，反之亦然。如下图所示。 若小明的同事加入了小明所在的项目，他们之间需要进行“联调”。这时，他只需将本地的服务打上一个和小明相同的环境标即可，如下图红色部分所示。 总结而言，虚拟环境是通过在服务实例（以及从这些实例发出的请求）上携带约定标签，将个别需要调试或测试的特定版本服务实例与其他公共服务实例组成临时虚拟集群的一种环境管理实践。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kt-env/deploy.html":{"url":"cloud-native/kt-env/deploy.html","title":"KT-env部署","keywords":"","body":"KT-env部署 前置条件 KT-env 部署之前，首先需要有一个 Kubernetes 集群并且已经部署了 Istio 。 同时，本地还需要一个配置好的 kubectl 工具。 下载部署包 首先，我们需要从 发布页面 下载最新的部署文件包，并解压。 wget https://github.com/alibaba/virtual-environment/releases/download/v0.5.4/kt-virtual-environment-v0.5.4.zip unzip kt-virtual-environment-v0.5.4.zip cd v0.5.4/ 安装相关组件 创建 CRD 在 KT-env 中，定义了一种新的资源对象: VirtualEnvironment 。 下面，我们第一步就来创建对应的 CRD 资源对象： kubectl apply -f global/ktenv_crd.yaml CRD组件会在Kubernetes集群内新增一种名为VirtualEnvironment的资源类型，在下一步我们将会用到它。可通过以下命令验证其安装状态： kubectl get crd virtualenvironments.env.alibaba.com 若输出类似以下信息，则表明KtEnv的CRD组件已经正确部署： NAME CREATED AT virtualenvironments.env.alibaba.com 2020-04-21T13:20:35Z 部署 Webhook 组件 Webhook组件用于将Pod的虚拟环境标写入到其Sidecar容器的运行时环境变量内。 kubectl apply -f global/ktenv_webhook.yaml Webhook组件默认被部署到名为kt-virtual-environment的Namespace中，包含一个Service和一个Deployment对象，以及它们创建的子资源对象，可用以下命令查看： kubectl -n kt-virtual-environment get all 若输出类似以下信息，则表明KtEnv的Webhook组件已经部署且正常运行: NAME READY STATUS RESTARTS AGE pod/webhook-server-5dd55c79b5-rf6dl 1/1 Running 0 86s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/webhook-server ClusterIP 172.21.0.254 443/TCP 109s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/webhook-server 1/1 1 1 109s NAME DESIRED CURRENT READY AGE replicaset.apps/webhook-server-5dd55c79b5 1 1 1 86s 创建 Role 和 ServiceAccount 如果 K8s 集群中，已经开启了 RBAC 权限控制，那么，为了保证我们的 Operator 可以正常工作，还需要部署相应的Role和ServiceAccount。 kubectl apply -n default -f ktenv_service_account.yaml 部署 KT-env Operator Operator是由CRD组件定义的虚拟环境管理器实例，需要在每个使用虚拟环境的Namespace里单独部署。 以使用default Namespace为例，通过以下命令完成部署: kubectl apply -n default -f ktenv_operator.yaml 此外，为了让Webhook组件对目标Namespace起作用，还应该为其添加值为enabled的environment-tag-injection标签。 kubectl label namespace default environment-tag-injection=enabled 现在，Kubernetes集群就已经具备使用虚拟环境能力了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kt-env/action.html":{"url":"cloud-native/kt-env/action.html","title":"KT-env实战","keywords":"","body":"KT-env实战 在之前的内容中，我们已经完成了 KT-env 的环境搭建。 同时，也了解了请求路由的基本原理。 下面，我们就来具体使用 KT-env 来实现对应的虚拟环境。 QuickStart 如果是一个新的 namespace，需要在新的 namespace 下部署 operator 和 role 相关信息，参考 deploy 。 Step1: 创建虚拟环境。 创建一个virtual-environment-cr.yaml 文件： apiVersion: env.alibaba.com/v1alpha2 kind: VirtualEnvironment metadata: name: demo-virtualenv spec: envHeader: name: ali-env-mark autoInject: true envLabel: name: virtual-env splitter: \".\" defaultSubset: dev 实例创建后，会自动监听所在Namespace中的所有Service、Deployment和StatefulSet对象并自动生成路由隔离规则，形成虚拟环境。 kubectl apply -n default -f virtual-environment-cr.yaml Step2: 拉取Git仓库，进入示例代码目录。 git clone https://github.com/alibaba/virtual-environment.git cd virtual-environment/examples Step3: 设置 default namespace 自动注入 sidecar 并使得 webhook 能够为 Envoy 自动注入环境变量。 kubectl label namespace default environment-tag-injection=enabled kubectl label namespace default istio-injection=enabled Step4: 在集群随意创建一个临时的Pod作为发送测试请求的客户端。 kubectl create deployment sleep --image=virtualenvironment/sleep --dry-run -o yaml | kubectl apply -n default -f - Step5: 部署相关应用 KtEnv支持Deployment和StatefulSet对象的路由隔离， 在这个例子中将部署3种不同语言实现的示例应用， 其中app-js和app-java被部署为Deployment，而app-go被部署为StatefulSet。 修改 app.sh 脚本中 apply_pods 函数如下： apply_pods() { type=${1} ee=`echo ${e} | sed -e \"s/\\./-/g\"` echo $s cat ${basepath}/${type}.yaml | sed -e \"s/service-name-env-placeholder/${s}-${ee}/g\" \\ -e \"s/service-name-placeholder/${s}/g\" \\ -e \"s/app-env-placeholder/${e}/g\" \\ -e \"s/app-image-placeholder/`hget images ${s}`/g\" \\ -e \"s#app-url-placeholder#`hget urls ${s}`#g\" \\ | kubectl ${action} --validate=false -n ${namespace} -f - } 使用app.sh脚本快速创建示例所需的VirtualEnvironment、Deployment、StatefulSet和Service资源： # default namespace 下启动演示的服务实例 deploy/app.sh apply default 依次使用kubectl get virtualenvironment、kubectl get deployment、kubectl get statefulset、kubectl get service 命令查看各资源的创建情况，等待所有资源部署完成。 Step6: 进入同Namespace的任意一个Pod，例如前面步骤创建的sleep容器。 # 进入集群中的容器 kubectl exec -n default -it $(kubectl get -n default pod -l app=sleep -o jsonpath='{.items[0].metadata.name}') -- /bin/sh Step7: 实验一下 分别在请求头加上不同的虚拟环境名称，使用curl工具调用app-js服务。 3个服务的关系是: app-js -> app-go -> app-java 。 注意该示例创建的VirtualEnvironment实例配置使用.作为环境层级分隔符，同时配置了传递标签Header的键名为ali-env-mark。 已知各服务输出文本结构为[项目名 @ 响应的Pod所属虚拟环境] 观察实际响应的服务实例情况: # 使用dev.proj1标签 > curl -H 'ali-env-mark: dev.proj1' app-js:8080/demo [springboot @ dev.proj1] curl -H 'ali-env-mark: dev.proj1.feature1' app-js:8080/demo [springboot @ dev.proj1.feature1] curl -H 'ali-env-mark: dev.proj2' app-js:8080/demo [springboot @ dev] curl app-js:8080/demo [springboot @ dev] VirtualEnvironment 配置文件解读 虚拟环境实例通过VirtualEnvironment类型的Kubernetes资源定义。其内容结构示例如下： apiVersion: env.alibaba.com/v1alpha2 kind: VirtualEnvironment metadata: name: demo-virtualenv spec: envHeader: name: ali-env-mark autoInject: true envLabel: name: virtual-env splitter: \".\" defaultSubset: dev 参数作用如下表所示： 配置参数 默认值 说明 envHeader.name X-Virtual-Env 用于透传虚拟环境名的HTTP头名称（虽然有默认值，建议显性设置） envHeader.autoInject false 是否为没有虚拟环境HTTP头记录的请求自动注入HTTP头（建议开启） envLabel.name virtual-env Pod上标记虚拟环境名用的标签名称（除非确实必要，建议保留默认值） envLabel.splitter . 虚拟环境名中用于划分环境默认路由层级的字符（只能是单个字符） envLabel.defaultSubset 无 请求未匹配到任何存在的虚拟环境时，进行兜底虚拟环境名（默认为随机路由） 注意：VirtualEnvironment实例只对其所在的Namespace有效。如有需要，可以通过在多个Namespace分别创建相同配置的实例。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/kt-env/source_code.html":{"url":"cloud-native/kt-env/source_code.html","title":"KT-env源码解读","keywords":"","body":"KT-env源码解读 了解了 KT-env 的基本功能、原理和使用之后，我们最后再来了解一下 KT-env 相关的源码实现。 KT-env 的源码仓库地址: virtual-environment 其中，我们先来了解一下它们的目录结构和功能： cmd: 二进制程序的入口文件 - 核心目录。 pkg: 相关功能模块的封装模块 - 核心目录。 version: 版本信息。 build: 编译脚本。 deploy: 部署脚本。 docs: 文档。 examples: 示例相关代码。 sdk: 透传 headers 相关的SDK。 其中，核心的源码目录是 cmd 和 pkg 两个目录。 查看 cmd 目录下的内容，可以很容易的看出，它一共涉及到三个二进制可执行程序，分别是 operator，inspector 和 webhook。 其中，inspector 的功能非常简单，就是一个 HTTP 客户端，可以调用 operator 的接口查询 operator 模块的版本信息、状态以及修改日志级别，不再赘述。 我们重点来分析 operator 和 webhook 两个程序的功能。 operator webhook 在 KT-env 中包含了一个全局的Mutating Admission Webhook组件， 它的主要作用是将Pod上的环境标信息通过环境变量注入到Sidecar容器里，便于Sidecar为出口流量的Header添加恰当的环境标。 那么什么是 Mutating Admission Webhook 呢？这是 K8s 中的一个特有的概念，我们先来了解一下。 Admission webhook 是一种用于接收准入请求并对其进行处理的 HTTP 回调机制。 K8s 中可以定义两种类型的 admission webhook，即 validating admission webhook 和 mutating admission webhook。 其中，Mutating admission webhook 会先被调用。 它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作。 K8s的具体的处理流程如下图所示： 而 Kt-env 中的 Webhook 其实就是这么一个组件，它主要用于将Pod上的环境标信息通过环境变量注入到Sidecar容器里， 即在 Webhook 阶段，修改了 Sidecar 的配置，向其中设置了对应的环境变量。 了解了 webhook 的原理之后，我们就来看一下 KT-env 中的 webhook 是如何实现的吧。 首先，我们先来简单看一下 Webhook 对应的 yaml 配置文件： apiVersion: admissionregistration.k8s.io/v1beta1 kind: MutatingWebhookConfiguration metadata: name: virtual-environment-webhook webhooks: - name: webhook-server.kt-virtual-environment.svc failurePolicy: Fail clientConfig: service: name: webhook-server namespace: kt-virtual-environment path: \"/inject\" caBundle: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURYVENDQWtXZ0F3SUJBZ0lVZG42TEl2bDNaV2ltbndEVGwxS3U3ODhKcDBrd0RRWUpLb1pJaHZjTkFRRUwKQlFBd1BqRThNRG9HQTFVRUF3d3pWbWx5ZEhWaGJDQkZiblpwY205dWJXVnVkQ0JCWkcxcGMzTnBiMjRnUTI5dQpkSEp2Ykd4bGNpQlhaV0pvYjI5cklFTkJNQjRYRFRJd01EZ3lOVEUxTURrMU5Wb1hEVE13TURneU16RTFNRGsxCk5Wb3dQakU4TURvR0ExVUVBd3d6Vm1seWRIVmhiQ0JGYm5acGNtOXViV1Z1ZENCQlpHMXBjM05wYjI0Z1EyOXUKZEhKdmJHeGxjaUJYWldKb2IyOXJJRU5CTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQ0FROEFNSUlCQ2dLQwpBUUVBeDYrQkZIaXlkZk9uR3FMRmt4Y2lpL21ZMG9XU3dRV2krTHYwdmNqeklQTndKa2c0V0FJYTRWK0RqdTV2CmZ5NlE2RFhUaitlRnhlK212MmtVSEFtYjNsWS9iT3RaWGp2VnQ4bnBHS1VLdlBBN0hVRFdhUkZKOTR1eUJpQm8KQnlXTnZtTGNka0VFTjRVMVVGTlVIV3B1L1lHNXNaSC9ZQWZjZGEyMDhIUzVkQmllNTNYMmJjdjQrNGhzS3oyOAp0UUR2MmR3ZkxFT2crZ2lVUWRWRHUrN0lXUXpjRkp4NmdpdlBpVkl1UVRHVk04K0tya2dITlhXVjU4OGIwcTU1CnNPNjR2YWQ4cW5XT0t5bk5oSThyZzN0dGVJVkFHdkEvUnJGczFocytERHVBZlMxamhiRWUyUEJHSHVMeGx6TGIKNjR2NUV5VEhEdDVVOS93bFpxS0hMWlZQeFFJREFRQUJvMU13VVRBZEJnTlZIUTRFRmdRVVg1cEI4dkYzbnducQpUUjA1TlVhVlhaQzd4VjB3SHdZRFZSMGpCQmd3Rm9BVVg1cEI4dkYzbnducVRSMDVOVWFWWFpDN3hWMHdEd1lEClZSMFRBUUgvQkFVd0F3RUIvekFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBbFU0YkxNMGlzbm5KaDA1dCs3TDkKWkFtS2M1eXhGdkUremlsK2Y5aEUzdzJpYjI0bVNYTVpOSWEvUWd6akxGK0owQVlIbUxXZTRQa2I4eXliQnVjRQp6d2VRNEc5Y3U2QWV5VFRHTk9zbU5lREx4WGRVOUJ1aElvRmZsR2ZDV1pudHA5ajZsbnFJbndqdjZJWDBEQmc1CkFEbXRNdVVrS0gyMXdUTHhXNVBWSmhQWnZiL3p1ZGNlNUxWRG1zT0Z5cjFkK2lnVnZPVzJJam51QUw3eGpXWFQKenVGYng5NnZBYTJjS0hWRjYyVzdoekp6NURiN0cwdWxJMXptOTF0ZXJaZjRYSHlUT3FzUC8wczFsYjV1V1k5cAo2NUZiZCtHMXJOL2NBcUM4NXo0K1Rrc2QrdTV1ZDFVREc5MEsvRG9UdS9vcis3U3o2bWNWdjVBejlLSHVxRzE2CnlBPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= rules: - operations: [\"CREATE\"] apiGroups: [\"\"] apiVersions: [\"v1\"] resources: [\"pods\"] namespaceSelector: matchLabels: environment-tag-injection: enabled 上述配置文件表示针对: 设置了 environment-tag-injection: enabled 的 namespace 下 Pod 资源对象在创建时 会触发 Mutating Admission Webhook 调用 调用的请求地址是 webhook-server.kt-virtual-environment.svc/inject 而具体的注入环境变量的逻辑则在 webhook-server 模块内， 其核心代码见 main.go 。 我们选择其中部分的核心代码进行说明： envLabels := os.Getenv(\"envLabel\") if envLabels == \"\" { logger.Fatal(\"Cannot determine env label !!\") } envLabelList := strings.Split(envLabels, \",\") envTag := \"\" for _, label := range envLabelList { if value, ok := pod.Labels[label]; ok { envTag = value break } } 从环境变量中读取 envLabel 的配置，并判断 Pod 上是否存在其中的某个 label，如果存在，则表示使用该 label 对应的 value 用于 headers 追加。 var patches []PatchOperation if envVarIndex 表示根据之前的计算规则，生成 patch 操作，用于向 Pod 中追加/修改对应的环境变量， 其中，key 为 VIRTUAL_ENVIRONMENT_TAG，取值为之前步骤中从 Pod 上获取到的 label 对应的值。 通过上述步骤，就完成了将业务 Pod 上中指定的 Label 对应的值设置到 Sidecar 容器中的环境变量中了。 那么，Sidecar 中的环境变量是如何追加到发送请求的 header 中的呢？ 这个其实是用到了 Istio 中的功能 EnvoyFilter。 如上文所示，在 operator 模块中，会创建 EnvoyFilter，在 EnvoyFilter 中，通过 lua 脚本，在出流量的阶段中，追加了 headers 信息。 示例 EnvoyFilter 配置如下: kind: EnvoyFilter apiVersion: networking.istio.io/v1alpha3 metadata: name: demo-virtualenv namespace: kt-env1 labels: envHeader: ali-env-mark envLabel: virtual-env spec: workloadSelector: ~ configPatches: - applyTo: HTTP_FILTER match: context: SIDECAR_OUTBOUND listener: filterChain: filter: name: envoy.http_connection_manager patch: operation: INSERT_BEFORE value: name: virtual.environment.lua typed_config: '@type': type.googleapis.com/envoy.config.filter.http.lua.v2.Lua inline_code: |- local curEnv = os.getenv(\"VIRTUAL_ENVIRONMENT_TAG\") function envoy_on_request(req) local env = req:headers():get(\"ali-env-mark\") if env == nil and curEnv ~= nil then req:headers():add(\"ali-env-mark\", curEnv) end end 其中，我们可以重点关注最下方的 lua 脚本，可以看出其基本的逻辑如下： 判断请求头部中是否包含 ali-env-mark，如果没有包含， 则从环境变量中取出 VIRTUAL_ENVIRONMENT_TAG 的值并设置为 ali-env-mark headers 的值。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/tracing/beginning.html":{"url":"cloud-native/tracing/beginning.html","title":"全链路追踪实战","keywords":"","body":"全链路追踪实战 在云原生的场景下，整个请求的链路会不变的变长。 例如，当一个请求发送后，后端可能会有数十个模块相互访问请求转发后才能得到最终的响应结果。 而随着链路的不断增加，问题定位的成本也不断增加，例如，对于一个请求异常的场景而言，我们可能需要从数十个模块中定位问题的发生点； 同时，对于一个耗时很长的请求而言，我们也需要从数十个模块中依次定位才可能找到性能的瓶颈。 为了能够保持随着链路的不断增长，问题定位和分析的成本保持可控，我们需要对整个访问链路进行追踪。 常用的分布式追踪方案包括 Zipkin, Jaegar, OpenTracing 等方案，它们可以记录整个链路请求的耗时，可以在链路之间透传 headers 等信息。 而在我们之前讲到的 KT-env 环境复用能力之中，一个前提的条件就是各个模块之间可以透传指定的 headers 。 除了强大的整体分布式追踪方案 Zipkin, Jaegar, OpenTracing 之外，如果仅仅是想要实现 headers 透传方案的话，可以有一些更加轻量化的方案。 在本系列的文章中，我们除了会介绍 Zipkin, Jaegar, OpenTracing 等方案外，也会介绍一些常用框架的简单的 headers 透传方案。 参考资料 分布式上下文实战 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/tracing/flask.html":{"url":"cloud-native/tracing/flask.html","title":"基于Python Flask框架的http headers透传","keywords":"","body":"基于Python Flask框架的http headers透传 在本文中，我们将会介绍在 Flask HTTP 框架中，如何能够简单快速的实现 headers 的透传方案。 原理分析 对于任何一个微服务而言，想要实现 headers 的透传的话，也是主要分三步： 接收 HTTP 请求时，从请求中读取中 headers 信息。 将 headers 在程序内部进行保存和传播。 发送 HTTP 请求时，将内部传播的 headers 在客户端请求加入并发送出去。 此外，为了避免在各个请求接收和请求发送中，都需要进行相关的改动，我们在程序实现中应该按照 AOP 的思想，一次改动全场生效。 请求读取 首先，在 flask 框架中，可以通过如下方式获取请求的 headers 信息： from flask import request request_headers = request.headers 请求内部传播 在 Flask 框架中，HTTP Server 都是一个 Request 只由一个线程处理。 所以，我们可以将 HTTP 请求 headers 信息存储在一个 Thread Local 中，然后在该线程中，需要使用时可以从中提取。 幸运的是，flask 框架中的 request.headers 本身已经帮助我们完成了对应的工作。 因此，我们不再需要自己重复在内部进行传播了，而是可以在使用时直接在 request.headers 中使用了。 请求发送 对于 Python 而言，对外的 HTTP 请求发送主要是通过 requests 库来实现的。 因此，我们可以直接从全局来修改 requests 库的逻辑，优先从 request.headers 中读取 headers 信息，然后追加至请求的 header 中。 实战 具体代码可以参考如下 repo 。 具体来说，使用起来也非常简单，只需要引入一个 instrument 函数，并调用该函数即可实现 AOP 的注入。 from request_wrapper import instrument instrument() 此外，另外一种相关的实现也可以参考 Flask+requests headers 透传 。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"cloud-native/tracing/gin.html":{"url":"cloud-native/tracing/gin.html","title":"基于Go gin框架的http headers透传","keywords":"","body":"基于Go gin框架的http headers透传 在本文中，我们将会介绍在 Gin HTTP 框架中，如何能够简单快速的实现 headers 的透传方案。 原理分析 对于任何一个微服务而言，想要实现 headers 的透传的话，也是主要分三步： 接收 HTTP 请求时，从请求中读取中 headers 信息。 将 headers 在程序内部进行保存和传播。 发送 HTTP 请求时，将内部传播的 headers 在客户端请求加入并发送出去。 此外，为了避免在各个请求接收和请求发送中，都需要进行相关的改动，我们在程序实现中应该按照 AOP 的思想，一次改动全场生效。 请求读取 首先，在 Gin 框架中，支持通过 middleware 的中间件方式在接收 http 请求处理的前后增加自定义逻辑。 因此，我们可以通过自定义 middleware 来读取请求头，并自身维护一个 Context 上下游对象，其中记录着对应的请求头信息。 func Middleware() gin.HandlerFunc { return handler } func handler(c *gin.Context) { headersWithFirst := make(map[string]string, len(c.Request.Header)) for k, v := range c.Request.Header { if len(v) > 0 { headersWithFirst[k] = v[0] } } carrier := cp.Extract(headersWithFirst) if len(carrier) > 0 { c.Request = c.Request.WithContext(context.WithValue(c.Request.Context(), cp.InternalContextKey{}, carrier)) } c.Next() } 请求内部传播 由于在读取请求 header 中，我们对原有的 Context 进行了扩展，将 headers 信息记录到了 c.Request.Context() 中。 因此，在仅接着的的 Context 上下文传递中，需要使用 c.Request.Context() 来代替 c 进行上下文传递即可。 例如： func TestApi(c *gin.Context) { SelfFunction1(c.Request.Context()) } 请求发送 在 Go 语言发送 http 请求时，默认基于的是 net/http 库，但是 net/http 库本身在发送请求时，无法基于 Context 上下文进行行为定制。 而我们其实是希望在 http 客户端发送请求时，可以从 context 上下文中获取对应的请求头信息并增加到 header 中传递出去。 因此，我们需要使用一个官方提供的http库 golang.org/x/net/context/ctxhttp 来代替原有lib库发送HTTP请求。 示例如下： resp, err := ctxhttp.Get(c.Request.Context(), client, \"http://127.0.0.1:8080/test\") 其中，ctxhttp 与 http 的功能基本相同，唯一的差别在于需要主动传递 context 上下文和实例化的 client 对象。 至此为止，我们其实只是传递了对应的上下文到ctxhttp中，但实际上还并没有实现http 客户端发送请求时， 可以从 context 上下文中获取对应的请求头信息并增加到 header 中传递出去。 因此，下面我们需要对 http.Client 对象进行一次扩展，实现可以自动从 context 上下文中获取对应的请求头信息并增加到 header 中传递出去。 示例代码如下： func WrapClient(c *http.Client) *http.Client { if c == nil { c = http.DefaultClient } copied := *c copied.Transport = WrapRoundTripper(copied.Transport) return &copied } func WrapRoundTripper(r http.RoundTripper) http.RoundTripper { if r == nil { r = http.DefaultTransport } return &roundTripper{rt: r} } type roundTripper struct { rt http.RoundTripper } func (s *roundTripper) RoundTrip(r *http.Request) (*http.Response, error) { carrier := r.Context().Value(cp.InternalContextKey{}) headers := cp.Inject(carrier) for k, v := range headers { r.Header.Set(k, v) } return s.rt.RoundTrip(r) } 在上述代码中，我们定义了一个 WrapClient 函数，它可以对已有的 http.Client 进行扩展， 具体来说，可以从上下文中获取对应的 headers 信息，然后注入到请求发送的 header 体中。 具体到使用中，其实非常简单，只需要对 http.Client 进行一次 Wrap 即可： package main import cphttp \"github.com/AminoApps/context-propagation-go/module/context-propagation-http\" import \"golang.org/x/net/context/ctxhttp\" client := cphttp.WrapClient(&http.Client{}) // Please use the ctxhttp to wrap the request. resp, err := ctxhttp.Get(ctx, client, \"http://127.0.0.1:8080/test\") 实战 最后，我们以一个实战的示例来演示对于一个 gin 框架的项目而言，是如何实现 headers 透传的： package main import ( cp \"github.com/AminoApps/context-propagation-go\" cpgin \"github.com/AminoApps/context-propagation-go/module/context-propagation-gin\" cphttp \"github.com/AminoApps/context-propagation-go/module/context-propagation-http\" \"github.com/gin-gonic/gin\" \"golang.org/x/net/context/ctxhttp\" \"net/http\" ) func main() { r := gin.New() r.Use(cpgin.Middleware()) r.GET(\"/JSON\", func(c *gin.Context) { value := cp.GetValueFromContext(c.Request.Context(), \"easyenv\") println(\"token: \", value) client := cphttp.WrapClient(&http.Client{}) resp, err := ctxhttp.Get(c.Request.Context(), client, \"http://127.0.0.1:8080/test\") println(\"resp: \", resp, err) c.JSON(http.StatusOK, resp) }) // Listen and serve on 0.0.0.0:8080 r.Run(\":8080\") } 相关的实现也可以参考 在 Go 的 Gin WEB 框架中如何实现 headers 透传 。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:32 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"tools/pycharm/remote_debug.html":{"url":"tools/pycharm/remote_debug.html","title":"PyCharm远程调试","keywords":"","body":"PyCharm开启远程调试 在本文中，我们将会讲解如何使用PyCharm进行远程调试。 主要包含两个方面： 远程文件同步。 远程调试。 远程文件同步 要远程调试代码，那么就先要将代码上传到服务器上，那么上传的方式就有很多了，例如scp等方式。 同时，PyCharm自身提供了一种远程文件同步的方案，本节主要讲解如何使用PyCharm进行远程文件同步。 具体来说，我们在 Tool--->Deployment 进行配置： 此时，从图中可以看出，Upload相关的选项是灰色，这是因为你没有配置。 下面，我们选择Configuration，对PyCharm提供的SFTP进行简单的配置： 点击左上角的加号，创建一个配置，将SFTP要链接的服务器路径、服务器用户名和密码都填上， 最下面的Web server root URL 字段PyCharm会自动帮我们填写，简单的配置后，可以点击 Test SFTP connection... 按钮，判断SFTP是否可以成功链接服务器，如果返回Success，则表示服务器链接成功。 接着还要配置一下本地代码上传到服务的路径，配置好这个，代码才会上传到相应的路径: 配置完后，我们就可以进行上传了。 其中，我们可以勾选Automatic Upload实现文件变更自动同步。 远程调试 光上传代码是不能进行调试，因为我们在PyCharm中运行项目使用的依旧是本地的Python解释器，依旧是在本地运行，那么此时对代码进行Debug跟线上的代码没有关系，线上的代码也没有启动。 如果要远程Debug，要完成两个配置： 配置PyCharm的Python解释器，使用服务器上的Python解释器。 配置PyCharm的Debug功能，让PyCharm运行服务器上的代码。 这里先做第一步，进入PyCharm的配置界面，选择Prjoect XXX---> Project Interpreter，配置Python解释器，点击⚙，如下图: 然后选Add Remote，接着选中SSH Credentials，将远程服务器的地址、服务器的用户名和密码填上，然后在服务器中选择Python解释的路径，也就是 Python interpreter path： 选中完后，点击OK，PyCharm就好将远程服务器上相应Python解释器的相关文件都同步下来。 你需要等待一下，然后就会出现下面界面，观察Project Interpreter，它已经是远程服务器的Python环境了。 这样第一步就完成了，接着来配置PyCharm中的Debug，如果不配置，那么Debug依旧会使用本地的Python解释器。 打开PyCharm Debug的配置界面（Run-->Debug-->Edit Configuration...），然后配置一下当前项目下的Python interpreter，确保Debug使用远程服务器的Python解释器来运行代码。 这里有点要注意，Debug配置界面中，Host要配置为0.0.0.0，否则会出现报错。 所有都配置完后，就可以进行Debug了，此时使用的就是远程的Python解释器，Debug的也是远程的Python代码，注意观察Debug的第一行，可以发送其通过SSH连接远程服务器。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"tools/Wireshark/beginning.html":{"url":"tools/Wireshark/beginning.html","title":"Wireshark","keywords":"","body":"Wireshark Wireshark简史 Wireshark的历史相当久远，其最初的版本叫做Ethereal，在1998年以GPL开源许可证发布。 后来，该项目改名为Wireshark，随后迅速取得了大众的青睐。 Wireshark优点 协议支持 Wireshark在协议支持方面是出类拔萃的，目前已经支持超过1000种协议。 这些协议从最基础的IP协议和DHCP协议到高级的专用协议，比如DNP3和BitTorrent等。 由于Wireshark是开源的，所以有大量的贡献者会贡献对新协议的支持。 用户友好度 Wireshark界面是一个用户友好的界面，它基于GUI，并提供了清晰的菜单栏和简明的布局。 为了增强实用性，它还提供了类似与不同协议的彩色高亮以及通过图形显示原始数据细节等不同功能。 相比tcpdump而言，Wireshark界面对于初学者而言还是非常友好的。 价格 Wireshark本身的开源的，因此任何人都可以免费下载。 软件支持 一个软件的好坏与后期的支持息息相关。 通常而言，一个开源软件很少有官方的支持，它只能依赖于开源社区的用户群提供帮助。 但幸运的是，Wireshark的开源社区非常活跃，包括在线文档、开发wiki、FAQ等一系列资源。 源码访问 Wireshark是一个开源软件，我们所以可以访问其源码，这对工具理解，问题定位等都有很大的帮助。 兼容性 Wireshark对主流的操作系统都提供了支持，包括Windows、Mac OS X以及Linux系统等。 Wireshark下载 Wireshark的下载非常简单，可以直接从Wireshark官方下载对应的安装包直接进行安装即可。 附录： Wireshark官方使用手册 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"tools/Wireshark/tutorial.html":{"url":"tools/Wireshark/tutorial.html","title":"Wireshark快速入门","keywords":"","body":"Wireshark快速入门 当你成功安装了Wireshark之后，我们就可以开始使用它了。 但是当你首次打开这个软件时，你确发现你看不到任何的数据包，下面我们来一步步进行相关知识的学习吧。 捕获第一个数据包 下面，我们来捕获一些数据包！ 第一步：打开Wireshark 第二步：从Capture的设备列表中找出一的网卡设备，然后双击进入，如下图所示。 第三步：等1min左右，当你打算停止捕获并查看你的数据时，操作拦中单击Stop按钮即可。 当你完成上述步骤后，Wireshark的主窗口中应该已经呈现了相应的数据，但是这些数据可能会非常难以理解，下面我们来依次对数据进行讲解。 Wireshark主窗口 下面，我们来详细学习一下Wireshark的主窗口，如下图所示： 在主窗口中，包含着三部分面板，从上到下依次是： 工具栏 显示过滤器 Packet List Packet Detail Packet Bytes 如果我们希望在Packet Detail面板中查看一个单独的数据包具体内容，那么首先需要在Packet List单击选择对应的数据包。 在选中了数据包之后，你可以在Packet Details面板中选中数据包的某个字段，从而可以在Packet Bytes面板中查看相应的字节信息。 PS：在Packet List中，针对每个包请求都列出了对应的协议，但是并没有使用不同的层次来对不同的协议进行视觉上的区分， 所有的数据包都是按照其在链路上的接收顺序排列的。 下面，我们依次来详细介绍每个面板的内容。 工具栏 Packet List（数据包列表） Packet List中显示了当前捕获文件中所有的数据包，其中包括了 数据包序号、数据包被捕获时的相对时间、数据包的源地址和目标地址、数据包的洗协议以及数据包的概况信息等。 Packet Detail（数据包细节） Packet Detail详细显示了一个数据包的内容，并且可以通过展开或者收缩来显示这个包捕获的全部内容。 Packet Bytes（数据包字节） Packet Bytes的内容可能是让人最难以理解的，因为它显示的是一个数据包未经过处理的原始数据格式，也就是在链接上传播时的内容。 数据包列表面板的标记符号 Wireshark偏好设置 Wireshark提供了一些配置项可以让你根据个人需要进行定制。 如果需要设置Wireshark的配置，可以在主菜单中选择Preferences，然后就可以看到对应的配置框，如下图所示： Wireshark的配置项主要包含如下几部分内容。 Apperance（外观） 此处的配置主要用于决定Wireshark中数据的显示方式。 你可以根据个人的喜好对大多数配置进行调整，例如窗口布局、滚动条的位置、字体、前景色和背景色等。 Capture（捕获） 此处的配置可以让你对自己捕获的数据包的方式进行特殊的设定，比如你的默认设备、是否默认使用混杂模式、是否实时更新Packet List面板等。 Filter Expressions（过滤器表达式） 此处的配置可以让你生成和管理你自己的过滤器。 Name Resolutions（名称解析） 通过这些设定，你可以开启Wireshark将地址解析成为一些更容易分辨和理解的别名。 并且，你还可以设定并发处理名称解析请求的最大数目。 Protocols（协议） 这一部分中的选项可以让你调整关于捕捉和显示各种Wireshark解码数据包的功能。 虽然并不是针对每一个协议都可以进行调整，但是大部分协议的选项都可以进行更改。 不过，通过经验来看，最好让他们保持默认值就行。 Statistics（统计） 这一部分提供了Wireshark中统计功能的相关配置选项，后续会进行深入的学习。 Advanced（高级） 除了上述配置之外的其他配置会会放在Advanced中进行配置。 不过这些配置一般只有Wireshark的高级用户才能去修改。 数据包彩色高亮 在Wireshark的Packet List面板中，针对不同的数据包显示的颜色各不相同。 不过这些数据包的颜色并不是随机分配的，而是大有讲究的。 这些数据包根据协议的不同而对应着不同的颜色。 例如，所有的DNS流量都是蓝色的，而HTTP流量的颜色都是绿色的。 通过不同的颜色可以快速将不同协议的数据包快速分开，而不需要依次查看每个数据包的具体协议， 这样可以大量节省时间。 如下图所示，Wireshark通过Coloring Rules窗口（View菜单下）可以轻松查看每个协议对应的颜色。 同时，你还可以创建属于你自己的着色规则或修改已有的规则。 例如，通过如下步骤，我们可以将HTTP流量的颜色由绿色改成淡紫色。 打开Wireshark，打开Coloring Rules窗口。（View -> Coloring Rules） 找出HTTP着色规则并单击选中 单击Foreground或者Background修改前景色或背景色 修改完成后单击OK保存即可。 配置文件 当我们想要修改配置时，知道Wireshark的配置文件存储位置对于我们的理解是很有帮助的。 想要找到该文件，可以在下拉菜单中单击Help并找出About Wireshark，然后单击Folder标签卡。 如下图所示： Wireshark的个性化设置中最重要的两个位置是个人和全局设置目录。 全局设置包含着所有的默认配置选项。 个人设置目录中只包含了针对你的账户的配置。任何你做的相关配置都使用你的账户存储在个人配置文件夹下。 配色方案 学习了Wireshark的参数配置后，有时你会发现你想要在不同场景使用不同的配置。 这时，Wireshark提供了一种个性化配置方案，可以让用户保存一组配置。 一个配置方案种存储了下面的配置信息： 参数选项 捕获过滤器 显示过滤器 着色规则 禁用协议 强制解码 最近的配置，例如窗口大小、菜单设置和列宽 协议自定义信息头 我们可以在主菜单下单击EDIT，选择Configuration Profiles选项。 此时，你就可以看到Wireshark的预设配置方案，例如默认、蓝牙、经典等。 在配置方案窗口页面种，你可以创建、复制、删除和应用配置方案。 Ps: 针对每一个配置方案，都是单独存储在一个目录种的，这也就意味着你可以快速的备份配置方案和共享给他人。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"tools/Wireshark/practice.html":{"url":"tools/Wireshark/practice.html","title":"Wireshark上手使用","keywords":"","body":"Wireshark上手使用 文件的导入与导出 Wireshark支持将数据包捕获下来进行保存，同时还支持导入之前保存的结果进行分析。 导入和导出捕获文件 导出捕获的数据包非常简单，只需要点击File -> Save as，然后可以打开对话框。 输入想要保存的文件位置即可。 默认的文件格式是.pcapng。 合并捕获文件 有时，我们需要将多个捕获文件合并成为一个文件。 只需要选择File -> Merge，这时会查询Merge With Capture File的对话框，然后即可选择对应的文件列表进行合并。 时间格式设定 Wireshark所捕获的每一个数据包都会有赋予一个时间戳。 Wireshark可以显示这个数据被捕获的绝对时间戳或者是与上一个捕获数据包的相对时间戳。 与时间显示相关的选项可以在主菜单的View菜单中找到，如下图所示： 设置捕获选项 在使用Wireshark进行数据捕获时，有相关的捕获选项可以配置。 想要查看这些选项，只需要选择Capture -> Options即可。 该页面包含三个标签页，分别是输入、输出和选项。 输入标签页 在输入标签页种，可以显示所有抓包的影响接口和有关这些接口的基本信息。如下图所示： 此时，还可以根据接口的捕获过滤器来过滤哪些包希望被抓取。 输出标签页 与之前我们所讲的先抓流量再存文件的方式不同，输出标签页中我们可以直接把抓的流量包存成一个文件。 选项标签页 在选项标签页面中，包含着一些其他的抓包配置，包含显示选项、解析名称和自动停止捕获等，如下图所示： By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"tools/Wireshark/capture_filter.html":{"url":"tools/Wireshark/capture_filter.html","title":"Wireshark捕获过滤器","keywords":"","body":"Wireshark捕获过滤器 概述 在Wireshark中包含了两种不同的过滤器： 捕获过滤器 显示过滤器 其中，两种过滤器是功能和使用场景各不一致。下面来依次进行对比。 过滤器类别 目的 功能强大性 捕获过滤器 减少抓取报文体积 使用BPF语法，功能相对有限 显示过滤器 对已抓取的报文过滤显示 功能强大 BPF过滤器 BPF过滤器全称是Berkeley Packet Filter。常用于在设备驱动级别提供抓包过滤结果，大部分抓包工具都支持此语法。 BPF过滤器支持expression表达式，在表达式中可以由多个原语组成。 下面，我们来依次讲解 原语，原语运算符 等含义。 原语：是由名称或数字以及描述它的多个限定词组成的，例如：Type、Dir、Proto等限定词。 原语运算符：原语运算符包含与（&&/and）、或（||/or）、非（!/not）组成。 一个简单的BPF过滤器表达式如下： src or dst portrange 6000-8000 && tcp or ip6 限定词 下面，我们来依次讲解几类常用的限定词。 Type：设置数字或者名称所指示类型 host：指定IP net：指定端口 port：指定子网，例如net 192.168.0.0 mask 255.255.255.0 或者 net 192.168.0.0/24 portrange：指定端口范围，例如portrange 6000-8000 设置网络出入方向 src、dst、src or dst、src and dst ra、ta、addr1、addr2、addr3、addr4 Proto指定协议类型 例如：ether、fddi、tr、wlan、ip、ip6、arp、rarp、decnet、 tcp、udp、icmp、igmp、igrp、pim、ah、esp、vrrp。 其他 gateway：指定网关IP地址 broadcast：广播报文 multicast：多播报文 less, greater：小于或者大于 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"tools/Wireshark/show_filter.html":{"url":"tools/Wireshark/show_filter.html","title":"Wireshark显示过滤器","keywords":"","body":"Wireshark显示过滤器 概述 上一节中，我们已经了解了什么是捕获过滤器，而接下来，我们将会继续学习显示过滤器。 显示过滤器的功能比捕获过滤器的功能要更加强大，任何在报文细节面板中解析得到的字段名称都可以作为过滤属性。 但是需要注意的是，报文细节面板中得到的字段名称与过滤属性中的字段名称并不一致。 而是在 View -> Internals -> Supported Protocols可以找到对应字段名称的属性名称。 例如，在TCP的报文细节面板中，我们可以看到一个Source Port字段。 我们可以在Supported Protocol中进行搜索即可： 显示过滤器比较符号 英文 符号 示例 eq|==|ip.src == 1.1.1.1 ne|!=|ip.src != 1.1.1.1 gt|>|frame.len > 10 lt|=|frame.len >= 10 le| 显示过滤器数据类型 无符号整型 有符号整型 布尔值 -或者.分隔的6字节地址，例如eth.dst这样的Mac地址 IPv4地址 IPv6地址 文本字符串 多个表达式之间的组合 英文 符号 and|&& or| xor|^^ not|! [...]| in| 其他常用操作符 大括号操作符：例如tcp.port in {443 4430..4434} 中括号[]Slice操作符：例如 [n:m]表示n是起始偏移量，m是长度 [n-m]表示n是起始偏移量，m是截止偏移量 [:m]从开始处到m截止偏移量 [m:]从m起始偏移量到结尾字段 [m]偏移量m处的字节 [,]使用,逗号分隔时，允许以上方式同时出现 支持的函数 upper lower len count string 显示过滤器对话框 除了自己从头开始输入显示过滤器表达式外，我们还可以借助显示过滤器可视化对话框来进行输入。 这样，我们就可以不需要记住所有的关键词、数据类型和比较符号了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"tools/proxy/beginning.html":{"url":"tools/proxy/beginning.html","title":"国内快速下载github等国外资源秘籍","keywords":"","body":"国内快速下载github等国外资源秘籍 作为一个国内程序员，相信你一定遇到过从 Github 上拉取代码是10kb每秒的窘境吧。 同样，可能你也会遇到过某些google软件/镜像等无法拉取下载等一系列问题。 今天我们就来分享一个小窍门，从而能快速的解决这一问题。 云服务 云现在已经是一个炙手可热的概念了。 国外有Amazon，Azure等云厂商，国内有阿里云、腾讯云、百度云等。 通过各个厂家的公有云服务，我们可以快速的购买虚拟机等资源，文件存储等服务。 而为了能够从 Github、Google 等国外站点快速地下载资源，我们可以通过购买云服务厂商的香港资源的虚拟机进行文件下载，再上传到公有云的文件存储服务上，再从本地就可以飞速的下载了。 在本文中，我们以腾讯云为例进行讲解。 Ps: 该方案需要一点的经费花销。 云服务器快速入门 首先，进入腾讯云 注册并登录。 进入控制台后，选择云服务器，可以看到你的云服务列表： 点击新建按钮创建一台香港机房的云服务器: 需要注意的有以下几点： 切换Tab页选择为自定义配置 计费模式选择为按量计费（我们每次下载很快，为了不浪费，我们可以选择随时用随时申请） 地域选择香港 操作系统推荐选择Ubuntu 18.04 然后点击下一步进入设置主机页面： 在设置主机页面，需要注意的是可以将登录方式设置为设置密码，然后根据自己的需要设置即可。 最后点击下一步确认配置信息并创建即可。 创建完成后，你就能重新回到实例列表页，稍等一两分钟后，云服务器就能创建成功了，点击登录按钮，可以直接从web页面登录云服务器。 对象存储入门 对象存储是是一种面向文件存储的系统，非常适合于文件持久化的存储。 腾讯云的对象存储产品也叫 COS 。 使用对象存储时，首先需要进入存储桶列表。 然后创建一个 bucket 。 其中，Bucket的所属地域需要与云服务器一致，即选择香港。 搭建Python SDK环境 进入bucket详情页面后，我们可以看到buckets中的文件列表。 同时，也可以从web页面进行文件管理等操作。 但是，由于Web页面只能上传本地问题，而我们需要从云服务器中上传文件，因此，我们需要通过COS的SDK来进行文件上传。 首先，需要登录我们刚才购买的云服务器。 接下来，我们需要安装python的包管理工具pip。 sudo apt install python-pip 然后使用pip来安装COS的Python的SDK: pip install -U cos-python-sdk-v5 此时，Python的SDK环境就已经搭建完成了。 一个示例的Python SDK上传文件的demo如下，创建一个put_file.py文件： # -*- coding=utf-8 -*- import sys import logging from qcloud_cos import CosConfig from qcloud_cos import CosS3Client logging.basicConfig(level=logging.INFO, stream=sys.stdout) # 1. 设置用户配置, 包括 secretId，secretKey 以及 Region file_name = sys.argv[1] bucket_name = sys.argv[2] secret_id = 'xxxxxxxxxxxxxxxxxxxx' # 替换为用户的 secretId secret_key = 'xxxxxxxxxxxxxxxxxxx' # 替换为用户的 secretKey region = 'ap-hongkong' # COS的Region token = None # 使用临时密钥需要传入 Token，默认为空，可不填 scheme = 'https' # 指定使用 http/https 协议来访问 COS，默认为 https，可不填 config = CosConfig(Region=region, SecretId=secret_id, SecretKey=secret_key, Token=token, Scheme=scheme) # 2. 获取客户端对象 client = CosS3Client(config) # 3. 上传文件 with open(file_name, 'rb') as fp: response = client.put_object( Bucket=bucket_name, Body=fp, Key=file_name, StorageClass='STANDARD', EnableMD5=False ) print(response['ETag']) 在该脚本中，需要修改对应的secret_id 和 secret_key，他们对应着腾讯云的账号信息。 查询地址如下： https://console.cloud.tencent.com/cam/capi 同时，上述脚本支持两个参数，分别是上传的文件名称以及Bucket的名称。 例如： python put_file.py demo.txt xianggang-1253296108 上述命令表示将本地的demo.txt文件上传到xianggang-1253296108 bucket中。 输出结果如下： 此时，刷新Bucket详情页面，你应该已经可以看到文件已经正常上传至COS中了。 我们已经可以用本地浏览器直接从Web的COS页面中进行飞速下载了。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"test/interface/beginning.html":{"url":"test/interface/beginning.html","title":"接口自动化测试","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"test/interface/json_schema.html":{"url":"test/interface/json_schema.html","title":"JSONSchema在接口测试中的应用","keywords":"","body":"JSON Schema在接口测试中的应用 JSON Schema简介 JSON Schema初探 下面，我们将会以Python3为例，演示如何使用JSON Schema来帮助我们进行用例结构断言。 第一步，我们首先需要安装第三方库 jsonschema: pip install jsonschema 接下来，我们可以看一个JSON Schema校验的例子: from jsonschema import validate schema = { \"type\" : \"object\", \"properties\" : { \"price\" : {\"type\" : \"number\"}, \"name\" : {\"type\" : \"string\"} } } validate(instance={\"name\" : \"Eggs\", \"price\" : 34.99}, schema=schema) validate(instance={\"name\" : \"Eggs\", \"price\" : \"Invalid\"}, schema=schema) 可以看到，对于第一个validate函数，执行时没有任何异常。 而对于第二个validate函数，执行时会抛出异常，即price字段期望是number类型，但是目前是string类型。 JSON Schema Generator部署与使用 JSON Schema高级用法 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"person/open_source/beginning.html":{"url":"person/open_source/beginning.html","title":"开源项目","keywords":"","body":" By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "},"person/open_source/learn.html":{"url":"person/open_source/learn.html","title":"如何高效的学习开源项目","keywords":"","body":"如何高效的学习开源项目 对于一个对痴迷技术的人而言，学习开源项目是提升技术能力的最好的方式之一。 但是一个开源的项目往往非常的庞大和复杂，这会儿造成我们往往不从下手，还没入门就直接放弃了。 那么，我们应该怎么样来高效的学习开源项目呢？ 怎么看待开源项目？ 得益于开源运动的蓬勃发展，众多技术顶尖的公司、团队或者个人通过开源的方式向技术社区贡献了许多优秀的开源项目，一方面大大促进了整体技术的发展，另一方面大大减轻了中小公司和团队在技术方面的投入压力，让团队能够更加聚焦于业务。 开源项目对团队和业务有很大好处，但对于技术人员来说，如果只是简单的采取“拿来主义”，那就变成一个陷阱：看似很快的用开源项目实现了需求，但自己的技术水平并没有什么提升；甚至可能出现看起来用了很多开源项目，知道很多项目名称，但技术水平止步不前的窘境。 因此，对于开源项目，不能简单的采取“拿来主义”，而要比较深入的去学习开源项目，做到“知其然，知其所以然”，一方面是为了更好地应用这些开源项目，另一方面也是为了通过学习优秀的开源项目来提升自己的能力。 对于开源项目，我们首先需要树立正确的观念： 不管你是什么身份，都可以从开源项目中学到很多东西。 不要只盯着数据结构和算法，事实上这两点在学习开源项目的时候并没有那么重要。 采取“自顶向下”的学习方法，源码不是第一步，而是最后一步。 “自顶向下”的学习方法和步骤 安装 很多人认为安装一个开源软件非常的简单。 但事实上，安装步骤远远不止这么简单，通过具体的安装过程，你可以获取到如下一些关键信息： 这个系统的依赖组件，而依赖的组件是系统设计和实现的基础。 安装目录也能够提供一些使用和运行的基本信息。 系统提供了哪些工具方便我们使用。 运行 安装完成后，我们需要真正将系统运行起来，运行系统的时候有两个地方要特别关注：命令行和配置文件。 它们主要提供了两个非常关键的信息：系统具备哪些能力和系统将会如何运行。 这些信息是我们窥视系统内部运行机制和原理的一扇窗口。 通常情况下，如果我们将每个命令行参数和配置项的作用和原理都全部掌握清楚了的话，基本上对系统已经很熟悉了。 一种学习方式就是先把所有的配置项全部研究一遍，包括配置项的原理、作用、影响，并且尝试去修改配置项然后看看系统会有什么变化。 例如，将 Memcache 的“–conn-limit”改为 1 后，查看多个连接请求时 Memecache 会返回什么错误、记录什么日志等。 原理研究 其实在研究命令行和配置项的时候已经涉及一部分原理了，但是还不系统，因此我们要专门针对原理进行系统性的研究。这里的关键就是“系统性”三个字，怎么才算系统性呢？ 主要体现在如下几个方面： 关键特性的基本实现原理。 优缺点对比分析：只有清楚掌握技术方案的优缺点后才算真正的掌握这门技术，也只有掌握了技术方案的优缺点后才能在架构设计的时候做出合理的选择。 那么，我们具体应该怎么进行系统性的学习呢？ 通读项目的设计文档。 阅读网上已有的分析文档。 Demo 验证。 测试 通常情况下，如果你真的准备在实际项目中使用某个开源项目的话，必须进行测试。 测试一定要在原理研究之后做，不能安装完成立马就测试！ 源码研究 源码研究的主要目的是学习原理背后的具体编码如何实现，通过学习这些技巧来提升我们自己的技术能力。 通常情况下，不建议通读所有源码，因为想掌握每行代码的含义和作用还是非常耗费时间的，尤其是 MySQL、Nginx 这种规模的项目，即使是他们的开发人员，都不一定每个人都掌握了所有代码。带着明确目的去研究源码，做到有的放矢，才能事半功倍，这也是源码研究要放在最后的原因。 对于一些基础库，除了阅读源码外，还可以自己写个 Demo 调用基础库完成一些简单的功能，然后通过调试来看具体的调用栈，通过调用栈来理解基础库的处理逻辑和过程，这比单纯看代码去理解逻辑要高效一些。 时间分配 前面介绍的“自顶向下”5 个步骤，完整执行下来需要花费较长时间，而时间又是大部分技术人员比较稀缺的资源。 通常情况下，以上 5 个步骤的前 3 个步骤，不管是已经成为架构师的技术人员，还是立志成为架构师的技术人员，在研究开源项目的时候都必不可少；第四步可以在准备采用开源项目的时候才实施，第五步可以根据你的时间来进行灵活安排。 By wangzhe0912，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2021-08-16 10:12:33 new Valine({el: \"#vcomments\",appId: '3tCbXut5BLzJCjGpdz0D3vPL-gzGzoHsz',appKey: 'DxRzz6qzatHku9sgCAgW73pe',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) "}}